| distributed init (rank 0): env://, gpu 0
| distributed init (rank 5): env://, gpu 5
| distributed init (rank 7): env://, gpu 7
| distributed init (rank 4): env://, gpu 4
| distributed init (rank 2): env://, gpu 2
| distributed init (rank 1): env://, gpu 1
| distributed init (rank 6): env://, gpu 6
| distributed init (rank 3): env://, gpu 3
Namespace(batch_size=128, epochs=300, update_freq=4, model='base', drop_path=0, input_size=224, layer_scale_init_value=1e-06, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, model_ema_eval=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=5.0, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=0.004, layer_decay=1.0, min_lr=1e-06, warmup_epochs=20, warmup_steps=-1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', crop_pct=None, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', head_init_scale=1.0, model_key='model|module', model_prefix='', data_path='/dev/shm/imagenet', eval_data_path=None, nb_classes=1000, imagenet_default_mean_and_std=True, data_set='IMNET', output_dir='./checkpoint_base_8.5G', log_dir=None, device='cuda', seed=0, resume='', auto_resume=True, save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, start_epoch=0, eval=False, dist_eval=True, disable_eval=False, num_workers=10, pin_mem=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', use_amp=True, enable_wandb=False, project='convnext', wandb_ckpt=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
Transform = 
RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic)
RandomHorizontalFlip(p=0.5)
RandAugment(n=2, ops=
	AugmentOp(name=AutoContrast, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Equalize, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Invert, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Rotate, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=PosterizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeAdd, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ColorIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ContrastIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=BrightnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SharpnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearX, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearY, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateXRel, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateYRel, p=0.5, m=9, mstd=0.5))
ToTensor()
Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))
RandomErasing(p=0.25, mode=pixel, count=(1, 1))
---------------------------
reading from datapath /dev/shm/imagenet
Number of the class = 1000
Transform = 
Resize(size=256, interpolation=bicubic, max_size=None, antialias=True)
CenterCrop(size=(224, 224))
ToTensor()
Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
---------------------------
reading from datapath /dev/shm/imagenet
Number of the class = 1000
Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f923ee95690>
Mixup is activated!
Model = SPCNN(
  (first_conv): ConvX(
    (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
  )
  (layer1): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): Identity()
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.010)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.020)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.030)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.040)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer2): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.050)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.060)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.070)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.080)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.090)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (5): BottleNeck(
      (drop_path): DropPath(drop_prob=0.100)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (6): BottleNeck(
      (drop_path): DropPath(drop_prob=0.110)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (7): BottleNeck(
      (drop_path): DropPath(drop_prob=0.120)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (8): BottleNeck(
      (drop_path): DropPath(drop_prob=0.130)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer3): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=768, bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.140)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.150)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.160)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.170)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.180)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (5): BottleNeck(
      (drop_path): DropPath(drop_prob=0.190)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (6): BottleNeck(
      (drop_path): DropPath(drop_prob=0.200)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (7): BottleNeck(
      (drop_path): DropPath(drop_prob=0.210)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (8): BottleNeck(
      (drop_path): DropPath(drop_prob=0.220)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (9): BottleNeck(
      (drop_path): DropPath(drop_prob=0.230)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (10): BottleNeck(
      (drop_path): DropPath(drop_prob=0.240)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (11): BottleNeck(
      (drop_path): DropPath(drop_prob=0.250)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (12): BottleNeck(
      (drop_path): DropPath(drop_prob=0.260)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (13): BottleNeck(
      (drop_path): DropPath(drop_prob=0.270)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (14): BottleNeck(
      (drop_path): DropPath(drop_prob=0.280)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (15): BottleNeck(
      (drop_path): DropPath(drop_prob=0.290)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (16): BottleNeck(
      (drop_path): DropPath(drop_prob=0.300)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer4): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1536, bias=False)
          (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.310)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.320)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.330)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.340)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.350)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (head): ConvX(
    (conv): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (classifier): MlpHead(
    (fc1): Linear(in_features=1024, out_features=2048, bias=False)
    (norm): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
    (drop): Dropout(p=0.2, inplace=False)
    (fc2): Linear(in_features=2048, out_features=1000, bias=False)
  )
)
number of params: 48903328
LR = 0.00400000
Batch size = 4096
Update frequent = 4
Number of training examples = 1281167
Number of training training per epoch = 312
Param groups = {
  "decay": {
    "weight_decay": 0.05,
    "params": [
      "first_conv.conv.weight",
      "layer1.0.mlp.0.conv.weight",
      "layer1.0.mlp.1.conv.weight",
      "layer1.0.mlp.2.conv.weight",
      "layer1.0.skip.0.conv.weight",
      "layer1.0.skip.1.conv.weight",
      "layer1.1.sblock_in.conv.weight",
      "layer1.1.sblock_dw.conv.weight",
      "layer1.1.sblock_proj.conv.weight",
      "layer1.1.mblock.0.conv.weight",
      "layer1.1.mblock.1.branch_1.1.conv.weight",
      "layer1.1.mblock.1.branch_2.1.conv.weight",
      "layer1.1.mblock.1.branch_3.1.conv.weight",
      "layer1.1.mblock.2.conv.weight",
      "layer1.2.sblock_in.conv.weight",
      "layer1.2.sblock_dw.conv.weight",
      "layer1.2.sblock_proj.conv.weight",
      "layer1.2.mblock.0.conv.weight",
      "layer1.2.mblock.1.branch_1.1.conv.weight",
      "layer1.2.mblock.1.branch_2.1.conv.weight",
      "layer1.2.mblock.1.branch_3.1.conv.weight",
      "layer1.2.mblock.2.conv.weight",
      "layer1.3.sblock_in.conv.weight",
      "layer1.3.sblock_dw.conv.weight",
      "layer1.3.sblock_proj.conv.weight",
      "layer1.3.mblock.0.conv.weight",
      "layer1.3.mblock.1.branch_1.1.conv.weight",
      "layer1.3.mblock.1.branch_2.1.conv.weight",
      "layer1.3.mblock.1.branch_3.1.conv.weight",
      "layer1.3.mblock.2.conv.weight",
      "layer1.4.sblock_in.conv.weight",
      "layer1.4.sblock_dw.conv.weight",
      "layer1.4.sblock_proj.conv.weight",
      "layer1.4.mblock.0.conv.weight",
      "layer1.4.mblock.1.branch_1.1.conv.weight",
      "layer1.4.mblock.1.branch_2.1.conv.weight",
      "layer1.4.mblock.1.branch_3.1.conv.weight",
      "layer1.4.mblock.2.conv.weight",
      "layer2.0.mlp.0.conv.weight",
      "layer2.0.mlp.1.conv.weight",
      "layer2.0.mlp.2.conv.weight",
      "layer2.0.skip.0.conv.weight",
      "layer2.0.skip.1.conv.weight",
      "layer2.1.sblock_in.conv.weight",
      "layer2.1.sblock_dw.conv.weight",
      "layer2.1.sblock_proj.conv.weight",
      "layer2.1.mblock.0.conv.weight",
      "layer2.1.mblock.1.branch_1.1.conv.weight",
      "layer2.1.mblock.1.branch_2.1.conv.weight",
      "layer2.1.mblock.1.branch_3.1.conv.weight",
      "layer2.1.mblock.2.conv.weight",
      "layer2.2.sblock_in.conv.weight",
      "layer2.2.sblock_dw.conv.weight",
      "layer2.2.sblock_proj.conv.weight",
      "layer2.2.mblock.0.conv.weight",
      "layer2.2.mblock.1.branch_1.1.conv.weight",
      "layer2.2.mblock.1.branch_2.1.conv.weight",
      "layer2.2.mblock.1.branch_3.1.conv.weight",
      "layer2.2.mblock.2.conv.weight",
      "layer2.3.sblock_in.conv.weight",
      "layer2.3.sblock_dw.conv.weight",
      "layer2.3.sblock_proj.conv.weight",
      "layer2.3.mblock.0.conv.weight",
      "layer2.3.mblock.1.branch_1.1.conv.weight",
      "layer2.3.mblock.1.branch_2.1.conv.weight",
      "layer2.3.mblock.1.branch_3.1.conv.weight",
      "layer2.3.mblock.2.conv.weight",
      "layer2.4.sblock_in.conv.weight",
      "layer2.4.sblock_dw.conv.weight",
      "layer2.4.sblock_proj.conv.weight",
      "layer2.4.mblock.0.conv.weight",
      "layer2.4.mblock.1.branch_1.1.conv.weight",
      "layer2.4.mblock.1.branch_2.1.conv.weight",
      "layer2.4.mblock.1.branch_3.1.conv.weight",
      "layer2.4.mblock.2.conv.weight",
      "layer2.5.sblock_in.conv.weight",
      "layer2.5.sblock_dw.conv.weight",
      "layer2.5.sblock_proj.conv.weight",
      "layer2.5.mblock.0.conv.weight",
      "layer2.5.mblock.1.branch_1.1.conv.weight",
      "layer2.5.mblock.1.branch_2.1.conv.weight",
      "layer2.5.mblock.1.branch_3.1.conv.weight",
      "layer2.5.mblock.2.conv.weight",
      "layer2.6.sblock_in.conv.weight",
      "layer2.6.sblock_dw.conv.weight",
      "layer2.6.sblock_proj.conv.weight",
      "layer2.6.mblock.0.conv.weight",
      "layer2.6.mblock.1.branch_1.1.conv.weight",
      "layer2.6.mblock.1.branch_2.1.conv.weight",
      "layer2.6.mblock.1.branch_3.1.conv.weight",
      "layer2.6.mblock.2.conv.weight",
      "layer2.7.sblock_in.conv.weight",
      "layer2.7.sblock_dw.conv.weight",
      "layer2.7.sblock_proj.conv.weight",
      "layer2.7.mblock.0.conv.weight",
      "layer2.7.mblock.1.branch_1.1.conv.weight",
      "layer2.7.mblock.1.branch_2.1.conv.weight",
      "layer2.7.mblock.1.branch_3.1.conv.weight",
      "layer2.7.mblock.2.conv.weight",
      "layer2.8.sblock_in.conv.weight",
      "layer2.8.sblock_dw.conv.weight",
      "layer2.8.sblock_proj.conv.weight",
      "layer2.8.mblock.0.conv.weight",
      "layer2.8.mblock.1.branch_1.1.conv.weight",
      "layer2.8.mblock.1.branch_2.1.conv.weight",
      "layer2.8.mblock.1.branch_3.1.conv.weight",
      "layer2.8.mblock.2.conv.weight",
      "layer3.0.mlp.0.conv.weight",
      "layer3.0.mlp.1.conv.weight",
      "layer3.0.mlp.2.conv.weight",
      "layer3.0.skip.0.conv.weight",
      "layer3.0.skip.1.conv.weight",
      "layer3.1.sblock_in.conv.weight",
      "layer3.1.sblock_dw.conv.weight",
      "layer3.1.sblock_proj.conv.weight",
      "layer3.1.mblock.0.conv.weight",
      "layer3.1.mblock.1.branch_1.1.conv.weight",
      "layer3.1.mblock.1.branch_2.1.conv.weight",
      "layer3.1.mblock.1.branch_3.1.conv.weight",
      "layer3.1.mblock.2.conv.weight",
      "layer3.2.sblock_in.conv.weight",
      "layer3.2.sblock_dw.conv.weight",
      "layer3.2.sblock_proj.conv.weight",
      "layer3.2.mblock.0.conv.weight",
      "layer3.2.mblock.1.branch_1.1.conv.weight",
      "layer3.2.mblock.1.branch_2.1.conv.weight",
      "layer3.2.mblock.1.branch_3.1.conv.weight",
      "layer3.2.mblock.2.conv.weight",
      "layer3.3.sblock_in.conv.weight",
      "layer3.3.sblock_dw.conv.weight",
      "layer3.3.sblock_proj.conv.weight",
      "layer3.3.mblock.0.conv.weight",
      "layer3.3.mblock.1.branch_1.1.conv.weight",
      "layer3.3.mblock.1.branch_2.1.conv.weight",
      "layer3.3.mblock.1.branch_3.1.conv.weight",
      "layer3.3.mblock.2.conv.weight",
      "layer3.4.sblock_in.conv.weight",
      "layer3.4.sblock_dw.conv.weight",
      "layer3.4.sblock_proj.conv.weight",
      "layer3.4.mblock.0.conv.weight",
      "layer3.4.mblock.1.branch_1.1.conv.weight",
      "layer3.4.mblock.1.branch_2.1.conv.weight",
      "layer3.4.mblock.1.branch_3.1.conv.weight",
      "layer3.4.mblock.2.conv.weight",
      "layer3.5.sblock_in.conv.weight",
      "layer3.5.sblock_dw.conv.weight",
      "layer3.5.sblock_proj.conv.weight",
      "layer3.5.mblock.0.conv.weight",
      "layer3.5.mblock.1.branch_1.1.conv.weight",
      "layer3.5.mblock.1.branch_2.1.conv.weight",
      "layer3.5.mblock.1.branch_3.1.conv.weight",
      "layer3.5.mblock.2.conv.weight",
      "layer3.6.sblock_in.conv.weight",
      "layer3.6.sblock_dw.conv.weight",
      "layer3.6.sblock_proj.conv.weight",
      "layer3.6.mblock.0.conv.weight",
      "layer3.6.mblock.1.branch_1.1.conv.weight",
      "layer3.6.mblock.1.branch_2.1.conv.weight",
      "layer3.6.mblock.1.branch_3.1.conv.weight",
      "layer3.6.mblock.2.conv.weight",
      "layer3.7.sblock_in.conv.weight",
      "layer3.7.sblock_dw.conv.weight",
      "layer3.7.sblock_proj.conv.weight",
      "layer3.7.mblock.0.conv.weight",
      "layer3.7.mblock.1.branch_1.1.conv.weight",
      "layer3.7.mblock.1.branch_2.1.conv.weight",
      "layer3.7.mblock.1.branch_3.1.conv.weight",
      "layer3.7.mblock.2.conv.weight",
      "layer3.8.sblock_in.conv.weight",
      "layer3.8.sblock_dw.conv.weight",
      "layer3.8.sblock_proj.conv.weight",
      "layer3.8.mblock.0.conv.weight",
      "layer3.8.mblock.1.branch_1.1.conv.weight",
      "layer3.8.mblock.1.branch_2.1.conv.weight",
      "layer3.8.mblock.1.branch_3.1.conv.weight",
      "layer3.8.mblock.2.conv.weight",
      "layer3.9.sblock_in.conv.weight",
      "layer3.9.sblock_dw.conv.weight",
      "layer3.9.sblock_proj.conv.weight",
      "layer3.9.mblock.0.conv.weight",
      "layer3.9.mblock.1.branch_1.1.conv.weight",
      "layer3.9.mblock.1.branch_2.1.conv.weight",
      "layer3.9.mblock.1.branch_3.1.conv.weight",
      "layer3.9.mblock.2.conv.weight",
      "layer3.10.sblock_in.conv.weight",
      "layer3.10.sblock_dw.conv.weight",
      "layer3.10.sblock_proj.conv.weight",
      "layer3.10.mblock.0.conv.weight",
      "layer3.10.mblock.1.branch_1.1.conv.weight",
      "layer3.10.mblock.1.branch_2.1.conv.weight",
      "layer3.10.mblock.1.branch_3.1.conv.weight",
      "layer3.10.mblock.2.conv.weight",
      "layer3.11.sblock_in.conv.weight",
      "layer3.11.sblock_dw.conv.weight",
      "layer3.11.sblock_proj.conv.weight",
      "layer3.11.mblock.0.conv.weight",
      "layer3.11.mblock.1.branch_1.1.conv.weight",
      "layer3.11.mblock.1.branch_2.1.conv.weight",
      "layer3.11.mblock.1.branch_3.1.conv.weight",
      "layer3.11.mblock.2.conv.weight",
      "layer3.12.sblock_in.conv.weight",
      "layer3.12.sblock_dw.conv.weight",
      "layer3.12.sblock_proj.conv.weight",
      "layer3.12.mblock.0.conv.weight",
      "layer3.12.mblock.1.branch_1.1.conv.weight",
      "layer3.12.mblock.1.branch_2.1.conv.weight",
      "layer3.12.mblock.1.branch_3.1.conv.weight",
      "layer3.12.mblock.2.conv.weight",
      "layer3.13.sblock_in.conv.weight",
      "layer3.13.sblock_dw.conv.weight",
      "layer3.13.sblock_proj.conv.weight",
      "layer3.13.mblock.0.conv.weight",
      "layer3.13.mblock.1.branch_1.1.conv.weight",
      "layer3.13.mblock.1.branch_2.1.conv.weight",
      "layer3.13.mblock.1.branch_3.1.conv.weight",
      "layer3.13.mblock.2.conv.weight",
      "layer3.14.sblock_in.conv.weight",
      "layer3.14.sblock_dw.conv.weight",
      "layer3.14.sblock_proj.conv.weight",
      "layer3.14.mblock.0.conv.weight",
      "layer3.14.mblock.1.branch_1.1.conv.weight",
      "layer3.14.mblock.1.branch_2.1.conv.weight",
      "layer3.14.mblock.1.branch_3.1.conv.weight",
      "layer3.14.mblock.2.conv.weight",
      "layer3.15.sblock_in.conv.weight",
      "layer3.15.sblock_dw.conv.weight",
      "layer3.15.sblock_proj.conv.weight",
      "layer3.15.mblock.0.conv.weight",
      "layer3.15.mblock.1.branch_1.1.conv.weight",
      "layer3.15.mblock.1.branch_2.1.conv.weight",
      "layer3.15.mblock.1.branch_3.1.conv.weight",
      "layer3.15.mblock.2.conv.weight",
      "layer3.16.sblock_in.conv.weight",
      "layer3.16.sblock_dw.conv.weight",
      "layer3.16.sblock_proj.conv.weight",
      "layer3.16.mblock.0.conv.weight",
      "layer3.16.mblock.1.branch_1.1.conv.weight",
      "layer3.16.mblock.1.branch_2.1.conv.weight",
      "layer3.16.mblock.1.branch_3.1.conv.weight",
      "layer3.16.mblock.2.conv.weight",
      "layer4.0.mlp.0.conv.weight",
      "layer4.0.mlp.1.conv.weight",
      "layer4.0.mlp.2.conv.weight",
      "layer4.0.skip.0.conv.weight",
      "layer4.0.skip.1.conv.weight",
      "layer4.1.sblock_in.conv.weight",
      "layer4.1.sblock_dw.conv.weight",
      "layer4.1.sblock_proj.conv.weight",
      "layer4.1.mblock.0.conv.weight",
      "layer4.1.mblock.1.branch_1.1.conv.weight",
      "layer4.1.mblock.1.branch_2.1.conv.weight",
      "layer4.1.mblock.1.branch_3.1.conv.weight",
      "layer4.1.mblock.2.conv.weight",
      "layer4.2.sblock_in.conv.weight",
      "layer4.2.sblock_dw.conv.weight",
      "layer4.2.sblock_proj.conv.weight",
      "layer4.2.mblock.0.conv.weight",
      "layer4.2.mblock.1.branch_1.1.conv.weight",
      "layer4.2.mblock.1.branch_2.1.conv.weight",
      "layer4.2.mblock.1.branch_3.1.conv.weight",
      "layer4.2.mblock.2.conv.weight",
      "layer4.3.sblock_in.conv.weight",
      "layer4.3.sblock_dw.conv.weight",
      "layer4.3.sblock_proj.conv.weight",
      "layer4.3.mblock.0.conv.weight",
      "layer4.3.mblock.1.branch_1.1.conv.weight",
      "layer4.3.mblock.1.branch_2.1.conv.weight",
      "layer4.3.mblock.1.branch_3.1.conv.weight",
      "layer4.3.mblock.2.conv.weight",
      "layer4.4.sblock_in.conv.weight",
      "layer4.4.sblock_dw.conv.weight",
      "layer4.4.sblock_proj.conv.weight",
      "layer4.4.mblock.0.conv.weight",
      "layer4.4.mblock.1.branch_1.1.conv.weight",
      "layer4.4.mblock.1.branch_2.1.conv.weight",
      "layer4.4.mblock.1.branch_3.1.conv.weight",
      "layer4.4.mblock.2.conv.weight",
      "head.conv.weight",
      "classifier.fc1.weight",
      "classifier.fc2.weight"
    ],
    "lr_scale": 1.0
  },
  "no_decay": {
    "weight_decay": 0.0,
    "params": [
      "first_conv.norm.weight",
      "first_conv.norm.bias",
      "layer1.0.mlp.0.norm.weight",
      "layer1.0.mlp.0.norm.bias",
      "layer1.0.mlp.1.norm.weight",
      "layer1.0.mlp.1.norm.bias",
      "layer1.0.mlp.2.norm.weight",
      "layer1.0.mlp.2.norm.bias",
      "layer1.0.skip.0.norm.weight",
      "layer1.0.skip.0.norm.bias",
      "layer1.0.skip.1.norm.weight",
      "layer1.0.skip.1.norm.bias",
      "layer1.1.sblock_in.norm.weight",
      "layer1.1.sblock_in.norm.bias",
      "layer1.1.sblock_dw.norm.weight",
      "layer1.1.sblock_dw.norm.bias",
      "layer1.1.sblock_proj.norm.weight",
      "layer1.1.sblock_proj.norm.bias",
      "layer1.1.mblock.0.norm.weight",
      "layer1.1.mblock.0.norm.bias",
      "layer1.1.mblock.1.branch_1.1.norm.weight",
      "layer1.1.mblock.1.branch_1.1.norm.bias",
      "layer1.1.mblock.1.branch_2.1.norm.weight",
      "layer1.1.mblock.1.branch_2.1.norm.bias",
      "layer1.1.mblock.1.branch_3.1.norm.weight",
      "layer1.1.mblock.1.branch_3.1.norm.bias",
      "layer1.1.mblock.2.norm.weight",
      "layer1.1.mblock.2.norm.bias",
      "layer1.2.sblock_in.norm.weight",
      "layer1.2.sblock_in.norm.bias",
      "layer1.2.sblock_dw.norm.weight",
      "layer1.2.sblock_dw.norm.bias",
      "layer1.2.sblock_proj.norm.weight",
      "layer1.2.sblock_proj.norm.bias",
      "layer1.2.mblock.0.norm.weight",
      "layer1.2.mblock.0.norm.bias",
      "layer1.2.mblock.1.branch_1.1.norm.weight",
      "layer1.2.mblock.1.branch_1.1.norm.bias",
      "layer1.2.mblock.1.branch_2.1.norm.weight",
      "layer1.2.mblock.1.branch_2.1.norm.bias",
      "layer1.2.mblock.1.branch_3.1.norm.weight",
      "layer1.2.mblock.1.branch_3.1.norm.bias",
      "layer1.2.mblock.2.norm.weight",
      "layer1.2.mblock.2.norm.bias",
      "layer1.3.sblock_in.norm.weight",
      "layer1.3.sblock_in.norm.bias",
      "layer1.3.sblock_dw.norm.weight",
      "layer1.3.sblock_dw.norm.bias",
      "layer1.3.sblock_proj.norm.weight",
      "layer1.3.sblock_proj.norm.bias",
      "layer1.3.mblock.0.norm.weight",
      "layer1.3.mblock.0.norm.bias",
      "layer1.3.mblock.1.branch_1.1.norm.weight",
      "layer1.3.mblock.1.branch_1.1.norm.bias",
      "layer1.3.mblock.1.branch_2.1.norm.weight",
      "layer1.3.mblock.1.branch_2.1.norm.bias",
      "layer1.3.mblock.1.branch_3.1.norm.weight",
      "layer1.3.mblock.1.branch_3.1.norm.bias",
      "layer1.3.mblock.2.norm.weight",
      "layer1.3.mblock.2.norm.bias",
      "layer1.4.sblock_in.norm.weight",
      "layer1.4.sblock_in.norm.bias",
      "layer1.4.sblock_dw.norm.weight",
      "layer1.4.sblock_dw.norm.bias",
      "layer1.4.sblock_proj.norm.weight",
      "layer1.4.sblock_proj.norm.bias",
      "layer1.4.mblock.0.norm.weight",
      "layer1.4.mblock.0.norm.bias",
      "layer1.4.mblock.1.branch_1.1.norm.weight",
      "layer1.4.mblock.1.branch_1.1.norm.bias",
      "layer1.4.mblock.1.branch_2.1.norm.weight",
      "layer1.4.mblock.1.branch_2.1.norm.bias",
      "layer1.4.mblock.1.branch_3.1.norm.weight",
      "layer1.4.mblock.1.branch_3.1.norm.bias",
      "layer1.4.mblock.2.norm.weight",
      "layer1.4.mblock.2.norm.bias",
      "layer2.0.mlp.0.norm.weight",
      "layer2.0.mlp.0.norm.bias",
      "layer2.0.mlp.1.norm.weight",
      "layer2.0.mlp.1.norm.bias",
      "layer2.0.mlp.2.norm.weight",
      "layer2.0.mlp.2.norm.bias",
      "layer2.0.skip.0.norm.weight",
      "layer2.0.skip.0.norm.bias",
      "layer2.0.skip.1.norm.weight",
      "layer2.0.skip.1.norm.bias",
      "layer2.1.sblock_in.norm.weight",
      "layer2.1.sblock_in.norm.bias",
      "layer2.1.sblock_dw.norm.weight",
      "layer2.1.sblock_dw.norm.bias",
      "layer2.1.sblock_proj.norm.weight",
      "layer2.1.sblock_proj.norm.bias",
      "layer2.1.mblock.0.norm.weight",
      "layer2.1.mblock.0.norm.bias",
      "layer2.1.mblock.1.branch_1.1.norm.weight",
      "layer2.1.mblock.1.branch_1.1.norm.bias",
      "layer2.1.mblock.1.branch_2.1.norm.weight",
      "layer2.1.mblock.1.branch_2.1.norm.bias",
      "layer2.1.mblock.1.branch_3.1.norm.weight",
      "layer2.1.mblock.1.branch_3.1.norm.bias",
      "layer2.1.mblock.2.norm.weight",
      "layer2.1.mblock.2.norm.bias",
      "layer2.2.sblock_in.norm.weight",
      "layer2.2.sblock_in.norm.bias",
      "layer2.2.sblock_dw.norm.weight",
      "layer2.2.sblock_dw.norm.bias",
      "layer2.2.sblock_proj.norm.weight",
      "layer2.2.sblock_proj.norm.bias",
      "layer2.2.mblock.0.norm.weight",
      "layer2.2.mblock.0.norm.bias",
      "layer2.2.mblock.1.branch_1.1.norm.weight",
      "layer2.2.mblock.1.branch_1.1.norm.bias",
      "layer2.2.mblock.1.branch_2.1.norm.weight",
      "layer2.2.mblock.1.branch_2.1.norm.bias",
      "layer2.2.mblock.1.branch_3.1.norm.weight",
      "layer2.2.mblock.1.branch_3.1.norm.bias",
      "layer2.2.mblock.2.norm.weight",
      "layer2.2.mblock.2.norm.bias",
      "layer2.3.sblock_in.norm.weight",
      "layer2.3.sblock_in.norm.bias",
      "layer2.3.sblock_dw.norm.weight",
      "layer2.3.sblock_dw.norm.bias",
      "layer2.3.sblock_proj.norm.weight",
      "layer2.3.sblock_proj.norm.bias",
      "layer2.3.mblock.0.norm.weight",
      "layer2.3.mblock.0.norm.bias",
      "layer2.3.mblock.1.branch_1.1.norm.weight",
      "layer2.3.mblock.1.branch_1.1.norm.bias",
      "layer2.3.mblock.1.branch_2.1.norm.weight",
      "layer2.3.mblock.1.branch_2.1.norm.bias",
      "layer2.3.mblock.1.branch_3.1.norm.weight",
      "layer2.3.mblock.1.branch_3.1.norm.bias",
      "layer2.3.mblock.2.norm.weight",
      "layer2.3.mblock.2.norm.bias",
      "layer2.4.sblock_in.norm.weight",
      "layer2.4.sblock_in.norm.bias",
      "layer2.4.sblock_dw.norm.weight",
      "layer2.4.sblock_dw.norm.bias",
      "layer2.4.sblock_proj.norm.weight",
      "layer2.4.sblock_proj.norm.bias",
      "layer2.4.mblock.0.norm.weight",
      "layer2.4.mblock.0.norm.bias",
      "layer2.4.mblock.1.branch_1.1.norm.weight",
      "layer2.4.mblock.1.branch_1.1.norm.bias",
      "layer2.4.mblock.1.branch_2.1.norm.weight",
      "layer2.4.mblock.1.branch_2.1.norm.bias",
      "layer2.4.mblock.1.branch_3.1.norm.weight",
      "layer2.4.mblock.1.branch_3.1.norm.bias",
      "layer2.4.mblock.2.norm.weight",
      "layer2.4.mblock.2.norm.bias",
      "layer2.5.sblock_in.norm.weight",
      "layer2.5.sblock_in.norm.bias",
      "layer2.5.sblock_dw.norm.weight",
      "layer2.5.sblock_dw.norm.bias",
      "layer2.5.sblock_proj.norm.weight",
      "layer2.5.sblock_proj.norm.bias",
      "layer2.5.mblock.0.norm.weight",
      "layer2.5.mblock.0.norm.bias",
      "layer2.5.mblock.1.branch_1.1.norm.weight",
      "layer2.5.mblock.1.branch_1.1.norm.bias",
      "layer2.5.mblock.1.branch_2.1.norm.weight",
      "layer2.5.mblock.1.branch_2.1.norm.bias",
      "layer2.5.mblock.1.branch_3.1.norm.weight",
      "layer2.5.mblock.1.branch_3.1.norm.bias",
      "layer2.5.mblock.2.norm.weight",
      "layer2.5.mblock.2.norm.bias",
      "layer2.6.sblock_in.norm.weight",
      "layer2.6.sblock_in.norm.bias",
      "layer2.6.sblock_dw.norm.weight",
      "layer2.6.sblock_dw.norm.bias",
      "layer2.6.sblock_proj.norm.weight",
      "layer2.6.sblock_proj.norm.bias",
      "layer2.6.mblock.0.norm.weight",
      "layer2.6.mblock.0.norm.bias",
      "layer2.6.mblock.1.branch_1.1.norm.weight",
      "layer2.6.mblock.1.branch_1.1.norm.bias",
      "layer2.6.mblock.1.branch_2.1.norm.weight",
      "layer2.6.mblock.1.branch_2.1.norm.bias",
      "layer2.6.mblock.1.branch_3.1.norm.weight",
      "layer2.6.mblock.1.branch_3.1.norm.bias",
      "layer2.6.mblock.2.norm.weight",
      "layer2.6.mblock.2.norm.bias",
      "layer2.7.sblock_in.norm.weight",
      "layer2.7.sblock_in.norm.bias",
      "layer2.7.sblock_dw.norm.weight",
      "layer2.7.sblock_dw.norm.bias",
      "layer2.7.sblock_proj.norm.weight",
      "layer2.7.sblock_proj.norm.bias",
      "layer2.7.mblock.0.norm.weight",
      "layer2.7.mblock.0.norm.bias",
      "layer2.7.mblock.1.branch_1.1.norm.weight",
      "layer2.7.mblock.1.branch_1.1.norm.bias",
      "layer2.7.mblock.1.branch_2.1.norm.weight",
      "layer2.7.mblock.1.branch_2.1.norm.bias",
      "layer2.7.mblock.1.branch_3.1.norm.weight",
      "layer2.7.mblock.1.branch_3.1.norm.bias",
      "layer2.7.mblock.2.norm.weight",
      "layer2.7.mblock.2.norm.bias",
      "layer2.8.sblock_in.norm.weight",
      "layer2.8.sblock_in.norm.bias",
      "layer2.8.sblock_dw.norm.weight",
      "layer2.8.sblock_dw.norm.bias",
      "layer2.8.sblock_proj.norm.weight",
      "layer2.8.sblock_proj.norm.bias",
      "layer2.8.mblock.0.norm.weight",
      "layer2.8.mblock.0.norm.bias",
      "layer2.8.mblock.1.branch_1.1.norm.weight",
      "layer2.8.mblock.1.branch_1.1.norm.bias",
      "layer2.8.mblock.1.branch_2.1.norm.weight",
      "layer2.8.mblock.1.branch_2.1.norm.bias",
      "layer2.8.mblock.1.branch_3.1.norm.weight",
      "layer2.8.mblock.1.branch_3.1.norm.bias",
      "layer2.8.mblock.2.norm.weight",
      "layer2.8.mblock.2.norm.bias",
      "layer3.0.mlp.0.norm.weight",
      "layer3.0.mlp.0.norm.bias",
      "layer3.0.mlp.1.norm.weight",
      "layer3.0.mlp.1.norm.bias",
      "layer3.0.mlp.2.norm.weight",
      "layer3.0.mlp.2.norm.bias",
      "layer3.0.skip.0.norm.weight",
      "layer3.0.skip.0.norm.bias",
      "layer3.0.skip.1.norm.weight",
      "layer3.0.skip.1.norm.bias",
      "layer3.1.sblock_in.norm.weight",
      "layer3.1.sblock_in.norm.bias",
      "layer3.1.sblock_dw.norm.weight",
      "layer3.1.sblock_dw.norm.bias",
      "layer3.1.sblock_proj.norm.weight",
      "layer3.1.sblock_proj.norm.bias",
      "layer3.1.mblock.0.norm.weight",
      "layer3.1.mblock.0.norm.bias",
      "layer3.1.mblock.1.branch_1.1.norm.weight",
      "layer3.1.mblock.1.branch_1.1.norm.bias",
      "layer3.1.mblock.1.branch_2.1.norm.weight",
      "layer3.1.mblock.1.branch_2.1.norm.bias",
      "layer3.1.mblock.1.branch_3.1.norm.weight",
      "layer3.1.mblock.1.branch_3.1.norm.bias",
      "layer3.1.mblock.2.norm.weight",
      "layer3.1.mblock.2.norm.bias",
      "layer3.2.sblock_in.norm.weight",
      "layer3.2.sblock_in.norm.bias",
      "layer3.2.sblock_dw.norm.weight",
      "layer3.2.sblock_dw.norm.bias",
      "layer3.2.sblock_proj.norm.weight",
      "layer3.2.sblock_proj.norm.bias",
      "layer3.2.mblock.0.norm.weight",
      "layer3.2.mblock.0.norm.bias",
      "layer3.2.mblock.1.branch_1.1.norm.weight",
      "layer3.2.mblock.1.branch_1.1.norm.bias",
      "layer3.2.mblock.1.branch_2.1.norm.weight",
      "layer3.2.mblock.1.branch_2.1.norm.bias",
      "layer3.2.mblock.1.branch_3.1.norm.weight",
      "layer3.2.mblock.1.branch_3.1.norm.bias",
      "layer3.2.mblock.2.norm.weight",
      "layer3.2.mblock.2.norm.bias",
      "layer3.3.sblock_in.norm.weight",
      "layer3.3.sblock_in.norm.bias",
      "layer3.3.sblock_dw.norm.weight",
      "layer3.3.sblock_dw.norm.bias",
      "layer3.3.sblock_proj.norm.weight",
      "layer3.3.sblock_proj.norm.bias",
      "layer3.3.mblock.0.norm.weight",
      "layer3.3.mblock.0.norm.bias",
      "layer3.3.mblock.1.branch_1.1.norm.weight",
      "layer3.3.mblock.1.branch_1.1.norm.bias",
      "layer3.3.mblock.1.branch_2.1.norm.weight",
      "layer3.3.mblock.1.branch_2.1.norm.bias",
      "layer3.3.mblock.1.branch_3.1.norm.weight",
      "layer3.3.mblock.1.branch_3.1.norm.bias",
      "layer3.3.mblock.2.norm.weight",
      "layer3.3.mblock.2.norm.bias",
      "layer3.4.sblock_in.norm.weight",
      "layer3.4.sblock_in.norm.bias",
      "layer3.4.sblock_dw.norm.weight",
      "layer3.4.sblock_dw.norm.bias",
      "layer3.4.sblock_proj.norm.weight",
      "layer3.4.sblock_proj.norm.bias",
      "layer3.4.mblock.0.norm.weight",
      "layer3.4.mblock.0.norm.bias",
      "layer3.4.mblock.1.branch_1.1.norm.weight",
      "layer3.4.mblock.1.branch_1.1.norm.bias",
      "layer3.4.mblock.1.branch_2.1.norm.weight",
      "layer3.4.mblock.1.branch_2.1.norm.bias",
      "layer3.4.mblock.1.branch_3.1.norm.weight",
      "layer3.4.mblock.1.branch_3.1.norm.bias",
      "layer3.4.mblock.2.norm.weight",
      "layer3.4.mblock.2.norm.bias",
      "layer3.5.sblock_in.norm.weight",
      "layer3.5.sblock_in.norm.bias",
      "layer3.5.sblock_dw.norm.weight",
      "layer3.5.sblock_dw.norm.bias",
      "layer3.5.sblock_proj.norm.weight",
      "layer3.5.sblock_proj.norm.bias",
      "layer3.5.mblock.0.norm.weight",
      "layer3.5.mblock.0.norm.bias",
      "layer3.5.mblock.1.branch_1.1.norm.weight",
      "layer3.5.mblock.1.branch_1.1.norm.bias",
      "layer3.5.mblock.1.branch_2.1.norm.weight",
      "layer3.5.mblock.1.branch_2.1.norm.bias",
      "layer3.5.mblock.1.branch_3.1.norm.weight",
      "layer3.5.mblock.1.branch_3.1.norm.bias",
      "layer3.5.mblock.2.norm.weight",
      "layer3.5.mblock.2.norm.bias",
      "layer3.6.sblock_in.norm.weight",
      "layer3.6.sblock_in.norm.bias",
      "layer3.6.sblock_dw.norm.weight",
      "layer3.6.sblock_dw.norm.bias",
      "layer3.6.sblock_proj.norm.weight",
      "layer3.6.sblock_proj.norm.bias",
      "layer3.6.mblock.0.norm.weight",
      "layer3.6.mblock.0.norm.bias",
      "layer3.6.mblock.1.branch_1.1.norm.weight",
      "layer3.6.mblock.1.branch_1.1.norm.bias",
      "layer3.6.mblock.1.branch_2.1.norm.weight",
      "layer3.6.mblock.1.branch_2.1.norm.bias",
      "layer3.6.mblock.1.branch_3.1.norm.weight",
      "layer3.6.mblock.1.branch_3.1.norm.bias",
      "layer3.6.mblock.2.norm.weight",
      "layer3.6.mblock.2.norm.bias",
      "layer3.7.sblock_in.norm.weight",
      "layer3.7.sblock_in.norm.bias",
      "layer3.7.sblock_dw.norm.weight",
      "layer3.7.sblock_dw.norm.bias",
      "layer3.7.sblock_proj.norm.weight",
      "layer3.7.sblock_proj.norm.bias",
      "layer3.7.mblock.0.norm.weight",
      "layer3.7.mblock.0.norm.bias",
      "layer3.7.mblock.1.branch_1.1.norm.weight",
      "layer3.7.mblock.1.branch_1.1.norm.bias",
      "layer3.7.mblock.1.branch_2.1.norm.weight",
      "layer3.7.mblock.1.branch_2.1.norm.bias",
      "layer3.7.mblock.1.branch_3.1.norm.weight",
      "layer3.7.mblock.1.branch_3.1.norm.bias",
      "layer3.7.mblock.2.norm.weight",
      "layer3.7.mblock.2.norm.bias",
      "layer3.8.sblock_in.norm.weight",
      "layer3.8.sblock_in.norm.bias",
      "layer3.8.sblock_dw.norm.weight",
      "layer3.8.sblock_dw.norm.bias",
      "layer3.8.sblock_proj.norm.weight",
      "layer3.8.sblock_proj.norm.bias",
      "layer3.8.mblock.0.norm.weight",
      "layer3.8.mblock.0.norm.bias",
      "layer3.8.mblock.1.branch_1.1.norm.weight",
      "layer3.8.mblock.1.branch_1.1.norm.bias",
      "layer3.8.mblock.1.branch_2.1.norm.weight",
      "layer3.8.mblock.1.branch_2.1.norm.bias",
      "layer3.8.mblock.1.branch_3.1.norm.weight",
      "layer3.8.mblock.1.branch_3.1.norm.bias",
      "layer3.8.mblock.2.norm.weight",
      "layer3.8.mblock.2.norm.bias",
      "layer3.9.sblock_in.norm.weight",
      "layer3.9.sblock_in.norm.bias",
      "layer3.9.sblock_dw.norm.weight",
      "layer3.9.sblock_dw.norm.bias",
      "layer3.9.sblock_proj.norm.weight",
      "layer3.9.sblock_proj.norm.bias",
      "layer3.9.mblock.0.norm.weight",
      "layer3.9.mblock.0.norm.bias",
      "layer3.9.mblock.1.branch_1.1.norm.weight",
      "layer3.9.mblock.1.branch_1.1.norm.bias",
      "layer3.9.mblock.1.branch_2.1.norm.weight",
      "layer3.9.mblock.1.branch_2.1.norm.bias",
      "layer3.9.mblock.1.branch_3.1.norm.weight",
      "layer3.9.mblock.1.branch_3.1.norm.bias",
      "layer3.9.mblock.2.norm.weight",
      "layer3.9.mblock.2.norm.bias",
      "layer3.10.sblock_in.norm.weight",
      "layer3.10.sblock_in.norm.bias",
      "layer3.10.sblock_dw.norm.weight",
      "layer3.10.sblock_dw.norm.bias",
      "layer3.10.sblock_proj.norm.weight",
      "layer3.10.sblock_proj.norm.bias",
      "layer3.10.mblock.0.norm.weight",
      "layer3.10.mblock.0.norm.bias",
      "layer3.10.mblock.1.branch_1.1.norm.weight",
      "layer3.10.mblock.1.branch_1.1.norm.bias",
      "layer3.10.mblock.1.branch_2.1.norm.weight",
      "layer3.10.mblock.1.branch_2.1.norm.bias",
      "layer3.10.mblock.1.branch_3.1.norm.weight",
      "layer3.10.mblock.1.branch_3.1.norm.bias",
      "layer3.10.mblock.2.norm.weight",
      "layer3.10.mblock.2.norm.bias",
      "layer3.11.sblock_in.norm.weight",
      "layer3.11.sblock_in.norm.bias",
      "layer3.11.sblock_dw.norm.weight",
      "layer3.11.sblock_dw.norm.bias",
      "layer3.11.sblock_proj.norm.weight",
      "layer3.11.sblock_proj.norm.bias",
      "layer3.11.mblock.0.norm.weight",
      "layer3.11.mblock.0.norm.bias",
      "layer3.11.mblock.1.branch_1.1.norm.weight",
      "layer3.11.mblock.1.branch_1.1.norm.bias",
      "layer3.11.mblock.1.branch_2.1.norm.weight",
      "layer3.11.mblock.1.branch_2.1.norm.bias",
      "layer3.11.mblock.1.branch_3.1.norm.weight",
      "layer3.11.mblock.1.branch_3.1.norm.bias",
      "layer3.11.mblock.2.norm.weight",
      "layer3.11.mblock.2.norm.bias",
      "layer3.12.sblock_in.norm.weight",
      "layer3.12.sblock_in.norm.bias",
      "layer3.12.sblock_dw.norm.weight",
      "layer3.12.sblock_dw.norm.bias",
      "layer3.12.sblock_proj.norm.weight",
      "layer3.12.sblock_proj.norm.bias",
      "layer3.12.mblock.0.norm.weight",
      "layer3.12.mblock.0.norm.bias",
      "layer3.12.mblock.1.branch_1.1.norm.weight",
      "layer3.12.mblock.1.branch_1.1.norm.bias",
      "layer3.12.mblock.1.branch_2.1.norm.weight",
      "layer3.12.mblock.1.branch_2.1.norm.bias",
      "layer3.12.mblock.1.branch_3.1.norm.weight",
      "layer3.12.mblock.1.branch_3.1.norm.bias",
      "layer3.12.mblock.2.norm.weight",
      "layer3.12.mblock.2.norm.bias",
      "layer3.13.sblock_in.norm.weight",
      "layer3.13.sblock_in.norm.bias",
      "layer3.13.sblock_dw.norm.weight",
      "layer3.13.sblock_dw.norm.bias",
      "layer3.13.sblock_proj.norm.weight",
      "layer3.13.sblock_proj.norm.bias",
      "layer3.13.mblock.0.norm.weight",
      "layer3.13.mblock.0.norm.bias",
      "layer3.13.mblock.1.branch_1.1.norm.weight",
      "layer3.13.mblock.1.branch_1.1.norm.bias",
      "layer3.13.mblock.1.branch_2.1.norm.weight",
      "layer3.13.mblock.1.branch_2.1.norm.bias",
      "layer3.13.mblock.1.branch_3.1.norm.weight",
      "layer3.13.mblock.1.branch_3.1.norm.bias",
      "layer3.13.mblock.2.norm.weight",
      "layer3.13.mblock.2.norm.bias",
      "layer3.14.sblock_in.norm.weight",
      "layer3.14.sblock_in.norm.bias",
      "layer3.14.sblock_dw.norm.weight",
      "layer3.14.sblock_dw.norm.bias",
      "layer3.14.sblock_proj.norm.weight",
      "layer3.14.sblock_proj.norm.bias",
      "layer3.14.mblock.0.norm.weight",
      "layer3.14.mblock.0.norm.bias",
      "layer3.14.mblock.1.branch_1.1.norm.weight",
      "layer3.14.mblock.1.branch_1.1.norm.bias",
      "layer3.14.mblock.1.branch_2.1.norm.weight",
      "layer3.14.mblock.1.branch_2.1.norm.bias",
      "layer3.14.mblock.1.branch_3.1.norm.weight",
      "layer3.14.mblock.1.branch_3.1.norm.bias",
      "layer3.14.mblock.2.norm.weight",
      "layer3.14.mblock.2.norm.bias",
      "layer3.15.sblock_in.norm.weight",
      "layer3.15.sblock_in.norm.bias",
      "layer3.15.sblock_dw.norm.weight",
      "layer3.15.sblock_dw.norm.bias",
      "layer3.15.sblock_proj.norm.weight",
      "layer3.15.sblock_proj.norm.bias",
      "layer3.15.mblock.0.norm.weight",
      "layer3.15.mblock.0.norm.bias",
      "layer3.15.mblock.1.branch_1.1.norm.weight",
      "layer3.15.mblock.1.branch_1.1.norm.bias",
      "layer3.15.mblock.1.branch_2.1.norm.weight",
      "layer3.15.mblock.1.branch_2.1.norm.bias",
      "layer3.15.mblock.1.branch_3.1.norm.weight",
      "layer3.15.mblock.1.branch_3.1.norm.bias",
      "layer3.15.mblock.2.norm.weight",
      "layer3.15.mblock.2.norm.bias",
      "layer3.16.sblock_in.norm.weight",
      "layer3.16.sblock_in.norm.bias",
      "layer3.16.sblock_dw.norm.weight",
      "layer3.16.sblock_dw.norm.bias",
      "layer3.16.sblock_proj.norm.weight",
      "layer3.16.sblock_proj.norm.bias",
      "layer3.16.mblock.0.norm.weight",
      "layer3.16.mblock.0.norm.bias",
      "layer3.16.mblock.1.branch_1.1.norm.weight",
      "layer3.16.mblock.1.branch_1.1.norm.bias",
      "layer3.16.mblock.1.branch_2.1.norm.weight",
      "layer3.16.mblock.1.branch_2.1.norm.bias",
      "layer3.16.mblock.1.branch_3.1.norm.weight",
      "layer3.16.mblock.1.branch_3.1.norm.bias",
      "layer3.16.mblock.2.norm.weight",
      "layer3.16.mblock.2.norm.bias",
      "layer4.0.mlp.0.norm.weight",
      "layer4.0.mlp.0.norm.bias",
      "layer4.0.mlp.1.norm.weight",
      "layer4.0.mlp.1.norm.bias",
      "layer4.0.mlp.2.norm.weight",
      "layer4.0.mlp.2.norm.bias",
      "layer4.0.skip.0.norm.weight",
      "layer4.0.skip.0.norm.bias",
      "layer4.0.skip.1.norm.weight",
      "layer4.0.skip.1.norm.bias",
      "layer4.1.sblock_in.norm.weight",
      "layer4.1.sblock_in.norm.bias",
      "layer4.1.sblock_dw.norm.weight",
      "layer4.1.sblock_dw.norm.bias",
      "layer4.1.sblock_proj.norm.weight",
      "layer4.1.sblock_proj.norm.bias",
      "layer4.1.mblock.0.norm.weight",
      "layer4.1.mblock.0.norm.bias",
      "layer4.1.mblock.1.branch_1.1.norm.weight",
      "layer4.1.mblock.1.branch_1.1.norm.bias",
      "layer4.1.mblock.1.branch_2.1.norm.weight",
      "layer4.1.mblock.1.branch_2.1.norm.bias",
      "layer4.1.mblock.1.branch_3.1.norm.weight",
      "layer4.1.mblock.1.branch_3.1.norm.bias",
      "layer4.1.mblock.2.norm.weight",
      "layer4.1.mblock.2.norm.bias",
      "layer4.2.sblock_in.norm.weight",
      "layer4.2.sblock_in.norm.bias",
      "layer4.2.sblock_dw.norm.weight",
      "layer4.2.sblock_dw.norm.bias",
      "layer4.2.sblock_proj.norm.weight",
      "layer4.2.sblock_proj.norm.bias",
      "layer4.2.mblock.0.norm.weight",
      "layer4.2.mblock.0.norm.bias",
      "layer4.2.mblock.1.branch_1.1.norm.weight",
      "layer4.2.mblock.1.branch_1.1.norm.bias",
      "layer4.2.mblock.1.branch_2.1.norm.weight",
      "layer4.2.mblock.1.branch_2.1.norm.bias",
      "layer4.2.mblock.1.branch_3.1.norm.weight",
      "layer4.2.mblock.1.branch_3.1.norm.bias",
      "layer4.2.mblock.2.norm.weight",
      "layer4.2.mblock.2.norm.bias",
      "layer4.3.sblock_in.norm.weight",
      "layer4.3.sblock_in.norm.bias",
      "layer4.3.sblock_dw.norm.weight",
      "layer4.3.sblock_dw.norm.bias",
      "layer4.3.sblock_proj.norm.weight",
      "layer4.3.sblock_proj.norm.bias",
      "layer4.3.mblock.0.norm.weight",
      "layer4.3.mblock.0.norm.bias",
      "layer4.3.mblock.1.branch_1.1.norm.weight",
      "layer4.3.mblock.1.branch_1.1.norm.bias",
      "layer4.3.mblock.1.branch_2.1.norm.weight",
      "layer4.3.mblock.1.branch_2.1.norm.bias",
      "layer4.3.mblock.1.branch_3.1.norm.weight",
      "layer4.3.mblock.1.branch_3.1.norm.bias",
      "layer4.3.mblock.2.norm.weight",
      "layer4.3.mblock.2.norm.bias",
      "layer4.4.sblock_in.norm.weight",
      "layer4.4.sblock_in.norm.bias",
      "layer4.4.sblock_dw.norm.weight",
      "layer4.4.sblock_dw.norm.bias",
      "layer4.4.sblock_proj.norm.weight",
      "layer4.4.sblock_proj.norm.bias",
      "layer4.4.mblock.0.norm.weight",
      "layer4.4.mblock.0.norm.bias",
      "layer4.4.mblock.1.branch_1.1.norm.weight",
      "layer4.4.mblock.1.branch_1.1.norm.bias",
      "layer4.4.mblock.1.branch_2.1.norm.weight",
      "layer4.4.mblock.1.branch_2.1.norm.bias",
      "layer4.4.mblock.1.branch_3.1.norm.weight",
      "layer4.4.mblock.1.branch_3.1.norm.bias",
      "layer4.4.mblock.2.norm.weight",
      "layer4.4.mblock.2.norm.bias",
      "head.norm.weight",
      "head.norm.bias",
      "classifier.norm.weight",
      "classifier.norm.bias"
    ],
    "lr_scale": 1.0
  }
}
Use Cosine LR scheduler
Set warmup steps = 6240
Set warmup steps = 0
Max WD = 0.0500000, Min WD = 0.0500000
criterion = SoftTargetCrossEntropy()
Auto resume checkpoint: 
Start training for 300 epochs
Epoch: [0]  [   0/1251]  eta: 4:30:23  lr: 0.000000  min_lr: 0.000000  loss: 6.9662 (6.9662)  weight_decay: 0.0500 (0.0500)  time: 12.9684  data: 2.2470  max mem: 40080
Epoch: [0]  [ 200/1251]  eta: 0:09:56  lr: 0.000032  min_lr: 0.000032  loss: 6.9207 (6.9443)  weight_decay: 0.0500 (0.0500)  grad_norm: 13.9601 (nan)  time: 0.5034  data: 0.0005  max mem: 40080
Epoch: [0]  [ 400/1251]  eta: 0:07:36  lr: 0.000064  min_lr: 0.000064  loss: 6.8599 (6.9136)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4055 (nan)  time: 0.5065  data: 0.0005  max mem: 40080
Epoch: [0]  [ 600/1251]  eta: 0:05:42  lr: 0.000096  min_lr: 0.000096  loss: 6.7620 (6.8742)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0003 (nan)  time: 0.5066  data: 0.0006  max mem: 40080
Epoch: [0]  [ 800/1251]  eta: 0:03:54  lr: 0.000128  min_lr: 0.000128  loss: 6.6747 (6.8322)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.6077 (nan)  time: 0.5039  data: 0.0005  max mem: 40080
Epoch: [0]  [1000/1251]  eta: 0:02:09  lr: 0.000160  min_lr: 0.000160  loss: 6.6132 (6.7885)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.7617 (nan)  time: 0.5062  data: 0.0005  max mem: 40080
Epoch: [0]  [1200/1251]  eta: 0:00:26  lr: 0.000192  min_lr: 0.000192  loss: 6.5704 (6.7509)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.8187 (nan)  time: 0.5062  data: 0.0005  max mem: 40080
Epoch: [0]  [1250/1251]  eta: 0:00:00  lr: 0.000199  min_lr: 0.000199  loss: 6.5324 (6.7418)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.5203 (nan)  time: 0.4277  data: 0.0007  max mem: 40080
Epoch: [0] Total time: 0:10:43 (0.5147 s / it)
Averaged stats: lr: 0.000199  min_lr: 0.000199  loss: 6.5324 (6.7408)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.5203 (nan)
Test:  [ 0/25]  eta: 0:04:33  loss: 5.7488 (5.7488)  acc1: 2.8000 (2.8000)  acc5: 12.4000 (12.4000)  time: 10.9486  data: 6.6355  max mem: 40080
Test:  [10/25]  eta: 0:00:18  loss: 5.7204 (5.6858)  acc1: 3.6000 (3.4182)  acc5: 11.6000 (11.6000)  time: 1.2325  data: 0.6035  max mem: 40080
Test:  [20/25]  eta: 0:00:03  loss: 5.7274 (5.7403)  acc1: 3.6000 (3.3905)  acc5: 10.8000 (11.2952)  time: 0.2609  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 5.7274 (5.6961)  acc1: 3.6000 (4.0000)  acc5: 11.6000 (12.5760)  time: 0.2608  data: 0.0001  max mem: 40080
Test: Total time: 0:00:17 (0.6908 s / it)
* Acc@1 3.584 Acc@5 11.990 loss 5.714
Accuracy of the model on the 50000 test images: 3.6%
Max accuracy: 3.58%
Epoch: [1]  [   0/1251]  eta: 1:00:49  lr: 0.000200  min_lr: 0.000200  loss: 6.0742 (6.0742)  weight_decay: 0.0500 (0.0500)  time: 2.9169  data: 2.2690  max mem: 40080
Epoch: [1]  [ 200/1251]  eta: 0:08:56  lr: 0.000232  min_lr: 0.000232  loss: 6.5171 (6.4820)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.6366 (4.0045)  time: 0.4977  data: 0.0003  max mem: 40080
Epoch: [1]  [ 400/1251]  eta: 0:07:09  lr: 0.000264  min_lr: 0.000264  loss: 6.4181 (6.4387)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.6315 (3.8747)  time: 0.4989  data: 0.0004  max mem: 40080
Epoch: [1]  [ 600/1251]  eta: 0:05:27  lr: 0.000296  min_lr: 0.000296  loss: 6.3506 (6.4075)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.4312 (3.8079)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [1]  [ 800/1251]  eta: 0:03:46  lr: 0.000328  min_lr: 0.000328  loss: 6.3358 (6.3742)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.8580 (3.8216)  time: 0.5041  data: 0.0004  max mem: 40080
Epoch: [1]  [1000/1251]  eta: 0:02:05  lr: 0.000360  min_lr: 0.000360  loss: 6.1015 (6.3432)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.4594 (3.7997)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [1]  [1200/1251]  eta: 0:00:25  lr: 0.000392  min_lr: 0.000392  loss: 6.2017 (6.3149)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.7041 (3.7557)  time: 0.5011  data: 0.0004  max mem: 40080
Epoch: [1]  [1250/1251]  eta: 0:00:00  lr: 0.000399  min_lr: 0.000399  loss: 6.0330 (6.3077)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.8453 (3.7594)  time: 0.4222  data: 0.0006  max mem: 40080
Epoch: [1] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.000399  min_lr: 0.000399  loss: 6.0330 (6.3092)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.8453 (3.7594)
Test:  [ 0/25]  eta: 0:02:12  loss: 4.7078 (4.7078)  acc1: 11.2000 (11.2000)  acc5: 28.8000 (28.8000)  time: 5.3142  data: 4.9952  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 4.5679 (4.6218)  acc1: 11.2000 (11.4545)  acc5: 30.0000 (30.1455)  time: 0.7210  data: 0.4545  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 4.8816 (4.7912)  acc1: 10.4000 (10.9714)  acc5: 27.6000 (28.5143)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 4.8816 (4.7705)  acc1: 11.2000 (11.4560)  acc5: 27.6000 (29.1840)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4666 s / it)
* Acc@1 11.466 Acc@5 28.932 loss 4.768
Accuracy of the model on the 50000 test images: 11.5%
Max accuracy: 11.47%
Epoch: [2]  [   0/1251]  eta: 0:57:15  lr: 0.000400  min_lr: 0.000400  loss: 5.7811 (5.7811)  weight_decay: 0.0500 (0.0500)  time: 2.7462  data: 2.2407  max mem: 40080
Epoch: [2]  [ 200/1251]  eta: 0:08:57  lr: 0.000432  min_lr: 0.000432  loss: 6.2642 (6.1388)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.4854 (3.5398)  time: 0.5000  data: 0.0004  max mem: 40080
Epoch: [2]  [ 400/1251]  eta: 0:07:10  lr: 0.000464  min_lr: 0.000464  loss: 6.0170 (6.0655)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.3650 (3.6057)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [2]  [ 600/1251]  eta: 0:05:27  lr: 0.000496  min_lr: 0.000496  loss: 6.0009 (6.0277)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.7923 (3.6163)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [2]  [ 800/1251]  eta: 0:03:46  lr: 0.000528  min_lr: 0.000528  loss: 5.8726 (5.9985)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.3436 (3.5811)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [2]  [1000/1251]  eta: 0:02:05  lr: 0.000560  min_lr: 0.000560  loss: 5.6900 (5.9651)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.3089 (3.5781)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [2]  [1200/1251]  eta: 0:00:25  lr: 0.000592  min_lr: 0.000592  loss: 5.8333 (5.9428)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.1858 (3.5706)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [2]  [1250/1251]  eta: 0:00:00  lr: 0.000599  min_lr: 0.000599  loss: 5.9007 (5.9386)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0186 (3.5489)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [2] Total time: 0:10:26 (0.5004 s / it)
Averaged stats: lr: 0.000599  min_lr: 0.000599  loss: 5.9007 (5.9276)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0186 (3.5489)
Test:  [ 0/25]  eta: 0:02:21  loss: 3.5829 (3.5829)  acc1: 24.4000 (24.4000)  acc5: 56.8000 (56.8000)  time: 5.6504  data: 5.3388  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 3.6186 (3.7093)  acc1: 24.4000 (22.6182)  acc5: 52.8000 (50.8000)  time: 0.7515  data: 0.4857  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 4.0763 (3.9450)  acc1: 19.2000 (21.0095)  acc5: 44.4000 (45.8476)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 4.0726 (3.9054)  acc1: 20.8000 (21.7600)  acc5: 44.4000 (46.3200)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4818 s / it)
* Acc@1 22.198 Acc@5 47.250 loss 3.893
Accuracy of the model on the 50000 test images: 22.2%
Max accuracy: 22.20%
Epoch: [3]  [   0/1251]  eta: 0:55:06  lr: 0.000600  min_lr: 0.000600  loss: 5.8441 (5.8441)  weight_decay: 0.0500 (0.0500)  time: 2.6431  data: 2.1363  max mem: 40080
Epoch: [3]  [ 200/1251]  eta: 0:08:54  lr: 0.000632  min_lr: 0.000632  loss: 5.6605 (5.6829)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.9610 (3.4502)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [3]  [ 400/1251]  eta: 0:07:08  lr: 0.000664  min_lr: 0.000664  loss: 5.6778 (5.6718)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.3140 (3.4928)  time: 0.4998  data: 0.0003  max mem: 40080
Epoch: [3]  [ 600/1251]  eta: 0:05:27  lr: 0.000696  min_lr: 0.000696  loss: 5.3731 (5.6509)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.3447 (3.3824)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [3]  [ 800/1251]  eta: 0:03:46  lr: 0.000728  min_lr: 0.000728  loss: 5.7253 (5.6359)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.8646 (3.3181)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [3]  [1000/1251]  eta: 0:02:05  lr: 0.000760  min_lr: 0.000760  loss: 5.5910 (5.6309)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.9635 (3.2811)  time: 0.4973  data: 0.0003  max mem: 40080
Epoch: [3]  [1200/1251]  eta: 0:00:25  lr: 0.000792  min_lr: 0.000792  loss: 5.8046 (5.6021)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.4975 (3.2489)  time: 0.4962  data: 0.0003  max mem: 40080
Epoch: [3]  [1250/1251]  eta: 0:00:00  lr: 0.000799  min_lr: 0.000799  loss: 5.6733 (5.5991)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.3334 (3.2444)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [3] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.000799  min_lr: 0.000799  loss: 5.6733 (5.6081)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.3334 (3.2444)
Test:  [ 0/25]  eta: 0:02:11  loss: 2.8506 (2.8506)  acc1: 43.2000 (43.2000)  acc5: 67.6000 (67.6000)  time: 5.2446  data: 4.9368  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 2.8506 (2.9966)  acc1: 42.0000 (36.2909)  acc5: 67.6000 (65.8909)  time: 0.7147  data: 0.4492  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 3.3904 (3.2858)  acc1: 29.6000 (32.7048)  acc5: 57.6000 (59.9238)  time: 0.2615  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 3.4071 (3.2719)  acc1: 29.6000 (32.9760)  acc5: 57.6000 (60.0480)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4642 s / it)
* Acc@1 32.654 Acc@5 59.666 loss 3.278
Accuracy of the model on the 50000 test images: 32.7%
Max accuracy: 32.65%
Epoch: [4]  [   0/1251]  eta: 0:57:03  lr: 0.000800  min_lr: 0.000800  loss: 5.3942 (5.3942)  weight_decay: 0.0500 (0.0500)  time: 2.7367  data: 2.2271  max mem: 40080
Epoch: [4]  [ 200/1251]  eta: 0:08:55  lr: 0.000832  min_lr: 0.000832  loss: 5.3884 (5.4335)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.9461 (3.0150)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [4]  [ 400/1251]  eta: 0:07:09  lr: 0.000864  min_lr: 0.000864  loss: 5.3695 (5.4340)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.7272 (2.9321)  time: 0.4992  data: 0.0004  max mem: 40080
Epoch: [4]  [ 600/1251]  eta: 0:05:26  lr: 0.000896  min_lr: 0.000896  loss: 5.5120 (5.4167)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4724 (2.8421)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [4]  [ 800/1251]  eta: 0:03:45  lr: 0.000928  min_lr: 0.000928  loss: 5.2907 (5.3919)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4340 (2.8143)  time: 0.5010  data: 0.0004  max mem: 40080
Epoch: [4]  [1000/1251]  eta: 0:02:05  lr: 0.000960  min_lr: 0.000960  loss: 5.5187 (5.3869)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4558 (2.8224)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [4]  [1200/1251]  eta: 0:00:25  lr: 0.000992  min_lr: 0.000992  loss: 5.5055 (5.3662)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.6368 (2.7746)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [4]  [1250/1251]  eta: 0:00:00  lr: 0.001000  min_lr: 0.001000  loss: 5.2700 (5.3597)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4262 (2.7603)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [4] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.001000  min_lr: 0.001000  loss: 5.2700 (5.3519)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4262 (2.7603)
Test:  [ 0/25]  eta: 0:02:20  loss: 2.4330 (2.4330)  acc1: 50.8000 (50.8000)  acc5: 76.4000 (76.4000)  time: 5.6368  data: 5.3224  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 2.4539 (2.5730)  acc1: 49.6000 (46.2182)  acc5: 77.2000 (74.3273)  time: 0.7503  data: 0.4841  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 2.9993 (2.9064)  acc1: 35.6000 (40.0571)  acc5: 63.6000 (67.2762)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 3.1290 (2.8976)  acc1: 35.6000 (40.2880)  acc5: 62.4000 (67.5200)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4797 s / it)
* Acc@1 40.502 Acc@5 67.534 loss 2.896
Accuracy of the model on the 50000 test images: 40.5%
Max accuracy: 40.50%
Epoch: [5]  [   0/1251]  eta: 0:50:19  lr: 0.001000  min_lr: 0.001000  loss: 5.4109 (5.4109)  weight_decay: 0.0500 (0.0500)  time: 2.4133  data: 1.8990  max mem: 40080
Epoch: [5]  [ 200/1251]  eta: 0:08:52  lr: 0.001032  min_lr: 0.001032  loss: 5.0818 (5.2989)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.3581 (2.4403)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [5]  [ 400/1251]  eta: 0:07:07  lr: 0.001064  min_lr: 0.001064  loss: 5.2887 (5.2265)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2102 (2.4773)  time: 0.5000  data: 0.0004  max mem: 40080
Epoch: [5]  [ 600/1251]  eta: 0:05:26  lr: 0.001096  min_lr: 0.001096  loss: 5.1726 (5.1986)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.3571 (2.4217)  time: 0.4989  data: 0.0004  max mem: 40080
Epoch: [5]  [ 800/1251]  eta: 0:03:46  lr: 0.001128  min_lr: 0.001128  loss: 5.0430 (5.1583)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2728 (2.4629)  time: 0.5054  data: 0.0004  max mem: 40080
Epoch: [5]  [1000/1251]  eta: 0:02:05  lr: 0.001160  min_lr: 0.001160  loss: 5.0520 (5.1528)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1808 (2.4041)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [5]  [1200/1251]  eta: 0:00:25  lr: 0.001192  min_lr: 0.001192  loss: 5.0456 (5.1388)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1879 (2.3602)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [5]  [1250/1251]  eta: 0:00:00  lr: 0.001200  min_lr: 0.001200  loss: 4.9452 (5.1352)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1886 (2.3627)  time: 0.4216  data: 0.0005  max mem: 40080
Epoch: [5] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.001200  min_lr: 0.001200  loss: 4.9452 (5.1401)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1886 (2.3627)
Test:  [ 0/25]  eta: 0:02:28  loss: 2.1137 (2.1137)  acc1: 56.4000 (56.4000)  acc5: 82.0000 (82.0000)  time: 5.9411  data: 5.6189  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 2.1306 (2.1929)  acc1: 52.8000 (52.1818)  acc5: 80.4000 (79.2364)  time: 0.7778  data: 0.5111  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 2.6182 (2.5536)  acc1: 42.4000 (45.8095)  acc5: 70.0000 (71.9238)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 2.6745 (2.5598)  acc1: 39.6000 (45.8560)  acc5: 64.4000 (71.7600)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4918 s / it)
* Acc@1 46.180 Acc@5 72.322 loss 2.544
Accuracy of the model on the 50000 test images: 46.2%
Max accuracy: 46.18%
Epoch: [6]  [   0/1251]  eta: 1:07:32  lr: 0.001200  min_lr: 0.001200  loss: 5.6321 (5.6321)  weight_decay: 0.0500 (0.0500)  time: 3.2394  data: 2.7343  max mem: 40080
Epoch: [6]  [ 200/1251]  eta: 0:08:59  lr: 0.001232  min_lr: 0.001232  loss: 4.8376 (5.0110)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9464 (2.1065)  time: 0.4986  data: 0.0004  max mem: 40080
Epoch: [6]  [ 400/1251]  eta: 0:07:11  lr: 0.001264  min_lr: 0.001264  loss: 5.0848 (4.9967)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9689 (2.1151)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [6]  [ 600/1251]  eta: 0:05:27  lr: 0.001296  min_lr: 0.001296  loss: 5.2432 (4.9860)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7999 (2.0505)  time: 0.4997  data: 0.0004  max mem: 40080
Epoch: [6]  [ 800/1251]  eta: 0:03:46  lr: 0.001328  min_lr: 0.001328  loss: 5.0305 (4.9801)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0237 (2.0447)  time: 0.4999  data: 0.0004  max mem: 40080
Epoch: [6]  [1000/1251]  eta: 0:02:05  lr: 0.001360  min_lr: 0.001360  loss: 4.6885 (4.9748)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0110 (2.0490)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [6]  [1200/1251]  eta: 0:00:25  lr: 0.001393  min_lr: 0.001393  loss: 4.7397 (4.9716)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6826 (2.0054)  time: 0.4994  data: 0.0004  max mem: 40080
Epoch: [6]  [1250/1251]  eta: 0:00:00  lr: 0.001400  min_lr: 0.001400  loss: 5.1069 (4.9712)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7632 (2.0052)  time: 0.4217  data: 0.0007  max mem: 40080
Epoch: [6] Total time: 0:10:26 (0.5006 s / it)
Averaged stats: lr: 0.001400  min_lr: 0.001400  loss: 5.1069 (4.9838)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7632 (2.0052)
Test:  [ 0/25]  eta: 0:01:58  loss: 2.0151 (2.0151)  acc1: 61.2000 (61.2000)  acc5: 83.2000 (83.2000)  time: 4.7446  data: 4.4489  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 2.0151 (2.1349)  acc1: 58.8000 (54.8727)  acc5: 84.4000 (81.7091)  time: 0.6972  data: 0.4263  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 2.5833 (2.4451)  acc1: 46.0000 (49.2952)  acc5: 72.4000 (76.0571)  time: 0.2771  data: 0.0121  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 2.5953 (2.4475)  acc1: 43.6000 (49.2000)  acc5: 72.0000 (75.9680)  time: 0.2631  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4563 s / it)
* Acc@1 49.572 Acc@5 76.002 loss 2.439
Accuracy of the model on the 50000 test images: 49.6%
Max accuracy: 49.57%
Epoch: [7]  [   0/1251]  eta: 0:55:45  lr: 0.001400  min_lr: 0.001400  loss: 5.6541 (5.6541)  weight_decay: 0.0500 (0.0500)  time: 2.6743  data: 2.1643  max mem: 40080
Epoch: [7]  [ 200/1251]  eta: 0:08:54  lr: 0.001432  min_lr: 0.001432  loss: 5.0559 (4.9303)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8693 (1.9034)  time: 0.4999  data: 0.0004  max mem: 40080
Epoch: [7]  [ 400/1251]  eta: 0:07:08  lr: 0.001464  min_lr: 0.001464  loss: 4.7580 (4.8903)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5458 (1.8449)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [7]  [ 600/1251]  eta: 0:05:26  lr: 0.001496  min_lr: 0.001496  loss: 4.8737 (4.8635)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6927 (1.8608)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [7]  [ 800/1251]  eta: 0:03:45  lr: 0.001528  min_lr: 0.001528  loss: 5.0013 (4.8655)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5189 (1.7946)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [7]  [1000/1251]  eta: 0:02:05  lr: 0.001561  min_lr: 0.001561  loss: 4.8463 (4.8603)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5958 (1.7745)  time: 0.5003  data: 0.0004  max mem: 40080
Epoch: [7]  [1200/1251]  eta: 0:00:25  lr: 0.001593  min_lr: 0.001593  loss: 4.9700 (4.8455)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4650 (1.7365)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [7]  [1250/1251]  eta: 0:00:00  lr: 0.001600  min_lr: 0.001600  loss: 4.9973 (4.8434)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5116 (1.7266)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [7] Total time: 0:10:24 (0.4989 s / it)
Averaged stats: lr: 0.001600  min_lr: 0.001600  loss: 4.9973 (4.8350)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5116 (1.7266)
Test:  [ 0/25]  eta: 0:02:16  loss: 1.6769 (1.6769)  acc1: 67.2000 (67.2000)  acc5: 86.4000 (86.4000)  time: 5.4586  data: 5.1623  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.7255 (1.8742)  acc1: 62.8000 (59.6364)  acc5: 86.4000 (85.0909)  time: 0.7340  data: 0.4696  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 2.2545 (2.2133)  acc1: 48.4000 (53.5810)  acc5: 76.8000 (78.7429)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 2.3893 (2.2214)  acc1: 48.4000 (53.5040)  acc5: 73.6000 (78.7200)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4727 s / it)
* Acc@1 53.568 Acc@5 78.786 loss 2.228
Accuracy of the model on the 50000 test images: 53.6%
Max accuracy: 53.57%
Epoch: [8]  [   0/1251]  eta: 0:55:12  lr: 0.001600  min_lr: 0.001600  loss: 4.5857 (4.5857)  weight_decay: 0.0500 (0.0500)  time: 2.6479  data: 2.1478  max mem: 40080
Epoch: [8]  [ 200/1251]  eta: 0:08:53  lr: 0.001632  min_lr: 0.001632  loss: 4.9084 (4.8289)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5934 (1.6403)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [8]  [ 400/1251]  eta: 0:07:08  lr: 0.001664  min_lr: 0.001664  loss: 4.5675 (4.8054)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7512 (1.6375)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [8]  [ 600/1251]  eta: 0:05:26  lr: 0.001696  min_lr: 0.001696  loss: 4.9178 (4.7715)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4458 (1.6099)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [8]  [ 800/1251]  eta: 0:03:45  lr: 0.001728  min_lr: 0.001728  loss: 4.8229 (4.7595)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5966 (1.6087)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [8]  [1000/1251]  eta: 0:02:05  lr: 0.001761  min_lr: 0.001761  loss: 4.8239 (4.7510)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4409 (1.5857)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [8]  [1200/1251]  eta: 0:00:25  lr: 0.001793  min_lr: 0.001793  loss: 4.7304 (4.7462)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4961 (1.5746)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [8]  [1250/1251]  eta: 0:00:00  lr: 0.001800  min_lr: 0.001800  loss: 4.9892 (4.7429)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4440 (1.5667)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [8] Total time: 0:10:23 (0.4983 s / it)
Averaged stats: lr: 0.001800  min_lr: 0.001800  loss: 4.9892 (4.7308)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4440 (1.5667)
Test:  [ 0/25]  eta: 0:02:28  loss: 1.6590 (1.6590)  acc1: 65.6000 (65.6000)  acc5: 87.2000 (87.2000)  time: 5.9298  data: 5.6360  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.6739 (1.8540)  acc1: 64.0000 (61.7091)  acc5: 88.0000 (86.0727)  time: 0.7768  data: 0.5127  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 2.2442 (2.1597)  acc1: 52.0000 (56.0762)  acc5: 78.4000 (80.4762)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 2.2520 (2.1649)  acc1: 52.0000 (55.7440)  acc5: 75.6000 (80.3360)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4915 s / it)
* Acc@1 55.552 Acc@5 80.286 loss 2.156
Accuracy of the model on the 50000 test images: 55.6%
Max accuracy: 55.55%
Epoch: [9]  [   0/1251]  eta: 0:49:56  lr: 0.001800  min_lr: 0.001800  loss: 4.9281 (4.9281)  weight_decay: 0.0500 (0.0500)  time: 2.3951  data: 1.8819  max mem: 40080
Epoch: [9]  [ 200/1251]  eta: 0:08:52  lr: 0.001832  min_lr: 0.001832  loss: 4.9388 (4.6809)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4438 (1.3953)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [9]  [ 400/1251]  eta: 0:07:07  lr: 0.001864  min_lr: 0.001864  loss: 4.4115 (4.6801)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3788 (1.3877)  time: 0.4957  data: 0.0004  max mem: 40080
Epoch: [9]  [ 600/1251]  eta: 0:05:26  lr: 0.001896  min_lr: 0.001896  loss: 4.6339 (4.6642)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2058 (1.3778)  time: 0.4988  data: 0.0005  max mem: 40080
Epoch: [9]  [ 800/1251]  eta: 0:03:45  lr: 0.001929  min_lr: 0.001929  loss: 4.7384 (4.6602)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3651 (1.4038)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [9]  [1000/1251]  eta: 0:02:05  lr: 0.001961  min_lr: 0.001961  loss: 4.5817 (4.6352)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3027 (1.3904)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [9]  [1200/1251]  eta: 0:00:25  lr: 0.001993  min_lr: 0.001993  loss: 4.4366 (4.6221)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0747 (1.3724)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [9]  [1250/1251]  eta: 0:00:00  lr: 0.002000  min_lr: 0.002000  loss: 4.7548 (4.6199)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1361 (1.3750)  time: 0.4211  data: 0.0006  max mem: 40080
Epoch: [9] Total time: 0:10:23 (0.4988 s / it)
Averaged stats: lr: 0.002000  min_lr: 0.002000  loss: 4.7548 (4.6519)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1361 (1.3750)
Test:  [ 0/25]  eta: 0:02:16  loss: 1.6860 (1.6860)  acc1: 67.2000 (67.2000)  acc5: 86.8000 (86.8000)  time: 5.4767  data: 5.1695  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.6488 (1.7167)  acc1: 67.2000 (64.0727)  acc5: 88.8000 (87.9636)  time: 0.7355  data: 0.4702  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 2.0699 (2.0073)  acc1: 55.6000 (57.8476)  acc5: 81.6000 (82.9143)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 2.1627 (2.0123)  acc1: 52.4000 (57.7280)  acc5: 80.4000 (82.7360)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4730 s / it)
* Acc@1 58.106 Acc@5 82.756 loss 2.011
Accuracy of the model on the 50000 test images: 58.1%
Max accuracy: 58.11%
Epoch: [10]  [   0/1251]  eta: 1:02:41  lr: 0.002000  min_lr: 0.002000  loss: 4.2225 (4.2225)  weight_decay: 0.0500 (0.0500)  time: 3.0066  data: 2.5004  max mem: 40080
Epoch: [10]  [ 200/1251]  eta: 0:08:57  lr: 0.002032  min_lr: 0.002032  loss: 4.8570 (4.6422)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1812 (1.3861)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [10]  [ 400/1251]  eta: 0:07:08  lr: 0.002064  min_lr: 0.002064  loss: 4.6907 (4.6136)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1987 (1.2947)  time: 0.4957  data: 0.0004  max mem: 40080
Epoch: [10]  [ 600/1251]  eta: 0:05:26  lr: 0.002096  min_lr: 0.002096  loss: 4.2551 (4.6029)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1718 (1.2648)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [10]  [ 800/1251]  eta: 0:03:46  lr: 0.002129  min_lr: 0.002129  loss: 4.4182 (4.5971)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1927 (1.2789)  time: 0.4992  data: 0.0004  max mem: 40080
Epoch: [10]  [1000/1251]  eta: 0:02:05  lr: 0.002161  min_lr: 0.002161  loss: 4.8335 (4.5870)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1619 (1.2784)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [10]  [1200/1251]  eta: 0:00:25  lr: 0.002193  min_lr: 0.002193  loss: 4.8595 (4.5627)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2606 (1.2666)  time: 0.4961  data: 0.0005  max mem: 40080
Epoch: [10]  [1250/1251]  eta: 0:00:00  lr: 0.002200  min_lr: 0.002200  loss: 4.5642 (4.5600)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2570 (1.2675)  time: 0.4297  data: 0.0005  max mem: 40080
Epoch: [10] Total time: 0:10:24 (0.4996 s / it)
Averaged stats: lr: 0.002200  min_lr: 0.002200  loss: 4.5642 (4.5681)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2570 (1.2675)
Test:  [ 0/25]  eta: 0:02:02  loss: 1.5020 (1.5020)  acc1: 73.6000 (73.6000)  acc5: 90.8000 (90.8000)  time: 4.9163  data: 4.6217  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.4854 (1.5880)  acc1: 69.2000 (66.6909)  acc5: 90.8000 (89.5273)  time: 0.6945  data: 0.4303  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.9231 (1.9043)  acc1: 56.4000 (60.8381)  acc5: 81.6000 (84.5333)  time: 0.2668  data: 0.0056  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 2.1301 (1.9223)  acc1: 55.2000 (60.3520)  acc5: 80.0000 (84.0800)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4621 s / it)
* Acc@1 60.146 Acc@5 83.816 loss 1.927
Accuracy of the model on the 50000 test images: 60.1%
Max accuracy: 60.15%
Epoch: [11]  [   0/1251]  eta: 0:55:24  lr: 0.002200  min_lr: 0.002200  loss: 4.5709 (4.5709)  weight_decay: 0.0500 (0.0500)  time: 2.6578  data: 2.1432  max mem: 40080
Epoch: [11]  [ 200/1251]  eta: 0:08:54  lr: 0.002232  min_lr: 0.002232  loss: 4.4847 (4.5114)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0479 (1.1218)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [11]  [ 400/1251]  eta: 0:07:07  lr: 0.002264  min_lr: 0.002264  loss: 4.4593 (4.5211)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1356 (1.1491)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [11]  [ 600/1251]  eta: 0:05:26  lr: 0.002297  min_lr: 0.002297  loss: 4.5691 (4.5060)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0421 (1.1457)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [11]  [ 800/1251]  eta: 0:03:45  lr: 0.002329  min_lr: 0.002329  loss: 4.9190 (4.5252)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1553 (1.1447)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [11]  [1000/1251]  eta: 0:02:05  lr: 0.002361  min_lr: 0.002361  loss: 4.4840 (4.5105)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0008 (1.1202)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [11]  [1200/1251]  eta: 0:00:25  lr: 0.002393  min_lr: 0.002393  loss: 4.5675 (4.5042)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1037 (1.1334)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [11]  [1250/1251]  eta: 0:00:00  lr: 0.002400  min_lr: 0.002400  loss: 4.2552 (4.5007)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0781 (1.1304)  time: 0.4217  data: 0.0006  max mem: 40080
Epoch: [11] Total time: 0:10:23 (0.4985 s / it)
Averaged stats: lr: 0.002400  min_lr: 0.002400  loss: 4.2552 (4.4884)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0781 (1.1304)
Test:  [ 0/25]  eta: 0:02:13  loss: 1.3495 (1.3495)  acc1: 74.4000 (74.4000)  acc5: 92.0000 (92.0000)  time: 5.3542  data: 5.0447  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.3682 (1.5085)  acc1: 71.6000 (68.2545)  acc5: 92.0000 (90.2545)  time: 0.7244  data: 0.4590  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.8737 (1.8278)  acc1: 58.4000 (61.9429)  acc5: 84.0000 (85.1429)  time: 0.2612  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.9747 (1.8406)  acc1: 56.8000 (61.9040)  acc5: 81.2000 (84.9760)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4679 s / it)
* Acc@1 61.496 Acc@5 84.738 loss 1.849
Accuracy of the model on the 50000 test images: 61.5%
Max accuracy: 61.50%
Epoch: [12]  [   0/1251]  eta: 0:56:04  lr: 0.002400  min_lr: 0.002400  loss: 4.2903 (4.2903)  weight_decay: 0.0500 (0.0500)  time: 2.6896  data: 2.1802  max mem: 40080
Epoch: [12]  [ 200/1251]  eta: 0:08:54  lr: 0.002432  min_lr: 0.002432  loss: 4.5112 (4.4597)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0477 (1.1172)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [12]  [ 400/1251]  eta: 0:07:08  lr: 0.002464  min_lr: 0.002464  loss: 4.6250 (4.4614)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0019 (1.0581)  time: 0.5070  data: 0.0004  max mem: 40080
Epoch: [12]  [ 600/1251]  eta: 0:05:26  lr: 0.002497  min_lr: 0.002497  loss: 4.8482 (4.4517)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9590 (1.0210)  time: 0.4954  data: 0.0004  max mem: 40080
Epoch: [12]  [ 800/1251]  eta: 0:03:45  lr: 0.002529  min_lr: 0.002529  loss: 4.5957 (4.4462)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0062 (1.0435)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [12]  [1000/1251]  eta: 0:02:05  lr: 0.002561  min_lr: 0.002561  loss: 4.7769 (4.4468)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9167 (1.0376)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [12]  [1200/1251]  eta: 0:00:25  lr: 0.002593  min_lr: 0.002593  loss: 4.4279 (4.4367)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9951 (1.0376)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [12]  [1250/1251]  eta: 0:00:00  lr: 0.002600  min_lr: 0.002600  loss: 4.4782 (4.4378)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0098 (1.0348)  time: 0.4244  data: 0.0006  max mem: 40080
Epoch: [12] Total time: 0:10:23 (0.4981 s / it)
Averaged stats: lr: 0.002600  min_lr: 0.002600  loss: 4.4782 (4.4414)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0098 (1.0348)
Test:  [ 0/25]  eta: 0:02:15  loss: 1.3766 (1.3766)  acc1: 74.8000 (74.8000)  acc5: 93.2000 (93.2000)  time: 5.4146  data: 5.0902  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.4177 (1.4981)  acc1: 71.2000 (70.3273)  acc5: 92.4000 (91.0909)  time: 0.7302  data: 0.4632  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.8084 (1.8174)  acc1: 62.8000 (64.0000)  acc5: 84.0000 (86.4381)  time: 0.2615  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 2.0125 (1.8320)  acc1: 58.4000 (63.4400)  acc5: 83.6000 (86.4160)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4707 s / it)
* Acc@1 63.204 Acc@5 85.974 loss 1.840
Accuracy of the model on the 50000 test images: 63.2%
Max accuracy: 63.20%
Epoch: [13]  [   0/1251]  eta: 1:04:03  lr: 0.002600  min_lr: 0.002600  loss: 4.4880 (4.4880)  weight_decay: 0.0500 (0.0500)  time: 3.0720  data: 2.5569  max mem: 40080
Epoch: [13]  [ 200/1251]  eta: 0:08:56  lr: 0.002632  min_lr: 0.002632  loss: 4.2789 (4.3132)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9865 (1.0330)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [13]  [ 400/1251]  eta: 0:07:09  lr: 0.002665  min_lr: 0.002665  loss: 4.4851 (4.3278)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9705 (0.9911)  time: 0.4993  data: 0.0004  max mem: 40080
Epoch: [13]  [ 600/1251]  eta: 0:05:27  lr: 0.002697  min_lr: 0.002697  loss: 4.0868 (4.3487)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0157 (0.9677)  time: 0.4975  data: 0.0005  max mem: 40080
Epoch: [13]  [ 800/1251]  eta: 0:03:46  lr: 0.002729  min_lr: 0.002729  loss: 3.8871 (4.3540)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9913 (0.9573)  time: 0.5069  data: 0.0005  max mem: 40080
Epoch: [13]  [1000/1251]  eta: 0:02:05  lr: 0.002761  min_lr: 0.002761  loss: 4.4216 (4.3551)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8955 (0.9755)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [13]  [1200/1251]  eta: 0:00:25  lr: 0.002793  min_lr: 0.002793  loss: 4.5063 (4.3571)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8655 (0.9690)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [13]  [1250/1251]  eta: 0:00:00  lr: 0.002800  min_lr: 0.002800  loss: 4.5496 (4.3519)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9335 (0.9660)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [13] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.002800  min_lr: 0.002800  loss: 4.5496 (4.3682)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9335 (0.9660)
Test:  [ 0/25]  eta: 0:02:19  loss: 1.1859 (1.1859)  acc1: 78.8000 (78.8000)  acc5: 92.8000 (92.8000)  time: 5.5610  data: 5.2619  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.3338 (1.4237)  acc1: 72.0000 (70.5091)  acc5: 92.4000 (91.3091)  time: 0.7435  data: 0.4787  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.8003 (1.7255)  acc1: 61.2000 (64.8381)  acc5: 86.0000 (86.9714)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.9626 (1.7453)  acc1: 60.8000 (64.3200)  acc5: 84.4000 (86.6400)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4765 s / it)
* Acc@1 64.202 Acc@5 86.690 loss 1.737
Accuracy of the model on the 50000 test images: 64.2%
Max accuracy: 64.20%
Epoch: [14]  [   0/1251]  eta: 1:04:58  lr: 0.002800  min_lr: 0.002800  loss: 4.1860 (4.1860)  weight_decay: 0.0500 (0.0500)  time: 3.1160  data: 2.6187  max mem: 40080
Epoch: [14]  [ 200/1251]  eta: 0:08:59  lr: 0.002833  min_lr: 0.002833  loss: 4.5307 (4.3263)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7815 (0.8324)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [14]  [ 400/1251]  eta: 0:07:10  lr: 0.002865  min_lr: 0.002865  loss: 4.2920 (4.3053)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8456 (0.8553)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [14]  [ 600/1251]  eta: 0:05:27  lr: 0.002897  min_lr: 0.002897  loss: 4.5199 (4.3034)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8563 (0.8649)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [14]  [ 800/1251]  eta: 0:03:46  lr: 0.002929  min_lr: 0.002929  loss: 4.6222 (4.3369)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8183 (0.8856)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [14]  [1000/1251]  eta: 0:02:05  lr: 0.002961  min_lr: 0.002961  loss: 4.4009 (4.3294)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7850 (0.8752)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [14]  [1200/1251]  eta: 0:00:25  lr: 0.002993  min_lr: 0.002993  loss: 4.3316 (4.3245)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8331 (0.8650)  time: 0.5024  data: 0.0004  max mem: 40080
Epoch: [14]  [1250/1251]  eta: 0:00:00  lr: 0.003000  min_lr: 0.003000  loss: 4.0816 (4.3213)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6962 (0.8580)  time: 0.4210  data: 0.0006  max mem: 40080
Epoch: [14] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.003000  min_lr: 0.003000  loss: 4.0816 (4.3243)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6962 (0.8580)
Test:  [ 0/25]  eta: 0:02:14  loss: 1.1924 (1.1924)  acc1: 79.2000 (79.2000)  acc5: 93.6000 (93.6000)  time: 5.3758  data: 5.0924  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.2145 (1.3607)  acc1: 71.2000 (70.8000)  acc5: 92.8000 (91.4182)  time: 0.7264  data: 0.4632  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.7187 (1.6535)  acc1: 59.6000 (64.6286)  acc5: 84.8000 (87.2381)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.8604 (1.6656)  acc1: 60.8000 (64.4000)  acc5: 84.4000 (86.9760)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4690 s / it)
* Acc@1 64.656 Acc@5 86.842 loss 1.670
Accuracy of the model on the 50000 test images: 64.7%
Max accuracy: 64.66%
Epoch: [15]  [   0/1251]  eta: 0:52:26  lr: 0.003000  min_lr: 0.003000  loss: 4.1334 (4.1334)  weight_decay: 0.0500 (0.0500)  time: 2.5154  data: 1.9945  max mem: 40080
Epoch: [15]  [ 200/1251]  eta: 0:08:52  lr: 0.003033  min_lr: 0.003033  loss: 4.2563 (4.2805)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8070 (0.8084)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [15]  [ 400/1251]  eta: 0:07:07  lr: 0.003065  min_lr: 0.003065  loss: 4.5966 (4.2883)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7698 (0.8651)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [15]  [ 600/1251]  eta: 0:05:26  lr: 0.003097  min_lr: 0.003097  loss: 4.3479 (4.2823)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7514 (0.8485)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [15]  [ 800/1251]  eta: 0:03:45  lr: 0.003129  min_lr: 0.003129  loss: 4.3828 (4.2882)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8125 (0.8470)  time: 0.4988  data: 0.0005  max mem: 40080
Epoch: [15]  [1000/1251]  eta: 0:02:05  lr: 0.003161  min_lr: 0.003161  loss: 4.3677 (4.2909)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8679 (0.8450)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [15]  [1200/1251]  eta: 0:00:25  lr: 0.003193  min_lr: 0.003193  loss: 4.1636 (4.2858)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7973 (0.8349)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [15]  [1250/1251]  eta: 0:00:00  lr: 0.003200  min_lr: 0.003200  loss: 4.3598 (4.2879)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8456 (0.8370)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [15] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.003200  min_lr: 0.003200  loss: 4.3598 (4.2853)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8456 (0.8370)
Test:  [ 0/25]  eta: 0:01:55  loss: 1.2009 (1.2009)  acc1: 76.8000 (76.8000)  acc5: 92.4000 (92.4000)  time: 4.6241  data: 4.3019  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.2673 (1.3621)  acc1: 70.8000 (71.3455)  acc5: 93.2000 (92.4727)  time: 0.6943  data: 0.4279  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.6642 (1.6382)  acc1: 64.0000 (66.5905)  acc5: 86.0000 (88.1905)  time: 0.2811  data: 0.0203  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.8121 (1.6545)  acc1: 61.6000 (66.0640)  acc5: 85.2000 (87.9520)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4548 s / it)
* Acc@1 65.996 Acc@5 87.812 loss 1.653
Accuracy of the model on the 50000 test images: 66.0%
Max accuracy: 66.00%
Epoch: [16]  [   0/1251]  eta: 1:04:59  lr: 0.003201  min_lr: 0.003201  loss: 4.0382 (4.0382)  weight_decay: 0.0500 (0.0500)  time: 3.1174  data: 2.6106  max mem: 40080
Epoch: [16]  [ 200/1251]  eta: 0:08:57  lr: 0.003233  min_lr: 0.003233  loss: 4.2507 (4.2728)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6643 (0.7924)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [16]  [ 400/1251]  eta: 0:07:09  lr: 0.003265  min_lr: 0.003265  loss: 3.8899 (4.2487)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7156 (0.7795)  time: 0.4975  data: 0.0005  max mem: 40080
Epoch: [16]  [ 600/1251]  eta: 0:05:27  lr: 0.003297  min_lr: 0.003297  loss: 4.3131 (4.2593)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6829 (0.7620)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [16]  [ 800/1251]  eta: 0:03:46  lr: 0.003329  min_lr: 0.003329  loss: 4.2079 (4.2705)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6761 (0.7439)  time: 0.4986  data: 0.0005  max mem: 40080
Epoch: [16]  [1000/1251]  eta: 0:02:05  lr: 0.003361  min_lr: 0.003361  loss: 4.3737 (4.2599)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7330 (0.7541)  time: 0.4986  data: 0.0005  max mem: 40080
Epoch: [16]  [1200/1251]  eta: 0:00:25  lr: 0.003393  min_lr: 0.003393  loss: 4.4395 (4.2452)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6280 (0.7443)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [16]  [1250/1251]  eta: 0:00:00  lr: 0.003400  min_lr: 0.003400  loss: 4.4474 (4.2488)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7896 (0.7491)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [16] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.003400  min_lr: 0.003400  loss: 4.4474 (4.2452)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7896 (0.7491)
Test:  [ 0/25]  eta: 0:02:25  loss: 1.2293 (1.2293)  acc1: 76.4000 (76.4000)  acc5: 92.0000 (92.0000)  time: 5.8093  data: 5.5008  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.2829 (1.4142)  acc1: 72.0000 (71.0909)  acc5: 92.8000 (91.6727)  time: 0.7658  data: 0.5004  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.7130 (1.6857)  acc1: 63.6000 (66.2286)  acc5: 87.2000 (88.0381)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.8535 (1.6885)  acc1: 63.6000 (66.2720)  acc5: 86.0000 (88.0960)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4877 s / it)
* Acc@1 66.418 Acc@5 87.934 loss 1.691
Accuracy of the model on the 50000 test images: 66.4%
Max accuracy: 66.42%
Epoch: [17]  [   0/1251]  eta: 0:56:47  lr: 0.003401  min_lr: 0.003401  loss: 4.4301 (4.4301)  weight_decay: 0.0500 (0.0500)  time: 2.7238  data: 2.2111  max mem: 40080
Epoch: [17]  [ 200/1251]  eta: 0:08:55  lr: 0.003433  min_lr: 0.003433  loss: 4.0465 (4.1789)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6274 (0.6994)  time: 0.4985  data: 0.0005  max mem: 40080
Epoch: [17]  [ 400/1251]  eta: 0:07:09  lr: 0.003465  min_lr: 0.003465  loss: 3.6004 (4.1382)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7427 (0.7271)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [17]  [ 600/1251]  eta: 0:05:26  lr: 0.003497  min_lr: 0.003497  loss: 4.5837 (4.1786)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7549 (0.7317)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [17]  [ 800/1251]  eta: 0:03:46  lr: 0.003529  min_lr: 0.003529  loss: 4.5640 (4.1944)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6842 (0.7202)  time: 0.5124  data: 0.0005  max mem: 40080
Epoch: [17]  [1000/1251]  eta: 0:02:05  lr: 0.003561  min_lr: 0.003561  loss: 4.2092 (4.1903)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7031 (0.7100)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [17]  [1200/1251]  eta: 0:00:25  lr: 0.003593  min_lr: 0.003593  loss: 4.2303 (4.2078)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7011 (0.7133)  time: 0.4966  data: 0.0005  max mem: 40080
Epoch: [17]  [1250/1251]  eta: 0:00:00  lr: 0.003600  min_lr: 0.003600  loss: 4.4697 (4.2133)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7451 (0.7167)  time: 0.4216  data: 0.0006  max mem: 40080
Epoch: [17] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.003600  min_lr: 0.003600  loss: 4.4697 (4.2166)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7451 (0.7167)
Test:  [ 0/25]  eta: 0:02:12  loss: 1.1667 (1.1667)  acc1: 79.6000 (79.6000)  acc5: 93.2000 (93.2000)  time: 5.2834  data: 4.9886  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.2936 (1.3588)  acc1: 70.8000 (72.1818)  acc5: 93.2000 (92.0364)  time: 0.7182  data: 0.4539  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.6482 (1.6384)  acc1: 64.0000 (67.2762)  acc5: 86.0000 (88.2667)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.8788 (1.6532)  acc1: 64.0000 (66.8640)  acc5: 85.6000 (88.3520)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4658 s / it)
* Acc@1 66.958 Acc@5 88.296 loss 1.656
Accuracy of the model on the 50000 test images: 67.0%
Max accuracy: 66.96%
Epoch: [18]  [   0/1251]  eta: 0:58:41  lr: 0.003601  min_lr: 0.003601  loss: 3.3791 (3.3791)  weight_decay: 0.0500 (0.0500)  time: 2.8152  data: 2.3064  max mem: 40080
Epoch: [18]  [ 200/1251]  eta: 0:08:57  lr: 0.003633  min_lr: 0.003633  loss: 4.4882 (4.2040)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7214 (0.7692)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [18]  [ 400/1251]  eta: 0:07:09  lr: 0.003665  min_lr: 0.003665  loss: 4.2526 (4.1648)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5978 (0.7322)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [18]  [ 600/1251]  eta: 0:05:27  lr: 0.003697  min_lr: 0.003697  loss: 3.7562 (4.1547)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5706 (0.7134)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [18]  [ 800/1251]  eta: 0:03:46  lr: 0.003729  min_lr: 0.003729  loss: 4.2648 (4.1618)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7861 (0.7161)  time: 0.4991  data: 0.0004  max mem: 40080
Epoch: [18]  [1000/1251]  eta: 0:02:05  lr: 0.003761  min_lr: 0.003761  loss: 4.3493 (4.1596)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6689 (0.7164)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [18]  [1200/1251]  eta: 0:00:25  lr: 0.003793  min_lr: 0.003793  loss: 4.2855 (4.1702)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6883 (0.7049)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [18]  [1250/1251]  eta: 0:00:00  lr: 0.003800  min_lr: 0.003800  loss: 4.2307 (4.1718)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5892 (0.7004)  time: 0.4209  data: 0.0005  max mem: 40080
Epoch: [18] Total time: 0:10:25 (0.4997 s / it)
Averaged stats: lr: 0.003800  min_lr: 0.003800  loss: 4.2307 (4.1808)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5892 (0.7004)
Test:  [ 0/25]  eta: 0:02:12  loss: 1.2218 (1.2218)  acc1: 81.6000 (81.6000)  acc5: 92.8000 (92.8000)  time: 5.2912  data: 4.9931  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.2406 (1.3810)  acc1: 73.6000 (72.4727)  acc5: 93.2000 (92.4000)  time: 0.7189  data: 0.4543  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.6047 (1.5985)  acc1: 64.0000 (68.0571)  acc5: 87.6000 (88.8952)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.7514 (1.6104)  acc1: 64.8000 (67.7760)  acc5: 86.0000 (88.6880)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4663 s / it)
* Acc@1 67.316 Acc@5 88.498 loss 1.608
Accuracy of the model on the 50000 test images: 67.3%
Max accuracy: 67.32%
Epoch: [19]  [   0/1251]  eta: 1:01:06  lr: 0.003801  min_lr: 0.003801  loss: 4.3633 (4.3633)  weight_decay: 0.0500 (0.0500)  time: 2.9308  data: 2.4192  max mem: 40080
Epoch: [19]  [ 200/1251]  eta: 0:08:56  lr: 0.003833  min_lr: 0.003833  loss: 4.1737 (4.1275)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6488 (0.6242)  time: 0.5044  data: 0.0004  max mem: 40080
Epoch: [19]  [ 400/1251]  eta: 0:07:09  lr: 0.003865  min_lr: 0.003865  loss: 4.2887 (4.1556)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5745 (0.6351)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [19]  [ 600/1251]  eta: 0:05:27  lr: 0.003897  min_lr: 0.003897  loss: 4.3278 (4.1669)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6135 (0.6513)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [19]  [ 800/1251]  eta: 0:03:46  lr: 0.003929  min_lr: 0.003929  loss: 4.2996 (4.1505)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5890 (0.6487)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [19]  [1000/1251]  eta: 0:02:05  lr: 0.003961  min_lr: 0.003961  loss: 4.2657 (4.1658)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6150 (0.6474)  time: 0.4993  data: 0.0004  max mem: 40080
Epoch: [19]  [1200/1251]  eta: 0:00:25  lr: 0.003993  min_lr: 0.003993  loss: 3.9501 (4.1637)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5989 (0.6451)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [19]  [1250/1251]  eta: 0:00:00  lr: 0.004000  min_lr: 0.004000  loss: 4.4634 (4.1672)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5947 (0.6442)  time: 0.4209  data: 0.0006  max mem: 40080
Epoch: [19] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.004000  min_lr: 0.004000  loss: 4.4634 (4.1555)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5947 (0.6442)
Test:  [ 0/25]  eta: 0:02:06  loss: 1.2255 (1.2255)  acc1: 80.4000 (80.4000)  acc5: 95.2000 (95.2000)  time: 5.0712  data: 4.7605  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.4327 (1.4490)  acc1: 73.2000 (72.3273)  acc5: 93.2000 (92.1455)  time: 0.6987  data: 0.4330  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.7609 (1.7030)  acc1: 62.8000 (67.3905)  acc5: 86.4000 (88.8762)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.9244 (1.7123)  acc1: 63.2000 (67.1840)  acc5: 85.6000 (88.8000)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4567 s / it)
* Acc@1 67.486 Acc@5 88.766 loss 1.715
Accuracy of the model on the 50000 test images: 67.5%
Max accuracy: 67.49%
Epoch: [20]  [   0/1251]  eta: 0:54:51  lr: 0.004000  min_lr: 0.004000  loss: 4.4587 (4.4587)  weight_decay: 0.0500 (0.0500)  time: 2.6310  data: 2.1242  max mem: 40080
Epoch: [20]  [ 200/1251]  eta: 0:08:53  lr: 0.004000  min_lr: 0.004000  loss: 3.9102 (4.0709)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7369 (0.6545)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [20]  [ 400/1251]  eta: 0:07:07  lr: 0.004000  min_lr: 0.004000  loss: 4.3636 (4.1341)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6063 (0.6223)  time: 0.4977  data: 0.0005  max mem: 40080
Epoch: [20]  [ 600/1251]  eta: 0:05:26  lr: 0.004000  min_lr: 0.004000  loss: 4.2264 (4.0972)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6997 (0.6550)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [20]  [ 800/1251]  eta: 0:03:45  lr: 0.004000  min_lr: 0.004000  loss: 4.2200 (4.1084)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5959 (0.6570)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [20]  [1000/1251]  eta: 0:02:05  lr: 0.004000  min_lr: 0.004000  loss: 3.8139 (4.0958)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5821 (0.6444)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [20]  [1200/1251]  eta: 0:00:25  lr: 0.004000  min_lr: 0.004000  loss: 3.5936 (4.0848)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6114 (0.6421)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [20]  [1250/1251]  eta: 0:00:00  lr: 0.004000  min_lr: 0.004000  loss: 4.1479 (4.0875)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5983 (0.6416)  time: 0.4207  data: 0.0005  max mem: 40080
Epoch: [20] Total time: 0:10:23 (0.4988 s / it)
Averaged stats: lr: 0.004000  min_lr: 0.004000  loss: 4.1479 (4.1231)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5983 (0.6416)
Test:  [ 0/25]  eta: 0:02:19  loss: 1.0342 (1.0342)  acc1: 79.2000 (79.2000)  acc5: 94.0000 (94.0000)  time: 5.5760  data: 5.2708  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.1857 (1.2321)  acc1: 76.0000 (73.7818)  acc5: 94.0000 (93.1636)  time: 0.7448  data: 0.4795  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.5144 (1.4908)  acc1: 64.4000 (68.6857)  acc5: 88.8000 (89.3333)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.6708 (1.5036)  acc1: 64.0000 (68.3200)  acc5: 86.4000 (89.2160)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4777 s / it)
* Acc@1 68.310 Acc@5 89.090 loss 1.512
Accuracy of the model on the 50000 test images: 68.3%
Max accuracy: 68.31%
Epoch: [21]  [   0/1251]  eta: 0:51:41  lr: 0.004000  min_lr: 0.004000  loss: 3.7710 (3.7710)  weight_decay: 0.0500 (0.0500)  time: 2.4796  data: 1.9637  max mem: 40080
Epoch: [21]  [ 200/1251]  eta: 0:08:54  lr: 0.004000  min_lr: 0.004000  loss: 3.8858 (4.1524)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6158 (0.5999)  time: 0.5065  data: 0.0004  max mem: 40080
Epoch: [21]  [ 400/1251]  eta: 0:07:08  lr: 0.004000  min_lr: 0.004000  loss: 4.2139 (4.1277)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5507 (0.5954)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [21]  [ 600/1251]  eta: 0:05:26  lr: 0.004000  min_lr: 0.004000  loss: 4.3294 (4.1209)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6034 (0.6140)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [21]  [ 800/1251]  eta: 0:03:45  lr: 0.004000  min_lr: 0.004000  loss: 3.9906 (4.1132)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5317 (0.6232)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [21]  [1000/1251]  eta: 0:02:05  lr: 0.004000  min_lr: 0.004000  loss: 4.2285 (4.1161)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5219 (0.6193)  time: 0.4977  data: 0.0005  max mem: 40080
Epoch: [21]  [1200/1251]  eta: 0:00:25  lr: 0.004000  min_lr: 0.004000  loss: 4.0851 (4.1016)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6027 (0.6132)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [21]  [1250/1251]  eta: 0:00:00  lr: 0.003999  min_lr: 0.003999  loss: 4.2347 (4.1014)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6207 (0.6185)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [21] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.003999  min_lr: 0.003999  loss: 4.2347 (4.0804)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6207 (0.6185)
Test:  [ 0/25]  eta: 0:02:15  loss: 1.0218 (1.0218)  acc1: 80.8000 (80.8000)  acc5: 96.0000 (96.0000)  time: 5.4392  data: 5.1282  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.1571 (1.2638)  acc1: 76.0000 (74.2545)  acc5: 93.6000 (93.5273)  time: 0.7323  data: 0.4665  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.5348 (1.5169)  acc1: 64.8000 (69.0667)  acc5: 89.6000 (89.8857)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.6844 (1.5299)  acc1: 64.8000 (68.5440)  acc5: 87.2000 (89.6480)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4724 s / it)
* Acc@1 69.096 Acc@5 89.650 loss 1.534
Accuracy of the model on the 50000 test images: 69.1%
Max accuracy: 69.10%
Epoch: [22]  [   0/1251]  eta: 0:59:20  lr: 0.003999  min_lr: 0.003999  loss: 3.0641 (3.0641)  weight_decay: 0.0500 (0.0500)  time: 2.8464  data: 2.3458  max mem: 40080
Epoch: [22]  [ 200/1251]  eta: 0:08:56  lr: 0.003999  min_lr: 0.003999  loss: 3.8619 (4.0208)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5500 (0.5991)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [22]  [ 400/1251]  eta: 0:07:08  lr: 0.003999  min_lr: 0.003999  loss: 4.2701 (4.0375)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6413 (0.6103)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [22]  [ 600/1251]  eta: 0:05:26  lr: 0.003999  min_lr: 0.003999  loss: 4.0949 (4.0372)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4784 (0.5993)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [22]  [ 800/1251]  eta: 0:03:45  lr: 0.003999  min_lr: 0.003999  loss: 4.0155 (4.0350)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5013 (0.5961)  time: 0.4956  data: 0.0004  max mem: 40080
Epoch: [22]  [1000/1251]  eta: 0:02:05  lr: 0.003999  min_lr: 0.003999  loss: 4.0675 (4.0292)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5851 (0.5948)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [22]  [1200/1251]  eta: 0:00:25  lr: 0.003999  min_lr: 0.003999  loss: 4.2175 (4.0423)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5433 (0.6014)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [22]  [1250/1251]  eta: 0:00:00  lr: 0.003999  min_lr: 0.003999  loss: 4.1892 (4.0452)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5101 (0.5991)  time: 0.4297  data: 0.0006  max mem: 40080
Epoch: [22] Total time: 0:10:23 (0.4988 s / it)
Averaged stats: lr: 0.003999  min_lr: 0.003999  loss: 4.1892 (4.0495)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5101 (0.5991)
Test:  [ 0/25]  eta: 0:02:19  loss: 1.0426 (1.0426)  acc1: 80.0000 (80.0000)  acc5: 94.8000 (94.8000)  time: 5.5951  data: 5.3028  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.1223 (1.2439)  acc1: 74.0000 (73.8182)  acc5: 94.4000 (93.5636)  time: 0.7465  data: 0.4824  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.5376 (1.4887)  acc1: 66.0000 (69.8667)  acc5: 88.4000 (89.9429)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.6970 (1.5076)  acc1: 66.0000 (69.4240)  acc5: 87.6000 (89.9040)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4784 s / it)
* Acc@1 69.266 Acc@5 89.902 loss 1.507
Accuracy of the model on the 50000 test images: 69.3%
Max accuracy: 69.27%
Epoch: [23]  [   0/1251]  eta: 0:58:33  lr: 0.003999  min_lr: 0.003999  loss: 4.8754 (4.8754)  weight_decay: 0.0500 (0.0500)  time: 2.8086  data: 2.3070  max mem: 40080
Epoch: [23]  [ 200/1251]  eta: 0:08:55  lr: 0.003999  min_lr: 0.003999  loss: 3.8586 (3.9881)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6089 (0.5832)  time: 0.4993  data: 0.0004  max mem: 40080
Epoch: [23]  [ 400/1251]  eta: 0:07:09  lr: 0.003999  min_lr: 0.003999  loss: 4.0735 (3.9946)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6158 (0.6054)  time: 0.4987  data: 0.0005  max mem: 40080
Epoch: [23]  [ 600/1251]  eta: 0:05:27  lr: 0.003998  min_lr: 0.003998  loss: 4.2490 (3.9969)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5296 (0.6172)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [23]  [ 800/1251]  eta: 0:03:46  lr: 0.003998  min_lr: 0.003998  loss: 4.2637 (4.0094)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5193 (0.6037)  time: 0.4969  data: 0.0005  max mem: 40080
Epoch: [23]  [1000/1251]  eta: 0:02:05  lr: 0.003998  min_lr: 0.003998  loss: 4.2210 (4.0073)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5222 (0.6002)  time: 0.4959  data: 0.0005  max mem: 40080
Epoch: [23]  [1200/1251]  eta: 0:00:25  lr: 0.003998  min_lr: 0.003998  loss: 4.0495 (4.0009)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5614 (0.5964)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [23]  [1250/1251]  eta: 0:00:00  lr: 0.003998  min_lr: 0.003998  loss: 4.2149 (3.9997)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6066 (0.5975)  time: 0.4208  data: 0.0007  max mem: 40080
Epoch: [23] Total time: 0:10:25 (0.4996 s / it)
Averaged stats: lr: 0.003998  min_lr: 0.003998  loss: 4.2149 (4.0126)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6066 (0.5975)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.9709 (0.9709)  acc1: 84.8000 (84.8000)  acc5: 96.8000 (96.8000)  time: 5.5652  data: 5.2576  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.1817 (1.2597)  acc1: 75.6000 (74.9455)  acc5: 94.4000 (93.8182)  time: 0.7435  data: 0.4783  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.5634 (1.4933)  acc1: 67.6000 (70.6286)  acc5: 90.0000 (90.2095)  time: 0.2612  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.6686 (1.5016)  acc1: 67.6000 (70.1760)  acc5: 88.0000 (90.1120)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4771 s / it)
* Acc@1 69.934 Acc@5 90.256 loss 1.500
Accuracy of the model on the 50000 test images: 69.9%
Max accuracy: 69.93%
Epoch: [24]  [   0/1251]  eta: 0:58:50  lr: 0.003998  min_lr: 0.003998  loss: 4.6918 (4.6918)  weight_decay: 0.0500 (0.0500)  time: 2.8223  data: 2.3068  max mem: 40080
Epoch: [24]  [ 200/1251]  eta: 0:08:55  lr: 0.003998  min_lr: 0.003998  loss: 4.0760 (4.0368)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5140 (0.5548)  time: 0.4995  data: 0.0004  max mem: 40080
Epoch: [24]  [ 400/1251]  eta: 0:07:09  lr: 0.003998  min_lr: 0.003998  loss: 4.1089 (4.0345)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4955 (0.5495)  time: 0.5057  data: 0.0005  max mem: 40080
Epoch: [24]  [ 600/1251]  eta: 0:05:27  lr: 0.003997  min_lr: 0.003997  loss: 4.0060 (4.0028)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5842 (0.5657)  time: 0.5003  data: 0.0004  max mem: 40080
Epoch: [24]  [ 800/1251]  eta: 0:03:46  lr: 0.003997  min_lr: 0.003997  loss: 3.9964 (3.9924)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4966 (0.5744)  time: 0.4989  data: 0.0004  max mem: 40080
Epoch: [24]  [1000/1251]  eta: 0:02:05  lr: 0.003997  min_lr: 0.003997  loss: 3.9434 (4.0098)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5196 (0.5751)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [24]  [1200/1251]  eta: 0:00:25  lr: 0.003997  min_lr: 0.003997  loss: 4.2252 (4.0193)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6012 (0.5827)  time: 0.4990  data: 0.0004  max mem: 40080
Epoch: [24]  [1250/1251]  eta: 0:00:00  lr: 0.003997  min_lr: 0.003997  loss: 3.7828 (4.0155)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4203  data: 0.0006  max mem: 40080
Epoch: [24] Total time: 0:10:25 (0.5004 s / it)
Averaged stats: lr: 0.003997  min_lr: 0.003997  loss: 3.7828 (3.9996)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.9305 (0.9305)  acc1: 80.4000 (80.4000)  acc5: 96.8000 (96.8000)  time: 5.5255  data: 5.2011  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.1020 (1.1715)  acc1: 74.8000 (74.9455)  acc5: 94.4000 (94.2545)  time: 0.7400  data: 0.4732  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.4749 (1.3962)  acc1: 68.0000 (70.4571)  acc5: 91.2000 (90.8952)  time: 0.2612  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.5936 (1.4089)  acc1: 66.4000 (70.0640)  acc5: 88.0000 (90.8320)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4749 s / it)
* Acc@1 70.262 Acc@5 90.508 loss 1.408
Accuracy of the model on the 50000 test images: 70.3%
Max accuracy: 70.26%
Epoch: [25]  [   0/1251]  eta: 0:55:17  lr: 0.003997  min_lr: 0.003997  loss: 3.0734 (3.0734)  weight_decay: 0.0500 (0.0500)  time: 2.6521  data: 2.1523  max mem: 40080
Epoch: [25]  [ 200/1251]  eta: 0:08:55  lr: 0.003997  min_lr: 0.003997  loss: 4.1618 (3.9628)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5658 (0.6553)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [25]  [ 400/1251]  eta: 0:07:08  lr: 0.003996  min_lr: 0.003996  loss: 4.1153 (3.9930)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5970 (0.6406)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [25]  [ 600/1251]  eta: 0:05:26  lr: 0.003996  min_lr: 0.003996  loss: 4.3308 (3.9992)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5231 (0.6289)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [25]  [ 800/1251]  eta: 0:03:45  lr: 0.003996  min_lr: 0.003996  loss: 3.8243 (3.9797)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5138 (0.5965)  time: 0.5100  data: 0.0004  max mem: 40080
Epoch: [25]  [1000/1251]  eta: 0:02:05  lr: 0.003996  min_lr: 0.003996  loss: 4.0144 (3.9898)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6254 (0.6010)  time: 0.5015  data: 0.0004  max mem: 40080
Epoch: [25]  [1200/1251]  eta: 0:00:25  lr: 0.003996  min_lr: 0.003996  loss: 4.1270 (3.9920)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5867 (0.6035)  time: 0.4969  data: 0.0005  max mem: 40080
Epoch: [25]  [1250/1251]  eta: 0:00:00  lr: 0.003995  min_lr: 0.003995  loss: 4.1183 (3.9917)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5825 (0.6050)  time: 0.4211  data: 0.0007  max mem: 40080
Epoch: [25] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.003995  min_lr: 0.003995  loss: 4.1183 (3.9689)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5825 (0.6050)
Test:  [ 0/25]  eta: 0:02:14  loss: 0.9815 (0.9815)  acc1: 82.4000 (82.4000)  acc5: 95.6000 (95.6000)  time: 5.3760  data: 5.0556  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.1120 (1.2228)  acc1: 77.6000 (74.7636)  acc5: 95.2000 (94.4727)  time: 0.7265  data: 0.4599  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.4714 (1.4541)  acc1: 67.2000 (70.6476)  acc5: 90.0000 (90.8571)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.6427 (1.4629)  acc1: 68.8000 (70.5920)  acc5: 88.4000 (90.8480)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4688 s / it)
* Acc@1 70.644 Acc@5 90.568 loss 1.463
Accuracy of the model on the 50000 test images: 70.6%
Max accuracy: 70.64%
Epoch: [26]  [   0/1251]  eta: 0:56:54  lr: 0.003995  min_lr: 0.003995  loss: 3.2028 (3.2028)  weight_decay: 0.0500 (0.0500)  time: 2.7297  data: 2.2113  max mem: 40080
Epoch: [26]  [ 200/1251]  eta: 0:08:56  lr: 0.003995  min_lr: 0.003995  loss: 4.2367 (3.9073)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4850 (0.5210)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [26]  [ 400/1251]  eta: 0:07:08  lr: 0.003995  min_lr: 0.003995  loss: 4.1812 (3.9457)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5261 (0.5474)  time: 0.4960  data: 0.0005  max mem: 40080
Epoch: [26]  [ 600/1251]  eta: 0:05:26  lr: 0.003995  min_lr: 0.003995  loss: 4.1245 (3.9422)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5712 (0.5730)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [26]  [ 800/1251]  eta: 0:03:46  lr: 0.003994  min_lr: 0.003994  loss: 4.1656 (3.9453)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5851 (0.5710)  time: 0.4989  data: 0.0004  max mem: 40080
Epoch: [26]  [1000/1251]  eta: 0:02:05  lr: 0.003994  min_lr: 0.003994  loss: 3.8096 (3.9431)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5336 (0.5736)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [26]  [1200/1251]  eta: 0:00:25  lr: 0.003994  min_lr: 0.003994  loss: 3.7990 (3.9552)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6519 (0.5777)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [26]  [1250/1251]  eta: 0:00:00  lr: 0.003994  min_lr: 0.003994  loss: 3.8114 (3.9510)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5709 (0.5790)  time: 0.4210  data: 0.0007  max mem: 40080
Epoch: [26] Total time: 0:10:25 (0.4997 s / it)
Averaged stats: lr: 0.003994  min_lr: 0.003994  loss: 3.8114 (3.9452)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5709 (0.5790)
Test:  [ 0/25]  eta: 0:02:11  loss: 0.9492 (0.9492)  acc1: 80.8000 (80.8000)  acc5: 94.8000 (94.8000)  time: 5.2486  data: 4.9396  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.1481 (1.1658)  acc1: 76.8000 (75.9636)  acc5: 94.8000 (93.9273)  time: 0.7146  data: 0.4493  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.4845 (1.4006)  acc1: 68.4000 (70.8762)  acc5: 89.2000 (90.4952)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.5439 (1.4016)  acc1: 69.2000 (71.0240)  acc5: 88.4000 (90.5280)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4635 s / it)
* Acc@1 70.816 Acc@5 90.734 loss 1.407
Accuracy of the model on the 50000 test images: 70.8%
Max accuracy: 70.82%
Epoch: [27]  [   0/1251]  eta: 0:50:56  lr: 0.003994  min_lr: 0.003994  loss: 4.2782 (4.2782)  weight_decay: 0.0500 (0.0500)  time: 2.4434  data: 1.9399  max mem: 40080
Epoch: [27]  [ 200/1251]  eta: 0:08:53  lr: 0.003994  min_lr: 0.003994  loss: 3.9626 (3.9206)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4817 (0.5267)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [27]  [ 400/1251]  eta: 0:07:08  lr: 0.003993  min_lr: 0.003993  loss: 3.8202 (3.8817)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5952 (0.5674)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [27]  [ 600/1251]  eta: 0:05:26  lr: 0.003993  min_lr: 0.003993  loss: 3.9225 (3.8706)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5219 (0.5724)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [27]  [ 800/1251]  eta: 0:03:46  lr: 0.003993  min_lr: 0.003993  loss: 4.1460 (3.8960)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5065 (0.5813)  time: 0.5023  data: 0.0004  max mem: 40080
Epoch: [27]  [1000/1251]  eta: 0:02:05  lr: 0.003992  min_lr: 0.003992  loss: 4.1420 (3.8894)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5814 (0.5871)  time: 0.4963  data: 0.0005  max mem: 40080
Epoch: [27]  [1200/1251]  eta: 0:00:25  lr: 0.003992  min_lr: 0.003992  loss: 3.6066 (3.9009)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5816 (0.5962)  time: 0.4965  data: 0.0005  max mem: 40080
Epoch: [27]  [1250/1251]  eta: 0:00:00  lr: 0.003992  min_lr: 0.003992  loss: 3.9069 (3.9033)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5408 (0.6018)  time: 0.4274  data: 0.0006  max mem: 40080
Epoch: [27] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.003992  min_lr: 0.003992  loss: 3.9069 (3.9151)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5408 (0.6018)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.9968 (0.9968)  acc1: 84.0000 (84.0000)  acc5: 96.0000 (96.0000)  time: 5.5186  data: 5.2181  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.1331 (1.2001)  acc1: 75.2000 (75.5273)  acc5: 94.8000 (94.1455)  time: 0.7396  data: 0.4747  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.4562 (1.4318)  acc1: 68.0000 (70.7048)  acc5: 89.6000 (90.8762)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.6053 (1.4394)  acc1: 68.4000 (70.9120)  acc5: 88.0000 (90.7520)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4747 s / it)
* Acc@1 71.210 Acc@5 90.904 loss 1.428
Accuracy of the model on the 50000 test images: 71.2%
Max accuracy: 71.21%
Epoch: [28]  [   0/1251]  eta: 0:50:30  lr: 0.003992  min_lr: 0.003992  loss: 4.0929 (4.0929)  weight_decay: 0.0500 (0.0500)  time: 2.4225  data: 1.9051  max mem: 40080
Epoch: [28]  [ 200/1251]  eta: 0:08:52  lr: 0.003992  min_lr: 0.003992  loss: 4.0515 (3.9127)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5486 (0.5772)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [28]  [ 400/1251]  eta: 0:07:07  lr: 0.003991  min_lr: 0.003991  loss: 4.0378 (3.9320)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5736 (0.5957)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [28]  [ 600/1251]  eta: 0:05:25  lr: 0.003991  min_lr: 0.003991  loss: 3.6905 (3.9031)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5214 (0.6022)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [28]  [ 800/1251]  eta: 0:03:45  lr: 0.003991  min_lr: 0.003991  loss: 4.0362 (3.9025)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6015 (0.6159)  time: 0.4972  data: 0.0005  max mem: 40080
Epoch: [28]  [1000/1251]  eta: 0:02:05  lr: 0.003990  min_lr: 0.003990  loss: 3.9289 (3.8934)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5817 (0.6118)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [28]  [1200/1251]  eta: 0:00:25  lr: 0.003990  min_lr: 0.003990  loss: 3.8111 (3.8788)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5606 (0.6019)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [28]  [1250/1251]  eta: 0:00:00  lr: 0.003990  min_lr: 0.003990  loss: 3.9545 (3.8815)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5117 (0.5983)  time: 0.4211  data: 0.0006  max mem: 40080
Epoch: [28] Total time: 0:10:23 (0.4984 s / it)
Averaged stats: lr: 0.003990  min_lr: 0.003990  loss: 3.9545 (3.9005)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5117 (0.5983)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.9581 (0.9581)  acc1: 82.0000 (82.0000)  acc5: 96.0000 (96.0000)  time: 5.5777  data: 5.2896  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.1049 (1.1689)  acc1: 74.8000 (76.1455)  acc5: 95.6000 (94.3636)  time: 0.7449  data: 0.4811  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.4156 (1.3823)  acc1: 68.8000 (71.7143)  acc5: 90.0000 (91.2952)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.5171 (1.3968)  acc1: 68.8000 (71.4560)  acc5: 88.8000 (91.1200)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4771 s / it)
* Acc@1 71.370 Acc@5 91.300 loss 1.393
Accuracy of the model on the 50000 test images: 71.4%
Max accuracy: 71.37%
Epoch: [29]  [   0/1251]  eta: 1:01:29  lr: 0.003990  min_lr: 0.003990  loss: 4.1581 (4.1581)  weight_decay: 0.0500 (0.0500)  time: 2.9491  data: 2.4400  max mem: 40080
Epoch: [29]  [ 200/1251]  eta: 0:08:56  lr: 0.003989  min_lr: 0.003989  loss: 3.8984 (3.8524)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6821 (0.6745)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [29]  [ 400/1251]  eta: 0:07:09  lr: 0.003989  min_lr: 0.003989  loss: 3.9424 (3.8700)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6257 (0.6477)  time: 0.4993  data: 0.0004  max mem: 40080
Epoch: [29]  [ 600/1251]  eta: 0:05:26  lr: 0.003989  min_lr: 0.003989  loss: 3.8031 (3.8735)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6929 (0.6452)  time: 0.4956  data: 0.0004  max mem: 40080
Epoch: [29]  [ 800/1251]  eta: 0:03:46  lr: 0.003988  min_lr: 0.003988  loss: 4.2143 (3.8801)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5802 (0.6393)  time: 0.5056  data: 0.0004  max mem: 40080
Epoch: [29]  [1000/1251]  eta: 0:02:05  lr: 0.003988  min_lr: 0.003988  loss: 3.7483 (3.8727)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5692 (0.6459)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [29]  [1200/1251]  eta: 0:00:25  lr: 0.003988  min_lr: 0.003988  loss: 3.8979 (3.8759)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5585 (0.6333)  time: 0.5050  data: 0.0004  max mem: 40080
Epoch: [29]  [1250/1251]  eta: 0:00:00  lr: 0.003987  min_lr: 0.003987  loss: 3.7246 (3.8747)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5034 (0.6282)  time: 0.4213  data: 0.0005  max mem: 40080
Epoch: [29] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.003987  min_lr: 0.003987  loss: 3.7246 (3.8766)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5034 (0.6282)
Test:  [ 0/25]  eta: 0:02:24  loss: 0.9524 (0.9524)  acc1: 80.0000 (80.0000)  acc5: 96.0000 (96.0000)  time: 5.7672  data: 5.4534  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0586 (1.1022)  acc1: 77.2000 (75.6727)  acc5: 95.2000 (94.5818)  time: 0.7621  data: 0.4961  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.3875 (1.3234)  acc1: 68.8000 (71.7143)  acc5: 91.2000 (91.6000)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.4804 (1.3328)  acc1: 68.8000 (71.6800)  acc5: 89.2000 (91.5680)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4859 s / it)
* Acc@1 72.058 Acc@5 91.402 loss 1.328
Accuracy of the model on the 50000 test images: 72.1%
Max accuracy: 72.06%
Epoch: [30]  [   0/1251]  eta: 1:03:49  lr: 0.003987  min_lr: 0.003987  loss: 4.2981 (4.2981)  weight_decay: 0.0500 (0.0500)  time: 3.0615  data: 2.5473  max mem: 40080
Epoch: [30]  [ 200/1251]  eta: 0:08:57  lr: 0.003987  min_lr: 0.003987  loss: 4.2066 (3.8152)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6187 (0.7151)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [30]  [ 400/1251]  eta: 0:07:09  lr: 0.003987  min_lr: 0.003987  loss: 3.8210 (3.8326)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4864 (0.6463)  time: 0.4966  data: 0.0005  max mem: 40080
Epoch: [30]  [ 600/1251]  eta: 0:05:26  lr: 0.003986  min_lr: 0.003986  loss: 3.9555 (3.8277)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5537 (0.6175)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [30]  [ 800/1251]  eta: 0:03:46  lr: 0.003986  min_lr: 0.003986  loss: 4.0742 (3.8469)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5415 (0.6149)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [30]  [1000/1251]  eta: 0:02:05  lr: 0.003985  min_lr: 0.003985  loss: 4.1501 (3.8429)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5289 (0.6120)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [30]  [1200/1251]  eta: 0:00:25  lr: 0.003985  min_lr: 0.003985  loss: 3.6534 (3.8372)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5587 (0.6268)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [30]  [1250/1251]  eta: 0:00:00  lr: 0.003985  min_lr: 0.003985  loss: 3.8072 (3.8363)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5732 (0.6256)  time: 0.4211  data: 0.0004  max mem: 40080
Epoch: [30] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.003985  min_lr: 0.003985  loss: 3.8072 (3.8520)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5732 (0.6256)
Test:  [ 0/25]  eta: 0:02:21  loss: 0.9673 (0.9673)  acc1: 81.2000 (81.2000)  acc5: 96.4000 (96.4000)  time: 5.6580  data: 5.3565  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0557 (1.1498)  acc1: 77.6000 (76.3273)  acc5: 95.2000 (94.6182)  time: 0.7519  data: 0.4873  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.4133 (1.3539)  acc1: 69.2000 (72.2857)  acc5: 90.8000 (91.4667)  time: 0.2612  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.5441 (1.3670)  acc1: 69.2000 (71.8880)  acc5: 88.4000 (91.3920)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4802 s / it)
* Acc@1 72.132 Acc@5 91.542 loss 1.364
Accuracy of the model on the 50000 test images: 72.1%
Max accuracy: 72.13%
Epoch: [31]  [   0/1251]  eta: 0:58:32  lr: 0.003985  min_lr: 0.003985  loss: 3.0438 (3.0438)  weight_decay: 0.0500 (0.0500)  time: 2.8078  data: 2.2997  max mem: 40080
Epoch: [31]  [ 200/1251]  eta: 0:08:56  lr: 0.003984  min_lr: 0.003984  loss: 4.1162 (3.7962)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6039 (0.6648)  time: 0.4975  data: 0.0005  max mem: 40080
Epoch: [31]  [ 400/1251]  eta: 0:07:08  lr: 0.003984  min_lr: 0.003984  loss: 4.0848 (3.8370)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5542 (0.6468)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [31]  [ 600/1251]  eta: 0:05:26  lr: 0.003983  min_lr: 0.003983  loss: 3.6204 (3.8379)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5656 (0.6234)  time: 0.5064  data: 0.0004  max mem: 40080
Epoch: [31]  [ 800/1251]  eta: 0:03:45  lr: 0.003983  min_lr: 0.003983  loss: 3.9662 (3.8440)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5285 (0.6070)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [31]  [1000/1251]  eta: 0:02:05  lr: 0.003982  min_lr: 0.003982  loss: 4.0381 (3.8528)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4939 (0.5985)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [31]  [1200/1251]  eta: 0:00:25  lr: 0.003982  min_lr: 0.003982  loss: 3.7545 (3.8472)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6421 (0.6115)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [31]  [1250/1251]  eta: 0:00:00  lr: 0.003982  min_lr: 0.003982  loss: 3.8578 (3.8449)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6858 (0.6157)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [31] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.003982  min_lr: 0.003982  loss: 3.8578 (3.8472)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6858 (0.6157)
Test:  [ 0/25]  eta: 0:02:14  loss: 0.8816 (0.8816)  acc1: 84.4000 (84.4000)  acc5: 97.6000 (97.6000)  time: 5.3613  data: 5.0629  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.0520 (1.0986)  acc1: 77.2000 (77.5636)  acc5: 95.2000 (94.8000)  time: 0.7251  data: 0.4606  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.3621 (1.3103)  acc1: 69.6000 (72.8571)  acc5: 91.2000 (91.7524)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.4280 (1.3272)  acc1: 69.6000 (72.5280)  acc5: 90.0000 (91.5840)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4687 s / it)
* Acc@1 72.480 Acc@5 91.748 loss 1.317
Accuracy of the model on the 50000 test images: 72.5%
Max accuracy: 72.48%
Epoch: [32]  [   0/1251]  eta: 0:58:46  lr: 0.003982  min_lr: 0.003982  loss: 4.1379 (4.1379)  weight_decay: 0.0500 (0.0500)  time: 2.8192  data: 2.3197  max mem: 40080
Epoch: [32]  [ 200/1251]  eta: 0:08:54  lr: 0.003981  min_lr: 0.003981  loss: 3.6024 (3.8093)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5588 (0.5798)  time: 0.4990  data: 0.0005  max mem: 40080
Epoch: [32]  [ 400/1251]  eta: 0:07:09  lr: 0.003981  min_lr: 0.003981  loss: 3.6243 (3.8359)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5036 (0.6207)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [32]  [ 600/1251]  eta: 0:05:26  lr: 0.003980  min_lr: 0.003980  loss: 3.9131 (3.8426)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6021 (0.6039)  time: 0.4955  data: 0.0005  max mem: 40080
Epoch: [32]  [ 800/1251]  eta: 0:03:45  lr: 0.003980  min_lr: 0.003980  loss: 3.8407 (3.8304)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5059 (0.6088)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [32]  [1000/1251]  eta: 0:02:05  lr: 0.003979  min_lr: 0.003979  loss: 3.5540 (3.8135)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6088 (0.6235)  time: 0.4979  data: 0.0005  max mem: 40080
Epoch: [32]  [1200/1251]  eta: 0:00:25  lr: 0.003979  min_lr: 0.003979  loss: 4.0214 (3.8284)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6832 (0.6443)  time: 0.4959  data: 0.0005  max mem: 40080
Epoch: [32]  [1250/1251]  eta: 0:00:00  lr: 0.003979  min_lr: 0.003979  loss: 3.7742 (3.8299)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4940 (0.6383)  time: 0.4206  data: 0.0006  max mem: 40080
Epoch: [32] Total time: 0:10:23 (0.4984 s / it)
Averaged stats: lr: 0.003979  min_lr: 0.003979  loss: 3.7742 (3.8235)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4940 (0.6383)
Test:  [ 0/25]  eta: 0:02:33  loss: 0.8854 (0.8854)  acc1: 85.6000 (85.6000)  acc5: 96.8000 (96.8000)  time: 6.1325  data: 5.8280  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0735 (1.1116)  acc1: 79.2000 (77.5636)  acc5: 95.6000 (94.8727)  time: 0.7950  data: 0.5301  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.4336 (1.3209)  acc1: 69.2000 (73.3905)  acc5: 92.4000 (91.7333)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.5326 (1.3373)  acc1: 69.2000 (72.8160)  acc5: 89.2000 (91.5840)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4997 s / it)
* Acc@1 72.618 Acc@5 91.852 loss 1.332
Accuracy of the model on the 50000 test images: 72.6%
Max accuracy: 72.62%
Epoch: [33]  [   0/1251]  eta: 0:53:24  lr: 0.003979  min_lr: 0.003979  loss: 2.8199 (2.8199)  weight_decay: 0.0500 (0.0500)  time: 2.5612  data: 2.0561  max mem: 40080
Epoch: [33]  [ 200/1251]  eta: 0:08:53  lr: 0.003978  min_lr: 0.003978  loss: 3.8569 (3.7761)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5256 (0.5633)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [33]  [ 400/1251]  eta: 0:07:08  lr: 0.003978  min_lr: 0.003978  loss: 4.0143 (3.7828)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6467 (0.6266)  time: 0.5005  data: 0.0005  max mem: 40080
Epoch: [33]  [ 600/1251]  eta: 0:05:26  lr: 0.003977  min_lr: 0.003977  loss: 3.8865 (3.7563)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4956 (0.6299)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [33]  [ 800/1251]  eta: 0:03:45  lr: 0.003977  min_lr: 0.003977  loss: 3.9538 (3.7676)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4888 (0.6425)  time: 0.4962  data: 0.0005  max mem: 40080
Epoch: [33]  [1000/1251]  eta: 0:02:05  lr: 0.003976  min_lr: 0.003976  loss: 4.0137 (3.7776)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7490 (0.6485)  time: 0.4964  data: 0.0005  max mem: 40080
Epoch: [33]  [1200/1251]  eta: 0:00:25  lr: 0.003976  min_lr: 0.003976  loss: 3.7153 (3.7826)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5252 (0.6541)  time: 0.4997  data: 0.0004  max mem: 40080
Epoch: [33]  [1250/1251]  eta: 0:00:00  lr: 0.003975  min_lr: 0.003975  loss: 3.9180 (3.7861)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5493 (0.6547)  time: 0.4214  data: 0.0005  max mem: 40080
Epoch: [33] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.003975  min_lr: 0.003975  loss: 3.9180 (3.8053)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5493 (0.6547)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.9356 (0.9356)  acc1: 83.6000 (83.6000)  acc5: 97.2000 (97.2000)  time: 5.4719  data: 5.1491  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.1318 (1.1627)  acc1: 76.8000 (76.5818)  acc5: 96.0000 (94.9455)  time: 0.7353  data: 0.4684  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.4448 (1.3594)  acc1: 70.0000 (72.3048)  acc5: 91.6000 (92.0381)  time: 0.2616  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.4985 (1.3678)  acc1: 69.6000 (72.0640)  acc5: 89.6000 (92.0160)  time: 0.2615  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4768 s / it)
* Acc@1 72.864 Acc@5 92.022 loss 1.365
Accuracy of the model on the 50000 test images: 72.9%
Max accuracy: 72.86%
Epoch: [34]  [   0/1251]  eta: 0:51:14  lr: 0.003975  min_lr: 0.003975  loss: 4.0313 (4.0313)  weight_decay: 0.0500 (0.0500)  time: 2.4577  data: 1.9571  max mem: 40080
Epoch: [34]  [ 200/1251]  eta: 0:08:54  lr: 0.003975  min_lr: 0.003975  loss: 3.8159 (3.7461)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6226 (0.6374)  time: 0.4966  data: 0.0005  max mem: 40080
Epoch: [34]  [ 400/1251]  eta: 0:07:08  lr: 0.003974  min_lr: 0.003974  loss: 3.8685 (3.7736)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5812 (0.6686)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [34]  [ 600/1251]  eta: 0:05:26  lr: 0.003974  min_lr: 0.003974  loss: 3.8551 (3.7612)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7030 (0.6811)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [34]  [ 800/1251]  eta: 0:03:45  lr: 0.003973  min_lr: 0.003973  loss: 3.8536 (3.7820)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4851 (0.6501)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [34]  [1000/1251]  eta: 0:02:05  lr: 0.003972  min_lr: 0.003972  loss: 4.0154 (3.7929)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5868 (0.6627)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [34]  [1200/1251]  eta: 0:00:25  lr: 0.003972  min_lr: 0.003972  loss: 3.5690 (3.7870)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5801 (0.6661)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [34]  [1250/1251]  eta: 0:00:00  lr: 0.003972  min_lr: 0.003972  loss: 3.6798 (3.7857)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5527 (0.6655)  time: 0.4297  data: 0.0005  max mem: 40080
Epoch: [34] Total time: 0:10:23 (0.4985 s / it)
Averaged stats: lr: 0.003972  min_lr: 0.003972  loss: 3.6798 (3.7929)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5527 (0.6655)
Test:  [ 0/25]  eta: 0:02:11  loss: 0.9326 (0.9326)  acc1: 83.2000 (83.2000)  acc5: 97.2000 (97.2000)  time: 5.2729  data: 4.9505  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.0441 (1.1172)  acc1: 80.0000 (77.6000)  acc5: 96.0000 (94.6909)  time: 0.7166  data: 0.4505  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.3434 (1.3224)  acc1: 69.2000 (73.1810)  acc5: 91.2000 (92.0191)  time: 0.2607  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.4330 (1.3320)  acc1: 70.0000 (73.0240)  acc5: 90.8000 (92.0320)  time: 0.2606  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4646 s / it)
* Acc@1 73.232 Acc@5 92.110 loss 1.330
Accuracy of the model on the 50000 test images: 73.2%
Max accuracy: 73.23%
Epoch: [35]  [   0/1251]  eta: 0:55:49  lr: 0.003972  min_lr: 0.003972  loss: 3.2638 (3.2638)  weight_decay: 0.0500 (0.0500)  time: 2.6775  data: 2.1629  max mem: 40080
Epoch: [35]  [ 200/1251]  eta: 0:08:53  lr: 0.003971  min_lr: 0.003971  loss: 3.6112 (3.7438)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6124 (inf)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [35]  [ 400/1251]  eta: 0:07:07  lr: 0.003971  min_lr: 0.003971  loss: 3.9124 (3.7761)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5273 (inf)  time: 0.4964  data: 0.0005  max mem: 40080
Epoch: [35]  [ 600/1251]  eta: 0:05:26  lr: 0.003970  min_lr: 0.003970  loss: 3.7379 (3.7995)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5395 (inf)  time: 0.4953  data: 0.0004  max mem: 40080
Epoch: [35]  [ 800/1251]  eta: 0:03:45  lr: 0.003969  min_lr: 0.003969  loss: 4.0213 (3.7921)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6430 (inf)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [35]  [1000/1251]  eta: 0:02:05  lr: 0.003969  min_lr: 0.003969  loss: 3.6738 (3.7883)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5532 (inf)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [35]  [1200/1251]  eta: 0:00:25  lr: 0.003968  min_lr: 0.003968  loss: 3.7880 (3.7850)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5564 (inf)  time: 0.4954  data: 0.0004  max mem: 40080
Epoch: [35]  [1250/1251]  eta: 0:00:00  lr: 0.003968  min_lr: 0.003968  loss: 3.7303 (3.7831)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7184 (inf)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [35] Total time: 0:10:22 (0.4978 s / it)
Averaged stats: lr: 0.003968  min_lr: 0.003968  loss: 3.7303 (3.7860)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7184 (inf)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.8463 (0.8463)  acc1: 83.6000 (83.6000)  acc5: 96.4000 (96.4000)  time: 5.5940  data: 5.2854  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0360 (1.0790)  acc1: 78.4000 (77.8546)  acc5: 95.6000 (94.9818)  time: 0.7464  data: 0.4808  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.3555 (1.2604)  acc1: 70.4000 (73.8857)  acc5: 92.4000 (92.5524)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.3881 (1.2756)  acc1: 71.2000 (73.6960)  acc5: 90.8000 (92.4320)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4784 s / it)
* Acc@1 73.618 Acc@5 92.272 loss 1.275
Accuracy of the model on the 50000 test images: 73.6%
Max accuracy: 73.62%
Epoch: [36]  [   0/1251]  eta: 0:54:26  lr: 0.003968  min_lr: 0.003968  loss: 3.9914 (3.9914)  weight_decay: 0.0500 (0.0500)  time: 2.6114  data: 2.0989  max mem: 40080
Epoch: [36]  [ 200/1251]  eta: 0:08:54  lr: 0.003967  min_lr: 0.003967  loss: 3.8003 (3.8257)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6772 (0.6930)  time: 0.4977  data: 0.0005  max mem: 40080
Epoch: [36]  [ 400/1251]  eta: 0:07:08  lr: 0.003967  min_lr: 0.003967  loss: 3.6978 (3.8065)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7529 (0.7231)  time: 0.5049  data: 0.0004  max mem: 40080
Epoch: [36]  [ 600/1251]  eta: 0:05:26  lr: 0.003966  min_lr: 0.003966  loss: 3.2508 (3.7797)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6568 (0.7272)  time: 0.4982  data: 0.0005  max mem: 40080
Epoch: [36]  [ 800/1251]  eta: 0:03:45  lr: 0.003965  min_lr: 0.003965  loss: 4.0385 (3.7740)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7570 (0.7173)  time: 0.5078  data: 0.0004  max mem: 40080
Epoch: [36]  [1000/1251]  eta: 0:02:05  lr: 0.003965  min_lr: 0.003965  loss: 3.8599 (3.7572)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5597 (0.7179)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [36]  [1200/1251]  eta: 0:00:25  lr: 0.003964  min_lr: 0.003964  loss: 4.0639 (3.7677)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6670 (0.7307)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [36]  [1250/1251]  eta: 0:00:00  lr: 0.003964  min_lr: 0.003964  loss: 4.0940 (3.7691)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6122 (0.7267)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [36] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.003964  min_lr: 0.003964  loss: 4.0940 (3.7656)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6122 (0.7267)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.9225 (0.9225)  acc1: 82.4000 (82.4000)  acc5: 97.6000 (97.6000)  time: 5.6297  data: 5.3411  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0580 (1.1454)  acc1: 77.6000 (77.4545)  acc5: 95.2000 (94.6182)  time: 0.7496  data: 0.4858  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.4064 (1.3634)  acc1: 70.4000 (73.0476)  acc5: 92.0000 (91.9429)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.5622 (1.3744)  acc1: 70.4000 (72.8480)  acc5: 90.0000 (91.9040)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4791 s / it)
* Acc@1 73.446 Acc@5 92.220 loss 1.363
Accuracy of the model on the 50000 test images: 73.4%
Max accuracy: 73.62%
Epoch: [37]  [   0/1251]  eta: 1:14:00  lr: 0.003964  min_lr: 0.003964  loss: 3.6949 (3.6949)  weight_decay: 0.0500 (0.0500)  time: 3.5499  data: 2.7282  max mem: 40080
Epoch: [37]  [ 200/1251]  eta: 0:08:59  lr: 0.003963  min_lr: 0.003963  loss: 3.8996 (3.7943)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5979 (0.7060)  time: 0.4956  data: 0.0005  max mem: 40080
Epoch: [37]  [ 400/1251]  eta: 0:07:10  lr: 0.003962  min_lr: 0.003962  loss: 4.0268 (3.7610)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5194 (0.6827)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [37]  [ 600/1251]  eta: 0:05:27  lr: 0.003962  min_lr: 0.003962  loss: 3.9403 (3.7454)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5966 (0.7050)  time: 0.5069  data: 0.0004  max mem: 40080
Epoch: [37]  [ 800/1251]  eta: 0:03:46  lr: 0.003961  min_lr: 0.003961  loss: 3.8755 (3.7621)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7307 (0.7246)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [37]  [1000/1251]  eta: 0:02:05  lr: 0.003960  min_lr: 0.003960  loss: 3.7917 (3.7632)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5047 (0.7167)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [37]  [1200/1251]  eta: 0:00:25  lr: 0.003960  min_lr: 0.003960  loss: 3.9780 (3.7665)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7556 (0.7323)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [37]  [1250/1251]  eta: 0:00:00  lr: 0.003959  min_lr: 0.003959  loss: 3.9345 (3.7695)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5748 (0.7288)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [37] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.003959  min_lr: 0.003959  loss: 3.9345 (3.7589)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5748 (0.7288)
Test:  [ 0/25]  eta: 0:01:51  loss: 0.8562 (0.8562)  acc1: 84.8000 (84.8000)  acc5: 97.6000 (97.6000)  time: 4.4661  data: 4.1203  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.1066 (1.1153)  acc1: 76.8000 (77.9273)  acc5: 95.6000 (95.3455)  time: 0.7012  data: 0.4326  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.3185 (1.2958)  acc1: 70.8000 (73.5429)  acc5: 92.0000 (92.7238)  time: 0.2928  data: 0.0320  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.4164 (1.3029)  acc1: 70.8000 (73.2960)  acc5: 90.0000 (92.5280)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4583 s / it)
* Acc@1 73.926 Acc@5 92.540 loss 1.295
Accuracy of the model on the 50000 test images: 73.9%
Max accuracy: 73.93%
Epoch: [38]  [   0/1251]  eta: 0:55:29  lr: 0.003959  min_lr: 0.003959  loss: 4.1992 (4.1992)  weight_decay: 0.0500 (0.0500)  time: 2.6614  data: 2.1588  max mem: 40080
Epoch: [38]  [ 200/1251]  eta: 0:08:54  lr: 0.003959  min_lr: 0.003959  loss: 3.8853 (3.7563)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6250 (0.7152)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [38]  [ 400/1251]  eta: 0:07:08  lr: 0.003958  min_lr: 0.003958  loss: 3.6946 (3.7771)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5051 (0.6775)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [38]  [ 600/1251]  eta: 0:05:26  lr: 0.003957  min_lr: 0.003957  loss: 3.9165 (3.7778)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6298 (0.7112)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [38]  [ 800/1251]  eta: 0:03:45  lr: 0.003956  min_lr: 0.003956  loss: 3.9638 (3.7651)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5365 (0.6903)  time: 0.4994  data: 0.0004  max mem: 40080
Epoch: [38]  [1000/1251]  eta: 0:02:05  lr: 0.003956  min_lr: 0.003956  loss: 3.8535 (3.7698)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7331 (0.7109)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [38]  [1200/1251]  eta: 0:00:25  lr: 0.003955  min_lr: 0.003955  loss: 3.9503 (3.7697)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6385 (0.7169)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [38]  [1250/1251]  eta: 0:00:00  lr: 0.003955  min_lr: 0.003955  loss: 3.4295 (3.7647)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7323 (0.7277)  time: 0.4297  data: 0.0005  max mem: 40080
Epoch: [38] Total time: 0:10:24 (0.4989 s / it)
Averaged stats: lr: 0.003955  min_lr: 0.003955  loss: 3.4295 (3.7446)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7323 (0.7277)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.8357 (0.8357)  acc1: 83.2000 (83.2000)  acc5: 97.6000 (97.6000)  time: 5.5508  data: 5.2486  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0213 (1.0386)  acc1: 79.2000 (78.3636)  acc5: 96.0000 (95.4909)  time: 0.7421  data: 0.4774  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2488 (1.2222)  acc1: 70.0000 (74.2286)  acc5: 92.0000 (92.9143)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.3718 (1.2352)  acc1: 70.0000 (73.9200)  acc5: 90.4000 (92.6560)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4761 s / it)
* Acc@1 74.306 Acc@5 92.598 loss 1.240
Accuracy of the model on the 50000 test images: 74.3%
Max accuracy: 74.31%
Epoch: [39]  [   0/1251]  eta: 0:45:35  lr: 0.003955  min_lr: 0.003955  loss: 4.0199 (4.0199)  weight_decay: 0.0500 (0.0500)  time: 2.1870  data: 1.6792  max mem: 40080
Epoch: [39]  [ 200/1251]  eta: 0:08:52  lr: 0.003954  min_lr: 0.003954  loss: 3.6541 (3.7097)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5448 (0.7664)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [39]  [ 400/1251]  eta: 0:07:07  lr: 0.003953  min_lr: 0.003953  loss: 3.7971 (3.7529)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6819 (0.7376)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [39]  [ 600/1251]  eta: 0:05:26  lr: 0.003952  min_lr: 0.003952  loss: 3.8166 (3.7582)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5355 (0.7645)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [39]  [ 800/1251]  eta: 0:03:45  lr: 0.003952  min_lr: 0.003952  loss: 3.7281 (3.7659)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7723 (0.7584)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [39]  [1000/1251]  eta: 0:02:05  lr: 0.003951  min_lr: 0.003951  loss: 3.8503 (3.7502)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5826 (0.7334)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [39]  [1200/1251]  eta: 0:00:25  lr: 0.003950  min_lr: 0.003950  loss: 3.9158 (3.7470)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5676 (0.7276)  time: 0.4985  data: 0.0005  max mem: 40080
Epoch: [39]  [1250/1251]  eta: 0:00:00  lr: 0.003950  min_lr: 0.003950  loss: 3.9518 (3.7509)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6306 (0.7317)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [39] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.003950  min_lr: 0.003950  loss: 3.9518 (3.7258)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6306 (0.7317)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.8830 (0.8830)  acc1: 82.0000 (82.0000)  acc5: 98.8000 (98.8000)  time: 5.4462  data: 5.1456  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.0379 (1.1286)  acc1: 80.4000 (78.8364)  acc5: 96.0000 (95.7818)  time: 0.7329  data: 0.4681  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.4232 (1.3298)  acc1: 71.2000 (74.3619)  acc5: 92.8000 (92.8762)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.4419 (1.3367)  acc1: 73.2000 (74.3680)  acc5: 90.0000 (92.6400)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4726 s / it)
* Acc@1 74.384 Acc@5 92.580 loss 1.330
Accuracy of the model on the 50000 test images: 74.4%
Max accuracy: 74.38%
Epoch: [40]  [   0/1251]  eta: 0:55:52  lr: 0.003950  min_lr: 0.003950  loss: 3.2351 (3.2351)  weight_decay: 0.0500 (0.0500)  time: 2.6801  data: 2.1728  max mem: 40080
Epoch: [40]  [ 200/1251]  eta: 0:08:54  lr: 0.003949  min_lr: 0.003949  loss: 3.7127 (3.7224)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7092 (0.8817)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [40]  [ 400/1251]  eta: 0:07:08  lr: 0.003948  min_lr: 0.003948  loss: 3.0658 (3.6999)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5744 (0.8020)  time: 0.5068  data: 0.0004  max mem: 40080
Epoch: [40]  [ 600/1251]  eta: 0:05:26  lr: 0.003947  min_lr: 0.003947  loss: 3.7843 (3.7394)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6067 (0.7756)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [40]  [ 800/1251]  eta: 0:03:45  lr: 0.003947  min_lr: 0.003947  loss: 3.9821 (3.7387)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7645 (0.7932)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [40]  [1000/1251]  eta: 0:02:05  lr: 0.003946  min_lr: 0.003946  loss: 3.7026 (3.7433)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7079 (0.7869)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [40]  [1200/1251]  eta: 0:00:25  lr: 0.003945  min_lr: 0.003945  loss: 3.9723 (3.7470)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6961 (0.7982)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [40]  [1250/1251]  eta: 0:00:00  lr: 0.003945  min_lr: 0.003945  loss: 3.9603 (3.7434)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7121 (0.7982)  time: 0.4210  data: 0.0006  max mem: 40080
Epoch: [40] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.003945  min_lr: 0.003945  loss: 3.9603 (3.7162)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7121 (0.7982)
Test:  [ 0/25]  eta: 0:02:24  loss: 0.8782 (0.8782)  acc1: 85.6000 (85.6000)  acc5: 97.6000 (97.6000)  time: 5.7973  data: 5.4820  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.1051 (1.0862)  acc1: 78.0000 (78.8727)  acc5: 96.0000 (95.7091)  time: 0.7645  data: 0.4986  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.3504 (1.2772)  acc1: 72.0000 (74.9143)  acc5: 91.6000 (92.7048)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.4437 (1.2899)  acc1: 72.0000 (74.4160)  acc5: 90.4000 (92.5920)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4857 s / it)
* Acc@1 74.332 Acc@5 92.716 loss 1.285
Accuracy of the model on the 50000 test images: 74.3%
Max accuracy: 74.38%
Epoch: [41]  [   0/1251]  eta: 1:11:43  lr: 0.003945  min_lr: 0.003945  loss: 3.9771 (3.9771)  weight_decay: 0.0500 (0.0500)  time: 3.4403  data: 1.5941  max mem: 40080
Epoch: [41]  [ 200/1251]  eta: 0:09:01  lr: 0.003944  min_lr: 0.003944  loss: 3.7975 (3.6193)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6694 (0.7163)  time: 0.4992  data: 0.0004  max mem: 40080
Epoch: [41]  [ 400/1251]  eta: 0:07:11  lr: 0.003943  min_lr: 0.003943  loss: 3.6973 (3.6721)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7057 (0.7740)  time: 0.4990  data: 0.0004  max mem: 40080
Epoch: [41]  [ 600/1251]  eta: 0:05:28  lr: 0.003942  min_lr: 0.003942  loss: 3.7947 (3.6813)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6243 (0.7830)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [41]  [ 800/1251]  eta: 0:03:46  lr: 0.003941  min_lr: 0.003941  loss: 3.7946 (3.6964)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6070 (0.7838)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [41]  [1000/1251]  eta: 0:02:05  lr: 0.003940  min_lr: 0.003940  loss: 3.8676 (3.7106)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7144 (0.7797)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [41]  [1200/1251]  eta: 0:00:25  lr: 0.003940  min_lr: 0.003940  loss: 3.9052 (3.7147)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7553 (0.7813)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [41]  [1250/1251]  eta: 0:00:00  lr: 0.003939  min_lr: 0.003939  loss: 3.8878 (3.7199)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4204  data: 0.0006  max mem: 40080
Epoch: [41] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.003939  min_lr: 0.003939  loss: 3.8878 (3.7158)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:02:27  loss: 0.8801 (0.8801)  acc1: 83.6000 (83.6000)  acc5: 98.0000 (98.0000)  time: 5.9019  data: 5.6047  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0974 (1.1148)  acc1: 80.4000 (79.2000)  acc5: 95.2000 (95.3455)  time: 0.7746  data: 0.5098  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.3652 (1.3251)  acc1: 70.8000 (74.8952)  acc5: 92.4000 (92.4952)  time: 0.2617  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.4773 (1.3293)  acc1: 71.2000 (74.6720)  acc5: 90.8000 (92.5440)  time: 0.2616  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4908 s / it)
* Acc@1 74.572 Acc@5 92.642 loss 1.326
Accuracy of the model on the 50000 test images: 74.6%
Max accuracy: 74.57%
Epoch: [42]  [   0/1251]  eta: 0:56:14  lr: 0.003939  min_lr: 0.003939  loss: 3.8841 (3.8841)  weight_decay: 0.0500 (0.0500)  time: 2.6977  data: 2.1976  max mem: 40080
Epoch: [42]  [ 200/1251]  eta: 0:08:55  lr: 0.003939  min_lr: 0.003939  loss: 3.8529 (3.7612)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0939 (0.8842)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [42]  [ 400/1251]  eta: 0:07:08  lr: 0.003938  min_lr: 0.003938  loss: 3.5795 (3.7004)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7542 (0.8494)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [42]  [ 600/1251]  eta: 0:05:26  lr: 0.003937  min_lr: 0.003937  loss: 3.5568 (3.6827)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7604 (0.8333)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [42]  [ 800/1251]  eta: 0:03:45  lr: 0.003936  min_lr: 0.003936  loss: 3.5047 (3.6839)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6477 (0.8192)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [42]  [1000/1251]  eta: 0:02:05  lr: 0.003935  min_lr: 0.003935  loss: 3.8510 (3.6786)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7111 (0.8120)  time: 0.4964  data: 0.0005  max mem: 40080
Epoch: [42]  [1200/1251]  eta: 0:00:25  lr: 0.003934  min_lr: 0.003934  loss: 3.7642 (3.6861)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7006 (0.8103)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [42]  [1250/1251]  eta: 0:00:00  lr: 0.003934  min_lr: 0.003934  loss: 3.6558 (3.6791)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7611 (0.8280)  time: 0.4296  data: 0.0006  max mem: 40080
Epoch: [42] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.003934  min_lr: 0.003934  loss: 3.6558 (3.6933)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7611 (0.8280)
Test:  [ 0/25]  eta: 0:02:08  loss: 0.7568 (0.7568)  acc1: 84.8000 (84.8000)  acc5: 97.2000 (97.2000)  time: 5.1585  data: 4.8435  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8913 (0.9495)  acc1: 80.4000 (79.4182)  acc5: 96.4000 (95.3818)  time: 0.7070  data: 0.4407  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2208 (1.1378)  acc1: 71.6000 (75.1810)  acc5: 92.0000 (93.0095)  time: 0.2616  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2712 (1.1502)  acc1: 71.6000 (74.7520)  acc5: 91.2000 (92.9760)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4608 s / it)
* Acc@1 75.022 Acc@5 92.976 loss 1.150
Accuracy of the model on the 50000 test images: 75.0%
Max accuracy: 75.02%
Epoch: [43]  [   0/1251]  eta: 0:48:07  lr: 0.003934  min_lr: 0.003934  loss: 3.7534 (3.7534)  weight_decay: 0.0500 (0.0500)  time: 2.3081  data: 1.8104  max mem: 40080
Epoch: [43]  [ 200/1251]  eta: 0:08:52  lr: 0.003933  min_lr: 0.003933  loss: 3.7566 (3.6886)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9226 (0.8834)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [43]  [ 400/1251]  eta: 0:07:07  lr: 0.003932  min_lr: 0.003932  loss: 3.8611 (3.6974)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6349 (0.7539)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [43]  [ 600/1251]  eta: 0:05:26  lr: 0.003931  min_lr: 0.003931  loss: 3.9215 (3.6992)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7380 (0.7848)  time: 0.5053  data: 0.0004  max mem: 40080
Epoch: [43]  [ 800/1251]  eta: 0:03:45  lr: 0.003930  min_lr: 0.003930  loss: 3.5563 (3.6846)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6446 (0.7821)  time: 0.4975  data: 0.0005  max mem: 40080
Epoch: [43]  [1000/1251]  eta: 0:02:05  lr: 0.003929  min_lr: 0.003929  loss: 3.5909 (3.6896)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5462 (0.7903)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [43]  [1200/1251]  eta: 0:00:25  lr: 0.003928  min_lr: 0.003928  loss: 3.9138 (3.6747)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6389 (0.7799)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [43]  [1250/1251]  eta: 0:00:00  lr: 0.003928  min_lr: 0.003928  loss: 3.9080 (3.6792)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8609 (0.7947)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [43] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.003928  min_lr: 0.003928  loss: 3.9080 (3.6839)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8609 (0.7947)
Test:  [ 0/25]  eta: 0:01:59  loss: 0.8986 (0.8986)  acc1: 84.0000 (84.0000)  acc5: 97.2000 (97.2000)  time: 4.7673  data: 4.4331  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.0015 (1.0441)  acc1: 82.4000 (79.2364)  acc5: 95.6000 (95.4546)  time: 0.6714  data: 0.4035  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2615 (1.2476)  acc1: 72.8000 (75.1048)  acc5: 92.0000 (92.7238)  time: 0.2616  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.3893 (1.2577)  acc1: 73.2000 (74.9920)  acc5: 90.4000 (92.6720)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4457 s / it)
* Acc@1 74.922 Acc@5 93.018 loss 1.251
Accuracy of the model on the 50000 test images: 74.9%
Max accuracy: 75.02%
Epoch: [44]  [   0/1251]  eta: 1:13:14  lr: 0.003928  min_lr: 0.003928  loss: 4.2284 (4.2284)  weight_decay: 0.0500 (0.0500)  time: 3.5131  data: 2.7555  max mem: 40080
Epoch: [44]  [ 200/1251]  eta: 0:08:58  lr: 0.003927  min_lr: 0.003927  loss: 3.7276 (3.6273)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8034 (0.8766)  time: 0.4965  data: 0.0005  max mem: 40080
Epoch: [44]  [ 400/1251]  eta: 0:07:10  lr: 0.003926  min_lr: 0.003926  loss: 3.7305 (3.6480)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7400 (0.8414)  time: 0.5056  data: 0.0004  max mem: 40080
Epoch: [44]  [ 600/1251]  eta: 0:05:27  lr: 0.003925  min_lr: 0.003925  loss: 3.7402 (3.6688)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5923 (0.8223)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [44]  [ 800/1251]  eta: 0:03:45  lr: 0.003924  min_lr: 0.003924  loss: 3.7034 (3.6774)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6601 (0.8273)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [44]  [1000/1251]  eta: 0:02:05  lr: 0.003923  min_lr: 0.003923  loss: 3.7288 (3.6654)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8406 (0.8532)  time: 0.4998  data: 0.0004  max mem: 40080
Epoch: [44]  [1200/1251]  eta: 0:00:25  lr: 0.003922  min_lr: 0.003922  loss: 3.7458 (3.6740)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1494 (0.8679)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [44]  [1250/1251]  eta: 0:00:00  lr: 0.003922  min_lr: 0.003922  loss: 3.4611 (3.6699)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6166 (0.8580)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [44] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.003922  min_lr: 0.003922  loss: 3.4611 (3.6731)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6166 (0.8580)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.7121 (0.7121)  acc1: 84.4000 (84.4000)  acc5: 97.6000 (97.6000)  time: 5.5442  data: 5.2284  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9408 (0.9456)  acc1: 80.0000 (78.9091)  acc5: 96.0000 (95.8909)  time: 0.7419  data: 0.4757  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1996 (1.1524)  acc1: 72.0000 (74.9524)  acc5: 93.2000 (93.0667)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.3072 (1.1711)  acc1: 70.8000 (74.4160)  acc5: 90.8000 (92.9760)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4774 s / it)
* Acc@1 75.080 Acc@5 93.066 loss 1.160
Accuracy of the model on the 50000 test images: 75.1%
Max accuracy: 75.08%
Epoch: [45]  [   0/1251]  eta: 0:55:21  lr: 0.003922  min_lr: 0.003922  loss: 3.9077 (3.9077)  weight_decay: 0.0500 (0.0500)  time: 2.6554  data: 2.1466  max mem: 40080
Epoch: [45]  [ 200/1251]  eta: 0:08:54  lr: 0.003921  min_lr: 0.003921  loss: 3.7949 (3.7210)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8184 (0.8802)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [45]  [ 400/1251]  eta: 0:07:08  lr: 0.003920  min_lr: 0.003920  loss: 3.7762 (3.7034)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8234 (0.8233)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [45]  [ 600/1251]  eta: 0:05:26  lr: 0.003919  min_lr: 0.003919  loss: 3.7464 (3.6885)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7180 (0.8451)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [45]  [ 800/1251]  eta: 0:03:45  lr: 0.003918  min_lr: 0.003918  loss: 3.8490 (3.6833)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6096 (0.8277)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [45]  [1000/1251]  eta: 0:02:05  lr: 0.003917  min_lr: 0.003917  loss: 3.7836 (3.6795)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0690 (0.8480)  time: 0.4986  data: 0.0005  max mem: 40080
Epoch: [45]  [1200/1251]  eta: 0:00:25  lr: 0.003916  min_lr: 0.003916  loss: 3.5551 (3.6684)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9874 (0.8537)  time: 0.5060  data: 0.0005  max mem: 40080
Epoch: [45]  [1250/1251]  eta: 0:00:00  lr: 0.003916  min_lr: 0.003916  loss: 3.5775 (3.6672)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6365 (0.8448)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [45] Total time: 0:10:24 (0.4990 s / it)
Averaged stats: lr: 0.003916  min_lr: 0.003916  loss: 3.5775 (3.6642)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6365 (0.8448)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.8533 (0.8533)  acc1: 85.2000 (85.2000)  acc5: 98.4000 (98.4000)  time: 5.4177  data: 5.1155  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.0550 (1.0579)  acc1: 80.4000 (79.0909)  acc5: 96.0000 (95.6364)  time: 0.7302  data: 0.4653  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2871 (1.2562)  acc1: 72.4000 (74.9143)  acc5: 92.8000 (92.9524)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.4201 (1.2615)  acc1: 72.4000 (74.6720)  acc5: 92.0000 (92.8480)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4711 s / it)
* Acc@1 75.266 Acc@5 93.044 loss 1.247
Accuracy of the model on the 50000 test images: 75.3%
Max accuracy: 75.27%
Epoch: [46]  [   0/1251]  eta: 0:55:05  lr: 0.003916  min_lr: 0.003916  loss: 4.2397 (4.2397)  weight_decay: 0.0500 (0.0500)  time: 2.6423  data: 2.1329  max mem: 40080
Epoch: [46]  [ 200/1251]  eta: 0:08:54  lr: 0.003914  min_lr: 0.003914  loss: 3.8305 (3.6324)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8311 (0.9669)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [46]  [ 400/1251]  eta: 0:07:08  lr: 0.003913  min_lr: 0.003913  loss: 3.8573 (3.6590)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5672 (0.8700)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [46]  [ 600/1251]  eta: 0:05:26  lr: 0.003912  min_lr: 0.003912  loss: 3.4656 (3.6373)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7740 (0.8798)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [46]  [ 800/1251]  eta: 0:03:45  lr: 0.003911  min_lr: 0.003911  loss: 3.8418 (3.6514)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7470 (0.8827)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [46]  [1000/1251]  eta: 0:02:05  lr: 0.003910  min_lr: 0.003910  loss: 3.5013 (3.6474)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5628 (0.8719)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [46]  [1200/1251]  eta: 0:00:25  lr: 0.003909  min_lr: 0.003909  loss: 3.5055 (3.6503)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8965 (0.9001)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [46]  [1250/1251]  eta: 0:00:00  lr: 0.003909  min_lr: 0.003909  loss: 3.7186 (3.6458)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7280 (0.8910)  time: 0.4296  data: 0.0005  max mem: 40080
Epoch: [46] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.003909  min_lr: 0.003909  loss: 3.7186 (3.6554)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7280 (0.8910)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.8073 (0.8073)  acc1: 86.0000 (86.0000)  acc5: 97.2000 (97.2000)  time: 5.4351  data: 5.1267  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9417 (1.0049)  acc1: 80.4000 (80.1455)  acc5: 95.2000 (95.6727)  time: 0.7318  data: 0.4664  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1916 (1.2081)  acc1: 73.2000 (75.4095)  acc5: 93.2000 (93.2952)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2660 (1.2154)  acc1: 72.4000 (75.2960)  acc5: 91.6000 (93.1840)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4719 s / it)
* Acc@1 75.476 Acc@5 93.298 loss 1.203
Accuracy of the model on the 50000 test images: 75.5%
Max accuracy: 75.48%
Epoch: [47]  [   0/1251]  eta: 0:58:19  lr: 0.003909  min_lr: 0.003909  loss: 3.6684 (3.6684)  weight_decay: 0.0500 (0.0500)  time: 2.7974  data: 2.2928  max mem: 40080
Epoch: [47]  [ 200/1251]  eta: 0:08:54  lr: 0.003908  min_lr: 0.003908  loss: 3.6255 (3.6546)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7237 (0.8335)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [47]  [ 400/1251]  eta: 0:07:07  lr: 0.003907  min_lr: 0.003907  loss: 3.7891 (3.6472)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6658 (0.8524)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [47]  [ 600/1251]  eta: 0:05:26  lr: 0.003906  min_lr: 0.003906  loss: 3.5843 (3.6617)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8882 (0.8831)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [47]  [ 800/1251]  eta: 0:03:45  lr: 0.003905  min_lr: 0.003905  loss: 3.5070 (3.6700)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7924 (0.8701)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [47]  [1000/1251]  eta: 0:02:05  lr: 0.003904  min_lr: 0.003904  loss: 3.4042 (3.6694)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7816 (0.8777)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [47]  [1200/1251]  eta: 0:00:25  lr: 0.003902  min_lr: 0.003902  loss: 3.4292 (3.6563)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7028 (0.8698)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [47]  [1250/1251]  eta: 0:00:00  lr: 0.003902  min_lr: 0.003902  loss: 3.8578 (3.6593)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7231 (0.8736)  time: 0.4209  data: 0.0005  max mem: 40080
Epoch: [47] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.003902  min_lr: 0.003902  loss: 3.8578 (3.6558)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7231 (0.8736)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.8776 (0.8776)  acc1: 86.4000 (86.4000)  acc5: 98.0000 (98.0000)  time: 5.5940  data: 5.3004  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0974 (1.1207)  acc1: 77.6000 (79.2364)  acc5: 96.4000 (95.5636)  time: 0.7463  data: 0.4822  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.3400 (1.2946)  acc1: 73.2000 (75.3333)  acc5: 92.8000 (93.0286)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.3943 (1.3057)  acc1: 72.8000 (75.1520)  acc5: 92.0000 (92.9440)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4777 s / it)
* Acc@1 75.508 Acc@5 93.034 loss 1.296
Accuracy of the model on the 50000 test images: 75.5%
Max accuracy: 75.51%
Epoch: [48]  [   0/1251]  eta: 0:50:52  lr: 0.003902  min_lr: 0.003902  loss: 2.5785 (2.5785)  weight_decay: 0.0500 (0.0500)  time: 2.4403  data: 1.9387  max mem: 40080
Epoch: [48]  [ 200/1251]  eta: 0:08:53  lr: 0.003901  min_lr: 0.003901  loss: 3.7832 (3.6574)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0366 (1.0075)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [48]  [ 400/1251]  eta: 0:07:08  lr: 0.003900  min_lr: 0.003900  loss: 3.8029 (3.6516)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7181 (0.9673)  time: 0.5064  data: 0.0004  max mem: 40080
Epoch: [48]  [ 600/1251]  eta: 0:05:26  lr: 0.003899  min_lr: 0.003899  loss: 3.4287 (3.6380)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7636 (0.9473)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [48]  [ 800/1251]  eta: 0:03:45  lr: 0.003898  min_lr: 0.003898  loss: 3.8135 (3.6544)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7203 (nan)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [48]  [1000/1251]  eta: 0:02:05  lr: 0.003897  min_lr: 0.003897  loss: 3.7077 (3.6551)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8690 (nan)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [48]  [1200/1251]  eta: 0:00:25  lr: 0.003895  min_lr: 0.003895  loss: 3.3808 (3.6493)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7772 (nan)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [48]  [1250/1251]  eta: 0:00:00  lr: 0.003895  min_lr: 0.003895  loss: 3.9007 (3.6512)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7441 (nan)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [48] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.003895  min_lr: 0.003895  loss: 3.9007 (3.6491)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7441 (nan)
Test:  [ 0/25]  eta: 0:02:14  loss: 0.7425 (0.7425)  acc1: 88.4000 (88.4000)  acc5: 99.2000 (99.2000)  time: 5.3636  data: 5.0571  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.0437 (1.0483)  acc1: 80.0000 (79.6727)  acc5: 96.4000 (95.7455)  time: 0.7256  data: 0.4602  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2750 (1.2130)  acc1: 73.6000 (76.0000)  acc5: 92.0000 (93.3143)  time: 0.2615  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2750 (1.2231)  acc1: 73.6000 (75.6320)  acc5: 91.6000 (93.1520)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4685 s / it)
* Acc@1 75.478 Acc@5 93.198 loss 1.220
Accuracy of the model on the 50000 test images: 75.5%
Max accuracy: 75.51%
Epoch: [49]  [   0/1251]  eta: 1:06:52  lr: 0.003895  min_lr: 0.003895  loss: 2.8600 (2.8600)  weight_decay: 0.0500 (0.0500)  time: 3.2071  data: 2.4685  max mem: 40080
Epoch: [49]  [ 200/1251]  eta: 0:08:58  lr: 0.003894  min_lr: 0.003894  loss: 3.6973 (3.6190)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7093 (0.8752)  time: 0.4998  data: 0.0004  max mem: 40080
Epoch: [49]  [ 400/1251]  eta: 0:07:09  lr: 0.003893  min_lr: 0.003893  loss: 3.6688 (3.5943)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1563 (0.9094)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [49]  [ 600/1251]  eta: 0:05:27  lr: 0.003892  min_lr: 0.003892  loss: 3.8265 (3.6197)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7261 (0.9391)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [49]  [ 800/1251]  eta: 0:03:46  lr: 0.003890  min_lr: 0.003890  loss: 3.8190 (3.6261)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5471 (0.9442)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [49]  [1000/1251]  eta: 0:02:05  lr: 0.003889  min_lr: 0.003889  loss: 3.5702 (3.6182)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6370 (0.9204)  time: 0.5012  data: 0.0004  max mem: 40080
Epoch: [49]  [1200/1251]  eta: 0:00:25  lr: 0.003888  min_lr: 0.003888  loss: 3.7304 (3.6140)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7450 (0.9375)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [49]  [1250/1251]  eta: 0:00:00  lr: 0.003888  min_lr: 0.003888  loss: 3.7859 (3.6170)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7716 (0.9339)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [49] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.003888  min_lr: 0.003888  loss: 3.7859 (3.6341)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7716 (0.9339)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.7660 (0.7660)  acc1: 84.4000 (84.4000)  acc5: 99.6000 (99.6000)  time: 5.5507  data: 5.2443  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0022 (1.0400)  acc1: 81.2000 (79.3818)  acc5: 96.4000 (95.9273)  time: 0.7424  data: 0.4770  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2847 (1.2162)  acc1: 72.0000 (75.3524)  acc5: 92.8000 (93.5238)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2573 (1.2192)  acc1: 73.6000 (75.3760)  acc5: 92.0000 (93.3760)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4774 s / it)
* Acc@1 75.538 Acc@5 93.324 loss 1.218
Accuracy of the model on the 50000 test images: 75.5%
Max accuracy: 75.54%
Epoch: [50]  [   0/1251]  eta: 1:01:10  lr: 0.003888  min_lr: 0.003888  loss: 4.3511 (4.3511)  weight_decay: 0.0500 (0.0500)  time: 2.9342  data: 2.4165  max mem: 40080
Epoch: [50]  [ 200/1251]  eta: 0:08:56  lr: 0.003887  min_lr: 0.003887  loss: 3.6294 (3.5743)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9022 (0.9312)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [50]  [ 400/1251]  eta: 0:07:08  lr: 0.003885  min_lr: 0.003885  loss: 3.6775 (3.6180)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5922 (0.8701)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [50]  [ 600/1251]  eta: 0:05:26  lr: 0.003884  min_lr: 0.003884  loss: 3.6383 (3.6314)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7254 (0.9177)  time: 0.4988  data: 0.0004  max mem: 40080
Epoch: [50]  [ 800/1251]  eta: 0:03:45  lr: 0.003883  min_lr: 0.003883  loss: 3.7072 (3.6306)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6511 (0.9300)  time: 0.5002  data: 0.0004  max mem: 40080
Epoch: [50]  [1000/1251]  eta: 0:02:05  lr: 0.003882  min_lr: 0.003882  loss: 3.7407 (3.6429)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8521 (nan)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [50]  [1200/1251]  eta: 0:00:25  lr: 0.003881  min_lr: 0.003881  loss: 3.5972 (3.6404)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6284 (nan)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [50]  [1250/1251]  eta: 0:00:00  lr: 0.003880  min_lr: 0.003880  loss: 3.7861 (3.6380)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7833 (nan)  time: 0.4301  data: 0.0005  max mem: 40080
Epoch: [50] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.003880  min_lr: 0.003880  loss: 3.7861 (3.6313)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7833 (nan)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.7984 (0.7984)  acc1: 84.8000 (84.8000)  acc5: 97.6000 (97.6000)  time: 5.5830  data: 5.2810  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0455 (1.0194)  acc1: 80.0000 (79.5636)  acc5: 96.8000 (96.0364)  time: 0.7453  data: 0.4804  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2370 (1.2037)  acc1: 74.0000 (75.4667)  acc5: 93.6000 (93.5429)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.3004 (1.2117)  acc1: 74.0000 (75.2800)  acc5: 92.4000 (93.3440)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4775 s / it)
* Acc@1 75.542 Acc@5 93.408 loss 1.205
Accuracy of the model on the 50000 test images: 75.5%
Max accuracy: 75.54%
Epoch: [51]  [   0/1251]  eta: 0:55:22  lr: 0.003880  min_lr: 0.003880  loss: 2.9374 (2.9374)  weight_decay: 0.0500 (0.0500)  time: 2.6555  data: 2.1578  max mem: 40080
Epoch: [51]  [ 200/1251]  eta: 0:08:55  lr: 0.003879  min_lr: 0.003879  loss: 3.7045 (3.6586)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7673 (0.9382)  time: 0.4963  data: 0.0005  max mem: 40080
Epoch: [51]  [ 400/1251]  eta: 0:07:08  lr: 0.003878  min_lr: 0.003878  loss: 3.5717 (3.6469)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8064 (0.9208)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [51]  [ 600/1251]  eta: 0:05:27  lr: 0.003877  min_lr: 0.003877  loss: 3.7747 (3.6290)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0994 (0.9362)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [51]  [ 800/1251]  eta: 0:03:46  lr: 0.003875  min_lr: 0.003875  loss: 3.7283 (3.6236)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8366 (0.9056)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [51]  [1000/1251]  eta: 0:02:05  lr: 0.003874  min_lr: 0.003874  loss: 3.3898 (3.6184)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7605 (0.9192)  time: 0.4967  data: 0.0006  max mem: 40080
Epoch: [51]  [1200/1251]  eta: 0:00:25  lr: 0.003873  min_lr: 0.003873  loss: 3.5306 (3.6024)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0788 (0.9313)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [51]  [1250/1251]  eta: 0:00:00  lr: 0.003873  min_lr: 0.003873  loss: 3.9624 (3.6075)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3016 (0.9371)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [51] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.003873  min_lr: 0.003873  loss: 3.9624 (3.6155)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3016 (0.9371)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.8742 (0.8742)  acc1: 84.0000 (84.0000)  acc5: 96.8000 (96.8000)  time: 5.4468  data: 5.1083  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9606 (1.0356)  acc1: 79.2000 (79.9636)  acc5: 96.4000 (95.6727)  time: 0.7331  data: 0.4648  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2588 (1.2160)  acc1: 73.2000 (75.6571)  acc5: 93.2000 (93.3714)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2863 (1.2228)  acc1: 73.6000 (75.4240)  acc5: 92.4000 (93.3120)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4721 s / it)
* Acc@1 75.900 Acc@5 93.428 loss 1.214
Accuracy of the model on the 50000 test images: 75.9%
Max accuracy: 75.90%
Epoch: [52]  [   0/1251]  eta: 0:58:17  lr: 0.003873  min_lr: 0.003873  loss: 3.3840 (3.3840)  weight_decay: 0.0500 (0.0500)  time: 2.7961  data: 2.2958  max mem: 40080
Epoch: [52]  [ 200/1251]  eta: 0:08:55  lr: 0.003871  min_lr: 0.003871  loss: 3.7033 (3.6112)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8046 (0.8360)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [52]  [ 400/1251]  eta: 0:07:08  lr: 0.003870  min_lr: 0.003870  loss: 3.6747 (3.6370)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8927 (0.8517)  time: 0.5065  data: 0.0004  max mem: 40080
Epoch: [52]  [ 600/1251]  eta: 0:05:26  lr: 0.003869  min_lr: 0.003869  loss: 3.8412 (3.6525)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7423 (0.9630)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [52]  [ 800/1251]  eta: 0:03:46  lr: 0.003867  min_lr: 0.003867  loss: 3.5645 (3.6413)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9845 (0.9682)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [52]  [1000/1251]  eta: 0:02:05  lr: 0.003866  min_lr: 0.003866  loss: 3.5993 (3.6297)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8726 (0.9695)  time: 0.5005  data: 0.0004  max mem: 40080
Epoch: [52]  [1200/1251]  eta: 0:00:25  lr: 0.003865  min_lr: 0.003865  loss: 3.8103 (3.6337)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7927 (0.9588)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [52]  [1250/1251]  eta: 0:00:00  lr: 0.003865  min_lr: 0.003865  loss: 3.7091 (3.6344)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8099 (0.9547)  time: 0.4211  data: 0.0004  max mem: 40080
Epoch: [52] Total time: 0:10:25 (0.4996 s / it)
Averaged stats: lr: 0.003865  min_lr: 0.003865  loss: 3.7091 (3.6110)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8099 (0.9547)
Test:  [ 0/25]  eta: 0:01:48  loss: 0.8434 (0.8434)  acc1: 86.0000 (86.0000)  acc5: 97.6000 (97.6000)  time: 4.3283  data: 4.0030  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.0082 (1.0529)  acc1: 79.2000 (79.7818)  acc5: 96.0000 (96.0000)  time: 0.6897  data: 0.4230  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2277 (1.2153)  acc1: 73.6000 (75.7143)  acc5: 93.2000 (93.5810)  time: 0.2934  data: 0.0325  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2679 (1.2167)  acc1: 74.4000 (75.5680)  acc5: 92.8000 (93.6320)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4528 s / it)
* Acc@1 75.940 Acc@5 93.540 loss 1.221
Accuracy of the model on the 50000 test images: 75.9%
Max accuracy: 75.94%
Epoch: [53]  [   0/1251]  eta: 0:53:35  lr: 0.003865  min_lr: 0.003865  loss: 4.1809 (4.1809)  weight_decay: 0.0500 (0.0500)  time: 2.5705  data: 2.0601  max mem: 40080
Epoch: [53]  [ 200/1251]  eta: 0:08:54  lr: 0.003863  min_lr: 0.003863  loss: 3.5961 (3.5680)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9399 (0.9949)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [53]  [ 400/1251]  eta: 0:07:07  lr: 0.003862  min_lr: 0.003862  loss: 3.5070 (3.5959)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0228 (1.0583)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [53]  [ 600/1251]  eta: 0:05:26  lr: 0.003861  min_lr: 0.003861  loss: 3.5511 (3.5931)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7187 (1.0146)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [53]  [ 800/1251]  eta: 0:03:45  lr: 0.003859  min_lr: 0.003859  loss: 3.6538 (3.6115)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9058 (0.9792)  time: 0.5076  data: 0.0005  max mem: 40080
Epoch: [53]  [1000/1251]  eta: 0:02:05  lr: 0.003858  min_lr: 0.003858  loss: 3.4837 (3.5963)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9319 (1.0050)  time: 0.5000  data: 0.0005  max mem: 40080
Epoch: [53]  [1200/1251]  eta: 0:00:25  lr: 0.003857  min_lr: 0.003857  loss: 3.7469 (3.5959)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8953 (0.9926)  time: 0.4966  data: 0.0005  max mem: 40080
Epoch: [53]  [1250/1251]  eta: 0:00:00  lr: 0.003856  min_lr: 0.003856  loss: 3.4687 (3.5952)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8613 (0.9881)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [53] Total time: 0:10:24 (0.4990 s / it)
Averaged stats: lr: 0.003856  min_lr: 0.003856  loss: 3.4687 (3.5935)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8613 (0.9881)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.8259 (0.8259)  acc1: 84.8000 (84.8000)  acc5: 98.0000 (98.0000)  time: 5.4636  data: 5.1528  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9796 (0.9878)  acc1: 81.6000 (80.4000)  acc5: 96.0000 (95.7091)  time: 0.7347  data: 0.4688  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1864 (1.1685)  acc1: 72.8000 (75.8476)  acc5: 92.0000 (93.4286)  time: 0.2616  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2421 (1.1724)  acc1: 72.8000 (75.5840)  acc5: 91.6000 (93.3440)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4726 s / it)
* Acc@1 75.788 Acc@5 93.492 loss 1.170
Accuracy of the model on the 50000 test images: 75.8%
Max accuracy: 75.94%
Epoch: [54]  [   0/1251]  eta: 1:09:23  lr: 0.003856  min_lr: 0.003856  loss: 4.2888 (4.2888)  weight_decay: 0.0500 (0.0500)  time: 3.3278  data: 2.4515  max mem: 40080
Epoch: [54]  [ 200/1251]  eta: 0:08:58  lr: 0.003855  min_lr: 0.003855  loss: 3.8289 (3.5450)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9553 (0.9391)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [54]  [ 400/1251]  eta: 0:07:10  lr: 0.003854  min_lr: 0.003854  loss: 3.5230 (3.5780)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0330 (1.0154)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [54]  [ 600/1251]  eta: 0:05:27  lr: 0.003852  min_lr: 0.003852  loss: 3.5507 (3.5849)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8580 (0.9820)  time: 0.4979  data: 0.0005  max mem: 40080
Epoch: [54]  [ 800/1251]  eta: 0:03:46  lr: 0.003851  min_lr: 0.003851  loss: 3.8052 (3.5883)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0016 (0.9754)  time: 0.4969  data: 0.0005  max mem: 40080
Epoch: [54]  [1000/1251]  eta: 0:02:05  lr: 0.003849  min_lr: 0.003849  loss: 3.6149 (3.6094)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2059 (0.9897)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [54]  [1200/1251]  eta: 0:00:25  lr: 0.003848  min_lr: 0.003848  loss: 3.5149 (3.6181)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9283 (0.9924)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [54]  [1250/1251]  eta: 0:00:00  lr: 0.003848  min_lr: 0.003848  loss: 3.4194 (3.6150)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7915 (0.9865)  time: 0.4214  data: 0.0005  max mem: 40080
Epoch: [54] Total time: 0:10:25 (0.4999 s / it)
Averaged stats: lr: 0.003848  min_lr: 0.003848  loss: 3.4194 (3.5969)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7915 (0.9865)
Test:  [ 0/25]  eta: 0:02:21  loss: 0.7860 (0.7860)  acc1: 87.6000 (87.6000)  acc5: 97.6000 (97.6000)  time: 5.6642  data: 5.3635  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0089 (1.0053)  acc1: 80.4000 (80.0727)  acc5: 96.0000 (95.7091)  time: 0.7527  data: 0.4879  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2109 (1.1693)  acc1: 74.0000 (75.8667)  acc5: 92.0000 (93.2000)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2652 (1.1748)  acc1: 74.0000 (75.6640)  acc5: 92.0000 (93.2160)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4805 s / it)
* Acc@1 75.934 Acc@5 93.670 loss 1.166
Accuracy of the model on the 50000 test images: 75.9%
Max accuracy: 75.94%
Epoch: [55]  [   0/1251]  eta: 1:13:36  lr: 0.003848  min_lr: 0.003848  loss: 4.0499 (4.0499)  weight_decay: 0.0500 (0.0500)  time: 3.5301  data: 2.9788  max mem: 40080
Epoch: [55]  [ 200/1251]  eta: 0:08:59  lr: 0.003846  min_lr: 0.003846  loss: 3.7354 (3.5889)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6437 (0.9823)  time: 0.5043  data: 0.0004  max mem: 40080
Epoch: [55]  [ 400/1251]  eta: 0:07:10  lr: 0.003845  min_lr: 0.003845  loss: 3.4850 (3.5862)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6282 (0.9682)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [55]  [ 600/1251]  eta: 0:05:27  lr: 0.003844  min_lr: 0.003844  loss: 3.6957 (3.5808)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6739 (0.9403)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [55]  [ 800/1251]  eta: 0:03:46  lr: 0.003842  min_lr: 0.003842  loss: 3.7072 (3.5902)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7428 (0.9277)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [55]  [1000/1251]  eta: 0:02:05  lr: 0.003841  min_lr: 0.003841  loss: 3.5220 (3.5810)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8760 (0.9492)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [55]  [1200/1251]  eta: 0:00:25  lr: 0.003839  min_lr: 0.003839  loss: 3.7450 (3.5849)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9441 (0.9677)  time: 0.4991  data: 0.0004  max mem: 40080
Epoch: [55]  [1250/1251]  eta: 0:00:00  lr: 0.003839  min_lr: 0.003839  loss: 3.0106 (3.5777)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8548 (0.9641)  time: 0.4209  data: 0.0005  max mem: 40080
Epoch: [55] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.003839  min_lr: 0.003839  loss: 3.0106 (3.5966)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8548 (0.9641)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.7302 (0.7302)  acc1: 84.4000 (84.4000)  acc5: 96.0000 (96.0000)  time: 5.5946  data: 5.2922  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9556 (0.9545)  acc1: 82.0000 (80.5455)  acc5: 96.0000 (96.0364)  time: 0.7462  data: 0.4814  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1553 (1.1376)  acc1: 73.6000 (76.3619)  acc5: 92.8000 (93.4095)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2032 (1.1430)  acc1: 73.6000 (76.2080)  acc5: 92.8000 (93.4880)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4790 s / it)
* Acc@1 76.278 Acc@5 93.586 loss 1.136
Accuracy of the model on the 50000 test images: 76.3%
Max accuracy: 76.28%
Epoch: [56]  [   0/1251]  eta: 0:56:41  lr: 0.003839  min_lr: 0.003839  loss: 4.0819 (4.0819)  weight_decay: 0.0500 (0.0500)  time: 2.7194  data: 2.2176  max mem: 40080
Epoch: [56]  [ 200/1251]  eta: 0:08:54  lr: 0.003838  min_lr: 0.003838  loss: 3.7990 (3.5522)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9108 (1.0575)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [56]  [ 400/1251]  eta: 0:07:08  lr: 0.003836  min_lr: 0.003836  loss: 3.6897 (3.5457)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9634 (1.0556)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [56]  [ 600/1251]  eta: 0:05:26  lr: 0.003835  min_lr: 0.003835  loss: 3.7341 (3.5721)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8482 (1.0685)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [56]  [ 800/1251]  eta: 0:03:45  lr: 0.003833  min_lr: 0.003833  loss: 3.7835 (3.5875)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7773 (1.0478)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [56]  [1000/1251]  eta: 0:02:05  lr: 0.003832  min_lr: 0.003832  loss: 3.4383 (3.5784)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7278 (1.0498)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [56]  [1200/1251]  eta: 0:00:25  lr: 0.003831  min_lr: 0.003831  loss: 3.3834 (3.5896)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9182 (1.0440)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [56]  [1250/1251]  eta: 0:00:00  lr: 0.003830  min_lr: 0.003830  loss: 3.7520 (3.5890)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1200 (1.0479)  time: 0.4208  data: 0.0006  max mem: 40080
Epoch: [56] Total time: 0:10:24 (0.4990 s / it)
Averaged stats: lr: 0.003830  min_lr: 0.003830  loss: 3.7520 (3.5906)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1200 (1.0479)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.8188 (0.8188)  acc1: 83.2000 (83.2000)  acc5: 98.8000 (98.8000)  time: 5.4885  data: 5.1951  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9714 (0.9947)  acc1: 80.8000 (79.6364)  acc5: 96.0000 (95.9273)  time: 0.7365  data: 0.4726  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1941 (1.1852)  acc1: 72.4000 (75.4286)  acc5: 93.2000 (93.6571)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2095 (1.1901)  acc1: 72.4000 (75.5680)  acc5: 92.4000 (93.5360)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4734 s / it)
* Acc@1 76.358 Acc@5 93.750 loss 1.177
Accuracy of the model on the 50000 test images: 76.4%
Max accuracy: 76.36%
Epoch: [57]  [   0/1251]  eta: 0:53:43  lr: 0.003830  min_lr: 0.003830  loss: 3.7737 (3.7737)  weight_decay: 0.0500 (0.0500)  time: 2.5764  data: 2.0711  max mem: 40080
Epoch: [57]  [ 200/1251]  eta: 0:08:54  lr: 0.003829  min_lr: 0.003829  loss: 3.1512 (3.5287)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9217 (1.0507)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [57]  [ 400/1251]  eta: 0:07:08  lr: 0.003827  min_lr: 0.003827  loss: 3.4136 (3.5355)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7163 (1.0253)  time: 0.4991  data: 0.0005  max mem: 40080
Epoch: [57]  [ 600/1251]  eta: 0:05:26  lr: 0.003826  min_lr: 0.003826  loss: 3.8539 (3.5568)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7486 (1.0321)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [57]  [ 800/1251]  eta: 0:03:46  lr: 0.003824  min_lr: 0.003824  loss: 3.6773 (3.5499)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9117 (1.0177)  time: 0.4979  data: 0.0005  max mem: 40080
Epoch: [57]  [1000/1251]  eta: 0:02:05  lr: 0.003823  min_lr: 0.003823  loss: 3.5770 (3.5621)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8949 (0.9954)  time: 0.4981  data: 0.0003  max mem: 40080
Epoch: [57]  [1200/1251]  eta: 0:00:25  lr: 0.003821  min_lr: 0.003821  loss: 3.4733 (3.5668)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9057 (1.0148)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [57]  [1250/1251]  eta: 0:00:00  lr: 0.003821  min_lr: 0.003821  loss: 3.6077 (3.5625)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2976 (1.0505)  time: 0.4208  data: 0.0006  max mem: 40080
Epoch: [57] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.003821  min_lr: 0.003821  loss: 3.6077 (3.5733)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2976 (1.0505)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.7501 (0.7501)  acc1: 83.6000 (83.6000)  acc5: 98.4000 (98.4000)  time: 5.3288  data: 5.0314  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9608 (0.9869)  acc1: 80.0000 (79.7091)  acc5: 96.8000 (95.8909)  time: 0.7222  data: 0.4577  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2453 (1.1604)  acc1: 73.6000 (76.0000)  acc5: 92.4000 (93.5238)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2529 (1.1701)  acc1: 73.6000 (75.7760)  acc5: 92.4000 (93.5200)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4675 s / it)
* Acc@1 76.292 Acc@5 93.708 loss 1.158
Accuracy of the model on the 50000 test images: 76.3%
Max accuracy: 76.36%
Epoch: [58]  [   0/1251]  eta: 1:11:05  lr: 0.003821  min_lr: 0.003821  loss: 3.7316 (3.7316)  weight_decay: 0.0500 (0.0500)  time: 3.4100  data: 2.4473  max mem: 40080
Epoch: [58]  [ 200/1251]  eta: 0:08:59  lr: 0.003820  min_lr: 0.003820  loss: 3.5633 (3.4796)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2115 (1.0856)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [58]  [ 400/1251]  eta: 0:07:10  lr: 0.003818  min_lr: 0.003818  loss: 3.6784 (3.5299)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8944 (1.0792)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [58]  [ 600/1251]  eta: 0:05:27  lr: 0.003817  min_lr: 0.003817  loss: 3.8562 (3.5675)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7740 (1.0293)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [58]  [ 800/1251]  eta: 0:03:46  lr: 0.003815  min_lr: 0.003815  loss: 3.7108 (3.5843)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0732 (1.0259)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [58]  [1000/1251]  eta: 0:02:05  lr: 0.003813  min_lr: 0.003813  loss: 3.4163 (3.5860)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8556 (1.0213)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [58]  [1200/1251]  eta: 0:00:25  lr: 0.003812  min_lr: 0.003812  loss: 3.8893 (3.5808)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0279 (1.0275)  time: 0.4964  data: 0.0005  max mem: 40080
Epoch: [58]  [1250/1251]  eta: 0:00:00  lr: 0.003812  min_lr: 0.003812  loss: 3.7385 (3.5810)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0909 (1.0354)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [58] Total time: 0:10:25 (0.4999 s / it)
Averaged stats: lr: 0.003812  min_lr: 0.003812  loss: 3.7385 (3.5788)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0909 (1.0354)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.8056 (0.8056)  acc1: 85.2000 (85.2000)  acc5: 98.8000 (98.8000)  time: 5.4818  data: 5.1633  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0153 (1.0107)  acc1: 80.4000 (80.4000)  acc5: 95.6000 (96.0727)  time: 0.7361  data: 0.4697  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2273 (1.2007)  acc1: 74.0000 (76.0381)  acc5: 93.6000 (93.6952)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2742 (1.2121)  acc1: 74.0000 (75.7920)  acc5: 92.0000 (93.6000)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4732 s / it)
* Acc@1 76.356 Acc@5 93.744 loss 1.194
Accuracy of the model on the 50000 test images: 76.4%
Max accuracy: 76.36%
Epoch: [59]  [   0/1251]  eta: 1:10:53  lr: 0.003812  min_lr: 0.003812  loss: 3.6733 (3.6733)  weight_decay: 0.0500 (0.0500)  time: 3.4001  data: 1.6672  max mem: 40080
Epoch: [59]  [ 200/1251]  eta: 0:08:59  lr: 0.003810  min_lr: 0.003810  loss: 3.4544 (3.4999)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9242 (1.0319)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [59]  [ 400/1251]  eta: 0:07:10  lr: 0.003809  min_lr: 0.003809  loss: 3.6780 (3.5180)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8517 (nan)  time: 0.4957  data: 0.0004  max mem: 40080
Epoch: [59]  [ 600/1251]  eta: 0:05:27  lr: 0.003807  min_lr: 0.003807  loss: 3.2764 (3.5300)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7522 (nan)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [59]  [ 800/1251]  eta: 0:03:46  lr: 0.003805  min_lr: 0.003805  loss: 3.5917 (3.5463)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2561 (nan)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [59]  [1000/1251]  eta: 0:02:05  lr: 0.003804  min_lr: 0.003804  loss: 3.4179 (3.5523)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9899 (nan)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [59]  [1200/1251]  eta: 0:00:25  lr: 0.003802  min_lr: 0.003802  loss: 3.6061 (3.5670)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5527 (nan)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [59]  [1250/1251]  eta: 0:00:00  lr: 0.003802  min_lr: 0.003802  loss: 3.6916 (3.5683)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6838 (nan)  time: 0.4216  data: 0.0006  max mem: 40080
Epoch: [59] Total time: 0:10:25 (0.4997 s / it)
Averaged stats: lr: 0.003802  min_lr: 0.003802  loss: 3.6916 (3.5699)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6838 (nan)
Test:  [ 0/25]  eta: 0:02:05  loss: 0.7420 (0.7420)  acc1: 84.8000 (84.8000)  acc5: 98.8000 (98.8000)  time: 5.0285  data: 4.7131  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9128 (0.9197)  acc1: 81.2000 (79.9636)  acc5: 96.8000 (96.2909)  time: 0.6989  data: 0.4326  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1437 (1.1178)  acc1: 74.4000 (76.4000)  acc5: 93.6000 (93.8476)  time: 0.2637  data: 0.0023  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2172 (1.1260)  acc1: 74.4000 (76.3040)  acc5: 92.8000 (93.7440)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4622 s / it)
* Acc@1 76.422 Acc@5 93.740 loss 1.130
Accuracy of the model on the 50000 test images: 76.4%
Max accuracy: 76.42%
Epoch: [60]  [   0/1251]  eta: 0:56:45  lr: 0.003802  min_lr: 0.003802  loss: 3.2313 (3.2313)  weight_decay: 0.0500 (0.0500)  time: 2.7222  data: 2.2239  max mem: 40080
Epoch: [60]  [ 200/1251]  eta: 0:08:54  lr: 0.003800  min_lr: 0.003800  loss: 3.3274 (3.5370)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9586 (1.0073)  time: 0.4991  data: 0.0004  max mem: 40080
Epoch: [60]  [ 400/1251]  eta: 0:07:08  lr: 0.003799  min_lr: 0.003799  loss: 3.6479 (3.5507)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0324 (1.0570)  time: 0.5051  data: 0.0004  max mem: 40080
Epoch: [60]  [ 600/1251]  eta: 0:05:26  lr: 0.003797  min_lr: 0.003797  loss: 3.5147 (3.5647)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7128 (0.9982)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [60]  [ 800/1251]  eta: 0:03:45  lr: 0.003796  min_lr: 0.003796  loss: 3.7439 (3.5845)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9661 (1.0451)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [60]  [1000/1251]  eta: 0:02:05  lr: 0.003794  min_lr: 0.003794  loss: 3.7829 (3.5837)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8569 (1.0518)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [60]  [1200/1251]  eta: 0:00:25  lr: 0.003793  min_lr: 0.003793  loss: 3.7631 (3.5730)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7742 (1.0402)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [60]  [1250/1251]  eta: 0:00:00  lr: 0.003792  min_lr: 0.003792  loss: 3.7941 (3.5780)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7750 (1.0382)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [60] Total time: 0:10:23 (0.4986 s / it)
Averaged stats: lr: 0.003792  min_lr: 0.003792  loss: 3.7941 (3.5591)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7750 (1.0382)
Test:  [ 0/25]  eta: 0:02:07  loss: 0.7735 (0.7735)  acc1: 86.0000 (86.0000)  acc5: 98.4000 (98.4000)  time: 5.1197  data: 4.8072  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9135 (0.9866)  acc1: 81.6000 (80.6182)  acc5: 96.8000 (96.4000)  time: 0.7032  data: 0.4373  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1697 (1.1730)  acc1: 75.6000 (76.9714)  acc5: 92.8000 (93.9429)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.3007 (1.1932)  acc1: 75.2000 (76.4640)  acc5: 91.6000 (93.7440)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4590 s / it)
* Acc@1 76.288 Acc@5 93.754 loss 1.198
Accuracy of the model on the 50000 test images: 76.3%
Max accuracy: 76.42%
Epoch: [61]  [   0/1251]  eta: 1:12:20  lr: 0.003792  min_lr: 0.003792  loss: 4.6723 (4.6723)  weight_decay: 0.0500 (0.0500)  time: 3.4694  data: 2.7107  max mem: 40080
Epoch: [61]  [ 200/1251]  eta: 0:08:57  lr: 0.003791  min_lr: 0.003791  loss: 3.6445 (3.5367)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7842 (1.1847)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [61]  [ 400/1251]  eta: 0:07:10  lr: 0.003789  min_lr: 0.003789  loss: 3.4601 (3.5394)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7572 (1.1291)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [61]  [ 600/1251]  eta: 0:05:27  lr: 0.003787  min_lr: 0.003787  loss: 3.5814 (3.5586)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2453 (1.1481)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [61]  [ 800/1251]  eta: 0:03:46  lr: 0.003786  min_lr: 0.003786  loss: 3.8359 (3.5674)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1225 (1.1250)  time: 0.4975  data: 0.0005  max mem: 40080
Epoch: [61]  [1000/1251]  eta: 0:02:05  lr: 0.003784  min_lr: 0.003784  loss: 3.6465 (3.5701)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3755 (1.1343)  time: 0.4957  data: 0.0004  max mem: 40080
Epoch: [61]  [1200/1251]  eta: 0:00:25  lr: 0.003782  min_lr: 0.003782  loss: 3.8057 (3.5787)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8237 (1.0964)  time: 0.4966  data: 0.0005  max mem: 40080
Epoch: [61]  [1250/1251]  eta: 0:00:00  lr: 0.003782  min_lr: 0.003782  loss: 3.5548 (3.5795)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8893 (1.0994)  time: 0.4214  data: 0.0007  max mem: 40080
Epoch: [61] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.003782  min_lr: 0.003782  loss: 3.5548 (3.5597)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8893 (1.0994)
Test:  [ 0/25]  eta: 0:02:08  loss: 0.7761 (0.7761)  acc1: 84.8000 (84.8000)  acc5: 97.6000 (97.6000)  time: 5.1334  data: 4.8276  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9320 (0.9327)  acc1: 80.4000 (80.8727)  acc5: 97.2000 (96.2182)  time: 0.7046  data: 0.4393  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1540 (1.1140)  acc1: 75.2000 (76.8191)  acc5: 93.6000 (93.8667)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2309 (1.1300)  acc1: 74.8000 (76.4480)  acc5: 92.4000 (93.7280)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4605 s / it)
* Acc@1 76.596 Acc@5 93.882 loss 1.123
Accuracy of the model on the 50000 test images: 76.6%
Max accuracy: 76.60%
Epoch: [62]  [   0/1251]  eta: 1:01:19  lr: 0.003782  min_lr: 0.003782  loss: 3.0339 (3.0339)  weight_decay: 0.0500 (0.0500)  time: 2.9413  data: 2.4254  max mem: 40080
Epoch: [62]  [ 200/1251]  eta: 0:08:58  lr: 0.003780  min_lr: 0.003780  loss: 3.2642 (3.5325)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8778 (0.9747)  time: 0.4986  data: 0.0004  max mem: 40080
Epoch: [62]  [ 400/1251]  eta: 0:07:09  lr: 0.003779  min_lr: 0.003779  loss: 3.9161 (3.5218)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0815 (1.0500)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [62]  [ 600/1251]  eta: 0:05:27  lr: 0.003777  min_lr: 0.003777  loss: 3.5557 (3.5381)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0345 (1.0451)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [62]  [ 800/1251]  eta: 0:03:46  lr: 0.003775  min_lr: 0.003775  loss: 3.7967 (3.5499)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9357 (1.0390)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [62]  [1000/1251]  eta: 0:02:05  lr: 0.003774  min_lr: 0.003774  loss: 3.6068 (3.5435)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7648 (1.0373)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [62]  [1200/1251]  eta: 0:00:25  lr: 0.003772  min_lr: 0.003772  loss: 3.5031 (3.5400)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0983 (1.0438)  time: 0.5086  data: 0.0004  max mem: 40080
Epoch: [62]  [1250/1251]  eta: 0:00:00  lr: 0.003772  min_lr: 0.003772  loss: 3.6622 (3.5432)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0283 (1.0431)  time: 0.4295  data: 0.0005  max mem: 40080
Epoch: [62] Total time: 0:10:26 (0.5004 s / it)
Averaged stats: lr: 0.003772  min_lr: 0.003772  loss: 3.6622 (3.5498)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0283 (1.0431)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.7094 (0.7094)  acc1: 86.0000 (86.0000)  acc5: 97.6000 (97.6000)  time: 5.4949  data: 5.1855  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9083 (0.9294)  acc1: 79.2000 (80.5818)  acc5: 96.0000 (95.9273)  time: 0.7371  data: 0.4717  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1400 (1.1105)  acc1: 74.4000 (76.8571)  acc5: 93.2000 (93.8095)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2263 (1.1219)  acc1: 73.6000 (76.5120)  acc5: 92.8000 (93.6320)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4734 s / it)
* Acc@1 76.882 Acc@5 93.898 loss 1.114
Accuracy of the model on the 50000 test images: 76.9%
Max accuracy: 76.88%
Epoch: [63]  [   0/1251]  eta: 0:57:47  lr: 0.003772  min_lr: 0.003772  loss: 2.8243 (2.8243)  weight_decay: 0.0500 (0.0500)  time: 2.7716  data: 2.2765  max mem: 40080
Epoch: [63]  [ 200/1251]  eta: 0:08:56  lr: 0.003770  min_lr: 0.003770  loss: 3.7271 (3.5412)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9921 (1.1094)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [63]  [ 400/1251]  eta: 0:07:09  lr: 0.003768  min_lr: 0.003768  loss: 3.4970 (3.5267)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8531 (1.0735)  time: 0.4982  data: 0.0005  max mem: 40080
Epoch: [63]  [ 600/1251]  eta: 0:05:27  lr: 0.003767  min_lr: 0.003767  loss: 3.7407 (3.5333)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9856 (1.1447)  time: 0.4989  data: 0.0005  max mem: 40080
Epoch: [63]  [ 800/1251]  eta: 0:03:46  lr: 0.003765  min_lr: 0.003765  loss: 3.8244 (3.5489)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0730 (1.0913)  time: 0.4992  data: 0.0005  max mem: 40080
Epoch: [63]  [1000/1251]  eta: 0:02:05  lr: 0.003763  min_lr: 0.003763  loss: 3.6392 (3.5489)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7723 (1.0603)  time: 0.4985  data: 0.0005  max mem: 40080
Epoch: [63]  [1200/1251]  eta: 0:00:25  lr: 0.003762  min_lr: 0.003762  loss: 3.6734 (3.5409)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2791 (1.0835)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [63]  [1250/1251]  eta: 0:00:00  lr: 0.003761  min_lr: 0.003761  loss: 3.5312 (3.5396)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1956 (1.0863)  time: 0.4211  data: 0.0006  max mem: 40080
Epoch: [63] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.003761  min_lr: 0.003761  loss: 3.5312 (3.5454)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1956 (1.0863)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.7675 (0.7675)  acc1: 84.0000 (84.0000)  acc5: 98.4000 (98.4000)  time: 5.3004  data: 5.0100  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9959 (0.9616)  acc1: 81.2000 (80.9091)  acc5: 96.4000 (95.9636)  time: 0.7198  data: 0.4558  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1110 (1.1488)  acc1: 74.0000 (76.8571)  acc5: 93.2000 (93.7333)  time: 0.2616  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2397 (1.1585)  acc1: 74.0000 (76.5600)  acc5: 92.4000 (93.7120)  time: 0.2615  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4662 s / it)
* Acc@1 76.656 Acc@5 93.930 loss 1.149
Accuracy of the model on the 50000 test images: 76.7%
Max accuracy: 76.88%
Epoch: [64]  [   0/1251]  eta: 1:08:25  lr: 0.003761  min_lr: 0.003761  loss: 3.4440 (3.4440)  weight_decay: 0.0500 (0.0500)  time: 3.2819  data: 1.6766  max mem: 40080
Epoch: [64]  [ 200/1251]  eta: 0:08:59  lr: 0.003760  min_lr: 0.003760  loss: 3.5166 (3.5354)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8233 (1.0170)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [64]  [ 400/1251]  eta: 0:07:10  lr: 0.003758  min_lr: 0.003758  loss: 3.6276 (3.5322)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8330 (0.9745)  time: 0.5080  data: 0.0005  max mem: 40080
Epoch: [64]  [ 600/1251]  eta: 0:05:27  lr: 0.003756  min_lr: 0.003756  loss: 3.7879 (3.5355)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1028 (1.0096)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [64]  [ 800/1251]  eta: 0:03:46  lr: 0.003754  min_lr: 0.003754  loss: 3.6691 (3.5372)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9219 (1.0499)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [64]  [1000/1251]  eta: 0:02:05  lr: 0.003753  min_lr: 0.003753  loss: 3.6305 (3.5351)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8580 (1.0668)  time: 0.4993  data: 0.0004  max mem: 40080
Epoch: [64]  [1200/1251]  eta: 0:00:25  lr: 0.003751  min_lr: 0.003751  loss: 3.5951 (3.5514)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9392 (1.0956)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [64]  [1250/1251]  eta: 0:00:00  lr: 0.003751  min_lr: 0.003751  loss: 3.4942 (3.5476)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0830 (1.0962)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [64] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.003751  min_lr: 0.003751  loss: 3.4942 (3.5506)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0830 (1.0962)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.6566 (0.6566)  acc1: 87.2000 (87.2000)  acc5: 98.8000 (98.8000)  time: 5.3196  data: 5.0232  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8690 (0.8979)  acc1: 80.0000 (80.8727)  acc5: 97.6000 (96.4364)  time: 0.7211  data: 0.4570  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1199 (1.0843)  acc1: 74.8000 (76.8571)  acc5: 93.6000 (94.0952)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2050 (1.0902)  acc1: 74.4000 (76.7040)  acc5: 92.8000 (93.9520)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4665 s / it)
* Acc@1 77.164 Acc@5 94.016 loss 1.083
Accuracy of the model on the 50000 test images: 77.2%
Max accuracy: 77.16%
Epoch: [65]  [   0/1251]  eta: 0:58:42  lr: 0.003751  min_lr: 0.003751  loss: 3.5429 (3.5429)  weight_decay: 0.0500 (0.0500)  time: 2.8158  data: 2.3111  max mem: 40080
Epoch: [65]  [ 200/1251]  eta: 0:08:56  lr: 0.003749  min_lr: 0.003749  loss: 3.4336 (3.4996)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7119 (1.0855)  time: 0.4979  data: 0.0005  max mem: 40080
Epoch: [65]  [ 400/1251]  eta: 0:07:09  lr: 0.003747  min_lr: 0.003747  loss: 3.4827 (3.5092)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8442 (1.1066)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [65]  [ 600/1251]  eta: 0:05:26  lr: 0.003745  min_lr: 0.003745  loss: 3.4775 (3.5175)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1590 (1.0688)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [65]  [ 800/1251]  eta: 0:03:45  lr: 0.003744  min_lr: 0.003744  loss: 3.6099 (3.5263)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8687 (1.0595)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [65]  [1000/1251]  eta: 0:02:05  lr: 0.003742  min_lr: 0.003742  loss: 3.6311 (3.5520)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1612 (1.0781)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [65]  [1200/1251]  eta: 0:00:25  lr: 0.003740  min_lr: 0.003740  loss: 3.6253 (3.5486)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8845 (1.0521)  time: 0.4956  data: 0.0004  max mem: 40080
Epoch: [65]  [1250/1251]  eta: 0:00:00  lr: 0.003740  min_lr: 0.003740  loss: 3.6685 (3.5460)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8318 (1.0467)  time: 0.4208  data: 0.0006  max mem: 40080
Epoch: [65] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.003740  min_lr: 0.003740  loss: 3.6685 (3.5369)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8318 (1.0467)
Test:  [ 0/25]  eta: 0:02:07  loss: 0.8214 (0.8214)  acc1: 85.2000 (85.2000)  acc5: 97.2000 (97.2000)  time: 5.1134  data: 4.7869  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.0004 (0.9601)  acc1: 80.8000 (80.7636)  acc5: 96.8000 (96.2909)  time: 0.7029  data: 0.4356  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1709 (1.1320)  acc1: 74.4000 (77.1048)  acc5: 93.6000 (94.0191)  time: 0.2616  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2034 (1.1459)  acc1: 73.6000 (76.7680)  acc5: 92.8000 (93.9680)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4587 s / it)
* Acc@1 76.812 Acc@5 93.878 loss 1.152
Accuracy of the model on the 50000 test images: 76.8%
Max accuracy: 77.16%
Epoch: [66]  [   0/1251]  eta: 1:09:38  lr: 0.003740  min_lr: 0.003740  loss: 3.3211 (3.3211)  weight_decay: 0.0500 (0.0500)  time: 3.3403  data: 2.3915  max mem: 40080
Epoch: [66]  [ 200/1251]  eta: 0:09:00  lr: 0.003738  min_lr: 0.003738  loss: 3.4813 (3.5682)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8262 (1.0501)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [66]  [ 400/1251]  eta: 0:07:10  lr: 0.003736  min_lr: 0.003736  loss: 3.8548 (3.5627)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [66]  [ 600/1251]  eta: 0:05:27  lr: 0.003734  min_lr: 0.003734  loss: 3.7525 (3.5589)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0539 (nan)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [66]  [ 800/1251]  eta: 0:03:46  lr: 0.003732  min_lr: 0.003732  loss: 3.5677 (3.5526)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8382 (nan)  time: 0.4995  data: 0.0005  max mem: 40080
Epoch: [66]  [1000/1251]  eta: 0:02:05  lr: 0.003731  min_lr: 0.003731  loss: 3.4803 (3.5536)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9412 (nan)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [66]  [1200/1251]  eta: 0:00:25  lr: 0.003729  min_lr: 0.003729  loss: 3.6560 (3.5471)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3733 (nan)  time: 0.4961  data: 0.0005  max mem: 40080
Epoch: [66]  [1250/1251]  eta: 0:00:00  lr: 0.003728  min_lr: 0.003728  loss: 3.7393 (3.5519)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4407 (nan)  time: 0.4280  data: 0.0007  max mem: 40080
Epoch: [66] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.003728  min_lr: 0.003728  loss: 3.7393 (3.5303)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4407 (nan)
Test:  [ 0/25]  eta: 0:02:11  loss: 0.8298 (0.8298)  acc1: 84.4000 (84.4000)  acc5: 96.8000 (96.8000)  time: 5.2627  data: 4.9500  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9671 (0.9720)  acc1: 81.2000 (80.9818)  acc5: 96.8000 (96.3273)  time: 0.7164  data: 0.4503  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1331 (1.1362)  acc1: 75.6000 (77.1429)  acc5: 94.0000 (94.2476)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2284 (1.1442)  acc1: 75.6000 (76.5920)  acc5: 93.2000 (94.2560)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4661 s / it)
* Acc@1 76.902 Acc@5 94.006 loss 1.139
Accuracy of the model on the 50000 test images: 76.9%
Max accuracy: 77.16%
Epoch: [67]  [   0/1251]  eta: 1:03:04  lr: 0.003728  min_lr: 0.003728  loss: 3.2654 (3.2654)  weight_decay: 0.0500 (0.0500)  time: 3.0249  data: 1.5482  max mem: 40080
Epoch: [67]  [ 200/1251]  eta: 0:08:57  lr: 0.003727  min_lr: 0.003727  loss: 3.6986 (3.5717)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8187 (0.8933)  time: 0.4988  data: 0.0004  max mem: 40080
Epoch: [67]  [ 400/1251]  eta: 0:07:09  lr: 0.003725  min_lr: 0.003725  loss: 3.7514 (3.5348)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1735 (1.0504)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [67]  [ 600/1251]  eta: 0:05:27  lr: 0.003723  min_lr: 0.003723  loss: 3.6839 (3.5339)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0575 (1.0336)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [67]  [ 800/1251]  eta: 0:03:46  lr: 0.003721  min_lr: 0.003721  loss: 3.8178 (3.5463)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7818 (1.0721)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [67]  [1000/1251]  eta: 0:02:05  lr: 0.003719  min_lr: 0.003719  loss: 3.5750 (3.5446)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9419 (1.0855)  time: 0.5036  data: 0.0005  max mem: 40080
Epoch: [67]  [1200/1251]  eta: 0:00:25  lr: 0.003717  min_lr: 0.003717  loss: 3.8486 (3.5554)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1834 (nan)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [67]  [1250/1251]  eta: 0:00:00  lr: 0.003717  min_lr: 0.003717  loss: 3.6515 (3.5591)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6446 (nan)  time: 0.4211  data: 0.0007  max mem: 40080
Epoch: [67] Total time: 0:10:24 (0.4990 s / it)
Averaged stats: lr: 0.003717  min_lr: 0.003717  loss: 3.6515 (3.5318)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6446 (nan)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.7861 (0.7861)  acc1: 85.2000 (85.2000)  acc5: 97.6000 (97.6000)  time: 5.6073  data: 5.3114  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0058 (0.9754)  acc1: 80.8000 (81.0545)  acc5: 96.8000 (96.2909)  time: 0.7476  data: 0.4832  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1431 (1.1433)  acc1: 76.4000 (77.0857)  acc5: 93.2000 (94.0952)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2709 (1.1566)  acc1: 74.0000 (76.7520)  acc5: 92.4000 (93.9200)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4790 s / it)
* Acc@1 77.238 Acc@5 93.988 loss 1.153
Accuracy of the model on the 50000 test images: 77.2%
Max accuracy: 77.24%
Epoch: [68]  [   0/1251]  eta: 0:58:28  lr: 0.003717  min_lr: 0.003717  loss: 3.1879 (3.1879)  weight_decay: 0.0500 (0.0500)  time: 2.8049  data: 2.3073  max mem: 40080
Epoch: [68]  [ 200/1251]  eta: 0:08:57  lr: 0.003715  min_lr: 0.003715  loss: 3.3417 (3.4992)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9882 (1.2077)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [68]  [ 400/1251]  eta: 0:07:09  lr: 0.003713  min_lr: 0.003713  loss: 3.3370 (3.5147)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8137 (1.1486)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [68]  [ 600/1251]  eta: 0:05:27  lr: 0.003711  min_lr: 0.003711  loss: 3.6141 (3.5188)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1422 (1.1680)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [68]  [ 800/1251]  eta: 0:03:46  lr: 0.003710  min_lr: 0.003710  loss: 3.7464 (3.5234)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8284 (1.1267)  time: 0.4988  data: 0.0004  max mem: 40080
Epoch: [68]  [1000/1251]  eta: 0:02:05  lr: 0.003708  min_lr: 0.003708  loss: 3.7154 (3.5288)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9795 (1.1375)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [68]  [1200/1251]  eta: 0:00:25  lr: 0.003706  min_lr: 0.003706  loss: 3.5718 (3.5199)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8672 (1.1092)  time: 0.5001  data: 0.0004  max mem: 40080
Epoch: [68]  [1250/1251]  eta: 0:00:00  lr: 0.003705  min_lr: 0.003705  loss: 3.4264 (3.5171)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9866 (1.1147)  time: 0.4213  data: 0.0005  max mem: 40080
Epoch: [68] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.003705  min_lr: 0.003705  loss: 3.4264 (3.5221)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9866 (1.1147)
Test:  [ 0/25]  eta: 0:02:11  loss: 0.7177 (0.7177)  acc1: 84.0000 (84.0000)  acc5: 98.4000 (98.4000)  time: 5.2416  data: 4.9440  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8848 (0.9260)  acc1: 79.6000 (80.5091)  acc5: 96.4000 (96.2545)  time: 0.7143  data: 0.4497  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1387 (1.0987)  acc1: 74.8000 (76.5905)  acc5: 93.6000 (94.0381)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1714 (1.1082)  acc1: 74.8000 (76.4160)  acc5: 92.8000 (94.0320)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4639 s / it)
* Acc@1 77.274 Acc@5 94.086 loss 1.100
Accuracy of the model on the 50000 test images: 77.3%
Max accuracy: 77.27%
Epoch: [69]  [   0/1251]  eta: 0:58:34  lr: 0.003705  min_lr: 0.003705  loss: 4.2805 (4.2805)  weight_decay: 0.0500 (0.0500)  time: 2.8092  data: 2.3073  max mem: 40080
Epoch: [69]  [ 200/1251]  eta: 0:08:55  lr: 0.003703  min_lr: 0.003703  loss: 3.7035 (3.4800)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8530 (0.9235)  time: 0.4992  data: 0.0005  max mem: 40080
Epoch: [69]  [ 400/1251]  eta: 0:07:09  lr: 0.003702  min_lr: 0.003702  loss: 3.6283 (3.4842)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1006 (1.0579)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [69]  [ 600/1251]  eta: 0:05:27  lr: 0.003700  min_lr: 0.003700  loss: 3.3707 (3.4802)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9935 (1.0871)  time: 0.4985  data: 0.0005  max mem: 40080
Epoch: [69]  [ 800/1251]  eta: 0:03:45  lr: 0.003698  min_lr: 0.003698  loss: 3.6913 (3.4928)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7880 (1.0910)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [69]  [1000/1251]  eta: 0:02:05  lr: 0.003696  min_lr: 0.003696  loss: 3.7514 (3.4951)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7956 (1.0590)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [69]  [1200/1251]  eta: 0:00:25  lr: 0.003694  min_lr: 0.003694  loss: 3.5967 (3.5063)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8104 (1.0827)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [69]  [1250/1251]  eta: 0:00:00  lr: 0.003694  min_lr: 0.003694  loss: 3.6070 (3.5107)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8104 (1.0791)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [69] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.003694  min_lr: 0.003694  loss: 3.6070 (3.5305)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8104 (1.0791)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.7544 (0.7544)  acc1: 86.0000 (86.0000)  acc5: 98.4000 (98.4000)  time: 5.6279  data: 5.3447  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9603 (0.9844)  acc1: 79.6000 (80.5818)  acc5: 96.4000 (96.1455)  time: 0.7495  data: 0.4862  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2468 (1.1506)  acc1: 75.2000 (76.9524)  acc5: 92.8000 (94.1143)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2800 (1.1615)  acc1: 75.2000 (76.8160)  acc5: 92.4000 (94.0480)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4793 s / it)
* Acc@1 77.176 Acc@5 94.188 loss 1.150
Accuracy of the model on the 50000 test images: 77.2%
Max accuracy: 77.27%
Epoch: [70]  [   0/1251]  eta: 1:08:16  lr: 0.003694  min_lr: 0.003694  loss: 4.2167 (4.2167)  weight_decay: 0.0500 (0.0500)  time: 3.2748  data: 2.6930  max mem: 40080
Epoch: [70]  [ 200/1251]  eta: 0:08:59  lr: 0.003692  min_lr: 0.003692  loss: 3.5711 (3.4919)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2849 (1.1340)  time: 0.5059  data: 0.0004  max mem: 40080
Epoch: [70]  [ 400/1251]  eta: 0:07:10  lr: 0.003690  min_lr: 0.003690  loss: 3.7000 (3.4948)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8252 (1.1052)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [70]  [ 600/1251]  eta: 0:05:27  lr: 0.003688  min_lr: 0.003688  loss: 3.4739 (3.4953)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8785 (1.1360)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [70]  [ 800/1251]  eta: 0:03:46  lr: 0.003686  min_lr: 0.003686  loss: 3.6501 (3.4869)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9515 (1.1362)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [70]  [1000/1251]  eta: 0:02:05  lr: 0.003684  min_lr: 0.003684  loss: 3.6608 (3.4905)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0790 (1.1239)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [70]  [1200/1251]  eta: 0:00:25  lr: 0.003682  min_lr: 0.003682  loss: 3.4900 (3.5060)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8934 (1.1105)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [70]  [1250/1251]  eta: 0:00:00  lr: 0.003682  min_lr: 0.003682  loss: 3.7590 (3.5092)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1694 (1.1144)  time: 0.4216  data: 0.0007  max mem: 40080
Epoch: [70] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.003682  min_lr: 0.003682  loss: 3.7590 (3.5114)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1694 (1.1144)
Test:  [ 0/25]  eta: 0:02:09  loss: 0.6958 (0.6958)  acc1: 89.6000 (89.6000)  acc5: 98.4000 (98.4000)  time: 5.1735  data: 4.8749  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8609 (0.9036)  acc1: 82.8000 (81.4545)  acc5: 97.2000 (96.6909)  time: 0.7081  data: 0.4435  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1165 (1.0915)  acc1: 74.0000 (77.8476)  acc5: 94.0000 (94.2286)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2288 (1.1043)  acc1: 74.4000 (77.5040)  acc5: 92.0000 (94.1120)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4611 s / it)
* Acc@1 77.256 Acc@5 94.162 loss 1.105
Accuracy of the model on the 50000 test images: 77.3%
Max accuracy: 77.27%
Epoch: [71]  [   0/1251]  eta: 1:13:07  lr: 0.003681  min_lr: 0.003681  loss: 3.4592 (3.4592)  weight_decay: 0.0500 (0.0500)  time: 3.5074  data: 2.8134  max mem: 40080
Epoch: [71]  [ 200/1251]  eta: 0:09:00  lr: 0.003680  min_lr: 0.003680  loss: 3.5668 (3.4923)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1179 (1.0389)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [71]  [ 400/1251]  eta: 0:07:10  lr: 0.003678  min_lr: 0.003678  loss: 3.6500 (3.5047)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8235 (1.1677)  time: 0.5003  data: 0.0004  max mem: 40080
Epoch: [71]  [ 600/1251]  eta: 0:05:28  lr: 0.003676  min_lr: 0.003676  loss: 3.3807 (3.4733)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9093 (1.0936)  time: 0.4993  data: 0.0004  max mem: 40080
Epoch: [71]  [ 800/1251]  eta: 0:03:46  lr: 0.003674  min_lr: 0.003674  loss: 3.3366 (3.4750)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7976 (1.1147)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [71]  [1000/1251]  eta: 0:02:06  lr: 0.003672  min_lr: 0.003672  loss: 3.6165 (3.4912)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9138 (1.1027)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [71]  [1200/1251]  eta: 0:00:25  lr: 0.003670  min_lr: 0.003670  loss: 3.8348 (3.5002)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0829 (1.1105)  time: 0.4988  data: 0.0004  max mem: 40080
Epoch: [71]  [1250/1251]  eta: 0:00:00  lr: 0.003669  min_lr: 0.003669  loss: 3.5219 (3.5026)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1924 (1.1205)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [71] Total time: 0:10:26 (0.5009 s / it)
Averaged stats: lr: 0.003669  min_lr: 0.003669  loss: 3.5219 (3.5072)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1924 (1.1205)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.7669 (0.7669)  acc1: 86.0000 (86.0000)  acc5: 98.0000 (98.0000)  time: 5.4594  data: 5.1573  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9992 (0.9675)  acc1: 80.0000 (81.2364)  acc5: 96.8000 (96.2909)  time: 0.7341  data: 0.4692  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1493 (1.1270)  acc1: 74.8000 (77.4857)  acc5: 94.0000 (94.4000)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1833 (1.1401)  acc1: 74.8000 (77.1040)  acc5: 93.6000 (94.3040)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4723 s / it)
* Acc@1 77.490 Acc@5 94.258 loss 1.130
Accuracy of the model on the 50000 test images: 77.5%
Max accuracy: 77.49%
Epoch: [72]  [   0/1251]  eta: 1:02:43  lr: 0.003669  min_lr: 0.003669  loss: 2.3050 (2.3050)  weight_decay: 0.0500 (0.0500)  time: 3.0088  data: 2.5025  max mem: 40080
Epoch: [72]  [ 200/1251]  eta: 0:08:55  lr: 0.003667  min_lr: 0.003667  loss: 3.6757 (3.4367)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9197 (1.2409)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [72]  [ 400/1251]  eta: 0:07:08  lr: 0.003665  min_lr: 0.003665  loss: 3.5832 (3.4571)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0978 (1.2323)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [72]  [ 600/1251]  eta: 0:05:26  lr: 0.003663  min_lr: 0.003663  loss: 3.5165 (3.4641)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9810 (1.1335)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [72]  [ 800/1251]  eta: 0:03:45  lr: 0.003661  min_lr: 0.003661  loss: 3.6444 (3.4690)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0129 (1.1449)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [72]  [1000/1251]  eta: 0:02:05  lr: 0.003659  min_lr: 0.003659  loss: 3.7214 (3.4815)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7214 (1.1556)  time: 0.5036  data: 0.0004  max mem: 40080
Epoch: [72]  [1200/1251]  eta: 0:00:25  lr: 0.003657  min_lr: 0.003657  loss: 3.7403 (3.4880)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1695 (1.1363)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [72]  [1250/1251]  eta: 0:00:00  lr: 0.003657  min_lr: 0.003657  loss: 3.6924 (3.4893)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8699 (1.1390)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [72] Total time: 0:10:23 (0.4986 s / it)
Averaged stats: lr: 0.003657  min_lr: 0.003657  loss: 3.6924 (3.5073)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8699 (1.1390)
Test:  [ 0/25]  eta: 0:01:51  loss: 0.7032 (0.7032)  acc1: 86.8000 (86.8000)  acc5: 98.4000 (98.4000)  time: 4.4581  data: 4.1590  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9264 (0.9353)  acc1: 81.2000 (80.4000)  acc5: 96.4000 (96.2182)  time: 0.7020  data: 0.4375  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1146 (1.1132)  acc1: 73.2000 (76.3810)  acc5: 93.6000 (94.0191)  time: 0.2937  data: 0.0327  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2343 (1.1259)  acc1: 74.0000 (76.2240)  acc5: 92.8000 (93.9360)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4586 s / it)
* Acc@1 77.070 Acc@5 94.126 loss 1.115
Accuracy of the model on the 50000 test images: 77.1%
Max accuracy: 77.49%
Epoch: [73]  [   0/1251]  eta: 1:11:16  lr: 0.003657  min_lr: 0.003657  loss: 4.2887 (4.2887)  weight_decay: 0.0500 (0.0500)  time: 3.4187  data: 2.4806  max mem: 40080
Epoch: [73]  [ 200/1251]  eta: 0:08:59  lr: 0.003655  min_lr: 0.003655  loss: 3.5525 (3.5142)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0667 (1.1482)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [73]  [ 400/1251]  eta: 0:07:10  lr: 0.003653  min_lr: 0.003653  loss: 3.3442 (3.4698)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1826 (1.1114)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [73]  [ 600/1251]  eta: 0:05:27  lr: 0.003651  min_lr: 0.003651  loss: 3.5346 (3.4795)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9041 (1.0893)  time: 0.5020  data: 0.0005  max mem: 40080
Epoch: [73]  [ 800/1251]  eta: 0:03:45  lr: 0.003649  min_lr: 0.003649  loss: 3.7091 (3.4625)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1219 (1.1157)  time: 0.4964  data: 0.0005  max mem: 40080
Epoch: [73]  [1000/1251]  eta: 0:02:05  lr: 0.003647  min_lr: 0.003647  loss: 3.4284 (3.4657)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9042 (1.1071)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [73]  [1200/1251]  eta: 0:00:25  lr: 0.003645  min_lr: 0.003645  loss: 3.5044 (3.4698)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3231 (1.1386)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [73]  [1250/1251]  eta: 0:00:00  lr: 0.003644  min_lr: 0.003644  loss: 3.5991 (3.4727)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8668 (1.1358)  time: 0.4214  data: 0.0007  max mem: 40080
Epoch: [73] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.003644  min_lr: 0.003644  loss: 3.5991 (3.4974)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8668 (1.1358)
Test:  [ 0/25]  eta: 0:02:25  loss: 0.7875 (0.7875)  acc1: 86.4000 (86.4000)  acc5: 97.6000 (97.6000)  time: 5.8093  data: 5.4891  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9536 (0.9551)  acc1: 79.2000 (81.1273)  acc5: 96.8000 (96.4000)  time: 0.7658  data: 0.4993  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1113 (1.1152)  acc1: 76.8000 (77.7714)  acc5: 93.6000 (94.3238)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1462 (1.1270)  acc1: 76.0000 (77.2480)  acc5: 92.8000 (94.1280)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4858 s / it)
* Acc@1 77.380 Acc@5 94.138 loss 1.124
Accuracy of the model on the 50000 test images: 77.4%
Max accuracy: 77.49%
Epoch: [74]  [   0/1251]  eta: 1:10:52  lr: 0.003644  min_lr: 0.003644  loss: 2.7516 (2.7516)  weight_decay: 0.0500 (0.0500)  time: 3.3993  data: 1.6012  max mem: 40080
Epoch: [74]  [ 200/1251]  eta: 0:09:00  lr: 0.003642  min_lr: 0.003642  loss: 3.5069 (3.4486)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8613 (1.0480)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [74]  [ 400/1251]  eta: 0:07:11  lr: 0.003640  min_lr: 0.003640  loss: 3.4571 (3.4624)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8429 (1.0929)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [74]  [ 600/1251]  eta: 0:05:27  lr: 0.003638  min_lr: 0.003638  loss: 3.8436 (3.4672)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8499 (1.1291)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [74]  [ 800/1251]  eta: 0:03:46  lr: 0.003636  min_lr: 0.003636  loss: 3.6831 (3.4897)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8776 (1.1451)  time: 0.4989  data: 0.0005  max mem: 40080
Epoch: [74]  [1000/1251]  eta: 0:02:05  lr: 0.003634  min_lr: 0.003634  loss: 3.7623 (3.4808)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9807 (1.1506)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [74]  [1200/1251]  eta: 0:00:25  lr: 0.003632  min_lr: 0.003632  loss: 3.3496 (3.4815)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8789 (1.1361)  time: 0.4997  data: 0.0005  max mem: 40080
Epoch: [74]  [1250/1251]  eta: 0:00:00  lr: 0.003631  min_lr: 0.003631  loss: 3.2859 (3.4788)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7087 (1.1267)  time: 0.4229  data: 0.0005  max mem: 40080
Epoch: [74] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.003631  min_lr: 0.003631  loss: 3.2859 (3.4978)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7087 (1.1267)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.7207 (0.7207)  acc1: 85.6000 (85.6000)  acc5: 98.8000 (98.8000)  time: 5.4025  data: 5.0917  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8984 (0.8918)  acc1: 81.6000 (80.8364)  acc5: 96.8000 (96.5091)  time: 0.7290  data: 0.4632  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0667 (1.0507)  acc1: 76.0000 (77.8286)  acc5: 94.0000 (94.3619)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1405 (1.0552)  acc1: 76.0000 (77.6000)  acc5: 93.2000 (94.2880)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4706 s / it)
* Acc@1 77.866 Acc@5 94.340 loss 1.050
Accuracy of the model on the 50000 test images: 77.9%
Max accuracy: 77.87%
Epoch: [75]  [   0/1251]  eta: 0:56:45  lr: 0.003631  min_lr: 0.003631  loss: 3.1504 (3.1504)  weight_decay: 0.0500 (0.0500)  time: 2.7220  data: 2.2169  max mem: 40080
Epoch: [75]  [ 200/1251]  eta: 0:08:56  lr: 0.003629  min_lr: 0.003629  loss: 3.5723 (3.5053)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0076 (1.2644)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [75]  [ 400/1251]  eta: 0:07:08  lr: 0.003627  min_lr: 0.003627  loss: 3.7983 (3.5136)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7533 (1.2497)  time: 0.4975  data: 0.0005  max mem: 40080
Epoch: [75]  [ 600/1251]  eta: 0:05:26  lr: 0.003625  min_lr: 0.003625  loss: 3.4036 (3.5118)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9740 (1.1636)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [75]  [ 800/1251]  eta: 0:03:45  lr: 0.003623  min_lr: 0.003623  loss: 3.7213 (3.5153)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9504 (1.1757)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [75]  [1000/1251]  eta: 0:02:05  lr: 0.003621  min_lr: 0.003621  loss: 3.7468 (3.5141)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7296 (1.1487)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [75]  [1200/1251]  eta: 0:00:25  lr: 0.003619  min_lr: 0.003619  loss: 3.6161 (3.5183)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3118 (1.1821)  time: 0.5052  data: 0.0004  max mem: 40080
Epoch: [75]  [1250/1251]  eta: 0:00:00  lr: 0.003618  min_lr: 0.003618  loss: 3.7578 (3.5212)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3818 (1.1898)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [75] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.003618  min_lr: 0.003618  loss: 3.7578 (3.4917)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3818 (1.1898)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.8080 (0.8080)  acc1: 86.4000 (86.4000)  acc5: 98.8000 (98.8000)  time: 5.4876  data: 5.1845  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 1.0243 (1.0283)  acc1: 80.0000 (81.2000)  acc5: 96.8000 (96.3273)  time: 0.7368  data: 0.4717  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2608 (1.1850)  acc1: 76.0000 (77.6381)  acc5: 93.6000 (94.2095)  time: 0.2616  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2713 (1.1965)  acc1: 75.6000 (77.4720)  acc5: 92.4000 (94.1280)  time: 0.2615  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4739 s / it)
* Acc@1 77.592 Acc@5 94.254 loss 1.184
Accuracy of the model on the 50000 test images: 77.6%
Max accuracy: 77.87%
Epoch: [76]  [   0/1251]  eta: 1:09:58  lr: 0.003618  min_lr: 0.003618  loss: 3.7684 (3.7684)  weight_decay: 0.0500 (0.0500)  time: 3.3564  data: 2.0812  max mem: 40080
Epoch: [76]  [ 200/1251]  eta: 0:08:59  lr: 0.003616  min_lr: 0.003616  loss: 3.6249 (3.4701)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7463 (0.9315)  time: 0.4994  data: 0.0004  max mem: 40080
Epoch: [76]  [ 400/1251]  eta: 0:07:10  lr: 0.003614  min_lr: 0.003614  loss: 3.5394 (3.4934)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7550 (0.9174)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [76]  [ 600/1251]  eta: 0:05:27  lr: 0.003612  min_lr: 0.003612  loss: 3.5062 (3.4756)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9090 (1.0384)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [76]  [ 800/1251]  eta: 0:03:46  lr: 0.003610  min_lr: 0.003610  loss: 3.4001 (3.4741)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9097 (1.0348)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [76]  [1000/1251]  eta: 0:02:05  lr: 0.003607  min_lr: 0.003607  loss: 3.5177 (3.4899)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8330 (1.0279)  time: 0.5045  data: 0.0004  max mem: 40080
Epoch: [76]  [1200/1251]  eta: 0:00:25  lr: 0.003605  min_lr: 0.003605  loss: 3.7017 (3.4823)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0742 (1.0655)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [76]  [1250/1251]  eta: 0:00:00  lr: 0.003605  min_lr: 0.003605  loss: 3.6502 (3.4811)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0405 (1.0674)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [76] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.003605  min_lr: 0.003605  loss: 3.6502 (3.4862)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0405 (1.0674)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.7843 (0.7843)  acc1: 87.2000 (87.2000)  acc5: 98.4000 (98.4000)  time: 5.6313  data: 5.3308  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9974 (0.9663)  acc1: 81.2000 (81.3455)  acc5: 96.8000 (96.2545)  time: 0.7498  data: 0.4850  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1694 (1.1283)  acc1: 76.4000 (77.8857)  acc5: 93.2000 (94.3238)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2070 (1.1369)  acc1: 76.4000 (77.6800)  acc5: 93.2000 (94.2720)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4795 s / it)
* Acc@1 77.538 Acc@5 94.260 loss 1.137
Accuracy of the model on the 50000 test images: 77.5%
Max accuracy: 77.87%
Epoch: [77]  [   0/1251]  eta: 1:09:55  lr: 0.003605  min_lr: 0.003605  loss: 2.8996 (2.8996)  weight_decay: 0.0500 (0.0500)  time: 3.3534  data: 1.6825  max mem: 40080
Epoch: [77]  [ 200/1251]  eta: 0:08:59  lr: 0.003603  min_lr: 0.003603  loss: 3.4290 (3.4303)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1187 (1.1884)  time: 0.5060  data: 0.0004  max mem: 40080
Epoch: [77]  [ 400/1251]  eta: 0:07:10  lr: 0.003601  min_lr: 0.003601  loss: 3.6003 (3.4662)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9070 (1.1925)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [77]  [ 600/1251]  eta: 0:05:27  lr: 0.003598  min_lr: 0.003598  loss: 3.6396 (3.4911)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9390 (1.1662)  time: 0.4959  data: 0.0005  max mem: 40080
Epoch: [77]  [ 800/1251]  eta: 0:03:46  lr: 0.003596  min_lr: 0.003596  loss: 3.5406 (3.4903)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7360 (1.1215)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [77]  [1000/1251]  eta: 0:02:05  lr: 0.003594  min_lr: 0.003594  loss: 3.4720 (3.4894)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9094 (1.1094)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [77]  [1200/1251]  eta: 0:00:25  lr: 0.003592  min_lr: 0.003592  loss: 3.5692 (3.4914)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1935 (1.1369)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [77]  [1250/1251]  eta: 0:00:00  lr: 0.003591  min_lr: 0.003591  loss: 3.7068 (3.4941)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7990 (1.1268)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [77] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.003591  min_lr: 0.003591  loss: 3.7068 (3.4861)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7990 (1.1268)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.7888 (0.7888)  acc1: 85.6000 (85.6000)  acc5: 98.8000 (98.8000)  time: 5.3292  data: 5.0094  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9674 (0.9890)  acc1: 82.4000 (81.6727)  acc5: 96.8000 (96.6546)  time: 0.7222  data: 0.4557  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1991 (1.1568)  acc1: 75.6000 (78.0191)  acc5: 93.6000 (94.4381)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2874 (1.1729)  acc1: 75.6000 (77.6000)  acc5: 93.2000 (94.2080)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4706 s / it)
* Acc@1 77.560 Acc@5 94.394 loss 1.165
Accuracy of the model on the 50000 test images: 77.6%
Max accuracy: 77.87%
Epoch: [78]  [   0/1251]  eta: 1:11:28  lr: 0.003591  min_lr: 0.003591  loss: 3.8910 (3.8910)  weight_decay: 0.0500 (0.0500)  time: 3.4284  data: 2.2089  max mem: 40080
Epoch: [78]  [ 200/1251]  eta: 0:09:00  lr: 0.003589  min_lr: 0.003589  loss: 3.7790 (3.4086)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1398 (1.0305)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [78]  [ 400/1251]  eta: 0:07:10  lr: 0.003587  min_lr: 0.003587  loss: 3.5260 (3.4652)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1849 (1.1515)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [78]  [ 600/1251]  eta: 0:05:27  lr: 0.003585  min_lr: 0.003585  loss: 3.5733 (3.4460)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2837 (1.1332)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [78]  [ 800/1251]  eta: 0:03:46  lr: 0.003583  min_lr: 0.003583  loss: 3.3591 (3.4475)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0783 (1.1212)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [78]  [1000/1251]  eta: 0:02:05  lr: 0.003580  min_lr: 0.003580  loss: 3.6456 (3.4584)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0731 (1.1317)  time: 0.4991  data: 0.0004  max mem: 40080
Epoch: [78]  [1200/1251]  eta: 0:00:25  lr: 0.003578  min_lr: 0.003578  loss: 3.7266 (3.4738)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7373 (1.1232)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [78]  [1250/1251]  eta: 0:00:00  lr: 0.003578  min_lr: 0.003578  loss: 3.3829 (3.4750)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0186 (1.1367)  time: 0.4213  data: 0.0005  max mem: 40080
Epoch: [78] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.003578  min_lr: 0.003578  loss: 3.3829 (3.4713)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0186 (1.1367)
Test:  [ 0/25]  eta: 0:01:43  loss: 0.6862 (0.6862)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 4.1378  data: 3.8067  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8858 (0.9169)  acc1: 81.6000 (81.1636)  acc5: 96.4000 (96.4000)  time: 0.7115  data: 0.4439  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1623 (1.0644)  acc1: 75.6000 (78.1143)  acc5: 94.0000 (94.7238)  time: 0.3149  data: 0.0539  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1627 (1.0790)  acc1: 75.6000 (77.8400)  acc5: 94.0000 (94.7360)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4627 s / it)
* Acc@1 77.704 Acc@5 94.458 loss 1.078
Accuracy of the model on the 50000 test images: 77.7%
Max accuracy: 77.87%
Epoch: [79]  [   0/1251]  eta: 1:10:08  lr: 0.003578  min_lr: 0.003578  loss: 3.3012 (3.3012)  weight_decay: 0.0500 (0.0500)  time: 3.3639  data: 2.2753  max mem: 40080
Epoch: [79]  [ 200/1251]  eta: 0:09:00  lr: 0.003575  min_lr: 0.003575  loss: 3.3589 (3.5026)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1827 (1.2351)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [79]  [ 400/1251]  eta: 0:07:11  lr: 0.003573  min_lr: 0.003573  loss: 3.8064 (3.4825)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8982 (1.1360)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [79]  [ 600/1251]  eta: 0:05:28  lr: 0.003571  min_lr: 0.003571  loss: 3.6535 (3.4734)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9038 (1.1363)  time: 0.4994  data: 0.0005  max mem: 40080
Epoch: [79]  [ 800/1251]  eta: 0:03:46  lr: 0.003569  min_lr: 0.003569  loss: 3.5832 (3.4823)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3131 (1.1782)  time: 0.4961  data: 0.0005  max mem: 40080
Epoch: [79]  [1000/1251]  eta: 0:02:05  lr: 0.003567  min_lr: 0.003567  loss: 3.6877 (3.4925)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8247 (1.1509)  time: 0.4960  data: 0.0005  max mem: 40080
Epoch: [79]  [1200/1251]  eta: 0:00:25  lr: 0.003564  min_lr: 0.003564  loss: 3.7553 (3.4813)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9552 (1.1265)  time: 0.4985  data: 0.0005  max mem: 40080
Epoch: [79]  [1250/1251]  eta: 0:00:00  lr: 0.003564  min_lr: 0.003564  loss: 3.7254 (3.4841)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1390 (1.1349)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [79] Total time: 0:10:26 (0.5006 s / it)
Averaged stats: lr: 0.003564  min_lr: 0.003564  loss: 3.7254 (3.4779)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1390 (1.1349)
Test:  [ 0/25]  eta: 0:02:25  loss: 0.8300 (0.8300)  acc1: 86.0000 (86.0000)  acc5: 99.2000 (99.2000)  time: 5.8156  data: 5.5022  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9608 (1.0036)  acc1: 81.6000 (81.0182)  acc5: 96.8000 (96.8364)  time: 0.7665  data: 0.5005  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2187 (1.1516)  acc1: 76.8000 (78.1524)  acc5: 93.6000 (94.5905)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2071 (1.1578)  acc1: 77.2000 (77.9040)  acc5: 92.8000 (94.5120)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4873 s / it)
* Acc@1 77.908 Acc@5 94.424 loss 1.159
Accuracy of the model on the 50000 test images: 77.9%
Max accuracy: 77.91%
Epoch: [80]  [   0/1251]  eta: 1:02:29  lr: 0.003564  min_lr: 0.003564  loss: 3.6092 (3.6092)  weight_decay: 0.0500 (0.0500)  time: 2.9969  data: 2.4845  max mem: 40080
Epoch: [80]  [ 200/1251]  eta: 0:08:56  lr: 0.003562  min_lr: 0.003562  loss: 3.6074 (3.4691)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3879 (1.2729)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [80]  [ 400/1251]  eta: 0:07:08  lr: 0.003559  min_lr: 0.003559  loss: 3.3868 (3.4602)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9376 (1.2348)  time: 0.4992  data: 0.0005  max mem: 40080
Epoch: [80]  [ 600/1251]  eta: 0:05:27  lr: 0.003557  min_lr: 0.003557  loss: 3.6025 (3.4658)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0817 (1.1579)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [80]  [ 800/1251]  eta: 0:03:46  lr: 0.003555  min_lr: 0.003555  loss: 3.5634 (3.4569)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2555 (1.2058)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [80]  [1000/1251]  eta: 0:02:05  lr: 0.003553  min_lr: 0.003553  loss: 3.6278 (3.4618)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8500 (1.1695)  time: 0.5120  data: 0.0005  max mem: 40080
Epoch: [80]  [1200/1251]  eta: 0:00:25  lr: 0.003550  min_lr: 0.003550  loss: 3.4949 (3.4572)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1958 (1.1636)  time: 0.5089  data: 0.0005  max mem: 40080
Epoch: [80]  [1250/1251]  eta: 0:00:00  lr: 0.003550  min_lr: 0.003550  loss: 3.0411 (3.4535)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0779 (1.1588)  time: 0.4207  data: 0.0006  max mem: 40080
Epoch: [80] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.003550  min_lr: 0.003550  loss: 3.0411 (3.4581)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0779 (1.1588)
Test:  [ 0/25]  eta: 0:02:07  loss: 0.7100 (0.7100)  acc1: 85.2000 (85.2000)  acc5: 98.0000 (98.0000)  time: 5.1166  data: 4.8230  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8702 (0.8931)  acc1: 81.2000 (81.3818)  acc5: 96.4000 (96.2909)  time: 0.7027  data: 0.4388  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1011 (1.0339)  acc1: 75.6000 (77.9238)  acc5: 94.0000 (94.6095)  time: 0.2612  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1011 (1.0444)  acc1: 75.6000 (77.4880)  acc5: 93.6000 (94.5440)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4585 s / it)
* Acc@1 77.868 Acc@5 94.556 loss 1.033
Accuracy of the model on the 50000 test images: 77.9%
Max accuracy: 77.91%
Epoch: [81]  [   0/1251]  eta: 1:08:53  lr: 0.003550  min_lr: 0.003550  loss: 3.9008 (3.9008)  weight_decay: 0.0500 (0.0500)  time: 3.3039  data: 2.3389  max mem: 40080
Epoch: [81]  [ 200/1251]  eta: 0:08:58  lr: 0.003547  min_lr: 0.003547  loss: 3.6739 (3.4616)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8617 (1.0108)  time: 0.4992  data: 0.0005  max mem: 40080
Epoch: [81]  [ 400/1251]  eta: 0:07:11  lr: 0.003545  min_lr: 0.003545  loss: 3.5764 (3.4795)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0418 (1.1401)  time: 0.5052  data: 0.0004  max mem: 40080
Epoch: [81]  [ 600/1251]  eta: 0:05:27  lr: 0.003543  min_lr: 0.003543  loss: 3.7038 (3.4740)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8175 (1.1163)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [81]  [ 800/1251]  eta: 0:03:46  lr: 0.003541  min_lr: 0.003541  loss: 3.5704 (3.4781)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0655 (1.1239)  time: 0.4957  data: 0.0004  max mem: 40080
Epoch: [81]  [1000/1251]  eta: 0:02:05  lr: 0.003538  min_lr: 0.003538  loss: 3.3785 (3.4852)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0480 (1.1175)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [81]  [1200/1251]  eta: 0:00:25  lr: 0.003536  min_lr: 0.003536  loss: 3.6345 (3.4814)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7993 (1.0973)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [81]  [1250/1251]  eta: 0:00:00  lr: 0.003535  min_lr: 0.003535  loss: 3.4473 (3.4824)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8525 (1.0860)  time: 0.4216  data: 0.0005  max mem: 40080
Epoch: [81] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.003535  min_lr: 0.003535  loss: 3.4473 (3.4616)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8525 (1.0860)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.7086 (0.7086)  acc1: 86.4000 (86.4000)  acc5: 98.0000 (98.0000)  time: 5.6041  data: 5.3182  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9126 (0.9149)  acc1: 81.2000 (81.6364)  acc5: 96.4000 (96.3636)  time: 0.7469  data: 0.4838  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1223 (1.0589)  acc1: 75.6000 (78.1905)  acc5: 94.0000 (94.4762)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1556 (1.0731)  acc1: 75.2000 (77.7760)  acc5: 94.0000 (94.4000)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4779 s / it)
* Acc@1 77.974 Acc@5 94.468 loss 1.066
Accuracy of the model on the 50000 test images: 78.0%
Max accuracy: 77.97%
Epoch: [82]  [   0/1251]  eta: 0:58:03  lr: 0.003535  min_lr: 0.003535  loss: 3.0637 (3.0637)  weight_decay: 0.0500 (0.0500)  time: 2.7846  data: 2.2722  max mem: 40080
Epoch: [82]  [ 200/1251]  eta: 0:08:58  lr: 0.003533  min_lr: 0.003533  loss: 3.5190 (3.3972)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4358 (1.2982)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [82]  [ 400/1251]  eta: 0:07:10  lr: 0.003531  min_lr: 0.003531  loss: 3.6007 (3.4435)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0488 (1.1909)  time: 0.4990  data: 0.0004  max mem: 40080
Epoch: [82]  [ 600/1251]  eta: 0:05:27  lr: 0.003528  min_lr: 0.003528  loss: 3.6542 (3.4582)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9323 (nan)  time: 0.4988  data: 0.0004  max mem: 40080
Epoch: [82]  [ 800/1251]  eta: 0:03:46  lr: 0.003526  min_lr: 0.003526  loss: 3.4691 (3.4545)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8711 (nan)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [82]  [1000/1251]  eta: 0:02:05  lr: 0.003524  min_lr: 0.003524  loss: 3.5816 (3.4586)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8897 (nan)  time: 0.4956  data: 0.0004  max mem: 40080
Epoch: [82]  [1200/1251]  eta: 0:00:25  lr: 0.003521  min_lr: 0.003521  loss: 3.6810 (3.4683)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8915 (nan)  time: 0.4956  data: 0.0004  max mem: 40080
Epoch: [82]  [1250/1251]  eta: 0:00:00  lr: 0.003521  min_lr: 0.003521  loss: 3.6982 (3.4675)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1353 (nan)  time: 0.4208  data: 0.0006  max mem: 40080
Epoch: [82] Total time: 0:10:25 (0.4996 s / it)
Averaged stats: lr: 0.003521  min_lr: 0.003521  loss: 3.6982 (3.4615)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1353 (nan)
Test:  [ 0/25]  eta: 0:02:04  loss: 0.6908 (0.6908)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 4.9611  data: 4.6386  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9055 (0.9244)  acc1: 82.0000 (81.7091)  acc5: 97.2000 (96.6546)  time: 0.7174  data: 0.4422  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1170 (1.0752)  acc1: 76.0000 (78.0571)  acc5: 94.0000 (94.8571)  time: 0.2779  data: 0.0113  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1769 (1.0865)  acc1: 76.8000 (77.8240)  acc5: 93.6000 (94.6720)  time: 0.2643  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4663 s / it)
* Acc@1 77.930 Acc@5 94.456 loss 1.086
Accuracy of the model on the 50000 test images: 77.9%
Max accuracy: 77.97%
Epoch: [83]  [   0/1251]  eta: 1:15:48  lr: 0.003521  min_lr: 0.003521  loss: 3.0559 (3.0559)  weight_decay: 0.0500 (0.0500)  time: 3.6356  data: 2.3585  max mem: 40080
Epoch: [83]  [ 200/1251]  eta: 0:09:00  lr: 0.003519  min_lr: 0.003519  loss: 3.5252 (3.3934)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9522 (1.3042)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [83]  [ 400/1251]  eta: 0:07:10  lr: 0.003516  min_lr: 0.003516  loss: 3.5661 (3.4426)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1321 (1.2242)  time: 0.4990  data: 0.0004  max mem: 40080
Epoch: [83]  [ 600/1251]  eta: 0:05:27  lr: 0.003514  min_lr: 0.003514  loss: 3.7191 (3.4423)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8158 (1.1648)  time: 0.5031  data: 0.0005  max mem: 40080
Epoch: [83]  [ 800/1251]  eta: 0:03:46  lr: 0.003512  min_lr: 0.003512  loss: 3.6364 (3.4385)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1555 (1.1518)  time: 0.4955  data: 0.0005  max mem: 40080
Epoch: [83]  [1000/1251]  eta: 0:02:05  lr: 0.003509  min_lr: 0.003509  loss: 3.3748 (3.4418)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9759 (1.1549)  time: 0.4963  data: 0.0005  max mem: 40080
Epoch: [83]  [1200/1251]  eta: 0:00:25  lr: 0.003507  min_lr: 0.003507  loss: 3.7480 (3.4436)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7950 (1.1444)  time: 0.4955  data: 0.0005  max mem: 40080
Epoch: [83]  [1250/1251]  eta: 0:00:00  lr: 0.003506  min_lr: 0.003506  loss: 3.2685 (3.4440)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0637 (1.1612)  time: 0.4207  data: 0.0007  max mem: 40080
Epoch: [83] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.003506  min_lr: 0.003506  loss: 3.2685 (3.4532)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0637 (1.1612)
Test:  [ 0/25]  eta: 0:02:28  loss: 0.7127 (0.7127)  acc1: 86.0000 (86.0000)  acc5: 98.8000 (98.8000)  time: 5.9423  data: 5.6337  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8807 (0.8843)  acc1: 82.0000 (81.6364)  acc5: 97.2000 (96.9091)  time: 0.7780  data: 0.5125  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0368 (1.0586)  acc1: 76.8000 (77.8286)  acc5: 94.4000 (94.6095)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1138 (1.0600)  acc1: 76.8000 (77.6320)  acc5: 93.6000 (94.5600)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4917 s / it)
* Acc@1 77.850 Acc@5 94.524 loss 1.054
Accuracy of the model on the 50000 test images: 77.9%
Max accuracy: 77.97%
Epoch: [84]  [   0/1251]  eta: 1:06:59  lr: 0.003506  min_lr: 0.003506  loss: 4.0125 (4.0125)  weight_decay: 0.0500 (0.0500)  time: 3.2127  data: 2.5422  max mem: 40080
Epoch: [84]  [ 200/1251]  eta: 0:08:57  lr: 0.003504  min_lr: 0.003504  loss: 3.5644 (3.4160)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9458 (1.1386)  time: 0.4990  data: 0.0004  max mem: 40080
Epoch: [84]  [ 400/1251]  eta: 0:07:09  lr: 0.003502  min_lr: 0.003502  loss: 3.6029 (3.4341)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9165 (1.0986)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [84]  [ 600/1251]  eta: 0:05:26  lr: 0.003499  min_lr: 0.003499  loss: 3.5115 (3.4329)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3741 (1.1608)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [84]  [ 800/1251]  eta: 0:03:45  lr: 0.003497  min_lr: 0.003497  loss: 3.6159 (3.4473)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9173 (1.1499)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [84]  [1000/1251]  eta: 0:02:05  lr: 0.003494  min_lr: 0.003494  loss: 3.7253 (3.4533)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2672 (1.1609)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [84]  [1200/1251]  eta: 0:00:25  lr: 0.003492  min_lr: 0.003492  loss: 3.4372 (3.4583)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7828 (1.1150)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [84]  [1250/1251]  eta: 0:00:00  lr: 0.003491  min_lr: 0.003491  loss: 3.6157 (3.4590)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8557 (1.1083)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [84] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.003491  min_lr: 0.003491  loss: 3.6157 (3.4592)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8557 (1.1083)
Test:  [ 0/25]  eta: 0:01:43  loss: 0.7067 (0.7067)  acc1: 87.6000 (87.6000)  acc5: 99.2000 (99.2000)  time: 4.1360  data: 3.8197  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9123 (0.9149)  acc1: 83.2000 (81.4909)  acc5: 96.8000 (96.7273)  time: 0.6849  data: 0.4154  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1391 (1.0820)  acc1: 75.2000 (77.6381)  acc5: 94.0000 (94.7238)  time: 0.3004  data: 0.0375  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1961 (1.0886)  acc1: 75.2000 (77.4240)  acc5: 94.0000 (94.6400)  time: 0.2620  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4513 s / it)
* Acc@1 78.064 Acc@5 94.420 loss 1.077
Accuracy of the model on the 50000 test images: 78.1%
Max accuracy: 78.06%
Epoch: [85]  [   0/1251]  eta: 0:47:45  lr: 0.003491  min_lr: 0.003491  loss: 3.0142 (3.0142)  weight_decay: 0.0500 (0.0500)  time: 2.2904  data: 1.7807  max mem: 40080
Epoch: [85]  [ 200/1251]  eta: 0:08:52  lr: 0.003489  min_lr: 0.003489  loss: 3.2733 (3.4421)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9597 (1.1513)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [85]  [ 400/1251]  eta: 0:07:07  lr: 0.003487  min_lr: 0.003487  loss: 3.0567 (3.4346)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2052 (1.1234)  time: 0.4988  data: 0.0004  max mem: 40080
Epoch: [85]  [ 600/1251]  eta: 0:05:26  lr: 0.003484  min_lr: 0.003484  loss: 3.6406 (3.4447)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1942 (1.1485)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [85]  [ 800/1251]  eta: 0:03:45  lr: 0.003482  min_lr: 0.003482  loss: 3.2679 (3.4313)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8491 (1.1129)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [85]  [1000/1251]  eta: 0:02:05  lr: 0.003479  min_lr: 0.003479  loss: 3.5044 (3.4410)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7446 (1.1191)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [85]  [1200/1251]  eta: 0:00:25  lr: 0.003477  min_lr: 0.003477  loss: 3.4917 (3.4356)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8107 (1.1171)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [85]  [1250/1251]  eta: 0:00:00  lr: 0.003476  min_lr: 0.003476  loss: 3.5497 (3.4370)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1566 (1.1273)  time: 0.4213  data: 0.0005  max mem: 40080
Epoch: [85] Total time: 0:10:25 (0.4996 s / it)
Averaged stats: lr: 0.003476  min_lr: 0.003476  loss: 3.5497 (3.4441)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1566 (1.1273)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.8181 (0.8181)  acc1: 86.4000 (86.4000)  acc5: 97.6000 (97.6000)  time: 5.3074  data: 5.0149  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9653 (0.9732)  acc1: 81.2000 (81.7455)  acc5: 97.6000 (96.8364)  time: 0.7205  data: 0.4562  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1755 (1.1080)  acc1: 76.8000 (78.4381)  acc5: 94.0000 (94.9143)  time: 0.2617  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1513 (1.1205)  acc1: 75.6000 (78.0480)  acc5: 93.6000 (94.7040)  time: 0.2616  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4685 s / it)
* Acc@1 77.998 Acc@5 94.594 loss 1.123
Accuracy of the model on the 50000 test images: 78.0%
Max accuracy: 78.06%
Epoch: [86]  [   0/1251]  eta: 1:13:16  lr: 0.003476  min_lr: 0.003476  loss: 3.5897 (3.5897)  weight_decay: 0.0500 (0.0500)  time: 3.5148  data: 2.8403  max mem: 40080
Epoch: [86]  [ 200/1251]  eta: 0:09:00  lr: 0.003474  min_lr: 0.003474  loss: 3.5579 (3.4408)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9972 (1.0101)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [86]  [ 400/1251]  eta: 0:07:10  lr: 0.003472  min_lr: 0.003472  loss: 3.5847 (3.4747)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0429 (1.1081)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [86]  [ 600/1251]  eta: 0:05:27  lr: 0.003469  min_lr: 0.003469  loss: 3.6018 (3.4931)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0418 (1.1905)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [86]  [ 800/1251]  eta: 0:03:46  lr: 0.003467  min_lr: 0.003467  loss: 3.3872 (3.4784)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1107 (1.1636)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [86]  [1000/1251]  eta: 0:02:05  lr: 0.003464  min_lr: 0.003464  loss: 3.5278 (3.4766)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6285 (1.1072)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [86]  [1200/1251]  eta: 0:00:25  lr: 0.003462  min_lr: 0.003462  loss: 3.6476 (3.4776)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9430 (1.0980)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [86]  [1250/1251]  eta: 0:00:00  lr: 0.003461  min_lr: 0.003461  loss: 3.0077 (3.4725)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6600 (1.0861)  time: 0.4210  data: 0.0007  max mem: 40080
Epoch: [86] Total time: 0:10:24 (0.4996 s / it)
Averaged stats: lr: 0.003461  min_lr: 0.003461  loss: 3.0077 (3.4434)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6600 (1.0861)
Test:  [ 0/25]  eta: 0:02:22  loss: 0.6707 (0.6707)  acc1: 87.6000 (87.6000)  acc5: 98.0000 (98.0000)  time: 5.7017  data: 5.3926  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8480 (0.8477)  acc1: 79.6000 (82.1455)  acc5: 96.4000 (96.2182)  time: 0.7561  data: 0.4905  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1013 (1.0045)  acc1: 77.2000 (78.7810)  acc5: 93.2000 (94.6286)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1013 (1.0218)  acc1: 76.4000 (78.2080)  acc5: 93.2000 (94.5280)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4821 s / it)
* Acc@1 78.218 Acc@5 94.592 loss 1.008
Accuracy of the model on the 50000 test images: 78.2%
Max accuracy: 78.22%
Epoch: [87]  [   0/1251]  eta: 0:48:02  lr: 0.003461  min_lr: 0.003461  loss: 2.7206 (2.7206)  weight_decay: 0.0500 (0.0500)  time: 2.3041  data: 1.7909  max mem: 40080
Epoch: [87]  [ 200/1251]  eta: 0:08:53  lr: 0.003459  min_lr: 0.003459  loss: 3.1577 (3.3730)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9127 (1.1624)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [87]  [ 400/1251]  eta: 0:07:07  lr: 0.003456  min_lr: 0.003456  loss: 3.3075 (3.3900)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9912 (1.1484)  time: 0.4965  data: 0.0005  max mem: 40080
Epoch: [87]  [ 600/1251]  eta: 0:05:26  lr: 0.003454  min_lr: 0.003454  loss: 3.4721 (3.3886)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2295 (1.1290)  time: 0.5077  data: 0.0005  max mem: 40080
Epoch: [87]  [ 800/1251]  eta: 0:03:45  lr: 0.003451  min_lr: 0.003451  loss: 3.6344 (3.4044)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9809 (1.0943)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [87]  [1000/1251]  eta: 0:02:05  lr: 0.003449  min_lr: 0.003449  loss: 3.4271 (3.4162)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6900 (1.0938)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [87]  [1200/1251]  eta: 0:00:25  lr: 0.003446  min_lr: 0.003446  loss: 3.4041 (3.4118)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6982 (1.0836)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [87]  [1250/1251]  eta: 0:00:00  lr: 0.003446  min_lr: 0.003446  loss: 3.5038 (3.4143)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8388 (1.0861)  time: 0.4214  data: 0.0005  max mem: 40080
Epoch: [87] Total time: 0:10:23 (0.4986 s / it)
Averaged stats: lr: 0.003446  min_lr: 0.003446  loss: 3.5038 (3.4335)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8388 (1.0861)
Test:  [ 0/25]  eta: 0:02:09  loss: 0.7478 (0.7478)  acc1: 86.0000 (86.0000)  acc5: 98.4000 (98.4000)  time: 5.1899  data: 4.8828  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9361 (0.9563)  acc1: 83.6000 (81.0909)  acc5: 97.2000 (96.6546)  time: 0.7096  data: 0.4442  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1542 (1.1080)  acc1: 74.8000 (77.6381)  acc5: 93.6000 (94.5905)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2013 (1.1134)  acc1: 74.8000 (77.6480)  acc5: 93.2000 (94.5280)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4624 s / it)
* Acc@1 78.068 Acc@5 94.536 loss 1.107
Accuracy of the model on the 50000 test images: 78.1%
Max accuracy: 78.22%
Epoch: [88]  [   0/1251]  eta: 1:12:10  lr: 0.003446  min_lr: 0.003446  loss: 4.0399 (4.0399)  weight_decay: 0.0500 (0.0500)  time: 3.4616  data: 2.8824  max mem: 40080
Epoch: [88]  [ 200/1251]  eta: 0:08:59  lr: 0.003443  min_lr: 0.003443  loss: 3.4865 (3.4581)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1665 (1.0529)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [88]  [ 400/1251]  eta: 0:07:10  lr: 0.003441  min_lr: 0.003441  loss: 3.4990 (3.4452)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9164 (1.0427)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [88]  [ 600/1251]  eta: 0:05:27  lr: 0.003438  min_lr: 0.003438  loss: 3.4279 (3.4280)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9684 (1.0484)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [88]  [ 800/1251]  eta: 0:03:46  lr: 0.003436  min_lr: 0.003436  loss: 3.3735 (3.4293)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0499 (1.0886)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [88]  [1000/1251]  eta: 0:02:05  lr: 0.003433  min_lr: 0.003433  loss: 3.4128 (3.4221)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8335 (1.1099)  time: 0.4981  data: 0.0005  max mem: 40080
Epoch: [88]  [1200/1251]  eta: 0:00:25  lr: 0.003431  min_lr: 0.003431  loss: 3.3601 (3.4366)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2226 (1.1074)  time: 0.4991  data: 0.0004  max mem: 40080
Epoch: [88]  [1250/1251]  eta: 0:00:00  lr: 0.003430  min_lr: 0.003430  loss: 3.6935 (3.4416)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1252 (1.1159)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [88] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.003430  min_lr: 0.003430  loss: 3.6935 (3.4407)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1252 (1.1159)
Test:  [ 0/25]  eta: 0:02:03  loss: 0.8193 (0.8193)  acc1: 86.8000 (86.8000)  acc5: 98.0000 (98.0000)  time: 4.9487  data: 4.6371  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.0573 (1.0444)  acc1: 80.0000 (81.3818)  acc5: 96.8000 (96.6546)  time: 0.6880  data: 0.4220  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1981 (1.2011)  acc1: 76.0000 (77.9810)  acc5: 94.8000 (94.4191)  time: 0.2616  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2745 (1.2133)  acc1: 75.6000 (77.7280)  acc5: 93.2000 (94.3680)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4545 s / it)
* Acc@1 77.950 Acc@5 94.428 loss 1.210
Accuracy of the model on the 50000 test images: 78.0%
Max accuracy: 78.22%
Epoch: [89]  [   0/1251]  eta: 1:16:12  lr: 0.003430  min_lr: 0.003430  loss: 3.6631 (3.6631)  weight_decay: 0.0500 (0.0500)  time: 3.6553  data: 2.2587  max mem: 40080
Epoch: [89]  [ 200/1251]  eta: 0:09:00  lr: 0.003428  min_lr: 0.003428  loss: 3.5083 (3.4795)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0396 (1.0558)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [89]  [ 400/1251]  eta: 0:07:10  lr: 0.003425  min_lr: 0.003425  loss: 3.5812 (3.4274)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8677 (1.0959)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [89]  [ 600/1251]  eta: 0:05:27  lr: 0.003423  min_lr: 0.003423  loss: 3.0417 (3.4353)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1193 (1.0764)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [89]  [ 800/1251]  eta: 0:03:46  lr: 0.003420  min_lr: 0.003420  loss: 3.5405 (3.4236)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8622 (1.1007)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [89]  [1000/1251]  eta: 0:02:05  lr: 0.003418  min_lr: 0.003418  loss: 3.6963 (3.4384)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7153 (1.1036)  time: 0.4965  data: 0.0005  max mem: 40080
Epoch: [89]  [1200/1251]  eta: 0:00:25  lr: 0.003415  min_lr: 0.003415  loss: 3.7254 (3.4441)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9873 (1.0936)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [89]  [1250/1251]  eta: 0:00:00  lr: 0.003414  min_lr: 0.003414  loss: 3.4050 (3.4419)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3092 (1.1047)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [89] Total time: 0:10:25 (0.4996 s / it)
Averaged stats: lr: 0.003414  min_lr: 0.003414  loss: 3.4050 (3.4315)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3092 (1.1047)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.7050 (0.7050)  acc1: 86.4000 (86.4000)  acc5: 97.6000 (97.6000)  time: 5.5177  data: 5.2134  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9176 (0.8993)  acc1: 83.2000 (82.8000)  acc5: 96.8000 (96.6182)  time: 0.7394  data: 0.4743  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0990 (1.0707)  acc1: 76.8000 (78.8952)  acc5: 94.0000 (94.6095)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1488 (1.0807)  acc1: 77.2000 (78.5600)  acc5: 93.6000 (94.5120)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4746 s / it)
* Acc@1 78.454 Acc@5 94.520 loss 1.083
Accuracy of the model on the 50000 test images: 78.5%
Max accuracy: 78.45%
Epoch: [90]  [   0/1251]  eta: 1:02:47  lr: 0.003414  min_lr: 0.003414  loss: 4.0660 (4.0660)  weight_decay: 0.0500 (0.0500)  time: 3.0117  data: 2.5026  max mem: 40080
Epoch: [90]  [ 200/1251]  eta: 0:08:57  lr: 0.003412  min_lr: 0.003412  loss: 3.5831 (3.4076)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8919 (1.0427)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [90]  [ 400/1251]  eta: 0:07:08  lr: 0.003409  min_lr: 0.003409  loss: 3.4127 (3.4084)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1289 (1.0484)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [90]  [ 600/1251]  eta: 0:05:26  lr: 0.003407  min_lr: 0.003407  loss: 3.6290 (3.4170)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1193 (1.0484)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [90]  [ 800/1251]  eta: 0:03:45  lr: 0.003404  min_lr: 0.003404  loss: 3.6317 (3.4171)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0764 (1.0421)  time: 0.4991  data: 0.0004  max mem: 40080
Epoch: [90]  [1000/1251]  eta: 0:02:05  lr: 0.003402  min_lr: 0.003402  loss: 3.3675 (3.4158)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9877 (1.0636)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [90]  [1200/1251]  eta: 0:00:25  lr: 0.003399  min_lr: 0.003399  loss: 3.5355 (3.4168)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9864 (1.0728)  time: 0.4957  data: 0.0005  max mem: 40080
Epoch: [90]  [1250/1251]  eta: 0:00:00  lr: 0.003398  min_lr: 0.003398  loss: 3.5355 (3.4172)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0551 (1.0799)  time: 0.4209  data: 0.0006  max mem: 40080
Epoch: [90] Total time: 0:10:24 (0.4990 s / it)
Averaged stats: lr: 0.003398  min_lr: 0.003398  loss: 3.5355 (3.4313)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0551 (1.0799)
Test:  [ 0/25]  eta: 0:02:11  loss: 0.7410 (0.7410)  acc1: 87.6000 (87.6000)  acc5: 99.2000 (99.2000)  time: 5.2500  data: 4.9391  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9504 (0.9004)  acc1: 83.6000 (82.3273)  acc5: 97.2000 (96.7636)  time: 0.7151  data: 0.4494  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0676 (1.0704)  acc1: 76.0000 (78.1905)  acc5: 94.4000 (94.7048)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1200 (1.0823)  acc1: 75.6000 (77.9040)  acc5: 93.2000 (94.5280)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4683 s / it)
* Acc@1 78.342 Acc@5 94.592 loss 1.074
Accuracy of the model on the 50000 test images: 78.3%
Max accuracy: 78.45%
Epoch: [91]  [   0/1251]  eta: 1:12:03  lr: 0.003398  min_lr: 0.003398  loss: 3.2431 (3.2431)  weight_decay: 0.0500 (0.0500)  time: 3.4560  data: 2.3918  max mem: 40080
Epoch: [91]  [ 200/1251]  eta: 0:08:59  lr: 0.003396  min_lr: 0.003396  loss: 3.2827 (3.3707)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0760 (1.0849)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [91]  [ 400/1251]  eta: 0:07:10  lr: 0.003393  min_lr: 0.003393  loss: 3.4328 (3.3935)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0216 (1.0535)  time: 0.4957  data: 0.0005  max mem: 40080
Epoch: [91]  [ 600/1251]  eta: 0:05:27  lr: 0.003391  min_lr: 0.003391  loss: 3.6125 (3.4142)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9218 (1.1032)  time: 0.5033  data: 0.0004  max mem: 40080
Epoch: [91]  [ 800/1251]  eta: 0:03:46  lr: 0.003388  min_lr: 0.003388  loss: 3.6209 (3.4290)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6919 (1.1484)  time: 0.5026  data: 0.0004  max mem: 40080
Epoch: [91]  [1000/1251]  eta: 0:02:05  lr: 0.003385  min_lr: 0.003385  loss: 3.6559 (3.4320)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0762 (1.1190)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [91]  [1200/1251]  eta: 0:00:25  lr: 0.003383  min_lr: 0.003383  loss: 3.5414 (3.4395)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8100 (1.1012)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [91]  [1250/1251]  eta: 0:00:00  lr: 0.003382  min_lr: 0.003382  loss: 3.4646 (3.4425)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9155 (1.0956)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [91] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.003382  min_lr: 0.003382  loss: 3.4646 (3.4356)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9155 (1.0956)
Test:  [ 0/25]  eta: 0:02:25  loss: 0.6765 (0.6765)  acc1: 87.2000 (87.2000)  acc5: 98.0000 (98.0000)  time: 5.8015  data: 5.4920  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8919 (0.9123)  acc1: 82.8000 (81.3818)  acc5: 96.8000 (96.7273)  time: 0.7650  data: 0.4996  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0886 (1.0534)  acc1: 75.2000 (78.0952)  acc5: 93.6000 (94.9714)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1559 (1.0666)  acc1: 75.2000 (77.7600)  acc5: 93.2000 (94.8640)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4860 s / it)
* Acc@1 78.170 Acc@5 94.648 loss 1.068
Accuracy of the model on the 50000 test images: 78.2%
Max accuracy: 78.45%
Epoch: [92]  [   0/1251]  eta: 1:12:48  lr: 0.003382  min_lr: 0.003382  loss: 2.9426 (2.9426)  weight_decay: 0.0500 (0.0500)  time: 3.4922  data: 2.7595  max mem: 40080
Epoch: [92]  [ 200/1251]  eta: 0:08:59  lr: 0.003380  min_lr: 0.003380  loss: 3.5601 (3.4203)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9417 (1.0792)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [92]  [ 400/1251]  eta: 0:07:10  lr: 0.003377  min_lr: 0.003377  loss: 3.6912 (3.3952)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8457 (1.0541)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [92]  [ 600/1251]  eta: 0:05:27  lr: 0.003374  min_lr: 0.003374  loss: 3.5382 (3.4136)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8772 (1.1093)  time: 0.5082  data: 0.0005  max mem: 40080
Epoch: [92]  [ 800/1251]  eta: 0:03:46  lr: 0.003372  min_lr: 0.003372  loss: 3.6001 (3.4329)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9766 (1.1207)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [92]  [1000/1251]  eta: 0:02:05  lr: 0.003369  min_lr: 0.003369  loss: 3.7579 (3.4392)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0189 (1.1172)  time: 0.4986  data: 0.0005  max mem: 40080
Epoch: [92]  [1200/1251]  eta: 0:00:25  lr: 0.003367  min_lr: 0.003367  loss: 3.5018 (3.4358)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8057 (1.1186)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [92]  [1250/1251]  eta: 0:00:00  lr: 0.003366  min_lr: 0.003366  loss: 3.4800 (3.4316)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7693 (1.1073)  time: 0.4220  data: 0.0005  max mem: 40080
Epoch: [92] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.003366  min_lr: 0.003366  loss: 3.4800 (3.4234)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7693 (1.1073)
Test:  [ 0/25]  eta: 0:01:58  loss: 0.6994 (0.6994)  acc1: 87.2000 (87.2000)  acc5: 98.4000 (98.4000)  time: 4.7346  data: 4.3898  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8628 (0.8935)  acc1: 82.0000 (81.6364)  acc5: 96.4000 (96.3636)  time: 0.7014  data: 0.4328  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1085 (1.0417)  acc1: 76.4000 (78.7048)  acc5: 94.0000 (94.5143)  time: 0.2794  data: 0.0186  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0717 (1.0521)  acc1: 76.4000 (78.3520)  acc5: 94.0000 (94.4480)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4587 s / it)
* Acc@1 78.622 Acc@5 94.664 loss 1.042
Accuracy of the model on the 50000 test images: 78.6%
Max accuracy: 78.62%
Epoch: [93]  [   0/1251]  eta: 0:52:25  lr: 0.003366  min_lr: 0.003366  loss: 3.5387 (3.5387)  weight_decay: 0.0500 (0.0500)  time: 2.5142  data: 2.0019  max mem: 40080
Epoch: [93]  [ 200/1251]  eta: 0:08:54  lr: 0.003363  min_lr: 0.003363  loss: 3.5557 (3.4296)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1807 (1.3242)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [93]  [ 400/1251]  eta: 0:07:08  lr: 0.003361  min_lr: 0.003361  loss: 3.5813 (3.4479)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0889 (1.1777)  time: 0.4963  data: 0.0005  max mem: 40080
Epoch: [93]  [ 600/1251]  eta: 0:05:26  lr: 0.003358  min_lr: 0.003358  loss: 3.6362 (3.4472)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6298 (1.1111)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [93]  [ 800/1251]  eta: 0:03:45  lr: 0.003355  min_lr: 0.003355  loss: 3.4640 (3.4436)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9767 (1.0621)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [93]  [1000/1251]  eta: 0:02:05  lr: 0.003353  min_lr: 0.003353  loss: 3.4775 (3.4418)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0353 (1.0917)  time: 0.4957  data: 0.0005  max mem: 40080
Epoch: [93]  [1200/1251]  eta: 0:00:25  lr: 0.003350  min_lr: 0.003350  loss: 3.4572 (3.4433)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8932 (1.0825)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [93]  [1250/1251]  eta: 0:00:00  lr: 0.003350  min_lr: 0.003350  loss: 3.3941 (3.4433)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7460 (1.0764)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [93] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.003350  min_lr: 0.003350  loss: 3.3941 (3.4235)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7460 (1.0764)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.7432 (0.7432)  acc1: 86.8000 (86.8000)  acc5: 97.6000 (97.6000)  time: 5.3532  data: 5.0483  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8956 (0.9335)  acc1: 82.4000 (81.9636)  acc5: 96.8000 (96.5091)  time: 0.7245  data: 0.4592  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0725 (1.0858)  acc1: 78.0000 (78.8191)  acc5: 94.8000 (95.0286)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1333 (1.0990)  acc1: 78.0000 (78.5120)  acc5: 94.0000 (94.8640)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4681 s / it)
* Acc@1 78.326 Acc@5 94.656 loss 1.100
Accuracy of the model on the 50000 test images: 78.3%
Max accuracy: 78.62%
Epoch: [94]  [   0/1251]  eta: 1:11:59  lr: 0.003350  min_lr: 0.003350  loss: 2.2320 (2.2320)  weight_decay: 0.0500 (0.0500)  time: 3.4525  data: 1.6161  max mem: 40080
Epoch: [94]  [ 200/1251]  eta: 0:09:01  lr: 0.003347  min_lr: 0.003347  loss: 3.6056 (3.3995)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0293 (1.0831)  time: 0.5009  data: 0.0004  max mem: 40080
Epoch: [94]  [ 400/1251]  eta: 0:07:10  lr: 0.003344  min_lr: 0.003344  loss: 3.1926 (3.3929)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7172 (1.0546)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [94]  [ 600/1251]  eta: 0:05:27  lr: 0.003342  min_lr: 0.003342  loss: 3.5579 (3.4035)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8188 (1.0784)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [94]  [ 800/1251]  eta: 0:03:46  lr: 0.003339  min_lr: 0.003339  loss: 3.5857 (3.4109)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7856 (1.0875)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [94]  [1000/1251]  eta: 0:02:05  lr: 0.003336  min_lr: 0.003336  loss: 3.6714 (3.4203)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4250 (1.1055)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [94]  [1200/1251]  eta: 0:00:25  lr: 0.003334  min_lr: 0.003334  loss: 3.2762 (3.4203)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3517 (1.1029)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [94]  [1250/1251]  eta: 0:00:00  lr: 0.003333  min_lr: 0.003333  loss: 3.3911 (3.4193)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1263 (1.1019)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [94] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.003333  min_lr: 0.003333  loss: 3.3911 (3.4058)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1263 (1.1019)
Test:  [ 0/25]  eta: 0:02:08  loss: 0.7346 (0.7346)  acc1: 87.6000 (87.6000)  acc5: 98.4000 (98.4000)  time: 5.1217  data: 4.8012  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8633 (0.9320)  acc1: 82.4000 (82.2545)  acc5: 96.8000 (96.7273)  time: 0.7036  data: 0.4369  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0876 (1.0902)  acc1: 76.0000 (78.6286)  acc5: 94.0000 (95.0095)  time: 0.2615  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1859 (1.1003)  acc1: 76.8000 (78.4160)  acc5: 94.0000 (94.9280)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4590 s / it)
* Acc@1 78.572 Acc@5 94.846 loss 1.096
Accuracy of the model on the 50000 test images: 78.6%
Max accuracy: 78.62%
Epoch: [95]  [   0/1251]  eta: 1:12:25  lr: 0.003333  min_lr: 0.003333  loss: 2.2884 (2.2884)  weight_decay: 0.0500 (0.0500)  time: 3.4739  data: 2.5512  max mem: 40080
Epoch: [95]  [ 200/1251]  eta: 0:09:00  lr: 0.003330  min_lr: 0.003330  loss: 3.3492 (3.3734)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9949 (0.9927)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [95]  [ 400/1251]  eta: 0:07:10  lr: 0.003327  min_lr: 0.003327  loss: 3.5971 (3.3790)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9956 (1.0280)  time: 0.5073  data: 0.0004  max mem: 40080
Epoch: [95]  [ 600/1251]  eta: 0:05:27  lr: 0.003325  min_lr: 0.003325  loss: 3.6543 (3.4027)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7785 (0.9975)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [95]  [ 800/1251]  eta: 0:03:46  lr: 0.003322  min_lr: 0.003322  loss: 3.4758 (3.4064)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [95]  [1000/1251]  eta: 0:02:05  lr: 0.003319  min_lr: 0.003319  loss: 3.3949 (3.4051)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7102 (nan)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [95]  [1200/1251]  eta: 0:00:25  lr: 0.003317  min_lr: 0.003317  loss: 3.5658 (3.4047)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2449 (nan)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [95]  [1250/1251]  eta: 0:00:00  lr: 0.003316  min_lr: 0.003316  loss: 3.4616 (3.4076)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1650 (nan)  time: 0.4211  data: 0.0007  max mem: 40080
Epoch: [95] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.003316  min_lr: 0.003316  loss: 3.4616 (3.4107)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1650 (nan)
Test:  [ 0/25]  eta: 0:02:22  loss: 0.6974 (0.6974)  acc1: 86.8000 (86.8000)  acc5: 98.0000 (98.0000)  time: 5.6945  data: 5.3977  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8882 (0.8884)  acc1: 82.8000 (82.9455)  acc5: 97.2000 (96.8727)  time: 0.7556  data: 0.4911  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0090 (1.0484)  acc1: 77.2000 (78.8571)  acc5: 94.8000 (94.9333)  time: 0.2616  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1323 (1.0609)  acc1: 76.4000 (78.4320)  acc5: 93.6000 (94.7360)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4819 s / it)
* Acc@1 78.400 Acc@5 94.808 loss 1.057
Accuracy of the model on the 50000 test images: 78.4%
Max accuracy: 78.62%
Epoch: [96]  [   0/1251]  eta: 1:14:38  lr: 0.003316  min_lr: 0.003316  loss: 3.1321 (3.1321)  weight_decay: 0.0500 (0.0500)  time: 3.5801  data: 2.2387  max mem: 40080
Epoch: [96]  [ 200/1251]  eta: 0:09:01  lr: 0.003313  min_lr: 0.003313  loss: 3.0738 (3.3545)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2000 (1.0116)  time: 0.4957  data: 0.0004  max mem: 40080
Epoch: [96]  [ 400/1251]  eta: 0:07:16  lr: 0.003311  min_lr: 0.003311  loss: 3.3279 (3.3660)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7948 (1.0270)  time: 0.5029  data: 0.0004  max mem: 40080
Epoch: [96]  [ 600/1251]  eta: 0:05:30  lr: 0.003308  min_lr: 0.003308  loss: 3.6475 (3.3910)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8367 (1.0179)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [96]  [ 800/1251]  eta: 0:03:47  lr: 0.003305  min_lr: 0.003305  loss: 3.4619 (3.3940)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2247 (1.0660)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [96]  [1000/1251]  eta: 0:02:06  lr: 0.003302  min_lr: 0.003302  loss: 3.5814 (3.4040)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9425 (1.0441)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [96]  [1200/1251]  eta: 0:00:25  lr: 0.003300  min_lr: 0.003300  loss: 3.4245 (3.4146)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9368 (1.0503)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [96]  [1250/1251]  eta: 0:00:00  lr: 0.003299  min_lr: 0.003299  loss: 3.5632 (3.4136)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7880 (1.0463)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [96] Total time: 0:10:28 (0.5022 s / it)
Averaged stats: lr: 0.003299  min_lr: 0.003299  loss: 3.5632 (3.4059)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7880 (1.0463)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.7662 (0.7662)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 5.3137  data: 5.0056  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8978 (0.9226)  acc1: 82.4000 (82.5818)  acc5: 96.8000 (97.0182)  time: 0.7208  data: 0.4553  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1387 (1.0923)  acc1: 76.4000 (78.6857)  acc5: 94.8000 (94.9905)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2055 (1.1043)  acc1: 77.6000 (78.5760)  acc5: 94.0000 (94.8800)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4672 s / it)
* Acc@1 78.512 Acc@5 94.776 loss 1.109
Accuracy of the model on the 50000 test images: 78.5%
Max accuracy: 78.62%
Epoch: [97]  [   0/1251]  eta: 1:14:35  lr: 0.003299  min_lr: 0.003299  loss: 2.3329 (2.3329)  weight_decay: 0.0500 (0.0500)  time: 3.5777  data: 1.4974  max mem: 40080
Epoch: [97]  [ 200/1251]  eta: 0:08:59  lr: 0.003296  min_lr: 0.003296  loss: 3.4068 (3.4111)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8851 (0.9666)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [97]  [ 400/1251]  eta: 0:07:10  lr: 0.003294  min_lr: 0.003294  loss: 3.5462 (3.4152)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1312 (1.1249)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [97]  [ 600/1251]  eta: 0:05:27  lr: 0.003291  min_lr: 0.003291  loss: 3.6043 (3.4304)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6772 (1.0426)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [97]  [ 800/1251]  eta: 0:03:46  lr: 0.003288  min_lr: 0.003288  loss: 3.2537 (3.4229)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9273 (1.0691)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [97]  [1000/1251]  eta: 0:02:05  lr: 0.003285  min_lr: 0.003285  loss: 2.8762 (3.4173)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6651 (1.0663)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [97]  [1200/1251]  eta: 0:00:25  lr: 0.003283  min_lr: 0.003283  loss: 3.5667 (3.4255)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8251 (1.0572)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [97]  [1250/1251]  eta: 0:00:00  lr: 0.003282  min_lr: 0.003282  loss: 3.3774 (3.4171)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0383 (1.0601)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [97] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.003282  min_lr: 0.003282  loss: 3.3774 (3.4012)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0383 (1.0601)
Test:  [ 0/25]  eta: 0:02:14  loss: 0.7112 (0.7112)  acc1: 88.0000 (88.0000)  acc5: 98.0000 (98.0000)  time: 5.3800  data: 5.0557  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8698 (0.8891)  acc1: 82.8000 (82.6909)  acc5: 96.4000 (96.5818)  time: 0.7271  data: 0.4600  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0475 (1.0437)  acc1: 77.2000 (78.8000)  acc5: 94.0000 (94.7429)  time: 0.2615  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1076 (1.0580)  acc1: 77.2000 (78.4640)  acc5: 94.0000 (94.5920)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4707 s / it)
* Acc@1 78.718 Acc@5 94.862 loss 1.051
Accuracy of the model on the 50000 test images: 78.7%
Max accuracy: 78.72%
Epoch: [98]  [   0/1251]  eta: 1:03:10  lr: 0.003282  min_lr: 0.003282  loss: 3.4929 (3.4929)  weight_decay: 0.0500 (0.0500)  time: 3.0298  data: 2.5255  max mem: 40080
Epoch: [98]  [ 200/1251]  eta: 0:08:59  lr: 0.003279  min_lr: 0.003279  loss: 3.2779 (3.3286)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0782 (1.2841)  time: 0.4993  data: 0.0004  max mem: 40080
Epoch: [98]  [ 400/1251]  eta: 0:07:10  lr: 0.003276  min_lr: 0.003276  loss: 3.4862 (3.3617)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7170 (1.1145)  time: 0.4960  data: 0.0005  max mem: 40080
Epoch: [98]  [ 600/1251]  eta: 0:05:27  lr: 0.003274  min_lr: 0.003274  loss: 3.5068 (3.3769)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0217 (1.1261)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [98]  [ 800/1251]  eta: 0:03:46  lr: 0.003271  min_lr: 0.003271  loss: 3.3623 (3.3787)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1334 (1.1257)  time: 0.4957  data: 0.0004  max mem: 40080
Epoch: [98]  [1000/1251]  eta: 0:02:05  lr: 0.003268  min_lr: 0.003268  loss: 3.5281 (3.3804)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0641 (1.1243)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [98]  [1200/1251]  eta: 0:00:25  lr: 0.003265  min_lr: 0.003265  loss: 3.6384 (3.3819)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0735 (1.0918)  time: 0.4965  data: 0.0005  max mem: 40080
Epoch: [98]  [1250/1251]  eta: 0:00:00  lr: 0.003265  min_lr: 0.003265  loss: 3.6908 (3.3890)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1102 (1.0870)  time: 0.4209  data: 0.0005  max mem: 40080
Epoch: [98] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.003265  min_lr: 0.003265  loss: 3.6908 (3.4025)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1102 (1.0870)
Test:  [ 0/25]  eta: 0:02:14  loss: 0.7699 (0.7699)  acc1: 87.6000 (87.6000)  acc5: 98.0000 (98.0000)  time: 5.3690  data: 5.0687  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.0094 (0.9705)  acc1: 81.2000 (82.2182)  acc5: 96.8000 (96.7636)  time: 0.7259  data: 0.4611  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1556 (1.1336)  acc1: 76.8000 (78.2857)  acc5: 94.4000 (94.9143)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2273 (1.1469)  acc1: 76.8000 (78.0480)  acc5: 93.6000 (94.7200)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4694 s / it)
* Acc@1 78.398 Acc@5 94.834 loss 1.139
Accuracy of the model on the 50000 test images: 78.4%
Max accuracy: 78.72%
Epoch: [99]  [   0/1251]  eta: 1:08:44  lr: 0.003265  min_lr: 0.003265  loss: 3.7897 (3.7897)  weight_decay: 0.0500 (0.0500)  time: 3.2970  data: 2.7062  max mem: 40080
Epoch: [99]  [ 200/1251]  eta: 0:09:01  lr: 0.003262  min_lr: 0.003262  loss: 3.4405 (3.4059)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9243 (0.9209)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [99]  [ 400/1251]  eta: 0:07:10  lr: 0.003259  min_lr: 0.003259  loss: 3.0709 (3.3940)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9922 (1.1231)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [99]  [ 600/1251]  eta: 0:05:28  lr: 0.003256  min_lr: 0.003256  loss: 3.0638 (3.3710)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8704 (1.0670)  time: 0.5107  data: 0.0004  max mem: 40080
Epoch: [99]  [ 800/1251]  eta: 0:03:46  lr: 0.003253  min_lr: 0.003253  loss: 3.5212 (3.3918)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7344 (1.0938)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [99]  [1000/1251]  eta: 0:02:05  lr: 0.003251  min_lr: 0.003251  loss: 3.4397 (3.3829)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9920 (1.0918)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [99]  [1200/1251]  eta: 0:00:25  lr: 0.003248  min_lr: 0.003248  loss: 3.6270 (3.3932)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9075 (1.0603)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [99]  [1250/1251]  eta: 0:00:00  lr: 0.003247  min_lr: 0.003247  loss: 3.6979 (3.3964)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9333 (1.0548)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [99] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.003247  min_lr: 0.003247  loss: 3.6979 (3.3975)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9333 (1.0548)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.7930 (0.7930)  acc1: 86.0000 (86.0000)  acc5: 98.4000 (98.4000)  time: 5.3012  data: 4.9994  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8965 (0.9445)  acc1: 83.6000 (82.8000)  acc5: 96.4000 (96.6909)  time: 0.7197  data: 0.4548  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1518 (1.1085)  acc1: 76.4000 (79.0286)  acc5: 94.0000 (94.5333)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2132 (1.1211)  acc1: 76.4000 (78.6080)  acc5: 93.2000 (94.4320)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4659 s / it)
* Acc@1 78.552 Acc@5 94.722 loss 1.112
Accuracy of the model on the 50000 test images: 78.6%
Max accuracy: 78.72%
Epoch: [100]  [   0/1251]  eta: 1:12:44  lr: 0.003247  min_lr: 0.003247  loss: 3.2560 (3.2560)  weight_decay: 0.0500 (0.0500)  time: 3.4890  data: 1.5203  max mem: 40080
Epoch: [100]  [ 200/1251]  eta: 0:08:58  lr: 0.003244  min_lr: 0.003244  loss: 3.5188 (3.3882)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8314 (1.0827)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [100]  [ 400/1251]  eta: 0:07:09  lr: 0.003242  min_lr: 0.003242  loss: 3.6016 (3.4156)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8520 (1.0612)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [100]  [ 600/1251]  eta: 0:05:27  lr: 0.003239  min_lr: 0.003239  loss: 3.5195 (3.3869)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8451 (1.0619)  time: 0.4957  data: 0.0004  max mem: 40080
Epoch: [100]  [ 800/1251]  eta: 0:03:46  lr: 0.003236  min_lr: 0.003236  loss: 3.6795 (3.3983)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9318 (1.0785)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [100]  [1000/1251]  eta: 0:02:05  lr: 0.003233  min_lr: 0.003233  loss: 3.5824 (3.4126)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8649 (1.0772)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [100]  [1200/1251]  eta: 0:00:25  lr: 0.003230  min_lr: 0.003230  loss: 3.4843 (3.4000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8695 (1.0660)  time: 0.4956  data: 0.0004  max mem: 40080
Epoch: [100]  [1250/1251]  eta: 0:00:00  lr: 0.003230  min_lr: 0.003230  loss: 3.5463 (3.4005)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8879 (1.0704)  time: 0.4208  data: 0.0005  max mem: 40080
Epoch: [100] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.003230  min_lr: 0.003230  loss: 3.5463 (3.3942)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8879 (1.0704)
Test:  [ 0/25]  eta: 0:01:53  loss: 0.7297 (0.7297)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 4.5225  data: 4.2249  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9674 (0.9347)  acc1: 82.4000 (83.3818)  acc5: 97.6000 (96.9818)  time: 0.7085  data: 0.4443  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1485 (1.0837)  acc1: 77.2000 (79.4667)  acc5: 94.4000 (95.0095)  time: 0.2940  data: 0.0332  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2034 (1.1038)  acc1: 76.4000 (79.0080)  acc5: 93.6000 (94.8480)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4613 s / it)
* Acc@1 78.908 Acc@5 94.772 loss 1.103
Accuracy of the model on the 50000 test images: 78.9%
Max accuracy: 78.91%
Epoch: [101]  [   0/1251]  eta: 0:59:48  lr: 0.003230  min_lr: 0.003230  loss: 2.6374 (2.6374)  weight_decay: 0.0500 (0.0500)  time: 2.8681  data: 2.3651  max mem: 40080
Epoch: [101]  [ 200/1251]  eta: 0:08:56  lr: 0.003227  min_lr: 0.003227  loss: 3.4876 (3.3844)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4084 (1.2232)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [101]  [ 400/1251]  eta: 0:07:08  lr: 0.003224  min_lr: 0.003224  loss: 3.4226 (3.3785)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7286 (1.0963)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [101]  [ 600/1251]  eta: 0:05:26  lr: 0.003221  min_lr: 0.003221  loss: 3.1598 (3.3738)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8009 (1.0723)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [101]  [ 800/1251]  eta: 0:03:45  lr: 0.003218  min_lr: 0.003218  loss: 3.3058 (3.3805)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1676 (1.0592)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [101]  [1000/1251]  eta: 0:02:05  lr: 0.003215  min_lr: 0.003215  loss: 3.6760 (3.3851)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7726 (1.0649)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [101]  [1200/1251]  eta: 0:00:25  lr: 0.003212  min_lr: 0.003212  loss: 3.3655 (3.3925)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7238 (1.0415)  time: 0.5086  data: 0.0004  max mem: 40080
Epoch: [101]  [1250/1251]  eta: 0:00:00  lr: 0.003212  min_lr: 0.003212  loss: 3.5188 (3.3914)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6857 (1.0316)  time: 0.4210  data: 0.0006  max mem: 40080
Epoch: [101] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.003212  min_lr: 0.003212  loss: 3.5188 (3.3911)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6857 (1.0316)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.7113 (0.7113)  acc1: 87.2000 (87.2000)  acc5: 98.0000 (98.0000)  time: 5.4593  data: 5.1679  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9553 (0.9297)  acc1: 80.8000 (82.3273)  acc5: 96.8000 (96.7636)  time: 0.7341  data: 0.4701  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1124 (1.0748)  acc1: 77.6000 (78.8191)  acc5: 94.8000 (94.9333)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1452 (1.0784)  acc1: 77.2000 (78.4640)  acc5: 94.8000 (94.9600)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4726 s / it)
* Acc@1 78.794 Acc@5 94.932 loss 1.071
Accuracy of the model on the 50000 test images: 78.8%
Max accuracy: 78.91%
Epoch: [102]  [   0/1251]  eta: 1:17:11  lr: 0.003212  min_lr: 0.003212  loss: 3.2080 (3.2080)  weight_decay: 0.0500 (0.0500)  time: 3.7022  data: 2.5185  max mem: 40080
Epoch: [102]  [ 200/1251]  eta: 0:09:01  lr: 0.003209  min_lr: 0.003209  loss: 3.3699 (3.3663)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8648 (0.9197)  time: 0.4964  data: 0.0005  max mem: 40080
Epoch: [102]  [ 400/1251]  eta: 0:07:10  lr: 0.003206  min_lr: 0.003206  loss: 3.3011 (3.3819)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0850 (1.0216)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [102]  [ 600/1251]  eta: 0:05:27  lr: 0.003203  min_lr: 0.003203  loss: 3.5819 (3.3844)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1281 (0.9998)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [102]  [ 800/1251]  eta: 0:03:46  lr: 0.003200  min_lr: 0.003200  loss: 3.1471 (3.3906)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7294 (0.9993)  time: 0.4986  data: 0.0005  max mem: 40080
Epoch: [102]  [1000/1251]  eta: 0:02:05  lr: 0.003197  min_lr: 0.003197  loss: 3.3953 (3.3904)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7310 (nan)  time: 0.5046  data: 0.0004  max mem: 40080
Epoch: [102]  [1200/1251]  eta: 0:00:25  lr: 0.003195  min_lr: 0.003195  loss: 3.5644 (3.3931)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2343 (nan)  time: 0.4997  data: 0.0004  max mem: 40080
Epoch: [102]  [1250/1251]  eta: 0:00:00  lr: 0.003194  min_lr: 0.003194  loss: 3.4326 (3.3998)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8305 (nan)  time: 0.4213  data: 0.0007  max mem: 40080
Epoch: [102] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.003194  min_lr: 0.003194  loss: 3.4326 (3.3834)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8305 (nan)
Test:  [ 0/25]  eta: 0:01:59  loss: 0.8876 (0.8876)  acc1: 86.0000 (86.0000)  acc5: 97.2000 (97.2000)  time: 4.7946  data: 4.4880  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 1.0418 (1.0262)  acc1: 82.0000 (82.3636)  acc5: 96.4000 (96.3636)  time: 0.7207  data: 0.4525  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.2071 (1.1678)  acc1: 76.8000 (79.0857)  acc5: 94.4000 (94.5905)  time: 0.2871  data: 0.0245  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1958 (1.1757)  acc1: 76.8000 (78.7680)  acc5: 94.4000 (94.7200)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4664 s / it)
* Acc@1 78.646 Acc@5 94.818 loss 1.168
Accuracy of the model on the 50000 test images: 78.6%
Max accuracy: 78.91%
Epoch: [103]  [   0/1251]  eta: 1:09:36  lr: 0.003194  min_lr: 0.003194  loss: 3.0172 (3.0172)  weight_decay: 0.0500 (0.0500)  time: 3.3385  data: 1.6820  max mem: 40080
Epoch: [103]  [ 200/1251]  eta: 0:08:59  lr: 0.003191  min_lr: 0.003191  loss: 3.3519 (3.3365)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0025 (1.1759)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [103]  [ 400/1251]  eta: 0:07:09  lr: 0.003188  min_lr: 0.003188  loss: 3.5788 (3.3620)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7814 (1.0946)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [103]  [ 600/1251]  eta: 0:05:27  lr: 0.003185  min_lr: 0.003185  loss: 3.5118 (3.3591)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9960 (1.1079)  time: 0.5051  data: 0.0005  max mem: 40080
Epoch: [103]  [ 800/1251]  eta: 0:03:46  lr: 0.003182  min_lr: 0.003182  loss: 3.4345 (3.3575)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7623 (1.0447)  time: 0.5006  data: 0.0004  max mem: 40080
Epoch: [103]  [1000/1251]  eta: 0:02:05  lr: 0.003179  min_lr: 0.003179  loss: 3.5796 (3.3671)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7715 (1.0597)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [103]  [1200/1251]  eta: 0:00:25  lr: 0.003176  min_lr: 0.003176  loss: 3.3645 (3.3602)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0781 (1.0745)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [103]  [1250/1251]  eta: 0:00:00  lr: 0.003176  min_lr: 0.003176  loss: 3.7269 (3.3619)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9612 (1.0650)  time: 0.4210  data: 0.0007  max mem: 40080
Epoch: [103] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.003176  min_lr: 0.003176  loss: 3.7269 (3.3794)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9612 (1.0650)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6928 (0.6928)  acc1: 87.2000 (87.2000)  acc5: 99.2000 (99.2000)  time: 5.5012  data: 5.1914  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8460 (0.8699)  acc1: 82.8000 (82.5091)  acc5: 96.8000 (96.8727)  time: 0.7379  data: 0.4722  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1062 (1.0210)  acc1: 76.8000 (79.0857)  acc5: 94.4000 (95.0667)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0525 (1.0300)  acc1: 76.0000 (78.5920)  acc5: 94.0000 (95.0080)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4743 s / it)
* Acc@1 78.898 Acc@5 94.906 loss 1.017
Accuracy of the model on the 50000 test images: 78.9%
Max accuracy: 78.91%
Epoch: [104]  [   0/1251]  eta: 1:07:51  lr: 0.003176  min_lr: 0.003176  loss: 3.5961 (3.5961)  weight_decay: 0.0500 (0.0500)  time: 3.2544  data: 2.3173  max mem: 40080
Epoch: [104]  [ 200/1251]  eta: 0:08:58  lr: 0.003173  min_lr: 0.003173  loss: 3.3998 (3.4180)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3468 (1.2283)  time: 0.4969  data: 0.0005  max mem: 40080
Epoch: [104]  [ 400/1251]  eta: 0:07:09  lr: 0.003170  min_lr: 0.003170  loss: 3.6401 (3.3930)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1439 (1.1333)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [104]  [ 600/1251]  eta: 0:05:27  lr: 0.003167  min_lr: 0.003167  loss: 3.5684 (3.4006)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7735 (1.0816)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [104]  [ 800/1251]  eta: 0:03:46  lr: 0.003164  min_lr: 0.003164  loss: 3.6292 (3.3878)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7354 (1.0714)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [104]  [1000/1251]  eta: 0:02:05  lr: 0.003161  min_lr: 0.003161  loss: 3.4144 (3.3888)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8718 (1.0422)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [104]  [1200/1251]  eta: 0:00:25  lr: 0.003158  min_lr: 0.003158  loss: 3.5981 (3.3892)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7753 (1.0383)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [104]  [1250/1251]  eta: 0:00:00  lr: 0.003158  min_lr: 0.003158  loss: 3.3601 (3.3864)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2779 (1.0613)  time: 0.4215  data: 0.0005  max mem: 40080
Epoch: [104] Total time: 0:10:24 (0.4996 s / it)
Averaged stats: lr: 0.003158  min_lr: 0.003158  loss: 3.3601 (3.3849)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2779 (1.0613)
Test:  [ 0/25]  eta: 0:02:09  loss: 0.6096 (0.6096)  acc1: 87.6000 (87.6000)  acc5: 98.8000 (98.8000)  time: 5.1932  data: 4.8687  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8419 (0.8476)  acc1: 82.8000 (81.9273)  acc5: 97.2000 (96.6546)  time: 0.7100  data: 0.4430  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0580 (0.9928)  acc1: 77.6000 (79.1238)  acc5: 94.4000 (95.1810)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0930 (1.0063)  acc1: 76.8000 (78.7840)  acc5: 94.4000 (94.9280)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4654 s / it)
* Acc@1 79.100 Acc@5 94.768 loss 1.002
Accuracy of the model on the 50000 test images: 79.1%
Max accuracy: 79.10%
Epoch: [105]  [   0/1251]  eta: 0:55:29  lr: 0.003158  min_lr: 0.003158  loss: 3.4089 (3.4089)  weight_decay: 0.0500 (0.0500)  time: 2.6612  data: 2.1548  max mem: 40080
Epoch: [105]  [ 200/1251]  eta: 0:08:54  lr: 0.003155  min_lr: 0.003155  loss: 3.4333 (3.3377)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1813 (1.0863)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [105]  [ 400/1251]  eta: 0:07:09  lr: 0.003152  min_lr: 0.003152  loss: 3.0372 (3.3442)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8599 (1.0202)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [105]  [ 600/1251]  eta: 0:05:26  lr: 0.003149  min_lr: 0.003149  loss: 3.5591 (3.3511)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8131 (0.9723)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [105]  [ 800/1251]  eta: 0:03:46  lr: 0.003146  min_lr: 0.003146  loss: 3.5330 (3.3494)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6955 (1.0041)  time: 0.5061  data: 0.0004  max mem: 40080
Epoch: [105]  [1000/1251]  eta: 0:02:05  lr: 0.003143  min_lr: 0.003143  loss: 3.3617 (3.3471)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1690 (1.0394)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [105]  [1200/1251]  eta: 0:00:25  lr: 0.003140  min_lr: 0.003140  loss: 3.4830 (3.3566)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8150 (1.0273)  time: 0.4989  data: 0.0004  max mem: 40080
Epoch: [105]  [1250/1251]  eta: 0:00:00  lr: 0.003139  min_lr: 0.003139  loss: 3.3443 (3.3582)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7543 (1.0254)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [105] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.003139  min_lr: 0.003139  loss: 3.3443 (3.3715)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7543 (1.0254)
Test:  [ 0/25]  eta: 0:01:50  loss: 0.7515 (0.7515)  acc1: 88.4000 (88.4000)  acc5: 98.4000 (98.4000)  time: 4.4312  data: 4.1175  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8329 (0.8853)  acc1: 84.4000 (82.4727)  acc5: 97.6000 (97.0909)  time: 0.6868  data: 0.4168  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0913 (1.0295)  acc1: 77.2000 (79.4095)  acc5: 94.8000 (95.1429)  time: 0.2924  data: 0.0234  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1135 (1.0435)  acc1: 76.4000 (79.0240)  acc5: 94.4000 (95.0400)  time: 0.2696  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4570 s / it)
* Acc@1 79.154 Acc@5 95.108 loss 1.038
Accuracy of the model on the 50000 test images: 79.2%
Max accuracy: 79.15%
Epoch: [106]  [   0/1251]  eta: 0:53:39  lr: 0.003139  min_lr: 0.003139  loss: 4.0937 (4.0937)  weight_decay: 0.0500 (0.0500)  time: 2.5739  data: 2.0573  max mem: 40080
Epoch: [106]  [ 200/1251]  eta: 0:08:54  lr: 0.003136  min_lr: 0.003136  loss: 3.3957 (3.3772)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8654 (0.9708)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [106]  [ 400/1251]  eta: 0:07:08  lr: 0.003133  min_lr: 0.003133  loss: 3.0968 (3.3747)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2782 (1.0976)  time: 0.5009  data: 0.0004  max mem: 40080
Epoch: [106]  [ 600/1251]  eta: 0:05:26  lr: 0.003130  min_lr: 0.003130  loss: 3.5306 (3.3756)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8724 (1.0054)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [106]  [ 800/1251]  eta: 0:03:45  lr: 0.003127  min_lr: 0.003127  loss: 3.2283 (3.3771)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9749 (1.0382)  time: 0.4986  data: 0.0004  max mem: 40080
Epoch: [106]  [1000/1251]  eta: 0:02:05  lr: 0.003124  min_lr: 0.003124  loss: 3.7003 (3.3899)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8398 (1.0292)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [106]  [1200/1251]  eta: 0:00:25  lr: 0.003121  min_lr: 0.003121  loss: 3.5840 (3.3925)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8799 (1.0263)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [106]  [1250/1251]  eta: 0:00:00  lr: 0.003121  min_lr: 0.003121  loss: 3.3678 (3.3919)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8772 (1.0314)  time: 0.4212  data: 0.0007  max mem: 40080
Epoch: [106] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.003121  min_lr: 0.003121  loss: 3.3678 (3.3815)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8772 (1.0314)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.6572 (0.6572)  acc1: 87.6000 (87.6000)  acc5: 98.4000 (98.4000)  time: 5.3393  data: 5.0408  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8174 (0.8542)  acc1: 83.2000 (81.8909)  acc5: 97.2000 (96.8364)  time: 0.7231  data: 0.4585  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0834 (1.0263)  acc1: 76.0000 (78.5524)  acc5: 95.2000 (94.9905)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1092 (1.0334)  acc1: 76.0000 (78.4160)  acc5: 94.0000 (94.8160)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4674 s / it)
* Acc@1 78.966 Acc@5 94.902 loss 1.024
Accuracy of the model on the 50000 test images: 79.0%
Max accuracy: 79.15%
Epoch: [107]  [   0/1251]  eta: 1:13:18  lr: 0.003121  min_lr: 0.003121  loss: 2.2670 (2.2670)  weight_decay: 0.0500 (0.0500)  time: 3.5159  data: 2.1349  max mem: 40080
Epoch: [107]  [ 200/1251]  eta: 0:09:01  lr: 0.003118  min_lr: 0.003118  loss: 3.2892 (3.3731)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9212 (1.0451)  time: 0.5000  data: 0.0005  max mem: 40080
Epoch: [107]  [ 400/1251]  eta: 0:07:11  lr: 0.003115  min_lr: 0.003115  loss: 3.4659 (3.3429)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7736 (0.9670)  time: 0.4969  data: 0.0005  max mem: 40080
Epoch: [107]  [ 600/1251]  eta: 0:05:28  lr: 0.003112  min_lr: 0.003112  loss: 3.3254 (3.3389)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7884 (1.0061)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [107]  [ 800/1251]  eta: 0:03:46  lr: 0.003109  min_lr: 0.003109  loss: 3.4601 (3.3495)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4455 (1.0900)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [107]  [1000/1251]  eta: 0:02:05  lr: 0.003106  min_lr: 0.003106  loss: 3.4373 (3.3557)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7695 (1.0390)  time: 0.4969  data: 0.0005  max mem: 40080
Epoch: [107]  [1200/1251]  eta: 0:00:25  lr: 0.003103  min_lr: 0.003103  loss: 3.4742 (3.3546)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1234 (1.0666)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [107]  [1250/1251]  eta: 0:00:00  lr: 0.003102  min_lr: 0.003102  loss: 3.4950 (3.3587)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8642 (1.0644)  time: 0.4219  data: 0.0007  max mem: 40080
Epoch: [107] Total time: 0:10:26 (0.5004 s / it)
Averaged stats: lr: 0.003102  min_lr: 0.003102  loss: 3.4950 (3.3712)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8642 (1.0644)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.6849 (0.6849)  acc1: 87.6000 (87.6000)  acc5: 98.0000 (98.0000)  time: 5.3213  data: 5.0154  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9129 (0.9212)  acc1: 83.2000 (82.4364)  acc5: 96.8000 (96.8364)  time: 0.7215  data: 0.4562  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1155 (1.0726)  acc1: 76.8000 (78.8381)  acc5: 94.8000 (94.9905)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1213 (1.0840)  acc1: 76.4000 (78.5280)  acc5: 93.6000 (94.7840)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4694 s / it)
* Acc@1 78.858 Acc@5 94.884 loss 1.080
Accuracy of the model on the 50000 test images: 78.9%
Max accuracy: 79.15%
Epoch: [108]  [   0/1251]  eta: 1:13:07  lr: 0.003102  min_lr: 0.003102  loss: 3.8890 (3.8890)  weight_decay: 0.0500 (0.0500)  time: 3.5069  data: 2.6073  max mem: 40080
Epoch: [108]  [ 200/1251]  eta: 0:09:00  lr: 0.003099  min_lr: 0.003099  loss: 3.0892 (3.3583)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0744 (1.0428)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [108]  [ 400/1251]  eta: 0:07:10  lr: 0.003096  min_lr: 0.003096  loss: 3.3397 (3.3594)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8347 (1.1194)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [108]  [ 600/1251]  eta: 0:05:27  lr: 0.003093  min_lr: 0.003093  loss: 3.3256 (3.3749)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8665 (1.0366)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [108]  [ 800/1251]  eta: 0:03:46  lr: 0.003090  min_lr: 0.003090  loss: 3.3078 (3.3690)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0641 (1.0322)  time: 0.5002  data: 0.0004  max mem: 40080
Epoch: [108]  [1000/1251]  eta: 0:02:05  lr: 0.003087  min_lr: 0.003087  loss: 3.6129 (3.3887)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6848 (1.0058)  time: 0.5012  data: 0.0005  max mem: 40080
Epoch: [108]  [1200/1251]  eta: 0:00:25  lr: 0.003084  min_lr: 0.003084  loss: 3.4818 (3.3909)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7874 (0.9992)  time: 0.4969  data: 0.0005  max mem: 40080
Epoch: [108]  [1250/1251]  eta: 0:00:00  lr: 0.003083  min_lr: 0.003083  loss: 3.3847 (3.3889)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9943 (1.0137)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [108] Total time: 0:10:26 (0.5009 s / it)
Averaged stats: lr: 0.003083  min_lr: 0.003083  loss: 3.3847 (3.3668)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9943 (1.0137)
Test:  [ 0/25]  eta: 0:02:00  loss: 0.6427 (0.6427)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 4.8151  data: 4.5188  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8352 (0.8380)  acc1: 84.8000 (83.3818)  acc5: 97.2000 (96.8000)  time: 0.6859  data: 0.4218  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0787 (0.9917)  acc1: 78.0000 (79.3524)  acc5: 94.8000 (95.0857)  time: 0.2669  data: 0.0061  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1065 (1.0072)  acc1: 77.2000 (78.8000)  acc5: 94.8000 (94.9920)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4539 s / it)
* Acc@1 79.178 Acc@5 94.994 loss 0.996
Accuracy of the model on the 50000 test images: 79.2%
Max accuracy: 79.18%
Epoch: [109]  [   0/1251]  eta: 0:51:52  lr: 0.003083  min_lr: 0.003083  loss: 3.0499 (3.0499)  weight_decay: 0.0500 (0.0500)  time: 2.4877  data: 1.9770  max mem: 40080
Epoch: [109]  [ 200/1251]  eta: 0:08:53  lr: 0.003080  min_lr: 0.003080  loss: 3.4841 (3.3782)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9981 (1.0873)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [109]  [ 400/1251]  eta: 0:07:07  lr: 0.003077  min_lr: 0.003077  loss: 3.3943 (3.3855)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [109]  [ 600/1251]  eta: 0:05:26  lr: 0.003074  min_lr: 0.003074  loss: 3.3012 (3.3656)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7090 (nan)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [109]  [ 800/1251]  eta: 0:03:45  lr: 0.003071  min_lr: 0.003071  loss: 3.4365 (3.3624)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1399 (nan)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [109]  [1000/1251]  eta: 0:02:05  lr: 0.003068  min_lr: 0.003068  loss: 3.4211 (3.3704)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7960 (nan)  time: 0.5002  data: 0.0005  max mem: 40080
Epoch: [109]  [1200/1251]  eta: 0:00:25  lr: 0.003065  min_lr: 0.003065  loss: 3.5332 (3.3673)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8709 (nan)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [109]  [1250/1251]  eta: 0:00:00  lr: 0.003064  min_lr: 0.003064  loss: 3.5330 (3.3691)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7441 (nan)  time: 0.4218  data: 0.0006  max mem: 40080
Epoch: [109] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.003064  min_lr: 0.003064  loss: 3.5330 (3.3649)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7441 (nan)
Test:  [ 0/25]  eta: 0:01:58  loss: 0.7368 (0.7368)  acc1: 85.6000 (85.6000)  acc5: 98.8000 (98.8000)  time: 4.7566  data: 4.4369  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9017 (0.9180)  acc1: 82.4000 (82.6546)  acc5: 97.2000 (97.1636)  time: 0.7210  data: 0.4469  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0973 (1.0910)  acc1: 77.2000 (79.3714)  acc5: 95.2000 (95.0095)  time: 0.2897  data: 0.0240  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1973 (1.0973)  acc1: 77.6000 (79.1520)  acc5: 93.6000 (94.8000)  time: 0.2636  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4677 s / it)
* Acc@1 79.124 Acc@5 95.026 loss 1.087
Accuracy of the model on the 50000 test images: 79.1%
Max accuracy: 79.18%
Epoch: [110]  [   0/1251]  eta: 1:09:52  lr: 0.003064  min_lr: 0.003064  loss: 3.7993 (3.7993)  weight_decay: 0.0500 (0.0500)  time: 3.3513  data: 1.7803  max mem: 40080
Epoch: [110]  [ 200/1251]  eta: 0:08:59  lr: 0.003061  min_lr: 0.003061  loss: 3.4873 (3.3231)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0423 (1.1132)  time: 0.4956  data: 0.0004  max mem: 40080
Epoch: [110]  [ 400/1251]  eta: 0:07:09  lr: 0.003058  min_lr: 0.003058  loss: 3.3395 (3.3454)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7918 (1.0368)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [110]  [ 600/1251]  eta: 0:05:26  lr: 0.003055  min_lr: 0.003055  loss: 3.5232 (3.3503)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8218 (1.0813)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [110]  [ 800/1251]  eta: 0:03:46  lr: 0.003052  min_lr: 0.003052  loss: 3.4080 (3.3510)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8332 (1.0166)  time: 0.4991  data: 0.0003  max mem: 40080
Epoch: [110]  [1000/1251]  eta: 0:02:05  lr: 0.003049  min_lr: 0.003049  loss: 3.3524 (3.3551)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8092 (1.0205)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [110]  [1200/1251]  eta: 0:00:25  lr: 0.003046  min_lr: 0.003046  loss: 3.4689 (3.3474)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0950 (1.0423)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [110]  [1250/1251]  eta: 0:00:00  lr: 0.003045  min_lr: 0.003045  loss: 3.5821 (3.3451)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0565 (1.0499)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [110] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.003045  min_lr: 0.003045  loss: 3.5821 (3.3513)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0565 (1.0499)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.6741 (0.6741)  acc1: 86.8000 (86.8000)  acc5: 98.0000 (98.0000)  time: 5.2165  data: 4.9234  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8799 (0.8603)  acc1: 81.2000 (81.8909)  acc5: 97.6000 (96.8000)  time: 0.7120  data: 0.4479  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0124 (1.0127)  acc1: 78.8000 (78.7238)  acc5: 94.4000 (94.9905)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0954 (1.0229)  acc1: 77.2000 (78.5280)  acc5: 94.0000 (94.8160)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4624 s / it)
* Acc@1 79.078 Acc@5 94.974 loss 1.010
Accuracy of the model on the 50000 test images: 79.1%
Max accuracy: 79.18%
Epoch: [111]  [   0/1251]  eta: 1:11:39  lr: 0.003045  min_lr: 0.003045  loss: 3.4351 (3.4351)  weight_decay: 0.0500 (0.0500)  time: 3.4370  data: 1.8066  max mem: 40080
Epoch: [111]  [ 200/1251]  eta: 0:08:58  lr: 0.003042  min_lr: 0.003042  loss: 3.4200 (3.2643)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0398 (1.0102)  time: 0.4957  data: 0.0004  max mem: 40080
Epoch: [111]  [ 400/1251]  eta: 0:07:09  lr: 0.003039  min_lr: 0.003039  loss: 3.4684 (3.3059)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0688 (1.0072)  time: 0.5004  data: 0.0004  max mem: 40080
Epoch: [111]  [ 600/1251]  eta: 0:05:27  lr: 0.003036  min_lr: 0.003036  loss: 3.5660 (3.3206)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7963 (1.0172)  time: 0.5061  data: 0.0005  max mem: 40080
Epoch: [111]  [ 800/1251]  eta: 0:03:46  lr: 0.003033  min_lr: 0.003033  loss: 3.3925 (3.3275)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9011 (0.9993)  time: 0.5000  data: 0.0004  max mem: 40080
Epoch: [111]  [1000/1251]  eta: 0:02:05  lr: 0.003030  min_lr: 0.003030  loss: 3.5287 (3.3387)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1435 (1.0582)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [111]  [1200/1251]  eta: 0:00:25  lr: 0.003027  min_lr: 0.003027  loss: 3.4588 (3.3385)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6424 (1.0154)  time: 0.4975  data: 0.0005  max mem: 40080
Epoch: [111]  [1250/1251]  eta: 0:00:00  lr: 0.003026  min_lr: 0.003026  loss: 3.4771 (3.3383)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7239 (1.0137)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [111] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.003026  min_lr: 0.003026  loss: 3.4771 (3.3532)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7239 (1.0137)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.7892 (0.7892)  acc1: 87.2000 (87.2000)  acc5: 98.4000 (98.4000)  time: 5.6359  data: 5.3354  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9636 (0.9246)  acc1: 83.6000 (82.5091)  acc5: 97.6000 (97.0182)  time: 0.7500  data: 0.4853  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0703 (1.0864)  acc1: 77.6000 (79.3333)  acc5: 94.4000 (94.9905)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1829 (1.0996)  acc1: 77.6000 (78.9280)  acc5: 94.4000 (94.8320)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4802 s / it)
* Acc@1 79.032 Acc@5 94.796 loss 1.094
Accuracy of the model on the 50000 test images: 79.0%
Max accuracy: 79.18%
Epoch: [112]  [   0/1251]  eta: 1:09:15  lr: 0.003026  min_lr: 0.003026  loss: 3.6538 (3.6538)  weight_decay: 0.0500 (0.0500)  time: 3.3217  data: 2.3908  max mem: 40080
Epoch: [112]  [ 200/1251]  eta: 0:08:57  lr: 0.003023  min_lr: 0.003023  loss: 3.0736 (3.3680)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8198 (1.2646)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [112]  [ 400/1251]  eta: 0:07:10  lr: 0.003020  min_lr: 0.003020  loss: 3.4707 (3.3617)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8062 (1.0876)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [112]  [ 600/1251]  eta: 0:05:27  lr: 0.003017  min_lr: 0.003017  loss: 3.1612 (3.3439)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8604 (1.0866)  time: 0.4999  data: 0.0003  max mem: 40080
Epoch: [112]  [ 800/1251]  eta: 0:03:46  lr: 0.003014  min_lr: 0.003014  loss: 3.3105 (3.3604)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7257 (1.0522)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [112]  [1000/1251]  eta: 0:02:05  lr: 0.003011  min_lr: 0.003011  loss: 3.3711 (3.3558)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0656 (1.0840)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [112]  [1200/1251]  eta: 0:00:25  lr: 0.003007  min_lr: 0.003007  loss: 3.4183 (3.3563)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7192 (1.0537)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [112]  [1250/1251]  eta: 0:00:00  lr: 0.003007  min_lr: 0.003007  loss: 3.3482 (3.3524)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9486 (1.0621)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [112] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.003007  min_lr: 0.003007  loss: 3.3482 (3.3545)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9486 (1.0621)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6812 (0.6812)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 5.5094  data: 5.1991  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8347 (0.8406)  acc1: 83.6000 (83.3455)  acc5: 97.2000 (97.3818)  time: 0.7388  data: 0.4730  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0230 (1.0002)  acc1: 77.2000 (79.1619)  acc5: 95.2000 (95.2191)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1301 (1.0108)  acc1: 76.0000 (78.8960)  acc5: 94.0000 (95.1360)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4747 s / it)
* Acc@1 79.230 Acc@5 95.164 loss 1.003
Accuracy of the model on the 50000 test images: 79.2%
Max accuracy: 79.23%
Epoch: [113]  [   0/1251]  eta: 0:47:30  lr: 0.003007  min_lr: 0.003007  loss: 3.4623 (3.4623)  weight_decay: 0.0500 (0.0500)  time: 2.2789  data: 1.7631  max mem: 40080
Epoch: [113]  [ 200/1251]  eta: 0:08:52  lr: 0.003004  min_lr: 0.003004  loss: 3.0170 (3.3245)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0258 (1.0392)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [113]  [ 400/1251]  eta: 0:07:07  lr: 0.003000  min_lr: 0.003000  loss: 3.4008 (3.2994)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0807 (1.0265)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [113]  [ 600/1251]  eta: 0:05:26  lr: 0.002997  min_lr: 0.002997  loss: 3.3224 (3.3167)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7400 (1.0095)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [113]  [ 800/1251]  eta: 0:03:45  lr: 0.002994  min_lr: 0.002994  loss: 3.4659 (3.3323)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0488 (1.0385)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [113]  [1000/1251]  eta: 0:02:05  lr: 0.002991  min_lr: 0.002991  loss: 3.2049 (3.3294)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6857 (1.0247)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [113]  [1200/1251]  eta: 0:00:25  lr: 0.002988  min_lr: 0.002988  loss: 3.3954 (3.3306)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8879 (1.0309)  time: 0.4961  data: 0.0005  max mem: 40080
Epoch: [113]  [1250/1251]  eta: 0:00:00  lr: 0.002987  min_lr: 0.002987  loss: 3.3844 (3.3294)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8879 (1.0377)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [113] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.002987  min_lr: 0.002987  loss: 3.3844 (3.3497)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8879 (1.0377)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.7017 (0.7017)  acc1: 86.8000 (86.8000)  acc5: 98.0000 (98.0000)  time: 5.2019  data: 4.8890  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8825 (0.8502)  acc1: 83.2000 (82.5818)  acc5: 96.4000 (96.7273)  time: 0.7103  data: 0.4449  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9900 (0.9959)  acc1: 76.8000 (79.0667)  acc5: 94.4000 (94.9143)  time: 0.2609  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0414 (1.0039)  acc1: 76.8000 (78.8960)  acc5: 93.6000 (94.8160)  time: 0.2608  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4616 s / it)
* Acc@1 79.460 Acc@5 95.006 loss 0.996
Accuracy of the model on the 50000 test images: 79.5%
Max accuracy: 79.46%
Epoch: [114]  [   0/1251]  eta: 0:58:17  lr: 0.002987  min_lr: 0.002987  loss: 3.2341 (3.2341)  weight_decay: 0.0500 (0.0500)  time: 2.7958  data: 2.2804  max mem: 40080
Epoch: [114]  [ 200/1251]  eta: 0:08:56  lr: 0.002984  min_lr: 0.002984  loss: 3.0020 (3.2935)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8205 (0.8153)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [114]  [ 400/1251]  eta: 0:07:08  lr: 0.002981  min_lr: 0.002981  loss: 3.4229 (3.3177)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0168 (0.9617)  time: 0.4977  data: 0.0005  max mem: 40080
Epoch: [114]  [ 600/1251]  eta: 0:05:26  lr: 0.002978  min_lr: 0.002978  loss: 3.4587 (3.3290)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0441 (nan)  time: 0.4958  data: 0.0005  max mem: 40080
Epoch: [114]  [ 800/1251]  eta: 0:03:45  lr: 0.002975  min_lr: 0.002975  loss: 3.4786 (3.3328)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8858 (nan)  time: 0.5074  data: 0.0005  max mem: 40080
Epoch: [114]  [1000/1251]  eta: 0:02:05  lr: 0.002972  min_lr: 0.002972  loss: 3.3054 (3.3260)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8322 (nan)  time: 0.4992  data: 0.0005  max mem: 40080
Epoch: [114]  [1200/1251]  eta: 0:00:25  lr: 0.002968  min_lr: 0.002968  loss: 3.6706 (3.3323)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8235 (nan)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [114]  [1250/1251]  eta: 0:00:00  lr: 0.002968  min_lr: 0.002968  loss: 3.3192 (3.3315)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8910 (nan)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [114] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.002968  min_lr: 0.002968  loss: 3.3192 (3.3446)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8910 (nan)
Test:  [ 0/25]  eta: 0:02:03  loss: 0.6462 (0.6462)  acc1: 87.6000 (87.6000)  acc5: 98.4000 (98.4000)  time: 4.9313  data: 4.6140  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8481 (0.8195)  acc1: 83.2000 (82.7636)  acc5: 96.8000 (96.7273)  time: 0.7178  data: 0.4517  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0090 (0.9707)  acc1: 78.0000 (79.5619)  acc5: 94.8000 (95.2000)  time: 0.2787  data: 0.0178  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0549 (0.9833)  acc1: 78.0000 (79.2800)  acc5: 94.0000 (95.0880)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4656 s / it)
* Acc@1 79.414 Acc@5 95.180 loss 0.974
Accuracy of the model on the 50000 test images: 79.4%
Max accuracy: 79.46%
Epoch: [115]  [   0/1251]  eta: 1:04:46  lr: 0.002968  min_lr: 0.002968  loss: 3.2240 (3.2240)  weight_decay: 0.0500 (0.0500)  time: 3.1071  data: 1.7378  max mem: 40080
Epoch: [115]  [ 200/1251]  eta: 0:08:59  lr: 0.002965  min_lr: 0.002965  loss: 3.5235 (3.2807)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8072 (1.1925)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [115]  [ 400/1251]  eta: 0:07:11  lr: 0.002961  min_lr: 0.002961  loss: 3.3295 (3.2995)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2082 (1.1020)  time: 0.4994  data: 0.0004  max mem: 40080
Epoch: [115]  [ 600/1251]  eta: 0:05:28  lr: 0.002958  min_lr: 0.002958  loss: 3.3703 (3.3194)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6279 (1.0684)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [115]  [ 800/1251]  eta: 0:03:46  lr: 0.002955  min_lr: 0.002955  loss: 3.6165 (3.3195)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7278 (1.0419)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [115]  [1000/1251]  eta: 0:02:05  lr: 0.002952  min_lr: 0.002952  loss: 3.1997 (3.3129)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7939 (1.0361)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [115]  [1200/1251]  eta: 0:00:25  lr: 0.002949  min_lr: 0.002949  loss: 3.2988 (3.3211)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8182 (1.0479)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [115]  [1250/1251]  eta: 0:00:00  lr: 0.002948  min_lr: 0.002948  loss: 3.4019 (3.3187)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7070 (1.0392)  time: 0.4211  data: 0.0007  max mem: 40080
Epoch: [115] Total time: 0:10:26 (0.5005 s / it)
Averaged stats: lr: 0.002948  min_lr: 0.002948  loss: 3.4019 (3.3350)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7070 (1.0392)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.7549 (0.7549)  acc1: 87.2000 (87.2000)  acc5: 97.6000 (97.6000)  time: 5.5433  data: 5.2236  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8957 (0.9044)  acc1: 82.0000 (82.4364)  acc5: 97.2000 (96.7636)  time: 0.7415  data: 0.4752  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0491 (1.0485)  acc1: 77.2000 (79.0667)  acc5: 94.0000 (94.8952)  time: 0.2612  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1251 (1.0601)  acc1: 76.8000 (78.6880)  acc5: 94.0000 (94.7840)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4754 s / it)
* Acc@1 79.154 Acc@5 95.014 loss 1.048
Accuracy of the model on the 50000 test images: 79.2%
Max accuracy: 79.46%
Epoch: [116]  [   0/1251]  eta: 1:05:50  lr: 0.002948  min_lr: 0.002948  loss: 3.9820 (3.9820)  weight_decay: 0.0500 (0.0500)  time: 3.1578  data: 2.5730  max mem: 40080
Epoch: [116]  [ 200/1251]  eta: 0:08:57  lr: 0.002945  min_lr: 0.002945  loss: 3.3443 (3.2993)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0777 (1.0257)  time: 0.4989  data: 0.0005  max mem: 40080
Epoch: [116]  [ 400/1251]  eta: 0:07:09  lr: 0.002942  min_lr: 0.002942  loss: 3.3995 (3.3029)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9854 (1.1323)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [116]  [ 600/1251]  eta: 0:05:27  lr: 0.002938  min_lr: 0.002938  loss: 3.1900 (3.3103)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8683 (1.0640)  time: 0.4958  data: 0.0005  max mem: 40080
Epoch: [116]  [ 800/1251]  eta: 0:03:46  lr: 0.002935  min_lr: 0.002935  loss: 3.4461 (3.3233)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7638 (1.0335)  time: 0.4958  data: 0.0005  max mem: 40080
Epoch: [116]  [1000/1251]  eta: 0:02:05  lr: 0.002932  min_lr: 0.002932  loss: 3.3430 (3.3281)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8460 (1.0365)  time: 0.4966  data: 0.0005  max mem: 40080
Epoch: [116]  [1200/1251]  eta: 0:00:25  lr: 0.002929  min_lr: 0.002929  loss: 3.3396 (3.3303)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7080 (1.0417)  time: 0.4969  data: 0.0005  max mem: 40080
Epoch: [116]  [1250/1251]  eta: 0:00:00  lr: 0.002928  min_lr: 0.002928  loss: 3.6086 (3.3322)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7311 (1.0346)  time: 0.4210  data: 0.0006  max mem: 40080
Epoch: [116] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.002928  min_lr: 0.002928  loss: 3.6086 (3.3401)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7311 (1.0346)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.7796 (0.7796)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 5.2056  data: 4.9060  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8935 (0.9193)  acc1: 83.6000 (83.0546)  acc5: 97.2000 (96.9091)  time: 0.7111  data: 0.4464  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0952 (1.0800)  acc1: 78.4000 (79.2762)  acc5: 94.8000 (94.8381)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.2030 (1.0934)  acc1: 76.4000 (78.8800)  acc5: 93.2000 (94.6560)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4637 s / it)
* Acc@1 79.490 Acc@5 94.990 loss 1.083
Accuracy of the model on the 50000 test images: 79.5%
Max accuracy: 79.49%
Epoch: [117]  [   0/1251]  eta: 1:07:18  lr: 0.002928  min_lr: 0.002928  loss: 3.5555 (3.5555)  weight_decay: 0.0500 (0.0500)  time: 3.2283  data: 2.7264  max mem: 40080
Epoch: [117]  [ 200/1251]  eta: 0:08:58  lr: 0.002925  min_lr: 0.002925  loss: 3.4894 (3.3541)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9212 (1.0899)  time: 0.4986  data: 0.0004  max mem: 40080
Epoch: [117]  [ 400/1251]  eta: 0:07:10  lr: 0.002922  min_lr: 0.002922  loss: 3.3959 (3.3311)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8931 (1.1342)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [117]  [ 600/1251]  eta: 0:05:27  lr: 0.002919  min_lr: 0.002919  loss: 3.3447 (3.3378)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9212 (1.0797)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [117]  [ 800/1251]  eta: 0:03:46  lr: 0.002915  min_lr: 0.002915  loss: 3.4514 (3.3380)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0698 (1.0784)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [117]  [1000/1251]  eta: 0:02:06  lr: 0.002912  min_lr: 0.002912  loss: 3.4173 (3.3399)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6939 (1.0226)  time: 0.4999  data: 0.0004  max mem: 40080
Epoch: [117]  [1200/1251]  eta: 0:00:25  lr: 0.002909  min_lr: 0.002909  loss: 3.5804 (3.3351)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3072 (1.0454)  time: 0.5037  data: 0.0004  max mem: 40080
Epoch: [117]  [1250/1251]  eta: 0:00:00  lr: 0.002908  min_lr: 0.002908  loss: 3.1102 (3.3350)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8620 (1.0424)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [117] Total time: 0:10:26 (0.5010 s / it)
Averaged stats: lr: 0.002908  min_lr: 0.002908  loss: 3.1102 (3.3294)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8620 (1.0424)
Test:  [ 0/25]  eta: 0:02:25  loss: 0.6579 (0.6579)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 5.8244  data: 5.5147  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7761 (0.8458)  acc1: 84.4000 (82.8364)  acc5: 97.2000 (96.8727)  time: 0.7673  data: 0.5017  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0024 (1.0018)  acc1: 78.0000 (79.3714)  acc5: 94.8000 (95.1810)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0838 (1.0107)  acc1: 76.4000 (78.9600)  acc5: 94.8000 (95.2000)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4889 s / it)
* Acc@1 79.436 Acc@5 95.136 loss 1.002
Accuracy of the model on the 50000 test images: 79.4%
Max accuracy: 79.49%
Epoch: [118]  [   0/1251]  eta: 1:10:17  lr: 0.002908  min_lr: 0.002908  loss: 2.2701 (2.2701)  weight_decay: 0.0500 (0.0500)  time: 3.3709  data: 2.7722  max mem: 40080
Epoch: [118]  [ 200/1251]  eta: 0:08:59  lr: 0.002905  min_lr: 0.002905  loss: 3.6381 (3.3389)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0052 (1.1710)  time: 0.4972  data: 0.0005  max mem: 40080
Epoch: [118]  [ 400/1251]  eta: 0:07:10  lr: 0.002902  min_lr: 0.002902  loss: 3.5641 (3.3626)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7673 (1.0443)  time: 0.5065  data: 0.0004  max mem: 40080
Epoch: [118]  [ 600/1251]  eta: 0:05:28  lr: 0.002899  min_lr: 0.002899  loss: 3.4341 (3.3569)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8779 (1.0249)  time: 0.4997  data: 0.0004  max mem: 40080
Epoch: [118]  [ 800/1251]  eta: 0:03:46  lr: 0.002895  min_lr: 0.002895  loss: 3.4880 (3.3429)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0533 (1.0472)  time: 0.4958  data: 0.0005  max mem: 40080
Epoch: [118]  [1000/1251]  eta: 0:02:05  lr: 0.002892  min_lr: 0.002892  loss: 3.4899 (3.3457)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7570 (1.0783)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [118]  [1200/1251]  eta: 0:00:25  lr: 0.002889  min_lr: 0.002889  loss: 3.4680 (3.3476)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0442 (1.0588)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [118]  [1250/1251]  eta: 0:00:00  lr: 0.002888  min_lr: 0.002888  loss: 3.1716 (3.3434)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7544 (1.0544)  time: 0.4210  data: 0.0007  max mem: 40080
Epoch: [118] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.002888  min_lr: 0.002888  loss: 3.1716 (3.3385)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7544 (1.0544)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.6293 (0.6293)  acc1: 88.0000 (88.0000)  acc5: 98.0000 (98.0000)  time: 5.2203  data: 4.9000  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8977 (0.8400)  acc1: 83.6000 (83.2364)  acc5: 96.8000 (97.0182)  time: 0.7122  data: 0.4457  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0256 (0.9983)  acc1: 78.4000 (79.7333)  acc5: 94.8000 (95.2191)  time: 0.2612  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0759 (1.0079)  acc1: 77.6000 (79.4080)  acc5: 94.4000 (95.1040)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4626 s / it)
* Acc@1 79.500 Acc@5 95.108 loss 0.993
Accuracy of the model on the 50000 test images: 79.5%
Max accuracy: 79.50%
Epoch: [119]  [   0/1251]  eta: 1:03:01  lr: 0.002888  min_lr: 0.002888  loss: 3.6047 (3.6047)  weight_decay: 0.0500 (0.0500)  time: 3.0230  data: 2.5209  max mem: 40080
Epoch: [119]  [ 200/1251]  eta: 0:08:57  lr: 0.002885  min_lr: 0.002885  loss: 3.1994 (3.2987)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9118 (1.0561)  time: 0.4956  data: 0.0004  max mem: 40080
Epoch: [119]  [ 400/1251]  eta: 0:07:09  lr: 0.002882  min_lr: 0.002882  loss: 3.3414 (3.3098)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3267 (1.0930)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [119]  [ 600/1251]  eta: 0:05:26  lr: 0.002879  min_lr: 0.002879  loss: 3.3305 (3.3027)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0275 (1.0964)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [119]  [ 800/1251]  eta: 0:03:46  lr: 0.002875  min_lr: 0.002875  loss: 3.3380 (3.2928)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9548 (1.0903)  time: 0.4997  data: 0.0004  max mem: 40080
Epoch: [119]  [1000/1251]  eta: 0:02:05  lr: 0.002872  min_lr: 0.002872  loss: 3.4575 (3.3075)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8899 (1.0627)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [119]  [1200/1251]  eta: 0:00:25  lr: 0.002869  min_lr: 0.002869  loss: 3.2205 (3.3105)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9341 (1.0654)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [119]  [1250/1251]  eta: 0:00:00  lr: 0.002868  min_lr: 0.002868  loss: 3.3468 (3.3154)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7489 (1.0636)  time: 0.4214  data: 0.0005  max mem: 40080
Epoch: [119] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.002868  min_lr: 0.002868  loss: 3.3468 (3.3248)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7489 (1.0636)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.7458 (0.7458)  acc1: 87.2000 (87.2000)  acc5: 98.0000 (98.0000)  time: 5.4990  data: 5.1830  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.9226 (0.9161)  acc1: 81.6000 (82.0000)  acc5: 97.2000 (96.9091)  time: 0.7377  data: 0.4715  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0603 (1.0702)  acc1: 77.2000 (79.1429)  acc5: 94.8000 (95.2952)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1190 (1.0757)  acc1: 77.2000 (78.7840)  acc5: 94.4000 (95.2480)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4739 s / it)
* Acc@1 79.204 Acc@5 95.244 loss 1.066
Accuracy of the model on the 50000 test images: 79.2%
Max accuracy: 79.50%
Epoch: [120]  [   0/1251]  eta: 1:15:32  lr: 0.002868  min_lr: 0.002868  loss: 3.6228 (3.6228)  weight_decay: 0.0500 (0.0500)  time: 3.6229  data: 3.0724  max mem: 40080
Epoch: [120]  [ 200/1251]  eta: 0:09:00  lr: 0.002865  min_lr: 0.002865  loss: 3.5281 (3.3208)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8485 (0.9676)  time: 0.4995  data: 0.0004  max mem: 40080
Epoch: [120]  [ 400/1251]  eta: 0:07:11  lr: 0.002862  min_lr: 0.002862  loss: 3.3477 (3.3324)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7415 (1.0125)  time: 0.5003  data: 0.0004  max mem: 40080
Epoch: [120]  [ 600/1251]  eta: 0:05:28  lr: 0.002858  min_lr: 0.002858  loss: 3.4079 (3.3287)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0371 (1.0452)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [120]  [ 800/1251]  eta: 0:03:46  lr: 0.002855  min_lr: 0.002855  loss: 3.5442 (3.3456)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8136 (1.0618)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [120]  [1000/1251]  eta: 0:02:05  lr: 0.002852  min_lr: 0.002852  loss: 3.5516 (3.3443)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8293 (1.0609)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [120]  [1200/1251]  eta: 0:00:25  lr: 0.002849  min_lr: 0.002849  loss: 3.6514 (3.3445)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8476 (1.0359)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [120]  [1250/1251]  eta: 0:00:00  lr: 0.002848  min_lr: 0.002848  loss: 3.3475 (3.3451)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1173 (1.0444)  time: 0.4208  data: 0.0005  max mem: 40080
Epoch: [120] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.002848  min_lr: 0.002848  loss: 3.3475 (3.3267)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1173 (1.0444)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.7066 (0.7066)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 5.3594  data: 5.0644  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8703 (0.8875)  acc1: 82.8000 (81.9273)  acc5: 96.8000 (96.8364)  time: 0.7250  data: 0.4607  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1089 (1.0313)  acc1: 76.8000 (79.0286)  acc5: 94.8000 (94.9333)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1504 (1.0462)  acc1: 76.8000 (78.8000)  acc5: 94.4000 (94.8480)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4686 s / it)
* Acc@1 79.436 Acc@5 95.130 loss 1.027
Accuracy of the model on the 50000 test images: 79.4%
Max accuracy: 79.50%
Epoch: [121]  [   0/1251]  eta: 1:11:57  lr: 0.002848  min_lr: 0.002848  loss: 3.3310 (3.3310)  weight_decay: 0.0500 (0.0500)  time: 3.4515  data: 2.7302  max mem: 40080
Epoch: [121]  [ 200/1251]  eta: 0:08:58  lr: 0.002845  min_lr: 0.002845  loss: 3.1574 (3.3051)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6940 (0.9332)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [121]  [ 400/1251]  eta: 0:07:10  lr: 0.002841  min_lr: 0.002841  loss: 3.3655 (3.3251)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7493 (0.9367)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [121]  [ 600/1251]  eta: 0:05:27  lr: 0.002838  min_lr: 0.002838  loss: 3.5140 (3.2920)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8518 (0.9798)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [121]  [ 800/1251]  eta: 0:03:45  lr: 0.002835  min_lr: 0.002835  loss: 3.6162 (3.3009)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9438 (0.9616)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [121]  [1000/1251]  eta: 0:02:05  lr: 0.002831  min_lr: 0.002831  loss: 3.2498 (3.3078)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7991 (0.9719)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [121]  [1200/1251]  eta: 0:00:25  lr: 0.002828  min_lr: 0.002828  loss: 3.2300 (3.3094)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7521 (1.0034)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [121]  [1250/1251]  eta: 0:00:00  lr: 0.002827  min_lr: 0.002827  loss: 3.4135 (3.3128)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7802 (0.9992)  time: 0.4214  data: 0.0005  max mem: 40080
Epoch: [121] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.002827  min_lr: 0.002827  loss: 3.4135 (3.3084)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7802 (0.9992)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.6993 (0.6993)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 5.3375  data: 5.0360  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8846 (0.8848)  acc1: 84.0000 (82.5818)  acc5: 96.8000 (97.2000)  time: 0.7230  data: 0.4581  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0974 (1.0460)  acc1: 77.6000 (79.4476)  acc5: 95.2000 (95.2571)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0974 (1.0560)  acc1: 77.6000 (79.2160)  acc5: 95.2000 (95.2000)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4700 s / it)
* Acc@1 79.502 Acc@5 95.158 loss 1.048
Accuracy of the model on the 50000 test images: 79.5%
Max accuracy: 79.50%
Epoch: [122]  [   0/1251]  eta: 0:57:11  lr: 0.002827  min_lr: 0.002827  loss: 2.4321 (2.4321)  weight_decay: 0.0500 (0.0500)  time: 2.7434  data: 2.2212  max mem: 40080
Epoch: [122]  [ 200/1251]  eta: 0:08:55  lr: 0.002824  min_lr: 0.002824  loss: 3.1163 (3.2984)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6596 (0.9085)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [122]  [ 400/1251]  eta: 0:07:08  lr: 0.002821  min_lr: 0.002821  loss: 3.5119 (3.3036)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7873 (0.9489)  time: 0.4991  data: 0.0005  max mem: 40080
Epoch: [122]  [ 600/1251]  eta: 0:05:27  lr: 0.002818  min_lr: 0.002818  loss: 3.2299 (3.2776)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6819 (1.0033)  time: 0.5005  data: 0.0005  max mem: 40080
Epoch: [122]  [ 800/1251]  eta: 0:03:46  lr: 0.002814  min_lr: 0.002814  loss: 3.5065 (3.2781)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [122]  [1000/1251]  eta: 0:02:05  lr: 0.002811  min_lr: 0.002811  loss: 3.3767 (3.2731)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8362 (nan)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [122]  [1200/1251]  eta: 0:00:25  lr: 0.002808  min_lr: 0.002808  loss: 3.4171 (3.2988)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8039 (nan)  time: 0.4963  data: 0.0005  max mem: 40080
Epoch: [122]  [1250/1251]  eta: 0:00:00  lr: 0.002807  min_lr: 0.002807  loss: 3.4352 (3.2988)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7319 (nan)  time: 0.4209  data: 0.0006  max mem: 40080
Epoch: [122] Total time: 0:10:25 (0.4996 s / it)
Averaged stats: lr: 0.002807  min_lr: 0.002807  loss: 3.4352 (3.3193)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7319 (nan)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.7751 (0.7751)  acc1: 87.2000 (87.2000)  acc5: 98.4000 (98.4000)  time: 5.4001  data: 5.0857  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9094 (0.9230)  acc1: 83.2000 (82.1091)  acc5: 96.8000 (96.8364)  time: 0.7284  data: 0.4626  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1327 (1.0652)  acc1: 76.8000 (79.1810)  acc5: 95.2000 (95.1429)  time: 0.2610  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1501 (1.0770)  acc1: 76.8000 (78.9920)  acc5: 94.8000 (95.0720)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4697 s / it)
* Acc@1 79.742 Acc@5 95.218 loss 1.062
Accuracy of the model on the 50000 test images: 79.7%
Max accuracy: 79.74%
Epoch: [123]  [   0/1251]  eta: 1:04:10  lr: 0.002807  min_lr: 0.002807  loss: 3.4254 (3.4254)  weight_decay: 0.0500 (0.0500)  time: 3.0782  data: 2.5706  max mem: 40080
Epoch: [123]  [ 200/1251]  eta: 0:08:57  lr: 0.002804  min_lr: 0.002804  loss: 3.2652 (3.2556)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6577 (0.9939)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [123]  [ 400/1251]  eta: 0:07:09  lr: 0.002800  min_lr: 0.002800  loss: 3.3504 (3.2852)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9334 (1.0218)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [123]  [ 600/1251]  eta: 0:05:27  lr: 0.002797  min_lr: 0.002797  loss: 3.4491 (3.3025)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9925 (1.0022)  time: 0.5057  data: 0.0004  max mem: 40080
Epoch: [123]  [ 800/1251]  eta: 0:03:45  lr: 0.002794  min_lr: 0.002794  loss: 3.3287 (3.3027)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6833 (0.9786)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [123]  [1000/1251]  eta: 0:02:05  lr: 0.002790  min_lr: 0.002790  loss: 3.5665 (3.3149)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6776 (0.9827)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [123]  [1200/1251]  eta: 0:00:25  lr: 0.002787  min_lr: 0.002787  loss: 3.4034 (3.3170)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9772 (1.0079)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [123]  [1250/1251]  eta: 0:00:00  lr: 0.002786  min_lr: 0.002786  loss: 3.3570 (3.3153)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0593 (1.0055)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [123] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.002786  min_lr: 0.002786  loss: 3.3570 (3.3150)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0593 (1.0055)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.5974 (0.5974)  acc1: 90.8000 (90.8000)  acc5: 99.2000 (99.2000)  time: 5.5749  data: 5.2765  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8462 (0.8250)  acc1: 83.2000 (83.0546)  acc5: 97.6000 (97.1636)  time: 0.7443  data: 0.4800  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0055 (0.9663)  acc1: 77.6000 (79.6571)  acc5: 94.8000 (95.0476)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0618 (0.9780)  acc1: 77.2000 (79.4400)  acc5: 94.4000 (95.0560)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4770 s / it)
* Acc@1 79.904 Acc@5 95.306 loss 0.966
Accuracy of the model on the 50000 test images: 79.9%
Max accuracy: 79.90%
Epoch: [124]  [   0/1251]  eta: 1:01:22  lr: 0.002786  min_lr: 0.002786  loss: 3.7860 (3.7860)  weight_decay: 0.0500 (0.0500)  time: 2.9439  data: 2.4418  max mem: 40080
Epoch: [124]  [ 200/1251]  eta: 0:08:55  lr: 0.002783  min_lr: 0.002783  loss: 3.4118 (3.3327)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1094 (1.0879)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [124]  [ 400/1251]  eta: 0:07:08  lr: 0.002780  min_lr: 0.002780  loss: 3.3439 (3.3029)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7601 (1.0892)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [124]  [ 600/1251]  eta: 0:05:26  lr: 0.002776  min_lr: 0.002776  loss: 3.4783 (3.3056)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8369 (1.1109)  time: 0.4959  data: 0.0003  max mem: 40080
Epoch: [124]  [ 800/1251]  eta: 0:03:45  lr: 0.002773  min_lr: 0.002773  loss: 3.3764 (3.3142)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9471 (1.1084)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [124]  [1000/1251]  eta: 0:02:05  lr: 0.002770  min_lr: 0.002770  loss: 3.4504 (3.3177)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8747 (1.0755)  time: 0.5051  data: 0.0004  max mem: 40080
Epoch: [124]  [1200/1251]  eta: 0:00:25  lr: 0.002766  min_lr: 0.002766  loss: 3.4474 (3.3199)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9382 (1.1058)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [124]  [1250/1251]  eta: 0:00:00  lr: 0.002766  min_lr: 0.002766  loss: 3.5082 (3.3152)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9777 (1.1004)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [124] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.002766  min_lr: 0.002766  loss: 3.5082 (3.3101)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9777 (1.1004)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6295 (0.6295)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 5.5555  data: 5.2642  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8049 (0.8228)  acc1: 84.4000 (83.2727)  acc5: 96.8000 (97.1636)  time: 0.7429  data: 0.4788  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0460 (0.9786)  acc1: 78.0000 (80.0381)  acc5: 95.2000 (95.2381)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1100 (0.9944)  acc1: 78.0000 (79.7600)  acc5: 94.0000 (95.1200)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4765 s / it)
* Acc@1 79.632 Acc@5 95.286 loss 0.979
Accuracy of the model on the 50000 test images: 79.6%
Max accuracy: 79.90%
Epoch: [125]  [   0/1251]  eta: 1:10:40  lr: 0.002766  min_lr: 0.002766  loss: 3.8852 (3.8852)  weight_decay: 0.0500 (0.0500)  time: 3.3894  data: 2.5518  max mem: 40080
Epoch: [125]  [ 200/1251]  eta: 0:08:58  lr: 0.002762  min_lr: 0.002762  loss: 3.5581 (3.3338)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7515 (0.9809)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [125]  [ 400/1251]  eta: 0:07:10  lr: 0.002759  min_lr: 0.002759  loss: 3.4066 (3.3241)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7820 (0.9741)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [125]  [ 600/1251]  eta: 0:05:27  lr: 0.002756  min_lr: 0.002756  loss: 3.3995 (3.3189)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7600 (0.9589)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [125]  [ 800/1251]  eta: 0:03:46  lr: 0.002752  min_lr: 0.002752  loss: 3.1912 (3.3190)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0389 (0.9950)  time: 0.5050  data: 0.0005  max mem: 40080
Epoch: [125]  [1000/1251]  eta: 0:02:05  lr: 0.002749  min_lr: 0.002749  loss: 3.5327 (3.3121)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7902 (0.9981)  time: 0.4993  data: 0.0005  max mem: 40080
Epoch: [125]  [1200/1251]  eta: 0:00:25  lr: 0.002746  min_lr: 0.002746  loss: 3.1901 (3.3012)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0940 (1.0185)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [125]  [1250/1251]  eta: 0:00:00  lr: 0.002745  min_lr: 0.002745  loss: 3.2097 (3.3015)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9100 (1.0132)  time: 0.4215  data: 0.0007  max mem: 40080
Epoch: [125] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.002745  min_lr: 0.002745  loss: 3.2097 (3.2997)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9100 (1.0132)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.6552 (0.6552)  acc1: 89.2000 (89.2000)  acc5: 97.6000 (97.6000)  time: 5.2020  data: 4.8986  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8122 (0.8359)  acc1: 83.2000 (83.6364)  acc5: 97.6000 (97.1636)  time: 0.7107  data: 0.4457  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0297 (0.9972)  acc1: 77.2000 (79.9238)  acc5: 94.8000 (95.1238)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1190 (1.0092)  acc1: 77.2000 (79.4560)  acc5: 94.4000 (95.0400)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4629 s / it)
* Acc@1 79.834 Acc@5 95.166 loss 1.005
Accuracy of the model on the 50000 test images: 79.8%
Max accuracy: 79.90%
Epoch: [126]  [   0/1251]  eta: 1:15:20  lr: 0.002745  min_lr: 0.002745  loss: 3.5162 (3.5162)  weight_decay: 0.0500 (0.0500)  time: 3.6139  data: 2.3044  max mem: 40080
Epoch: [126]  [ 200/1251]  eta: 0:09:02  lr: 0.002742  min_lr: 0.002742  loss: 3.1680 (3.2713)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9840 (1.0018)  time: 0.4997  data: 0.0005  max mem: 40080
Epoch: [126]  [ 400/1251]  eta: 0:07:11  lr: 0.002738  min_lr: 0.002738  loss: 3.3308 (3.3131)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8014 (1.0612)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [126]  [ 600/1251]  eta: 0:05:28  lr: 0.002735  min_lr: 0.002735  loss: 3.5973 (3.3200)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8291 (1.0268)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [126]  [ 800/1251]  eta: 0:03:46  lr: 0.002732  min_lr: 0.002732  loss: 3.3618 (3.3267)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8349 (1.0450)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [126]  [1000/1251]  eta: 0:02:05  lr: 0.002728  min_lr: 0.002728  loss: 3.3945 (3.3203)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7591 (1.0410)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [126]  [1200/1251]  eta: 0:00:25  lr: 0.002725  min_lr: 0.002725  loss: 3.2434 (3.3156)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8538 (1.0620)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [126]  [1250/1251]  eta: 0:00:00  lr: 0.002724  min_lr: 0.002724  loss: 3.3310 (3.3193)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7359 (1.0530)  time: 0.4214  data: 0.0007  max mem: 40080
Epoch: [126] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.002724  min_lr: 0.002724  loss: 3.3310 (3.3017)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7359 (1.0530)
Test:  [ 0/25]  eta: 0:01:48  loss: 0.7414 (0.7414)  acc1: 88.0000 (88.0000)  acc5: 97.6000 (97.6000)  time: 4.3580  data: 4.0558  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8948 (0.9016)  acc1: 84.0000 (83.1273)  acc5: 97.6000 (97.2364)  time: 0.6870  data: 0.4141  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1213 (1.0366)  acc1: 78.0000 (79.8286)  acc5: 95.2000 (95.5619)  time: 0.2912  data: 0.0250  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1274 (1.0487)  acc1: 78.8000 (79.7760)  acc5: 94.4000 (95.3440)  time: 0.2641  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4525 s / it)
* Acc@1 79.742 Acc@5 95.186 loss 1.046
Accuracy of the model on the 50000 test images: 79.7%
Max accuracy: 79.90%
Epoch: [127]  [   0/1251]  eta: 1:12:17  lr: 0.002724  min_lr: 0.002724  loss: 3.2028 (3.2028)  weight_decay: 0.0500 (0.0500)  time: 3.4675  data: 2.7750  max mem: 40080
Epoch: [127]  [ 200/1251]  eta: 0:09:00  lr: 0.002721  min_lr: 0.002721  loss: 3.3617 (3.2518)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9641 (1.0789)  time: 0.4972  data: 0.0005  max mem: 40080
Epoch: [127]  [ 400/1251]  eta: 0:07:11  lr: 0.002717  min_lr: 0.002717  loss: 3.3660 (3.2881)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9124 (0.9893)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [127]  [ 600/1251]  eta: 0:05:28  lr: 0.002714  min_lr: 0.002714  loss: 3.1823 (3.2912)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8800 (1.0735)  time: 0.4995  data: 0.0004  max mem: 40080
Epoch: [127]  [ 800/1251]  eta: 0:03:46  lr: 0.002711  min_lr: 0.002711  loss: 3.2057 (3.2932)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9910 (1.0816)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [127]  [1000/1251]  eta: 0:02:05  lr: 0.002707  min_lr: 0.002707  loss: 3.3695 (3.2891)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8787 (1.0455)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [127]  [1200/1251]  eta: 0:00:25  lr: 0.002704  min_lr: 0.002704  loss: 3.3153 (3.2867)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7163 (1.0290)  time: 0.4991  data: 0.0004  max mem: 40080
Epoch: [127]  [1250/1251]  eta: 0:00:00  lr: 0.002703  min_lr: 0.002703  loss: 3.2682 (3.2841)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2064 (1.0502)  time: 0.4218  data: 0.0005  max mem: 40080
Epoch: [127] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.002703  min_lr: 0.002703  loss: 3.2682 (3.2948)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2064 (1.0502)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.6903 (0.6903)  acc1: 87.2000 (87.2000)  acc5: 98.8000 (98.8000)  time: 5.4497  data: 5.1541  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8211 (0.8475)  acc1: 82.8000 (83.0182)  acc5: 96.8000 (97.0545)  time: 0.7332  data: 0.4688  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0072 (0.9862)  acc1: 77.6000 (79.6571)  acc5: 95.6000 (95.3333)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0344 (0.9915)  acc1: 77.2000 (79.5040)  acc5: 94.4000 (95.2640)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4723 s / it)
* Acc@1 79.832 Acc@5 95.354 loss 0.986
Accuracy of the model on the 50000 test images: 79.8%
Max accuracy: 79.90%
Epoch: [128]  [   0/1251]  eta: 1:13:09  lr: 0.002703  min_lr: 0.002703  loss: 3.2214 (3.2214)  weight_decay: 0.0500 (0.0500)  time: 3.5087  data: 2.4964  max mem: 40080
Epoch: [128]  [ 200/1251]  eta: 0:09:00  lr: 0.002700  min_lr: 0.002700  loss: 3.2983 (3.2829)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0022 (1.0765)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [128]  [ 400/1251]  eta: 0:07:10  lr: 0.002696  min_lr: 0.002696  loss: 3.3712 (3.2675)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8559 (1.1085)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [128]  [ 600/1251]  eta: 0:05:27  lr: 0.002693  min_lr: 0.002693  loss: 3.3776 (3.2879)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8122 (1.1290)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [128]  [ 800/1251]  eta: 0:03:46  lr: 0.002690  min_lr: 0.002690  loss: 3.3942 (3.2782)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2097 (1.1178)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [128]  [1000/1251]  eta: 0:02:05  lr: 0.002686  min_lr: 0.002686  loss: 3.5235 (3.2777)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6768 (1.0747)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [128]  [1200/1251]  eta: 0:00:25  lr: 0.002683  min_lr: 0.002683  loss: 3.2056 (3.2738)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9532 (1.0659)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [128]  [1250/1251]  eta: 0:00:00  lr: 0.002682  min_lr: 0.002682  loss: 3.5602 (3.2787)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1259 (1.0720)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [128] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.002682  min_lr: 0.002682  loss: 3.5602 (3.2926)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1259 (1.0720)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.7089 (0.7089)  acc1: 87.6000 (87.6000)  acc5: 98.4000 (98.4000)  time: 5.5192  data: 5.1962  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8952 (0.8882)  acc1: 84.4000 (82.7273)  acc5: 97.2000 (96.9818)  time: 0.7398  data: 0.4728  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0941 (1.0407)  acc1: 76.8000 (79.4667)  acc5: 94.4000 (95.0286)  time: 0.2616  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1505 (1.0457)  acc1: 77.2000 (79.2320)  acc5: 94.0000 (95.0400)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4752 s / it)
* Acc@1 79.906 Acc@5 95.324 loss 1.034
Accuracy of the model on the 50000 test images: 79.9%
Max accuracy: 79.91%
Epoch: [129]  [   0/1251]  eta: 0:53:13  lr: 0.002682  min_lr: 0.002682  loss: 3.1289 (3.1289)  weight_decay: 0.0500 (0.0500)  time: 2.5527  data: 2.0382  max mem: 40080
Epoch: [129]  [ 200/1251]  eta: 0:08:53  lr: 0.002679  min_lr: 0.002679  loss: 3.2421 (3.2718)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8158 (1.1132)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [129]  [ 400/1251]  eta: 0:07:09  lr: 0.002675  min_lr: 0.002675  loss: 3.3874 (3.2652)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9484 (1.0855)  time: 0.5060  data: 0.0004  max mem: 40080
Epoch: [129]  [ 600/1251]  eta: 0:05:27  lr: 0.002672  min_lr: 0.002672  loss: 3.5455 (3.2661)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0881 (1.1405)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [129]  [ 800/1251]  eta: 0:03:46  lr: 0.002668  min_lr: 0.002668  loss: 3.2250 (3.2915)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8159 (1.1351)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [129]  [1000/1251]  eta: 0:02:05  lr: 0.002665  min_lr: 0.002665  loss: 3.1773 (3.2911)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8317 (1.1143)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [129]  [1200/1251]  eta: 0:00:25  lr: 0.002662  min_lr: 0.002662  loss: 3.1067 (3.2940)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6774 (1.0750)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [129]  [1250/1251]  eta: 0:00:00  lr: 0.002661  min_lr: 0.002661  loss: 3.5703 (3.2986)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8936 (1.0919)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [129] Total time: 0:10:25 (0.4997 s / it)
Averaged stats: lr: 0.002661  min_lr: 0.002661  loss: 3.5703 (3.2888)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8936 (1.0919)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.8049 (0.8049)  acc1: 86.0000 (86.0000)  acc5: 98.0000 (98.0000)  time: 5.2016  data: 4.8940  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.9712 (0.9477)  acc1: 84.8000 (82.5818)  acc5: 97.6000 (97.3091)  time: 0.7108  data: 0.4453  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1026 (1.0767)  acc1: 77.2000 (79.5810)  acc5: 94.8000 (95.5048)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1715 (1.0863)  acc1: 76.4000 (79.1680)  acc5: 94.4000 (95.2800)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4624 s / it)
* Acc@1 79.736 Acc@5 95.260 loss 1.080
Accuracy of the model on the 50000 test images: 79.7%
Max accuracy: 79.91%
Epoch: [130]  [   0/1251]  eta: 1:15:47  lr: 0.002661  min_lr: 0.002661  loss: 3.1261 (3.1261)  weight_decay: 0.0500 (0.0500)  time: 3.6353  data: 2.3763  max mem: 40080
Epoch: [130]  [ 200/1251]  eta: 0:09:02  lr: 0.002657  min_lr: 0.002657  loss: 3.3957 (3.3317)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0100 (1.0717)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [130]  [ 400/1251]  eta: 0:07:11  lr: 0.002654  min_lr: 0.002654  loss: 3.4893 (3.2984)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0234 (1.1442)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [130]  [ 600/1251]  eta: 0:05:28  lr: 0.002651  min_lr: 0.002651  loss: 3.3795 (3.3187)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6740 (1.0952)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [130]  [ 800/1251]  eta: 0:03:46  lr: 0.002647  min_lr: 0.002647  loss: 3.2762 (3.3156)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9952 (1.1191)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [130]  [1000/1251]  eta: 0:02:05  lr: 0.002644  min_lr: 0.002644  loss: 3.2396 (3.3194)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8862 (1.0847)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [130]  [1200/1251]  eta: 0:00:25  lr: 0.002640  min_lr: 0.002640  loss: 3.3154 (3.3143)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8425 (1.0542)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [130]  [1250/1251]  eta: 0:00:00  lr: 0.002640  min_lr: 0.002640  loss: 3.3562 (3.3111)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9904 (1.0531)  time: 0.4210  data: 0.0006  max mem: 40080
Epoch: [130] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.002640  min_lr: 0.002640  loss: 3.3562 (3.2909)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9904 (1.0531)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.6515 (0.6515)  acc1: 88.4000 (88.4000)  acc5: 98.4000 (98.4000)  time: 5.2886  data: 4.9748  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8207 (0.8331)  acc1: 84.8000 (83.2727)  acc5: 97.6000 (97.3455)  time: 0.7186  data: 0.4526  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0707 (0.9878)  acc1: 79.2000 (80.1333)  acc5: 95.6000 (95.6191)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0818 (1.0027)  acc1: 79.2000 (79.8560)  acc5: 94.4000 (95.4400)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4674 s / it)
* Acc@1 80.156 Acc@5 95.342 loss 1.000
Accuracy of the model on the 50000 test images: 80.2%
Max accuracy: 80.16%
Epoch: [131]  [   0/1251]  eta: 0:54:10  lr: 0.002640  min_lr: 0.002640  loss: 3.7912 (3.7912)  weight_decay: 0.0500 (0.0500)  time: 2.5986  data: 2.0803  max mem: 40080
Epoch: [131]  [ 200/1251]  eta: 0:08:54  lr: 0.002636  min_lr: 0.002636  loss: 3.2778 (3.3215)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1532 (1.1821)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [131]  [ 400/1251]  eta: 0:07:08  lr: 0.002633  min_lr: 0.002633  loss: 3.3788 (3.3358)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1761 (1.1865)  time: 0.4979  data: 0.0005  max mem: 40080
Epoch: [131]  [ 600/1251]  eta: 0:05:26  lr: 0.002629  min_lr: 0.002629  loss: 3.2110 (3.3110)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8918 (1.1311)  time: 0.5060  data: 0.0004  max mem: 40080
Epoch: [131]  [ 800/1251]  eta: 0:03:45  lr: 0.002626  min_lr: 0.002626  loss: 3.3364 (3.3062)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9687 (1.1067)  time: 0.4963  data: 0.0005  max mem: 40080
Epoch: [131]  [1000/1251]  eta: 0:02:05  lr: 0.002623  min_lr: 0.002623  loss: 3.5590 (3.2910)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8668 (1.1158)  time: 0.4964  data: 0.0005  max mem: 40080
Epoch: [131]  [1200/1251]  eta: 0:00:25  lr: 0.002619  min_lr: 0.002619  loss: 3.2932 (3.2903)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9154 (1.0852)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [131]  [1250/1251]  eta: 0:00:00  lr: 0.002618  min_lr: 0.002618  loss: 3.3549 (3.2924)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1764 (1.0948)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [131] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.002618  min_lr: 0.002618  loss: 3.3549 (3.2816)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1764 (1.0948)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6473 (0.6473)  acc1: 87.2000 (87.2000)  acc5: 99.2000 (99.2000)  time: 5.4871  data: 5.1732  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8102 (0.8233)  acc1: 84.8000 (83.2000)  acc5: 97.2000 (97.0546)  time: 0.7366  data: 0.4706  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0784 (0.9738)  acc1: 77.2000 (80.0191)  acc5: 94.4000 (95.2381)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0619 (0.9855)  acc1: 77.6000 (79.6000)  acc5: 94.4000 (95.2000)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4766 s / it)
* Acc@1 80.106 Acc@5 95.380 loss 0.969
Accuracy of the model on the 50000 test images: 80.1%
Max accuracy: 80.16%
Epoch: [132]  [   0/1251]  eta: 1:11:42  lr: 0.002618  min_lr: 0.002618  loss: 3.1343 (3.1343)  weight_decay: 0.0500 (0.0500)  time: 3.4392  data: 2.8390  max mem: 40080
Epoch: [132]  [ 200/1251]  eta: 0:08:59  lr: 0.002615  min_lr: 0.002615  loss: 3.5042 (3.2734)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9661 (1.1189)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [132]  [ 400/1251]  eta: 0:07:10  lr: 0.002612  min_lr: 0.002612  loss: 3.0868 (3.2831)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8741 (1.0727)  time: 0.5007  data: 0.0005  max mem: 40080
Epoch: [132]  [ 600/1251]  eta: 0:05:27  lr: 0.002608  min_lr: 0.002608  loss: 3.1151 (3.2689)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2265 (1.1462)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [132]  [ 800/1251]  eta: 0:03:46  lr: 0.002605  min_lr: 0.002605  loss: 3.5567 (3.2870)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8366 (1.0721)  time: 0.4989  data: 0.0005  max mem: 40080
Epoch: [132]  [1000/1251]  eta: 0:02:05  lr: 0.002601  min_lr: 0.002601  loss: 3.3782 (3.2936)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1411 (1.0850)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [132]  [1200/1251]  eta: 0:00:25  lr: 0.002598  min_lr: 0.002598  loss: 3.5628 (3.2867)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8841 (1.0604)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [132]  [1250/1251]  eta: 0:00:00  lr: 0.002597  min_lr: 0.002597  loss: 3.1082 (3.2873)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6993 (1.0512)  time: 0.4218  data: 0.0007  max mem: 40080
Epoch: [132] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.002597  min_lr: 0.002597  loss: 3.1082 (3.2770)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6993 (1.0512)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.6264 (0.6264)  acc1: 88.8000 (88.8000)  acc5: 99.2000 (99.2000)  time: 5.6340  data: 5.3280  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8435 (0.8268)  acc1: 83.2000 (82.8364)  acc5: 96.8000 (97.0182)  time: 0.7499  data: 0.4846  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0526 (0.9739)  acc1: 77.6000 (79.6381)  acc5: 94.8000 (95.3333)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0864 (0.9856)  acc1: 76.8000 (79.2160)  acc5: 94.8000 (95.3440)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4800 s / it)
* Acc@1 80.010 Acc@5 95.486 loss 0.968
Accuracy of the model on the 50000 test images: 80.0%
Max accuracy: 80.16%
Epoch: [133]  [   0/1251]  eta: 1:10:14  lr: 0.002597  min_lr: 0.002597  loss: 2.4102 (2.4102)  weight_decay: 0.0500 (0.0500)  time: 3.3686  data: 1.8788  max mem: 40080
Epoch: [133]  [ 200/1251]  eta: 0:09:00  lr: 0.002594  min_lr: 0.002594  loss: 3.3438 (3.2546)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0372 (1.2286)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [133]  [ 400/1251]  eta: 0:07:11  lr: 0.002590  min_lr: 0.002590  loss: 3.2852 (3.2667)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8232 (1.1158)  time: 0.4981  data: 0.0005  max mem: 40080
Epoch: [133]  [ 600/1251]  eta: 0:05:28  lr: 0.002587  min_lr: 0.002587  loss: 3.4026 (3.2765)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1094 (1.1150)  time: 0.4992  data: 0.0005  max mem: 40080
Epoch: [133]  [ 800/1251]  eta: 0:03:46  lr: 0.002583  min_lr: 0.002583  loss: 3.3618 (3.2750)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9375 (1.0876)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [133]  [1000/1251]  eta: 0:02:05  lr: 0.002580  min_lr: 0.002580  loss: 3.2709 (3.2837)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0710 (1.1112)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [133]  [1200/1251]  eta: 0:00:25  lr: 0.002576  min_lr: 0.002576  loss: 3.2845 (3.2745)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8492 (1.1435)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [133]  [1250/1251]  eta: 0:00:00  lr: 0.002576  min_lr: 0.002576  loss: 3.3337 (3.2746)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9325 (1.1416)  time: 0.4211  data: 0.0007  max mem: 40080
Epoch: [133] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.002576  min_lr: 0.002576  loss: 3.3337 (3.2776)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9325 (1.1416)
Test:  [ 0/25]  eta: 0:01:52  loss: 0.6626 (0.6626)  acc1: 87.2000 (87.2000)  acc5: 98.8000 (98.8000)  time: 4.4885  data: 4.1963  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8583 (0.8318)  acc1: 83.6000 (84.1818)  acc5: 96.8000 (96.9455)  time: 0.6972  data: 0.4334  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0590 (0.9827)  acc1: 78.4000 (80.4381)  acc5: 95.2000 (95.2381)  time: 0.2895  data: 0.0286  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0306 (0.9911)  acc1: 78.0000 (79.9200)  acc5: 95.2000 (95.3120)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4565 s / it)
* Acc@1 80.200 Acc@5 95.510 loss 0.975
Accuracy of the model on the 50000 test images: 80.2%
Max accuracy: 80.20%
Epoch: [134]  [   0/1251]  eta: 0:55:06  lr: 0.002576  min_lr: 0.002576  loss: 3.6536 (3.6536)  weight_decay: 0.0500 (0.0500)  time: 2.6434  data: 2.1397  max mem: 40080
Epoch: [134]  [ 200/1251]  eta: 0:08:55  lr: 0.002572  min_lr: 0.002572  loss: 3.4460 (3.2360)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7916 (0.9747)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [134]  [ 400/1251]  eta: 0:07:08  lr: 0.002569  min_lr: 0.002569  loss: 3.2897 (3.2580)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0846 (1.0831)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [134]  [ 600/1251]  eta: 0:05:26  lr: 0.002565  min_lr: 0.002565  loss: 3.0920 (3.2474)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9721 (1.0829)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [134]  [ 800/1251]  eta: 0:03:45  lr: 0.002562  min_lr: 0.002562  loss: 3.5615 (3.2670)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9011 (1.0585)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [134]  [1000/1251]  eta: 0:02:05  lr: 0.002558  min_lr: 0.002558  loss: 3.2321 (3.2620)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4879 (1.0982)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [134]  [1200/1251]  eta: 0:00:25  lr: 0.002555  min_lr: 0.002555  loss: 3.3173 (3.2690)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8891 (1.1203)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [134]  [1250/1251]  eta: 0:00:00  lr: 0.002554  min_lr: 0.002554  loss: 3.3746 (3.2724)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8143 (1.1089)  time: 0.4211  data: 0.0006  max mem: 40080
Epoch: [134] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.002554  min_lr: 0.002554  loss: 3.3746 (3.2756)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8143 (1.1089)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6715 (0.6715)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 5.4959  data: 5.2004  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8336 (0.8336)  acc1: 84.0000 (83.4909)  acc5: 97.6000 (97.2727)  time: 0.7375  data: 0.4731  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0075 (0.9779)  acc1: 78.8000 (80.5333)  acc5: 95.2000 (95.6000)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0672 (0.9894)  acc1: 78.8000 (80.1920)  acc5: 94.8000 (95.4560)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4743 s / it)
* Acc@1 80.142 Acc@5 95.560 loss 0.984
Accuracy of the model on the 50000 test images: 80.1%
Max accuracy: 80.20%
Epoch: [135]  [   0/1251]  eta: 1:09:10  lr: 0.002554  min_lr: 0.002554  loss: 3.0638 (3.0638)  weight_decay: 0.0500 (0.0500)  time: 3.3174  data: 2.4172  max mem: 40080
Epoch: [135]  [ 200/1251]  eta: 0:08:59  lr: 0.002551  min_lr: 0.002551  loss: 3.3287 (3.2518)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6705 (1.1222)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [135]  [ 400/1251]  eta: 0:07:09  lr: 0.002547  min_lr: 0.002547  loss: 3.2069 (3.2527)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9718 (1.1034)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [135]  [ 600/1251]  eta: 0:05:27  lr: 0.002544  min_lr: 0.002544  loss: 3.4860 (3.2873)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1168 (1.0934)  time: 0.5056  data: 0.0004  max mem: 40080
Epoch: [135]  [ 800/1251]  eta: 0:03:46  lr: 0.002540  min_lr: 0.002540  loss: 3.3359 (3.2861)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7294 (inf)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [135]  [1000/1251]  eta: 0:02:05  lr: 0.002537  min_lr: 0.002537  loss: 3.4128 (3.2913)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7985 (inf)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [135]  [1200/1251]  eta: 0:00:25  lr: 0.002533  min_lr: 0.002533  loss: 3.4559 (3.2931)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0750 (inf)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [135]  [1250/1251]  eta: 0:00:00  lr: 0.002533  min_lr: 0.002533  loss: 3.1844 (3.2910)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8016 (inf)  time: 0.4269  data: 0.0005  max mem: 40080
Epoch: [135] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.002533  min_lr: 0.002533  loss: 3.1844 (3.2631)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8016 (inf)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.6302 (0.6302)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 5.5794  data: 5.2656  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8046 (0.8190)  acc1: 83.6000 (83.1636)  acc5: 96.8000 (97.0909)  time: 0.7450  data: 0.4790  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9781 (0.9650)  acc1: 77.2000 (79.6952)  acc5: 95.2000 (95.4095)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0663 (0.9757)  acc1: 77.2000 (79.3920)  acc5: 94.4000 (95.3280)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4771 s / it)
* Acc@1 80.258 Acc@5 95.516 loss 0.960
Accuracy of the model on the 50000 test images: 80.3%
Max accuracy: 80.26%
Epoch: [136]  [   0/1251]  eta: 0:56:39  lr: 0.002532  min_lr: 0.002532  loss: 2.8710 (2.8710)  weight_decay: 0.0500 (0.0500)  time: 2.7177  data: 2.2172  max mem: 40080
Epoch: [136]  [ 200/1251]  eta: 0:08:53  lr: 0.002529  min_lr: 0.002529  loss: 3.2366 (3.2330)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7598 (0.9243)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [136]  [ 400/1251]  eta: 0:07:07  lr: 0.002526  min_lr: 0.002526  loss: 3.4455 (3.2358)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0244 (1.0382)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [136]  [ 600/1251]  eta: 0:05:26  lr: 0.002522  min_lr: 0.002522  loss: 3.3845 (3.2602)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1742 (1.0749)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [136]  [ 800/1251]  eta: 0:03:45  lr: 0.002519  min_lr: 0.002519  loss: 3.4021 (3.2692)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3135 (1.1062)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [136]  [1000/1251]  eta: 0:02:05  lr: 0.002515  min_lr: 0.002515  loss: 3.2979 (3.2708)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8623 (1.1028)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [136]  [1200/1251]  eta: 0:00:25  lr: 0.002512  min_lr: 0.002512  loss: 3.4108 (3.2768)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6868 (1.0642)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [136]  [1250/1251]  eta: 0:00:00  lr: 0.002511  min_lr: 0.002511  loss: 3.3669 (3.2785)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6868 (1.0551)  time: 0.4207  data: 0.0005  max mem: 40080
Epoch: [136] Total time: 0:10:23 (0.4986 s / it)
Averaged stats: lr: 0.002511  min_lr: 0.002511  loss: 3.3669 (3.2665)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6868 (1.0551)
Test:  [ 0/25]  eta: 0:02:08  loss: 0.6510 (0.6510)  acc1: 87.6000 (87.6000)  acc5: 98.8000 (98.8000)  time: 5.1547  data: 4.8285  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8334 (0.8529)  acc1: 84.0000 (83.5273)  acc5: 97.6000 (96.9455)  time: 0.7064  data: 0.4393  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0914 (1.0005)  acc1: 76.4000 (79.8095)  acc5: 94.4000 (95.1429)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0574 (1.0113)  acc1: 78.0000 (79.6160)  acc5: 94.4000 (95.1360)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4617 s / it)
* Acc@1 80.004 Acc@5 95.340 loss 0.996
Accuracy of the model on the 50000 test images: 80.0%
Max accuracy: 80.26%
Epoch: [137]  [   0/1251]  eta: 1:12:08  lr: 0.002511  min_lr: 0.002511  loss: 3.3480 (3.3480)  weight_decay: 0.0500 (0.0500)  time: 3.4604  data: 2.2534  max mem: 40080
Epoch: [137]  [ 200/1251]  eta: 0:09:01  lr: 0.002507  min_lr: 0.002507  loss: 3.4476 (3.1879)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4423 (1.2945)  time: 0.4999  data: 0.0004  max mem: 40080
Epoch: [137]  [ 400/1251]  eta: 0:07:11  lr: 0.002504  min_lr: 0.002504  loss: 3.5580 (3.2270)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8518 (1.1550)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [137]  [ 600/1251]  eta: 0:05:27  lr: 0.002500  min_lr: 0.002500  loss: 3.3346 (3.2465)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8644 (1.1177)  time: 0.4989  data: 0.0004  max mem: 40080
Epoch: [137]  [ 800/1251]  eta: 0:03:46  lr: 0.002497  min_lr: 0.002497  loss: 3.4910 (3.2374)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7188 (1.1176)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [137]  [1000/1251]  eta: 0:02:05  lr: 0.002493  min_lr: 0.002493  loss: 3.3282 (3.2354)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9943 (1.1023)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [137]  [1200/1251]  eta: 0:00:25  lr: 0.002490  min_lr: 0.002490  loss: 3.3425 (3.2339)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9841 (1.1182)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [137]  [1250/1251]  eta: 0:00:00  lr: 0.002489  min_lr: 0.002489  loss: 3.0367 (3.2309)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0953 (1.1203)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [137] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.002489  min_lr: 0.002489  loss: 3.0367 (3.2562)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0953 (1.1203)
Test:  [ 0/25]  eta: 0:02:24  loss: 0.5991 (0.5991)  acc1: 87.6000 (87.6000)  acc5: 99.2000 (99.2000)  time: 5.7662  data: 5.4512  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8220 (0.7925)  acc1: 83.6000 (83.7455)  acc5: 97.2000 (97.2000)  time: 0.7617  data: 0.4959  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9942 (0.9335)  acc1: 77.6000 (80.3048)  acc5: 94.8000 (95.2952)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0074 (0.9411)  acc1: 77.6000 (80.1600)  acc5: 95.2000 (95.2640)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4843 s / it)
* Acc@1 80.334 Acc@5 95.414 loss 0.934
Accuracy of the model on the 50000 test images: 80.3%
Max accuracy: 80.33%
Epoch: [138]  [   0/1251]  eta: 0:58:45  lr: 0.002489  min_lr: 0.002489  loss: 3.6864 (3.6864)  weight_decay: 0.0500 (0.0500)  time: 2.8183  data: 2.3007  max mem: 40080
Epoch: [138]  [ 200/1251]  eta: 0:08:56  lr: 0.002486  min_lr: 0.002486  loss: 3.4819 (3.3140)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8498 (1.0290)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [138]  [ 400/1251]  eta: 0:07:09  lr: 0.002482  min_lr: 0.002482  loss: 3.4705 (3.2907)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [138]  [ 600/1251]  eta: 0:05:26  lr: 0.002479  min_lr: 0.002479  loss: 3.1408 (3.2862)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0137 (nan)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [138]  [ 800/1251]  eta: 0:03:46  lr: 0.002475  min_lr: 0.002475  loss: 3.0339 (3.2682)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0621 (nan)  time: 0.5000  data: 0.0005  max mem: 40080
Epoch: [138]  [1000/1251]  eta: 0:02:05  lr: 0.002472  min_lr: 0.002472  loss: 2.8850 (3.2519)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2898 (nan)  time: 0.5024  data: 0.0004  max mem: 40080
Epoch: [138]  [1200/1251]  eta: 0:00:25  lr: 0.002468  min_lr: 0.002468  loss: 3.2738 (3.2544)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8267 (nan)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [138]  [1250/1251]  eta: 0:00:00  lr: 0.002467  min_lr: 0.002467  loss: 3.3873 (3.2563)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0200 (nan)  time: 0.4211  data: 0.0006  max mem: 40080
Epoch: [138] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.002467  min_lr: 0.002467  loss: 3.3873 (3.2592)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0200 (nan)
Test:  [ 0/25]  eta: 0:02:14  loss: 0.7145 (0.7145)  acc1: 87.2000 (87.2000)  acc5: 98.8000 (98.8000)  time: 5.3623  data: 5.0623  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8968 (0.8567)  acc1: 83.6000 (82.9818)  acc5: 98.0000 (97.5273)  time: 0.7254  data: 0.4606  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0563 (0.9954)  acc1: 78.0000 (79.8667)  acc5: 96.0000 (95.6191)  time: 0.2615  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0931 (1.0102)  acc1: 77.2000 (79.5520)  acc5: 94.4000 (95.4560)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4704 s / it)
* Acc@1 80.148 Acc@5 95.472 loss 1.000
Accuracy of the model on the 50000 test images: 80.1%
Max accuracy: 80.33%
Epoch: [139]  [   0/1251]  eta: 1:10:16  lr: 0.002467  min_lr: 0.002467  loss: 3.7326 (3.7326)  weight_decay: 0.0500 (0.0500)  time: 3.3702  data: 2.3546  max mem: 40080
Epoch: [139]  [ 200/1251]  eta: 0:08:59  lr: 0.002464  min_lr: 0.002464  loss: 3.3056 (3.3364)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8250 (1.0100)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [139]  [ 400/1251]  eta: 0:07:10  lr: 0.002460  min_lr: 0.002460  loss: 3.3704 (3.3031)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8551 (1.0704)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [139]  [ 600/1251]  eta: 0:05:27  lr: 0.002457  min_lr: 0.002457  loss: 3.2371 (3.2908)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9153 (1.0295)  time: 0.5062  data: 0.0004  max mem: 40080
Epoch: [139]  [ 800/1251]  eta: 0:03:46  lr: 0.002453  min_lr: 0.002453  loss: 3.7401 (3.2908)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8708 (1.0824)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [139]  [1000/1251]  eta: 0:02:05  lr: 0.002450  min_lr: 0.002450  loss: 3.2495 (3.2880)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1280 (1.1008)  time: 0.5010  data: 0.0005  max mem: 40080
Epoch: [139]  [1200/1251]  eta: 0:00:25  lr: 0.002446  min_lr: 0.002446  loss: 3.3341 (3.2829)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7492 (1.0838)  time: 0.4986  data: 0.0004  max mem: 40080
Epoch: [139]  [1250/1251]  eta: 0:00:00  lr: 0.002446  min_lr: 0.002446  loss: 3.1399 (3.2795)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9083 (1.0846)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [139] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.002446  min_lr: 0.002446  loss: 3.1399 (3.2550)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9083 (1.0846)
Test:  [ 0/25]  eta: 0:02:11  loss: 0.6285 (0.6285)  acc1: 88.0000 (88.0000)  acc5: 99.2000 (99.2000)  time: 5.2695  data: 4.9558  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7903 (0.7974)  acc1: 82.8000 (83.2364)  acc5: 97.2000 (97.4182)  time: 0.7169  data: 0.4509  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9622 (0.9471)  acc1: 77.2000 (79.9048)  acc5: 95.6000 (95.4095)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0522 (0.9602)  acc1: 77.2000 (79.5680)  acc5: 94.0000 (95.2320)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4650 s / it)
* Acc@1 80.408 Acc@5 95.572 loss 0.941
Accuracy of the model on the 50000 test images: 80.4%
Max accuracy: 80.41%
Epoch: [140]  [   0/1251]  eta: 1:04:29  lr: 0.002445  min_lr: 0.002445  loss: 2.6214 (2.6214)  weight_decay: 0.0500 (0.0500)  time: 3.0927  data: 2.5926  max mem: 40080
Epoch: [140]  [ 200/1251]  eta: 0:08:57  lr: 0.002442  min_lr: 0.002442  loss: 3.3851 (3.2072)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7590 (1.1567)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [140]  [ 400/1251]  eta: 0:07:09  lr: 0.002438  min_lr: 0.002438  loss: 3.4133 (3.2377)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0179 (1.0904)  time: 0.5013  data: 0.0004  max mem: 40080
Epoch: [140]  [ 600/1251]  eta: 0:05:27  lr: 0.002435  min_lr: 0.002435  loss: 3.4391 (3.2466)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7853 (1.0744)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [140]  [ 800/1251]  eta: 0:03:46  lr: 0.002431  min_lr: 0.002431  loss: 3.3698 (3.2499)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9179 (1.0772)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [140]  [1000/1251]  eta: 0:02:05  lr: 0.002428  min_lr: 0.002428  loss: 3.4205 (3.2547)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9726 (1.1253)  time: 0.5086  data: 0.0004  max mem: 40080
Epoch: [140]  [1200/1251]  eta: 0:00:25  lr: 0.002424  min_lr: 0.002424  loss: 3.1456 (3.2559)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7744 (1.1079)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [140]  [1250/1251]  eta: 0:00:00  lr: 0.002424  min_lr: 0.002424  loss: 3.4704 (3.2576)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3583 (1.1291)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [140] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.002424  min_lr: 0.002424  loss: 3.4704 (3.2483)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3583 (1.1291)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.7281 (0.7281)  acc1: 88.4000 (88.4000)  acc5: 99.2000 (99.2000)  time: 5.5458  data: 5.2522  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8691 (0.8846)  acc1: 85.6000 (84.1091)  acc5: 97.6000 (97.4182)  time: 0.7420  data: 0.4778  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1077 (1.0187)  acc1: 78.8000 (80.9333)  acc5: 96.0000 (95.7714)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1121 (1.0379)  acc1: 78.4000 (80.5280)  acc5: 95.2000 (95.6160)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4758 s / it)
* Acc@1 80.192 Acc@5 95.530 loss 1.043
Accuracy of the model on the 50000 test images: 80.2%
Max accuracy: 80.41%
Epoch: [141]  [   0/1251]  eta: 1:08:36  lr: 0.002424  min_lr: 0.002424  loss: 3.2630 (3.2630)  weight_decay: 0.0500 (0.0500)  time: 3.2905  data: 1.6579  max mem: 40080
Epoch: [141]  [ 200/1251]  eta: 0:08:59  lr: 0.002420  min_lr: 0.002420  loss: 3.3270 (3.2317)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8374 (1.0499)  time: 0.4991  data: 0.0004  max mem: 40080
Epoch: [141]  [ 400/1251]  eta: 0:07:11  lr: 0.002417  min_lr: 0.002417  loss: 3.3843 (3.2597)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0548 (1.0517)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [141]  [ 600/1251]  eta: 0:05:28  lr: 0.002413  min_lr: 0.002413  loss: 2.9582 (3.2332)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1778 (1.0893)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [141]  [ 800/1251]  eta: 0:03:46  lr: 0.002409  min_lr: 0.002409  loss: 3.1445 (3.2223)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7932 (1.0984)  time: 0.5038  data: 0.0004  max mem: 40080
Epoch: [141]  [1000/1251]  eta: 0:02:05  lr: 0.002406  min_lr: 0.002406  loss: 3.4645 (3.2262)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8590 (1.1313)  time: 0.4966  data: 0.0005  max mem: 40080
Epoch: [141]  [1200/1251]  eta: 0:00:25  lr: 0.002402  min_lr: 0.002402  loss: 3.4699 (3.2381)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0724 (1.1357)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [141]  [1250/1251]  eta: 0:00:00  lr: 0.002402  min_lr: 0.002402  loss: 3.3144 (3.2362)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8840 (1.1278)  time: 0.4215  data: 0.0005  max mem: 40080
Epoch: [141] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.002402  min_lr: 0.002402  loss: 3.3144 (3.2456)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8840 (1.1278)
Test:  [ 0/25]  eta: 0:02:21  loss: 0.6974 (0.6974)  acc1: 87.6000 (87.6000)  acc5: 97.6000 (97.6000)  time: 5.6406  data: 5.3501  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7948 (0.8299)  acc1: 83.6000 (83.9273)  acc5: 97.6000 (97.3455)  time: 0.7506  data: 0.4866  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0451 (0.9734)  acc1: 78.8000 (80.7238)  acc5: 95.2000 (95.6571)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0451 (0.9892)  acc1: 78.4000 (80.2880)  acc5: 94.4000 (95.4720)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4805 s / it)
* Acc@1 80.532 Acc@5 95.552 loss 0.986
Accuracy of the model on the 50000 test images: 80.5%
Max accuracy: 80.53%
Epoch: [142]  [   0/1251]  eta: 0:57:37  lr: 0.002402  min_lr: 0.002402  loss: 3.3437 (3.3437)  weight_decay: 0.0500 (0.0500)  time: 2.7638  data: 2.2638  max mem: 40080
Epoch: [142]  [ 200/1251]  eta: 0:08:56  lr: 0.002398  min_lr: 0.002398  loss: 3.4837 (3.3123)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8374 (0.8857)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [142]  [ 400/1251]  eta: 0:07:08  lr: 0.002395  min_lr: 0.002395  loss: 3.4256 (3.3142)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7883 (0.9103)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [142]  [ 600/1251]  eta: 0:05:26  lr: 0.002391  min_lr: 0.002391  loss: 3.3761 (3.2923)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8217 (1.0089)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [142]  [ 800/1251]  eta: 0:03:45  lr: 0.002387  min_lr: 0.002387  loss: 3.3040 (3.2786)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9633 (1.0162)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [142]  [1000/1251]  eta: 0:02:05  lr: 0.002384  min_lr: 0.002384  loss: 3.3646 (3.2603)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7456 (1.0178)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [142]  [1200/1251]  eta: 0:00:25  lr: 0.002380  min_lr: 0.002380  loss: 3.3193 (3.2561)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6438 (1.0400)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [142]  [1250/1251]  eta: 0:00:00  lr: 0.002380  min_lr: 0.002380  loss: 3.1767 (3.2545)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4037 (1.0621)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [142] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.002380  min_lr: 0.002380  loss: 3.1767 (3.2440)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4037 (1.0621)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6774 (0.6774)  acc1: 87.6000 (87.6000)  acc5: 98.8000 (98.8000)  time: 5.5085  data: 5.1803  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8423 (0.8453)  acc1: 84.0000 (82.9455)  acc5: 97.6000 (97.3455)  time: 0.7386  data: 0.4712  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0221 (0.9932)  acc1: 78.8000 (80.2095)  acc5: 94.8000 (95.5048)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0752 (1.0067)  acc1: 77.6000 (79.8080)  acc5: 94.8000 (95.3120)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4769 s / it)
* Acc@1 80.326 Acc@5 95.536 loss 0.990
Accuracy of the model on the 50000 test images: 80.3%
Max accuracy: 80.53%
Epoch: [143]  [   0/1251]  eta: 1:11:11  lr: 0.002380  min_lr: 0.002380  loss: 3.0107 (3.0107)  weight_decay: 0.0500 (0.0500)  time: 3.4147  data: 2.5298  max mem: 40080
Epoch: [143]  [ 200/1251]  eta: 0:09:00  lr: 0.002376  min_lr: 0.002376  loss: 3.4101 (3.3308)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0352 (1.3026)  time: 0.4985  data: 0.0005  max mem: 40080
Epoch: [143]  [ 400/1251]  eta: 0:07:10  lr: 0.002373  min_lr: 0.002373  loss: 3.1875 (3.2673)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9610 (1.1425)  time: 0.4994  data: 0.0005  max mem: 40080
Epoch: [143]  [ 600/1251]  eta: 0:05:27  lr: 0.002369  min_lr: 0.002369  loss: 3.3163 (3.2562)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8813 (1.1179)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [143]  [ 800/1251]  eta: 0:03:46  lr: 0.002365  min_lr: 0.002365  loss: 3.1486 (3.2457)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9985 (1.1280)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [143]  [1000/1251]  eta: 0:02:05  lr: 0.002362  min_lr: 0.002362  loss: 3.5624 (3.2471)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9490 (1.1445)  time: 0.4987  data: 0.0005  max mem: 40080
Epoch: [143]  [1200/1251]  eta: 0:00:25  lr: 0.002358  min_lr: 0.002358  loss: 3.4087 (3.2344)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8714 (1.1404)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [143]  [1250/1251]  eta: 0:00:00  lr: 0.002358  min_lr: 0.002358  loss: 3.3100 (3.2321)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8862 (1.1373)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [143] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.002358  min_lr: 0.002358  loss: 3.3100 (3.2350)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8862 (1.1373)
Test:  [ 0/25]  eta: 0:01:46  loss: 0.6420 (0.6420)  acc1: 86.4000 (86.4000)  acc5: 98.4000 (98.4000)  time: 4.2485  data: 3.9103  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7863 (0.8139)  acc1: 84.0000 (83.0909)  acc5: 97.6000 (97.3091)  time: 0.6726  data: 0.4045  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9933 (0.9567)  acc1: 78.4000 (80.1333)  acc5: 95.2000 (95.6191)  time: 0.2879  data: 0.0270  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0020 (0.9730)  acc1: 77.6000 (79.7760)  acc5: 94.0000 (95.4720)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4455 s / it)
* Acc@1 80.584 Acc@5 95.608 loss 0.957
Accuracy of the model on the 50000 test images: 80.6%
Max accuracy: 80.58%
Epoch: [144]  [   0/1251]  eta: 0:50:09  lr: 0.002358  min_lr: 0.002358  loss: 3.6987 (3.6987)  weight_decay: 0.0500 (0.0500)  time: 2.4060  data: 1.9037  max mem: 40080
Epoch: [144]  [ 200/1251]  eta: 0:08:53  lr: 0.002354  min_lr: 0.002354  loss: 3.2066 (3.1965)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0937 (1.2314)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [144]  [ 400/1251]  eta: 0:07:07  lr: 0.002350  min_lr: 0.002350  loss: 3.4122 (3.2183)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8823 (1.1397)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [144]  [ 600/1251]  eta: 0:05:26  lr: 0.002347  min_lr: 0.002347  loss: 3.0084 (3.2073)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9365 (1.0908)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [144]  [ 800/1251]  eta: 0:03:45  lr: 0.002343  min_lr: 0.002343  loss: 3.2398 (3.2136)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0935 (1.1453)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [144]  [1000/1251]  eta: 0:02:05  lr: 0.002340  min_lr: 0.002340  loss: 3.2852 (3.2244)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0835 (1.1305)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [144]  [1200/1251]  eta: 0:00:25  lr: 0.002336  min_lr: 0.002336  loss: 3.3104 (3.2170)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1579 (1.1390)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [144]  [1250/1251]  eta: 0:00:00  lr: 0.002335  min_lr: 0.002335  loss: 3.2039 (3.2175)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7361 (1.1251)  time: 0.4210  data: 0.0006  max mem: 40080
Epoch: [144] Total time: 0:10:23 (0.4985 s / it)
Averaged stats: lr: 0.002335  min_lr: 0.002335  loss: 3.2039 (3.2291)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7361 (1.1251)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.5752 (0.5752)  acc1: 89.2000 (89.2000)  acc5: 98.0000 (98.0000)  time: 5.4197  data: 5.0887  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8100 (0.7905)  acc1: 82.4000 (83.2727)  acc5: 97.6000 (97.0546)  time: 0.7305  data: 0.4629  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0281 (0.9399)  acc1: 78.8000 (80.1905)  acc5: 94.8000 (95.4667)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0329 (0.9526)  acc1: 78.0000 (79.7920)  acc5: 94.8000 (95.3440)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4722 s / it)
* Acc@1 80.554 Acc@5 95.582 loss 0.940
Accuracy of the model on the 50000 test images: 80.6%
Max accuracy: 80.58%
Epoch: [145]  [   0/1251]  eta: 1:15:15  lr: 0.002335  min_lr: 0.002335  loss: 3.1942 (3.1942)  weight_decay: 0.0500 (0.0500)  time: 3.6096  data: 2.7219  max mem: 40080
Epoch: [145]  [ 200/1251]  eta: 0:08:59  lr: 0.002332  min_lr: 0.002332  loss: 3.1707 (3.1682)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8421 (1.1440)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [145]  [ 400/1251]  eta: 0:07:10  lr: 0.002328  min_lr: 0.002328  loss: 3.1059 (3.1957)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8631 (1.1227)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [145]  [ 600/1251]  eta: 0:05:27  lr: 0.002325  min_lr: 0.002325  loss: 3.3897 (3.2130)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8608 (1.1240)  time: 0.4954  data: 0.0004  max mem: 40080
Epoch: [145]  [ 800/1251]  eta: 0:03:45  lr: 0.002321  min_lr: 0.002321  loss: 3.2454 (3.2155)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9995 (1.1131)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [145]  [1000/1251]  eta: 0:02:05  lr: 0.002318  min_lr: 0.002318  loss: 3.2338 (3.2215)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7167 (1.1218)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [145]  [1200/1251]  eta: 0:00:25  lr: 0.002314  min_lr: 0.002314  loss: 3.3132 (3.2215)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8257 (1.1112)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [145]  [1250/1251]  eta: 0:00:00  lr: 0.002313  min_lr: 0.002313  loss: 3.3576 (3.2236)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9129 (1.1083)  time: 0.4207  data: 0.0005  max mem: 40080
Epoch: [145] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.002313  min_lr: 0.002313  loss: 3.3576 (3.2195)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9129 (1.1083)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6310 (0.6310)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 5.4883  data: 5.1795  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8801 (0.8514)  acc1: 82.8000 (83.3818)  acc5: 97.6000 (97.2364)  time: 0.7367  data: 0.4712  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0163 (0.9925)  acc1: 78.8000 (80.3429)  acc5: 95.2000 (95.6381)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0862 (1.0070)  acc1: 78.0000 (79.9680)  acc5: 94.8000 (95.4880)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4737 s / it)
* Acc@1 80.474 Acc@5 95.634 loss 0.985
Accuracy of the model on the 50000 test images: 80.5%
Max accuracy: 80.58%
Epoch: [146]  [   0/1251]  eta: 1:14:44  lr: 0.002313  min_lr: 0.002313  loss: 2.6948 (2.6948)  weight_decay: 0.0500 (0.0500)  time: 3.5850  data: 1.7413  max mem: 40080
Epoch: [146]  [ 200/1251]  eta: 0:09:01  lr: 0.002310  min_lr: 0.002310  loss: 3.0652 (3.1625)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9632 (1.5247)  time: 0.4969  data: 0.0005  max mem: 40080
Epoch: [146]  [ 400/1251]  eta: 0:07:10  lr: 0.002306  min_lr: 0.002306  loss: 3.4444 (3.1882)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7261 (1.2190)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [146]  [ 600/1251]  eta: 0:05:27  lr: 0.002303  min_lr: 0.002303  loss: 3.2045 (3.1787)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9669 (1.1561)  time: 0.5015  data: 0.0005  max mem: 40080
Epoch: [146]  [ 800/1251]  eta: 0:03:46  lr: 0.002299  min_lr: 0.002299  loss: 3.2335 (3.1845)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6767 (1.1662)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [146]  [1000/1251]  eta: 0:02:05  lr: 0.002296  min_lr: 0.002296  loss: 2.9475 (3.1920)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1906 (1.1699)  time: 0.4965  data: 0.0005  max mem: 40080
Epoch: [146]  [1200/1251]  eta: 0:00:25  lr: 0.002292  min_lr: 0.002292  loss: 3.3199 (3.1972)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7312 (1.1400)  time: 0.4969  data: 0.0005  max mem: 40080
Epoch: [146]  [1250/1251]  eta: 0:00:00  lr: 0.002291  min_lr: 0.002291  loss: 3.2158 (3.1971)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6531 (1.1258)  time: 0.4209  data: 0.0006  max mem: 40080
Epoch: [146] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.002291  min_lr: 0.002291  loss: 3.2158 (3.2241)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6531 (1.1258)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6188 (0.6188)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 5.5450  data: 5.2411  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8592 (0.8148)  acc1: 82.4000 (82.9455)  acc5: 97.6000 (97.0182)  time: 0.7420  data: 0.4768  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9916 (0.9497)  acc1: 77.2000 (80.0762)  acc5: 95.2000 (95.4095)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0192 (0.9654)  acc1: 77.2000 (79.6640)  acc5: 94.8000 (95.3600)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4760 s / it)
* Acc@1 80.456 Acc@5 95.628 loss 0.946
Accuracy of the model on the 50000 test images: 80.5%
Max accuracy: 80.58%
Epoch: [147]  [   0/1251]  eta: 1:11:00  lr: 0.002291  min_lr: 0.002291  loss: 3.5334 (3.5334)  weight_decay: 0.0500 (0.0500)  time: 3.4057  data: 2.7156  max mem: 40080
Epoch: [147]  [ 200/1251]  eta: 0:08:59  lr: 0.002288  min_lr: 0.002288  loss: 3.3705 (3.2220)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8518 (1.0313)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [147]  [ 400/1251]  eta: 0:07:09  lr: 0.002284  min_lr: 0.002284  loss: 3.1601 (3.2176)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9790 (1.1466)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [147]  [ 600/1251]  eta: 0:05:27  lr: 0.002280  min_lr: 0.002280  loss: 3.3489 (3.2107)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2642 (1.2052)  time: 0.5060  data: 0.0004  max mem: 40080
Epoch: [147]  [ 800/1251]  eta: 0:03:46  lr: 0.002277  min_lr: 0.002277  loss: 3.2763 (3.2046)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9433 (1.1886)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [147]  [1000/1251]  eta: 0:02:05  lr: 0.002273  min_lr: 0.002273  loss: 3.4973 (3.2106)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8017 (1.1903)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [147]  [1200/1251]  eta: 0:00:25  lr: 0.002270  min_lr: 0.002270  loss: 3.5137 (3.2157)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8268 (1.1467)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [147]  [1250/1251]  eta: 0:00:00  lr: 0.002269  min_lr: 0.002269  loss: 3.2743 (3.2180)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9002 (1.1466)  time: 0.4215  data: 0.0008  max mem: 40080
Epoch: [147] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.002269  min_lr: 0.002269  loss: 3.2743 (3.2270)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9002 (1.1466)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.7002 (0.7002)  acc1: 88.4000 (88.4000)  acc5: 97.6000 (97.6000)  time: 5.2110  data: 4.8809  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8856 (0.8645)  acc1: 83.6000 (83.0182)  acc5: 97.2000 (97.4545)  time: 0.7115  data: 0.4440  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0446 (1.0036)  acc1: 77.6000 (79.9048)  acc5: 96.4000 (95.9810)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1079 (1.0211)  acc1: 77.6000 (79.3600)  acc5: 94.8000 (95.7760)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4640 s / it)
* Acc@1 80.596 Acc@5 95.658 loss 1.001
Accuracy of the model on the 50000 test images: 80.6%
Max accuracy: 80.60%
Epoch: [148]  [   0/1251]  eta: 0:57:38  lr: 0.002269  min_lr: 0.002269  loss: 3.7079 (3.7079)  weight_decay: 0.0500 (0.0500)  time: 2.7643  data: 2.2520  max mem: 40080
Epoch: [148]  [ 200/1251]  eta: 0:08:56  lr: 0.002265  min_lr: 0.002265  loss: 3.4349 (3.2042)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9912 (1.2141)  time: 0.4988  data: 0.0004  max mem: 40080
Epoch: [148]  [ 400/1251]  eta: 0:07:08  lr: 0.002262  min_lr: 0.002262  loss: 3.2935 (3.1967)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9753 (1.2266)  time: 0.4994  data: 0.0004  max mem: 40080
Epoch: [148]  [ 600/1251]  eta: 0:05:26  lr: 0.002258  min_lr: 0.002258  loss: 2.9944 (3.2031)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7800 (1.1860)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [148]  [ 800/1251]  eta: 0:03:46  lr: 0.002255  min_lr: 0.002255  loss: 3.2777 (3.2008)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0963 (1.2175)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [148]  [1000/1251]  eta: 0:02:05  lr: 0.002251  min_lr: 0.002251  loss: 3.3736 (3.2061)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7694 (1.1933)  time: 0.5071  data: 0.0005  max mem: 40080
Epoch: [148]  [1200/1251]  eta: 0:00:25  lr: 0.002248  min_lr: 0.002248  loss: 3.3553 (3.2120)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8322 (1.1865)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [148]  [1250/1251]  eta: 0:00:00  lr: 0.002247  min_lr: 0.002247  loss: 3.2157 (3.2105)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8260 (1.1800)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [148] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.002247  min_lr: 0.002247  loss: 3.2157 (3.2185)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8260 (1.1800)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.7032 (0.7032)  acc1: 87.2000 (87.2000)  acc5: 98.8000 (98.8000)  time: 5.3405  data: 5.0117  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8644 (0.8370)  acc1: 82.8000 (83.6000)  acc5: 96.8000 (97.2727)  time: 0.7233  data: 0.4559  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0145 (0.9774)  acc1: 80.0000 (80.6286)  acc5: 95.6000 (95.8095)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1127 (0.9925)  acc1: 77.6000 (80.1280)  acc5: 94.8000 (95.6640)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4675 s / it)
* Acc@1 80.646 Acc@5 95.644 loss 0.980
Accuracy of the model on the 50000 test images: 80.6%
Max accuracy: 80.65%
Epoch: [149]  [   0/1251]  eta: 0:58:57  lr: 0.002247  min_lr: 0.002247  loss: 3.3479 (3.3479)  weight_decay: 0.0500 (0.0500)  time: 2.8275  data: 2.3254  max mem: 40080
Epoch: [149]  [ 200/1251]  eta: 0:08:56  lr: 0.002243  min_lr: 0.002243  loss: 3.3943 (3.2550)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1341 (1.0082)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [149]  [ 400/1251]  eta: 0:07:08  lr: 0.002240  min_lr: 0.002240  loss: 3.4710 (3.2362)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1300 (1.2563)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [149]  [ 600/1251]  eta: 0:05:26  lr: 0.002236  min_lr: 0.002236  loss: 3.4119 (3.2304)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0781 (1.1944)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [149]  [ 800/1251]  eta: 0:03:45  lr: 0.002232  min_lr: 0.002232  loss: 3.4158 (3.2332)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8121 (1.2168)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [149]  [1000/1251]  eta: 0:02:05  lr: 0.002229  min_lr: 0.002229  loss: 3.3966 (3.2356)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3792 (1.2232)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [149]  [1200/1251]  eta: 0:00:25  lr: 0.002225  min_lr: 0.002225  loss: 3.2532 (3.2255)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8023 (1.1851)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [149]  [1250/1251]  eta: 0:00:00  lr: 0.002224  min_lr: 0.002224  loss: 3.0192 (3.2188)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9522 (1.1760)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [149] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.002224  min_lr: 0.002224  loss: 3.0192 (3.2195)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9522 (1.1760)
Test:  [ 0/25]  eta: 0:02:21  loss: 0.6485 (0.6485)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 5.6671  data: 5.3655  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8298 (0.8002)  acc1: 85.2000 (83.9273)  acc5: 97.2000 (97.3091)  time: 0.7529  data: 0.4881  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9616 (0.9283)  acc1: 78.8000 (80.7048)  acc5: 95.2000 (95.7524)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9933 (0.9419)  acc1: 78.8000 (80.3520)  acc5: 95.2000 (95.6480)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4809 s / it)
* Acc@1 80.904 Acc@5 95.582 loss 0.933
Accuracy of the model on the 50000 test images: 80.9%
Max accuracy: 80.90%
Epoch: [150]  [   0/1251]  eta: 0:57:42  lr: 0.002224  min_lr: 0.002224  loss: 3.9145 (3.9145)  weight_decay: 0.0500 (0.0500)  time: 2.7676  data: 2.2522  max mem: 40080
Epoch: [150]  [ 200/1251]  eta: 0:08:57  lr: 0.002221  min_lr: 0.002221  loss: 3.1544 (3.2075)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8330 (1.0873)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [150]  [ 400/1251]  eta: 0:07:08  lr: 0.002217  min_lr: 0.002217  loss: 3.0410 (3.1908)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8849 (1.1724)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [150]  [ 600/1251]  eta: 0:05:26  lr: 0.002214  min_lr: 0.002214  loss: 3.2161 (3.1943)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7955 (1.0970)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [150]  [ 800/1251]  eta: 0:03:45  lr: 0.002210  min_lr: 0.002210  loss: 3.4098 (3.2004)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7672 (1.1202)  time: 0.4981  data: 0.0005  max mem: 40080
Epoch: [150]  [1000/1251]  eta: 0:02:05  lr: 0.002207  min_lr: 0.002207  loss: 3.3597 (3.1793)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3998 (1.1651)  time: 0.4993  data: 0.0005  max mem: 40080
Epoch: [150]  [1200/1251]  eta: 0:00:25  lr: 0.002203  min_lr: 0.002203  loss: 3.3618 (3.1896)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2166 (1.1739)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [150]  [1250/1251]  eta: 0:00:00  lr: 0.002202  min_lr: 0.002202  loss: 3.4080 (3.1886)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0802 (1.1759)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [150] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.002202  min_lr: 0.002202  loss: 3.4080 (3.2134)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0802 (1.1759)
Test:  [ 0/25]  eta: 0:02:22  loss: 0.6356 (0.6356)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 5.6846  data: 5.3822  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8026 (0.8016)  acc1: 85.2000 (84.0000)  acc5: 97.2000 (97.1636)  time: 0.7544  data: 0.4895  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9841 (0.9380)  acc1: 78.0000 (80.8191)  acc5: 95.6000 (95.7333)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9914 (0.9509)  acc1: 78.0000 (80.4160)  acc5: 95.2000 (95.6640)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4826 s / it)
* Acc@1 80.592 Acc@5 95.690 loss 0.952
Accuracy of the model on the 50000 test images: 80.6%
Max accuracy: 80.90%
Epoch: [151]  [   0/1251]  eta: 1:09:21  lr: 0.002202  min_lr: 0.002202  loss: 3.3012 (3.3012)  weight_decay: 0.0500 (0.0500)  time: 3.3269  data: 2.6546  max mem: 40080
Epoch: [151]  [ 200/1251]  eta: 0:09:01  lr: 0.002198  min_lr: 0.002198  loss: 3.3195 (3.1748)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0646 (1.1359)  time: 0.4986  data: 0.0005  max mem: 40080
Epoch: [151]  [ 400/1251]  eta: 0:07:10  lr: 0.002195  min_lr: 0.002195  loss: 3.1382 (3.1773)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9671 (1.1441)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [151]  [ 600/1251]  eta: 0:05:28  lr: 0.002191  min_lr: 0.002191  loss: 3.4174 (3.1961)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0419 (nan)  time: 0.5088  data: 0.0005  max mem: 40080
Epoch: [151]  [ 800/1251]  eta: 0:03:46  lr: 0.002188  min_lr: 0.002188  loss: 3.2297 (3.1968)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7560 (nan)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [151]  [1000/1251]  eta: 0:02:05  lr: 0.002184  min_lr: 0.002184  loss: 3.4323 (3.2046)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9617 (nan)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [151]  [1200/1251]  eta: 0:00:25  lr: 0.002181  min_lr: 0.002181  loss: 3.4498 (3.2073)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9829 (nan)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [151]  [1250/1251]  eta: 0:00:00  lr: 0.002180  min_lr: 0.002180  loss: 3.2518 (3.2096)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7412 (nan)  time: 0.4214  data: 0.0007  max mem: 40080
Epoch: [151] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.002180  min_lr: 0.002180  loss: 3.2518 (3.2057)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7412 (nan)
Test:  [ 0/25]  eta: 0:02:23  loss: 0.6243 (0.6243)  acc1: 89.6000 (89.6000)  acc5: 98.4000 (98.4000)  time: 5.7407  data: 5.4240  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8056 (0.8064)  acc1: 84.4000 (83.6364)  acc5: 97.6000 (96.8727)  time: 0.7595  data: 0.4934  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0121 (0.9417)  acc1: 77.2000 (80.7619)  acc5: 94.8000 (95.6952)  time: 0.2612  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0481 (0.9539)  acc1: 77.2000 (80.2880)  acc5: 94.8000 (95.6160)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4835 s / it)
* Acc@1 80.862 Acc@5 95.686 loss 0.938
Accuracy of the model on the 50000 test images: 80.9%
Max accuracy: 80.90%
Epoch: [152]  [   0/1251]  eta: 1:14:29  lr: 0.002180  min_lr: 0.002180  loss: 3.5280 (3.5280)  weight_decay: 0.0500 (0.0500)  time: 3.5727  data: 2.7723  max mem: 40080
Epoch: [152]  [ 200/1251]  eta: 0:08:58  lr: 0.002176  min_lr: 0.002176  loss: 3.3892 (3.2282)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9882 (1.0846)  time: 0.4972  data: 0.0005  max mem: 40080
Epoch: [152]  [ 400/1251]  eta: 0:07:10  lr: 0.002173  min_lr: 0.002173  loss: 3.3386 (3.2500)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [152]  [ 600/1251]  eta: 0:05:27  lr: 0.002169  min_lr: 0.002169  loss: 3.4278 (3.2412)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1333 (nan)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [152]  [ 800/1251]  eta: 0:03:46  lr: 0.002165  min_lr: 0.002165  loss: 3.2027 (3.2435)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1314 (nan)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [152]  [1000/1251]  eta: 0:02:05  lr: 0.002162  min_lr: 0.002162  loss: 3.2395 (3.2278)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6683 (nan)  time: 0.4972  data: 0.0005  max mem: 40080
Epoch: [152]  [1200/1251]  eta: 0:00:25  lr: 0.002158  min_lr: 0.002158  loss: 3.0612 (3.2170)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0436 (nan)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [152]  [1250/1251]  eta: 0:00:00  lr: 0.002157  min_lr: 0.002157  loss: 3.2076 (3.2165)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1394 (nan)  time: 0.4216  data: 0.0006  max mem: 40080
Epoch: [152] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.002157  min_lr: 0.002157  loss: 3.2076 (3.2009)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1394 (nan)
Test:  [ 0/25]  eta: 0:02:23  loss: 0.6969 (0.6969)  acc1: 86.4000 (86.4000)  acc5: 98.0000 (98.0000)  time: 5.7461  data: 5.4277  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7637 (0.7995)  acc1: 83.6000 (83.2364)  acc5: 97.6000 (97.2727)  time: 0.7602  data: 0.4937  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9342 (0.9268)  acc1: 78.4000 (80.6857)  acc5: 95.2000 (95.8286)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0048 (0.9395)  acc1: 77.6000 (80.0960)  acc5: 94.8000 (95.6960)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4850 s / it)
* Acc@1 80.924 Acc@5 95.776 loss 0.927
Accuracy of the model on the 50000 test images: 80.9%
Max accuracy: 80.92%
Epoch: [153]  [   0/1251]  eta: 0:58:48  lr: 0.002157  min_lr: 0.002157  loss: 2.6640 (2.6640)  weight_decay: 0.0500 (0.0500)  time: 2.8208  data: 2.3014  max mem: 40080
Epoch: [153]  [ 200/1251]  eta: 0:08:56  lr: 0.002154  min_lr: 0.002154  loss: 3.2803 (3.2622)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1593 (1.0587)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [153]  [ 400/1251]  eta: 0:07:09  lr: 0.002150  min_lr: 0.002150  loss: 3.3633 (3.2335)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1365 (1.1190)  time: 0.4983  data: 0.0003  max mem: 40080
Epoch: [153]  [ 600/1251]  eta: 0:05:27  lr: 0.002147  min_lr: 0.002147  loss: 3.0188 (3.2031)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9585 (1.1691)  time: 0.5035  data: 0.0004  max mem: 40080
Epoch: [153]  [ 800/1251]  eta: 0:03:46  lr: 0.002143  min_lr: 0.002143  loss: 3.2454 (3.2046)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0286 (1.1254)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [153]  [1000/1251]  eta: 0:02:05  lr: 0.002139  min_lr: 0.002139  loss: 3.2026 (3.2014)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0690 (1.1374)  time: 0.4964  data: 0.0003  max mem: 40080
Epoch: [153]  [1200/1251]  eta: 0:00:25  lr: 0.002136  min_lr: 0.002136  loss: 3.3513 (3.2042)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9015 (1.1530)  time: 0.4963  data: 0.0003  max mem: 40080
Epoch: [153]  [1250/1251]  eta: 0:00:00  lr: 0.002135  min_lr: 0.002135  loss: 3.1425 (3.2043)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0553 (1.1633)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [153] Total time: 0:10:25 (0.4997 s / it)
Averaged stats: lr: 0.002135  min_lr: 0.002135  loss: 3.1425 (3.2029)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0553 (1.1633)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.6268 (0.6268)  acc1: 86.8000 (86.8000)  acc5: 98.8000 (98.8000)  time: 5.5827  data: 5.2808  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7828 (0.7851)  acc1: 84.8000 (83.7091)  acc5: 97.2000 (97.1636)  time: 0.7453  data: 0.4804  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9727 (0.9140)  acc1: 78.8000 (80.8762)  acc5: 95.6000 (95.8476)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9912 (0.9246)  acc1: 78.8000 (80.5280)  acc5: 95.2000 (95.6800)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4772 s / it)
* Acc@1 80.848 Acc@5 95.778 loss 0.911
Accuracy of the model on the 50000 test images: 80.8%
Max accuracy: 80.92%
Epoch: [154]  [   0/1251]  eta: 1:09:30  lr: 0.002135  min_lr: 0.002135  loss: 2.6936 (2.6936)  weight_decay: 0.0500 (0.0500)  time: 3.3340  data: 2.3615  max mem: 40080
Epoch: [154]  [ 200/1251]  eta: 0:08:59  lr: 0.002131  min_lr: 0.002131  loss: 3.3181 (3.1475)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8975 (0.9664)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [154]  [ 400/1251]  eta: 0:07:10  lr: 0.002128  min_lr: 0.002128  loss: 2.9931 (3.1348)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0419 (1.0833)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [154]  [ 600/1251]  eta: 0:05:27  lr: 0.002124  min_lr: 0.002124  loss: 3.5057 (3.1530)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0833 (1.0587)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [154]  [ 800/1251]  eta: 0:03:46  lr: 0.002121  min_lr: 0.002121  loss: 3.4407 (3.1555)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0622 (1.1119)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [154]  [1000/1251]  eta: 0:02:05  lr: 0.002117  min_lr: 0.002117  loss: 3.3541 (3.1626)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9916 (1.1101)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [154]  [1200/1251]  eta: 0:00:25  lr: 0.002113  min_lr: 0.002113  loss: 3.2386 (3.1767)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9016 (1.1077)  time: 0.4963  data: 0.0005  max mem: 40080
Epoch: [154]  [1250/1251]  eta: 0:00:00  lr: 0.002113  min_lr: 0.002113  loss: 3.0631 (3.1759)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8365 (1.1047)  time: 0.4213  data: 0.0005  max mem: 40080
Epoch: [154] Total time: 0:10:25 (0.4996 s / it)
Averaged stats: lr: 0.002113  min_lr: 0.002113  loss: 3.0631 (3.1866)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8365 (1.1047)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.6537 (0.6537)  acc1: 87.6000 (87.6000)  acc5: 98.4000 (98.4000)  time: 5.4123  data: 5.1085  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8280 (0.8116)  acc1: 84.4000 (83.7455)  acc5: 97.6000 (97.8182)  time: 0.7297  data: 0.4647  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9616 (0.9459)  acc1: 79.6000 (80.9333)  acc5: 96.4000 (96.0952)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0236 (0.9549)  acc1: 79.2000 (80.7840)  acc5: 94.8000 (95.9200)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4704 s / it)
* Acc@1 80.900 Acc@5 95.826 loss 0.954
Accuracy of the model on the 50000 test images: 80.9%
Max accuracy: 80.92%
Epoch: [155]  [   0/1251]  eta: 1:08:48  lr: 0.002113  min_lr: 0.002113  loss: 2.0087 (2.0087)  weight_decay: 0.0500 (0.0500)  time: 3.3006  data: 2.5445  max mem: 40080
Epoch: [155]  [ 200/1251]  eta: 0:09:01  lr: 0.002109  min_lr: 0.002109  loss: 3.0568 (3.1104)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9910 (1.2141)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [155]  [ 400/1251]  eta: 0:07:11  lr: 0.002105  min_lr: 0.002105  loss: 3.1296 (3.1379)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0582 (1.1894)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [155]  [ 600/1251]  eta: 0:05:28  lr: 0.002102  min_lr: 0.002102  loss: 3.2151 (3.1536)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9427 (1.2033)  time: 0.4990  data: 0.0004  max mem: 40080
Epoch: [155]  [ 800/1251]  eta: 0:03:46  lr: 0.002098  min_lr: 0.002098  loss: 3.3369 (3.1730)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2075 (1.2149)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [155]  [1000/1251]  eta: 0:02:05  lr: 0.002095  min_lr: 0.002095  loss: 3.3874 (3.1723)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6998 (1.1884)  time: 0.5013  data: 0.0004  max mem: 40080
Epoch: [155]  [1200/1251]  eta: 0:00:25  lr: 0.002091  min_lr: 0.002091  loss: 3.5473 (3.1820)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9809 (1.1530)  time: 0.4996  data: 0.0005  max mem: 40080
Epoch: [155]  [1250/1251]  eta: 0:00:00  lr: 0.002090  min_lr: 0.002090  loss: 3.1459 (3.1787)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9645 (1.1468)  time: 0.4217  data: 0.0006  max mem: 40080
Epoch: [155] Total time: 0:10:26 (0.5006 s / it)
Averaged stats: lr: 0.002090  min_lr: 0.002090  loss: 3.1459 (3.1902)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9645 (1.1468)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.6437 (0.6437)  acc1: 88.0000 (88.0000)  acc5: 98.0000 (98.0000)  time: 5.6028  data: 5.3004  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8565 (0.8186)  acc1: 84.4000 (83.6000)  acc5: 97.2000 (97.1636)  time: 0.7472  data: 0.4822  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9846 (0.9602)  acc1: 77.6000 (80.1905)  acc5: 94.4000 (95.3333)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0420 (0.9732)  acc1: 77.6000 (79.7920)  acc5: 94.4000 (95.2320)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4781 s / it)
* Acc@1 81.016 Acc@5 95.732 loss 0.946
Accuracy of the model on the 50000 test images: 81.0%
Max accuracy: 81.02%
Epoch: [156]  [   0/1251]  eta: 0:50:29  lr: 0.002090  min_lr: 0.002090  loss: 3.2841 (3.2841)  weight_decay: 0.0500 (0.0500)  time: 2.4213  data: 1.9111  max mem: 40080
Epoch: [156]  [ 200/1251]  eta: 0:08:53  lr: 0.002087  min_lr: 0.002087  loss: 3.2895 (3.2168)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9223 (1.2634)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [156]  [ 400/1251]  eta: 0:07:07  lr: 0.002083  min_lr: 0.002083  loss: 3.2520 (3.1981)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9197 (1.1595)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [156]  [ 600/1251]  eta: 0:05:26  lr: 0.002079  min_lr: 0.002079  loss: 3.3396 (3.1886)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8525 (1.1168)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [156]  [ 800/1251]  eta: 0:03:45  lr: 0.002076  min_lr: 0.002076  loss: 3.4642 (3.1790)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2304 (1.1892)  time: 0.4989  data: 0.0004  max mem: 40080
Epoch: [156]  [1000/1251]  eta: 0:02:05  lr: 0.002072  min_lr: 0.002072  loss: 3.3220 (3.1851)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9125 (1.2035)  time: 0.4962  data: 0.0005  max mem: 40080
Epoch: [156]  [1200/1251]  eta: 0:00:25  lr: 0.002069  min_lr: 0.002069  loss: 3.1601 (3.1842)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0506 (1.1795)  time: 0.4986  data: 0.0004  max mem: 40080
Epoch: [156]  [1250/1251]  eta: 0:00:00  lr: 0.002068  min_lr: 0.002068  loss: 2.9080 (3.1829)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3175 (1.1970)  time: 0.4220  data: 0.0005  max mem: 40080
Epoch: [156] Total time: 0:10:24 (0.4990 s / it)
Averaged stats: lr: 0.002068  min_lr: 0.002068  loss: 2.9080 (3.1791)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3175 (1.1970)
Test:  [ 0/25]  eta: 0:02:23  loss: 0.6350 (0.6350)  acc1: 89.2000 (89.2000)  acc5: 98.0000 (98.0000)  time: 5.7369  data: 5.4212  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8215 (0.8065)  acc1: 84.8000 (83.8182)  acc5: 97.6000 (97.2364)  time: 0.7592  data: 0.4931  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9778 (0.9416)  acc1: 79.2000 (80.3619)  acc5: 95.2000 (95.6571)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9984 (0.9514)  acc1: 79.2000 (80.1760)  acc5: 95.2000 (95.5680)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4837 s / it)
* Acc@1 80.820 Acc@5 95.722 loss 0.933
Accuracy of the model on the 50000 test images: 80.8%
Max accuracy: 81.02%
Epoch: [157]  [   0/1251]  eta: 1:09:54  lr: 0.002068  min_lr: 0.002068  loss: 3.8987 (3.8987)  weight_decay: 0.0500 (0.0500)  time: 3.3528  data: 1.6818  max mem: 40080
Epoch: [157]  [ 200/1251]  eta: 0:08:57  lr: 0.002064  min_lr: 0.002064  loss: 3.1208 (3.2166)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0734 (1.0224)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [157]  [ 400/1251]  eta: 0:07:10  lr: 0.002061  min_lr: 0.002061  loss: 3.3880 (3.1978)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9277 (1.0237)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [157]  [ 600/1251]  eta: 0:05:27  lr: 0.002057  min_lr: 0.002057  loss: 3.0580 (3.1963)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1805 (1.0794)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [157]  [ 800/1251]  eta: 0:03:46  lr: 0.002053  min_lr: 0.002053  loss: 3.3211 (3.1967)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2039 (1.0947)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [157]  [1000/1251]  eta: 0:02:05  lr: 0.002050  min_lr: 0.002050  loss: 3.1603 (3.1874)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0378 (1.1136)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [157]  [1200/1251]  eta: 0:00:25  lr: 0.002046  min_lr: 0.002046  loss: 3.3794 (3.1914)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8098 (1.1371)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [157]  [1250/1251]  eta: 0:00:00  lr: 0.002045  min_lr: 0.002045  loss: 3.1595 (3.1924)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7901 (1.1271)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [157] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.002045  min_lr: 0.002045  loss: 3.1595 (3.1805)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7901 (1.1271)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.6976 (0.6976)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 5.5919  data: 5.2928  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8559 (0.8810)  acc1: 84.4000 (83.5636)  acc5: 97.2000 (97.2000)  time: 0.7461  data: 0.4814  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0306 (1.0152)  acc1: 78.0000 (80.5143)  acc5: 95.2000 (95.6191)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0874 (1.0305)  acc1: 78.0000 (80.0160)  acc5: 95.2000 (95.6160)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4780 s / it)
* Acc@1 80.780 Acc@5 95.730 loss 1.016
Accuracy of the model on the 50000 test images: 80.8%
Max accuracy: 81.02%
Epoch: [158]  [   0/1251]  eta: 1:14:11  lr: 0.002045  min_lr: 0.002045  loss: 3.7505 (3.7505)  weight_decay: 0.0500 (0.0500)  time: 3.5585  data: 3.0188  max mem: 40080
Epoch: [158]  [ 200/1251]  eta: 0:09:00  lr: 0.002042  min_lr: 0.002042  loss: 2.8074 (3.1467)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2697 (1.2940)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [158]  [ 400/1251]  eta: 0:07:10  lr: 0.002038  min_lr: 0.002038  loss: 3.5271 (3.1527)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5649 (1.3197)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [158]  [ 600/1251]  eta: 0:05:27  lr: 0.002035  min_lr: 0.002035  loss: 3.0268 (3.1636)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9577 (1.2306)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [158]  [ 800/1251]  eta: 0:03:46  lr: 0.002031  min_lr: 0.002031  loss: 3.2557 (3.1613)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7885 (1.1754)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [158]  [1000/1251]  eta: 0:02:05  lr: 0.002027  min_lr: 0.002027  loss: 3.2566 (3.1660)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8098 (1.1719)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [158]  [1200/1251]  eta: 0:00:25  lr: 0.002024  min_lr: 0.002024  loss: 3.0809 (3.1807)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8410 (1.1575)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [158]  [1250/1251]  eta: 0:00:00  lr: 0.002023  min_lr: 0.002023  loss: 3.1749 (3.1782)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1445 (1.2028)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [158] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.002023  min_lr: 0.002023  loss: 3.1749 (3.1779)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1445 (1.2028)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6823 (0.6823)  acc1: 85.2000 (85.2000)  acc5: 98.8000 (98.8000)  time: 5.5584  data: 5.2510  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7946 (0.8011)  acc1: 85.2000 (84.0000)  acc5: 97.2000 (97.4909)  time: 0.7432  data: 0.4776  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9517 (0.9391)  acc1: 79.6000 (80.5333)  acc5: 95.6000 (95.8095)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0112 (0.9499)  acc1: 79.6000 (80.4320)  acc5: 94.4000 (95.5680)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4760 s / it)
* Acc@1 81.028 Acc@5 95.744 loss 0.933
Accuracy of the model on the 50000 test images: 81.0%
Max accuracy: 81.03%
Epoch: [159]  [   0/1251]  eta: 0:52:24  lr: 0.002023  min_lr: 0.002023  loss: 3.5826 (3.5826)  weight_decay: 0.0500 (0.0500)  time: 2.5133  data: 2.0085  max mem: 40080
Epoch: [159]  [ 200/1251]  eta: 0:08:53  lr: 0.002019  min_lr: 0.002019  loss: 3.1555 (3.1906)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0626 (1.1187)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [159]  [ 400/1251]  eta: 0:07:08  lr: 0.002016  min_lr: 0.002016  loss: 3.0671 (3.2065)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1148 (1.1342)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [159]  [ 600/1251]  eta: 0:05:26  lr: 0.002012  min_lr: 0.002012  loss: 3.0874 (3.1924)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7985 (1.0942)  time: 0.5065  data: 0.0005  max mem: 40080
Epoch: [159]  [ 800/1251]  eta: 0:03:45  lr: 0.002009  min_lr: 0.002009  loss: 3.4364 (3.1967)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9884 (1.1428)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [159]  [1000/1251]  eta: 0:02:05  lr: 0.002005  min_lr: 0.002005  loss: 3.0035 (3.1753)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8048 (1.1137)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [159]  [1200/1251]  eta: 0:00:25  lr: 0.002001  min_lr: 0.002001  loss: 3.3024 (3.1776)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1059 (1.1396)  time: 0.4972  data: 0.0005  max mem: 40080
Epoch: [159]  [1250/1251]  eta: 0:00:00  lr: 0.002001  min_lr: 0.002001  loss: 3.2929 (3.1804)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1098 (1.1401)  time: 0.4211  data: 0.0006  max mem: 40080
Epoch: [159] Total time: 0:10:23 (0.4987 s / it)
Averaged stats: lr: 0.002001  min_lr: 0.002001  loss: 3.2929 (3.1719)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1098 (1.1401)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.6764 (0.6764)  acc1: 89.2000 (89.2000)  acc5: 98.0000 (98.0000)  time: 5.4223  data: 5.1041  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8041 (0.7916)  acc1: 84.8000 (84.6182)  acc5: 97.6000 (97.4546)  time: 0.7307  data: 0.4643  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9816 (0.9218)  acc1: 77.6000 (80.6857)  acc5: 95.6000 (95.9810)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0288 (0.9365)  acc1: 77.6000 (80.2880)  acc5: 95.2000 (95.8560)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4730 s / it)
* Acc@1 81.130 Acc@5 95.866 loss 0.927
Accuracy of the model on the 50000 test images: 81.1%
Max accuracy: 81.13%
Epoch: [160]  [   0/1251]  eta: 0:56:41  lr: 0.002001  min_lr: 0.002001  loss: 3.4547 (3.4547)  weight_decay: 0.0500 (0.0500)  time: 2.7194  data: 2.2062  max mem: 40080
Epoch: [160]  [ 200/1251]  eta: 0:08:54  lr: 0.001997  min_lr: 0.001997  loss: 3.1657 (3.1568)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1705 (1.4610)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [160]  [ 400/1251]  eta: 0:07:08  lr: 0.001993  min_lr: 0.001993  loss: 3.3224 (3.1651)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2192 (1.3913)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [160]  [ 600/1251]  eta: 0:05:26  lr: 0.001990  min_lr: 0.001990  loss: 3.0121 (3.1595)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9242 (1.2389)  time: 0.5045  data: 0.0005  max mem: 40080
Epoch: [160]  [ 800/1251]  eta: 0:03:45  lr: 0.001986  min_lr: 0.001986  loss: 3.3762 (3.1642)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1801 (1.2279)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [160]  [1000/1251]  eta: 0:02:05  lr: 0.001983  min_lr: 0.001983  loss: 3.2580 (3.1593)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0240 (1.2272)  time: 0.5031  data: 0.0005  max mem: 40080
Epoch: [160]  [1200/1251]  eta: 0:00:25  lr: 0.001979  min_lr: 0.001979  loss: 3.0355 (3.1540)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7777 (1.1840)  time: 0.4958  data: 0.0005  max mem: 40080
Epoch: [160]  [1250/1251]  eta: 0:00:00  lr: 0.001978  min_lr: 0.001978  loss: 3.4127 (3.1553)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7808 (1.1712)  time: 0.4208  data: 0.0005  max mem: 40080
Epoch: [160] Total time: 0:10:23 (0.4983 s / it)
Averaged stats: lr: 0.001978  min_lr: 0.001978  loss: 3.4127 (3.1740)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7808 (1.1712)
Test:  [ 0/25]  eta: 0:02:23  loss: 0.6992 (0.6992)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 5.7231  data: 5.4122  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8807 (0.8355)  acc1: 83.6000 (84.2545)  acc5: 97.6000 (97.4545)  time: 0.7582  data: 0.4924  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9936 (0.9683)  acc1: 78.4000 (81.1048)  acc5: 95.6000 (95.9810)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0204 (0.9772)  acc1: 78.4000 (80.6880)  acc5: 95.6000 (96.0320)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4832 s / it)
* Acc@1 80.930 Acc@5 95.888 loss 0.977
Accuracy of the model on the 50000 test images: 80.9%
Max accuracy: 81.13%
Epoch: [161]  [   0/1251]  eta: 1:13:09  lr: 0.001978  min_lr: 0.001978  loss: 2.9077 (2.9077)  weight_decay: 0.0500 (0.0500)  time: 3.5084  data: 2.3961  max mem: 40080
Epoch: [161]  [ 200/1251]  eta: 0:08:59  lr: 0.001974  min_lr: 0.001974  loss: 3.3493 (3.1016)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1275 (1.3225)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [161]  [ 400/1251]  eta: 0:07:10  lr: 0.001971  min_lr: 0.001971  loss: 2.8977 (3.1109)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1569 (1.2510)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [161]  [ 600/1251]  eta: 0:05:27  lr: 0.001967  min_lr: 0.001967  loss: 3.0642 (3.1030)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9936 (1.2000)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [161]  [ 800/1251]  eta: 0:03:46  lr: 0.001964  min_lr: 0.001964  loss: 3.2392 (3.1096)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0813 (1.1859)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [161]  [1000/1251]  eta: 0:02:05  lr: 0.001960  min_lr: 0.001960  loss: 3.1376 (3.1257)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9123 (1.1813)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [161]  [1200/1251]  eta: 0:00:25  lr: 0.001956  min_lr: 0.001956  loss: 3.3810 (3.1331)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8824 (1.1887)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [161]  [1250/1251]  eta: 0:00:00  lr: 0.001956  min_lr: 0.001956  loss: 3.0666 (3.1356)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8824 (1.1867)  time: 0.4211  data: 0.0007  max mem: 40080
Epoch: [161] Total time: 0:10:24 (0.4990 s / it)
Averaged stats: lr: 0.001956  min_lr: 0.001956  loss: 3.0666 (3.1612)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8824 (1.1867)
Test:  [ 0/25]  eta: 0:02:22  loss: 0.6549 (0.6549)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 5.6969  data: 5.3692  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7967 (0.8014)  acc1: 83.6000 (83.6727)  acc5: 98.0000 (97.4546)  time: 0.7557  data: 0.4885  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9561 (0.9297)  acc1: 78.8000 (80.7429)  acc5: 96.0000 (95.9810)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0116 (0.9409)  acc1: 78.4000 (80.3360)  acc5: 95.2000 (95.8720)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4832 s / it)
* Acc@1 81.044 Acc@5 95.806 loss 0.936
Accuracy of the model on the 50000 test images: 81.0%
Max accuracy: 81.13%
Epoch: [162]  [   0/1251]  eta: 1:14:22  lr: 0.001956  min_lr: 0.001956  loss: 2.7083 (2.7083)  weight_decay: 0.0500 (0.0500)  time: 3.5674  data: 2.4253  max mem: 40080
Epoch: [162]  [ 200/1251]  eta: 0:09:00  lr: 0.001952  min_lr: 0.001952  loss: 3.3838 (3.1780)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1145 (1.3475)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [162]  [ 400/1251]  eta: 0:07:10  lr: 0.001948  min_lr: 0.001948  loss: 3.2341 (3.1730)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8562 (1.2547)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [162]  [ 600/1251]  eta: 0:05:27  lr: 0.001945  min_lr: 0.001945  loss: 3.2867 (3.1568)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5903 (1.2726)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [162]  [ 800/1251]  eta: 0:03:46  lr: 0.001941  min_lr: 0.001941  loss: 3.4145 (3.1524)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2931 (1.3037)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [162]  [1000/1251]  eta: 0:02:05  lr: 0.001938  min_lr: 0.001938  loss: 3.3484 (3.1576)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9209 (1.2305)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [162]  [1200/1251]  eta: 0:00:25  lr: 0.001934  min_lr: 0.001934  loss: 3.4404 (3.1655)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2296 (1.2228)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [162]  [1250/1251]  eta: 0:00:00  lr: 0.001933  min_lr: 0.001933  loss: 3.3616 (3.1655)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9998 (1.2227)  time: 0.4211  data: 0.0007  max mem: 40080
Epoch: [162] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.001933  min_lr: 0.001933  loss: 3.3616 (3.1577)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9998 (1.2227)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.6714 (0.6714)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 5.4136  data: 5.1183  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8910 (0.8467)  acc1: 85.2000 (84.0364)  acc5: 97.6000 (97.4909)  time: 0.7299  data: 0.4656  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0179 (0.9746)  acc1: 79.2000 (81.0667)  acc5: 95.2000 (95.8857)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0350 (0.9885)  acc1: 79.2000 (80.6720)  acc5: 95.2000 (95.8080)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4713 s / it)
* Acc@1 81.178 Acc@5 95.780 loss 0.979
Accuracy of the model on the 50000 test images: 81.2%
Max accuracy: 81.18%
Epoch: [163]  [   0/1251]  eta: 1:04:39  lr: 0.001933  min_lr: 0.001933  loss: 3.4114 (3.4114)  weight_decay: 0.0500 (0.0500)  time: 3.1014  data: 2.5843  max mem: 40080
Epoch: [163]  [ 200/1251]  eta: 0:08:59  lr: 0.001930  min_lr: 0.001930  loss: 3.0183 (3.1391)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3191 (1.2598)  time: 0.4988  data: 0.0006  max mem: 40080
Epoch: [163]  [ 400/1251]  eta: 0:07:10  lr: 0.001926  min_lr: 0.001926  loss: 3.3334 (3.1578)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8473 (1.2511)  time: 0.4989  data: 0.0005  max mem: 40080
Epoch: [163]  [ 600/1251]  eta: 0:05:28  lr: 0.001922  min_lr: 0.001922  loss: 3.2902 (3.1719)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4296 (1.3136)  time: 0.5003  data: 0.0005  max mem: 40080
Epoch: [163]  [ 800/1251]  eta: 0:03:46  lr: 0.001919  min_lr: 0.001919  loss: 3.3384 (3.1617)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0440 (1.2525)  time: 0.4966  data: 0.0005  max mem: 40080
Epoch: [163]  [1000/1251]  eta: 0:02:05  lr: 0.001915  min_lr: 0.001915  loss: 3.2544 (3.1580)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8894 (1.2319)  time: 0.4981  data: 0.0005  max mem: 40080
Epoch: [163]  [1200/1251]  eta: 0:00:25  lr: 0.001912  min_lr: 0.001912  loss: 3.0917 (3.1635)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1558 (1.2659)  time: 0.4991  data: 0.0005  max mem: 40080
Epoch: [163]  [1250/1251]  eta: 0:00:00  lr: 0.001911  min_lr: 0.001911  loss: 3.2434 (3.1629)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0073 (1.2578)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [163] Total time: 0:10:26 (0.5004 s / it)
Averaged stats: lr: 0.001911  min_lr: 0.001911  loss: 3.2434 (3.1509)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0073 (1.2578)
Test:  [ 0/25]  eta: 0:02:14  loss: 0.7262 (0.7262)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 5.3742  data: 5.0606  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8831 (0.8688)  acc1: 84.0000 (83.4182)  acc5: 97.2000 (97.5273)  time: 0.7262  data: 0.4603  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0512 (0.9952)  acc1: 78.4000 (80.7238)  acc5: 95.6000 (96.0952)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0843 (1.0061)  acc1: 78.4000 (80.4000)  acc5: 95.6000 (95.9520)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4692 s / it)
* Acc@1 80.986 Acc@5 95.910 loss 0.993
Accuracy of the model on the 50000 test images: 81.0%
Max accuracy: 81.18%
Epoch: [164]  [   0/1251]  eta: 1:08:24  lr: 0.001911  min_lr: 0.001911  loss: 3.3464 (3.3464)  weight_decay: 0.0500 (0.0500)  time: 3.2809  data: 2.7203  max mem: 40080
Epoch: [164]  [ 200/1251]  eta: 0:08:59  lr: 0.001907  min_lr: 0.001907  loss: 3.2184 (3.1493)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8122 (1.3288)  time: 0.4990  data: 0.0005  max mem: 40080
Epoch: [164]  [ 400/1251]  eta: 0:07:11  lr: 0.001904  min_lr: 0.001904  loss: 3.0077 (3.1466)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0316 (1.3160)  time: 0.4979  data: 0.0005  max mem: 40080
Epoch: [164]  [ 600/1251]  eta: 0:05:28  lr: 0.001900  min_lr: 0.001900  loss: 3.1583 (3.1706)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8944 (1.1976)  time: 0.4975  data: 0.0006  max mem: 40080
Epoch: [164]  [ 800/1251]  eta: 0:03:46  lr: 0.001896  min_lr: 0.001896  loss: 3.0403 (3.1683)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1840 (1.1946)  time: 0.5037  data: 0.0005  max mem: 40080
Epoch: [164]  [1000/1251]  eta: 0:02:06  lr: 0.001893  min_lr: 0.001893  loss: 3.0890 (3.1649)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1949 (1.2104)  time: 0.4988  data: 0.0005  max mem: 40080
Epoch: [164]  [1200/1251]  eta: 0:00:25  lr: 0.001889  min_lr: 0.001889  loss: 3.4295 (3.1671)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9803 (1.2284)  time: 0.4988  data: 0.0005  max mem: 40080
Epoch: [164]  [1250/1251]  eta: 0:00:00  lr: 0.001888  min_lr: 0.001888  loss: 3.2719 (3.1725)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8778 (1.2202)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [164] Total time: 0:10:26 (0.5008 s / it)
Averaged stats: lr: 0.001888  min_lr: 0.001888  loss: 3.2719 (3.1569)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8778 (1.2202)
Test:  [ 0/25]  eta: 0:01:53  loss: 0.7276 (0.7276)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 4.5507  data: 4.2501  max mem: 40080
Test:  [10/25]  eta: 0:00:09  loss: 0.8991 (0.8895)  acc1: 84.8000 (84.2545)  acc5: 97.6000 (97.2727)  time: 0.6528  data: 0.3880  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0669 (1.0205)  acc1: 79.6000 (81.3524)  acc5: 95.2000 (95.5429)  time: 0.2621  data: 0.0009  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0854 (1.0337)  acc1: 79.2000 (80.9600)  acc5: 95.2000 (95.5360)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:10 (0.4374 s / it)
* Acc@1 80.900 Acc@5 95.784 loss 1.023
Accuracy of the model on the 50000 test images: 80.9%
Max accuracy: 81.18%
Epoch: [165]  [   0/1251]  eta: 1:08:21  lr: 0.001888  min_lr: 0.001888  loss: 2.6541 (2.6541)  weight_decay: 0.0500 (0.0500)  time: 3.2784  data: 1.6200  max mem: 40080
Epoch: [165]  [ 200/1251]  eta: 0:08:57  lr: 0.001885  min_lr: 0.001885  loss: 3.0244 (3.1524)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4962  data: 0.0005  max mem: 40080
Epoch: [165]  [ 400/1251]  eta: 0:07:09  lr: 0.001881  min_lr: 0.001881  loss: 3.3909 (3.1608)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4906 (nan)  time: 0.4981  data: 0.0005  max mem: 40080
Epoch: [165]  [ 600/1251]  eta: 0:05:27  lr: 0.001878  min_lr: 0.001878  loss: 3.2223 (3.1660)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0642 (nan)  time: 0.5051  data: 0.0005  max mem: 40080
Epoch: [165]  [ 800/1251]  eta: 0:03:46  lr: 0.001874  min_lr: 0.001874  loss: 3.1791 (3.1658)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [165]  [1000/1251]  eta: 0:02:05  lr: 0.001870  min_lr: 0.001870  loss: 3.0789 (3.1637)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1363 (nan)  time: 0.4990  data: 0.0004  max mem: 40080
Epoch: [165]  [1200/1251]  eta: 0:00:25  lr: 0.001867  min_lr: 0.001867  loss: 3.2902 (3.1750)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9899 (nan)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [165]  [1250/1251]  eta: 0:00:00  lr: 0.001866  min_lr: 0.001866  loss: 3.2300 (3.1745)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9599 (nan)  time: 0.4215  data: 0.0005  max mem: 40080
Epoch: [165] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.001866  min_lr: 0.001866  loss: 3.2300 (3.1549)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9599 (nan)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6802 (0.6802)  acc1: 87.6000 (87.6000)  acc5: 98.4000 (98.4000)  time: 5.4908  data: 5.2009  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8259 (0.8122)  acc1: 84.4000 (84.2182)  acc5: 97.6000 (97.3455)  time: 0.7370  data: 0.4731  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9819 (0.9295)  acc1: 79.2000 (81.3905)  acc5: 95.6000 (95.6191)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0084 (0.9408)  acc1: 78.8000 (80.9920)  acc5: 95.2000 (95.5840)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4743 s / it)
* Acc@1 81.424 Acc@5 95.886 loss 0.934
Accuracy of the model on the 50000 test images: 81.4%
Max accuracy: 81.42%
Epoch: [166]  [   0/1251]  eta: 0:58:14  lr: 0.001866  min_lr: 0.001866  loss: 2.9057 (2.9057)  weight_decay: 0.0500 (0.0500)  time: 2.7935  data: 2.2749  max mem: 40080
Epoch: [166]  [ 200/1251]  eta: 0:08:57  lr: 0.001862  min_lr: 0.001862  loss: 2.9610 (3.1023)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4343 (1.3882)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [166]  [ 400/1251]  eta: 0:07:09  lr: 0.001859  min_lr: 0.001859  loss: 3.4299 (3.1093)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9465 (1.3118)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [166]  [ 600/1251]  eta: 0:05:26  lr: 0.001855  min_lr: 0.001855  loss: 3.2887 (3.1186)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3721 (1.3438)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [166]  [ 800/1251]  eta: 0:03:45  lr: 0.001852  min_lr: 0.001852  loss: 3.2717 (3.1131)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1653 (1.3104)  time: 0.4977  data: 0.0005  max mem: 40080
Epoch: [166]  [1000/1251]  eta: 0:02:05  lr: 0.001848  min_lr: 0.001848  loss: 3.0898 (3.1148)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6721 (1.3073)  time: 0.4985  data: 0.0005  max mem: 40080
Epoch: [166]  [1200/1251]  eta: 0:00:25  lr: 0.001844  min_lr: 0.001844  loss: 3.3479 (3.1219)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8879 (1.2977)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [166]  [1250/1251]  eta: 0:00:00  lr: 0.001844  min_lr: 0.001844  loss: 3.2752 (3.1231)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8848 (1.2790)  time: 0.4213  data: 0.0005  max mem: 40080
Epoch: [166] Total time: 0:10:24 (0.4990 s / it)
Averaged stats: lr: 0.001844  min_lr: 0.001844  loss: 3.2752 (3.1440)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8848 (1.2790)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.6417 (0.6417)  acc1: 89.6000 (89.6000)  acc5: 98.4000 (98.4000)  time: 5.3498  data: 5.0461  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8335 (0.8218)  acc1: 85.6000 (84.8727)  acc5: 97.6000 (97.3091)  time: 0.7241  data: 0.4590  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9909 (0.9443)  acc1: 79.6000 (81.6952)  acc5: 96.0000 (95.9238)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9512 (0.9506)  acc1: 80.0000 (81.3760)  acc5: 95.2000 (95.8560)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4682 s / it)
* Acc@1 81.380 Acc@5 95.934 loss 0.948
Accuracy of the model on the 50000 test images: 81.4%
Max accuracy: 81.42%
Epoch: [167]  [   0/1251]  eta: 1:11:47  lr: 0.001844  min_lr: 0.001844  loss: 3.5536 (3.5536)  weight_decay: 0.0500 (0.0500)  time: 3.4435  data: 1.5683  max mem: 40080
Epoch: [167]  [ 200/1251]  eta: 0:09:01  lr: 0.001840  min_lr: 0.001840  loss: 3.3923 (3.1096)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3111 (1.4200)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [167]  [ 400/1251]  eta: 0:07:10  lr: 0.001836  min_lr: 0.001836  loss: 3.3275 (3.1098)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8610 (1.3031)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [167]  [ 600/1251]  eta: 0:05:27  lr: 0.001833  min_lr: 0.001833  loss: 3.2682 (3.1338)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8401 (1.2159)  time: 0.5081  data: 0.0005  max mem: 40080
Epoch: [167]  [ 800/1251]  eta: 0:03:46  lr: 0.001829  min_lr: 0.001829  loss: 3.2100 (3.1588)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0838 (1.1804)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [167]  [1000/1251]  eta: 0:02:05  lr: 0.001826  min_lr: 0.001826  loss: 3.2670 (3.1518)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9733 (1.1925)  time: 0.4981  data: 0.0005  max mem: 40080
Epoch: [167]  [1200/1251]  eta: 0:00:25  lr: 0.001822  min_lr: 0.001822  loss: 3.2971 (3.1608)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9569 (1.1909)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [167]  [1250/1251]  eta: 0:00:00  lr: 0.001821  min_lr: 0.001821  loss: 3.1348 (3.1567)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8918 (1.1874)  time: 0.4213  data: 0.0005  max mem: 40080
Epoch: [167] Total time: 0:10:26 (0.5005 s / it)
Averaged stats: lr: 0.001821  min_lr: 0.001821  loss: 3.1348 (3.1420)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8918 (1.1874)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.6805 (0.6805)  acc1: 86.8000 (86.8000)  acc5: 98.4000 (98.4000)  time: 5.4385  data: 5.1365  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7851 (0.7832)  acc1: 84.8000 (84.4364)  acc5: 98.0000 (97.8182)  time: 0.7323  data: 0.4673  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9477 (0.9232)  acc1: 80.0000 (81.2952)  acc5: 96.0000 (96.1524)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0081 (0.9369)  acc1: 80.0000 (81.0880)  acc5: 95.2000 (96.0000)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4717 s / it)
* Acc@1 81.136 Acc@5 95.896 loss 0.933
Accuracy of the model on the 50000 test images: 81.1%
Max accuracy: 81.42%
Epoch: [168]  [   0/1251]  eta: 1:13:13  lr: 0.001821  min_lr: 0.001821  loss: 3.0291 (3.0291)  weight_decay: 0.0500 (0.0500)  time: 3.5117  data: 1.7670  max mem: 40080
Epoch: [168]  [ 200/1251]  eta: 0:08:58  lr: 0.001818  min_lr: 0.001818  loss: 3.1598 (3.1351)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5048 (1.2347)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [168]  [ 400/1251]  eta: 0:07:09  lr: 0.001814  min_lr: 0.001814  loss: 3.2518 (3.1293)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3799 (1.3483)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [168]  [ 600/1251]  eta: 0:05:27  lr: 0.001811  min_lr: 0.001811  loss: 3.3026 (3.1288)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9668 (1.2770)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [168]  [ 800/1251]  eta: 0:03:46  lr: 0.001807  min_lr: 0.001807  loss: 3.0782 (3.1218)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0384 (1.2469)  time: 0.4960  data: 0.0005  max mem: 40080
Epoch: [168]  [1000/1251]  eta: 0:02:05  lr: 0.001803  min_lr: 0.001803  loss: 3.0715 (3.1253)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7412 (1.2280)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [168]  [1200/1251]  eta: 0:00:25  lr: 0.001800  min_lr: 0.001800  loss: 3.0856 (3.1194)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5577 (1.2661)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [168]  [1250/1251]  eta: 0:00:00  lr: 0.001799  min_lr: 0.001799  loss: 3.3926 (3.1197)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2532 (1.2670)  time: 0.4209  data: 0.0005  max mem: 40080
Epoch: [168] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.001799  min_lr: 0.001799  loss: 3.3926 (3.1315)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2532 (1.2670)
Test:  [ 0/25]  eta: 0:02:26  loss: 0.6238 (0.6238)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 5.8659  data: 5.5802  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7873 (0.7987)  acc1: 85.6000 (84.9455)  acc5: 97.2000 (97.4182)  time: 0.7710  data: 0.5075  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9751 (0.9407)  acc1: 80.0000 (81.5238)  acc5: 95.6000 (95.6381)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9805 (0.9449)  acc1: 79.2000 (81.2000)  acc5: 95.6000 (95.7120)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4888 s / it)
* Acc@1 81.438 Acc@5 95.822 loss 0.938
Accuracy of the model on the 50000 test images: 81.4%
Max accuracy: 81.44%
Epoch: [169]  [   0/1251]  eta: 0:55:47  lr: 0.001799  min_lr: 0.001799  loss: 3.1707 (3.1707)  weight_decay: 0.0500 (0.0500)  time: 2.6756  data: 2.1658  max mem: 40080
Epoch: [169]  [ 200/1251]  eta: 0:08:55  lr: 0.001795  min_lr: 0.001795  loss: 2.9815 (3.1357)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9206 (1.1407)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [169]  [ 400/1251]  eta: 0:07:09  lr: 0.001792  min_lr: 0.001792  loss: 3.1688 (3.1298)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0284 (1.1620)  time: 0.4991  data: 0.0005  max mem: 40080
Epoch: [169]  [ 600/1251]  eta: 0:05:27  lr: 0.001788  min_lr: 0.001788  loss: 3.2371 (3.1127)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0113 (1.2270)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [169]  [ 800/1251]  eta: 0:03:46  lr: 0.001785  min_lr: 0.001785  loss: 3.1374 (3.1157)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1762 (1.2619)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [169]  [1000/1251]  eta: 0:02:05  lr: 0.001781  min_lr: 0.001781  loss: 3.1242 (3.1294)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2055 (1.2924)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [169]  [1200/1251]  eta: 0:00:25  lr: 0.001777  min_lr: 0.001777  loss: 3.2714 (3.1385)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9289 (1.2665)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [169]  [1250/1251]  eta: 0:00:00  lr: 0.001777  min_lr: 0.001777  loss: 3.2523 (3.1389)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9929 (1.2974)  time: 0.4213  data: 0.0004  max mem: 40080
Epoch: [169] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.001777  min_lr: 0.001777  loss: 3.2523 (3.1244)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9929 (1.2974)
Test:  [ 0/25]  eta: 0:02:22  loss: 0.7153 (0.7153)  acc1: 88.8000 (88.8000)  acc5: 98.0000 (98.0000)  time: 5.6915  data: 5.3976  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8063 (0.8343)  acc1: 85.6000 (84.2909)  acc5: 97.6000 (97.5636)  time: 0.7551  data: 0.4909  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0406 (0.9779)  acc1: 79.6000 (81.0476)  acc5: 96.0000 (95.9048)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0677 (0.9857)  acc1: 79.6000 (80.9120)  acc5: 95.2000 (95.8560)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4822 s / it)
* Acc@1 81.426 Acc@5 95.926 loss 0.980
Accuracy of the model on the 50000 test images: 81.4%
Max accuracy: 81.44%
Epoch: [170]  [   0/1251]  eta: 1:16:59  lr: 0.001777  min_lr: 0.001777  loss: 3.0695 (3.0695)  weight_decay: 0.0500 (0.0500)  time: 3.6928  data: 2.5631  max mem: 40080
Epoch: [170]  [ 200/1251]  eta: 0:09:01  lr: 0.001773  min_lr: 0.001773  loss: 3.3278 (3.0763)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0360 (1.1160)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [170]  [ 400/1251]  eta: 0:07:10  lr: 0.001769  min_lr: 0.001769  loss: 3.3757 (3.1169)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4372 (1.2765)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [170]  [ 600/1251]  eta: 0:05:27  lr: 0.001766  min_lr: 0.001766  loss: 3.3728 (3.1177)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8640 (1.2322)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [170]  [ 800/1251]  eta: 0:03:46  lr: 0.001762  min_lr: 0.001762  loss: 3.3110 (3.1284)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3816 (1.2352)  time: 0.4977  data: 0.0003  max mem: 40080
Epoch: [170]  [1000/1251]  eta: 0:02:05  lr: 0.001759  min_lr: 0.001759  loss: 3.1209 (3.1295)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9785 (1.2278)  time: 0.5032  data: 0.0004  max mem: 40080
Epoch: [170]  [1200/1251]  eta: 0:00:25  lr: 0.001755  min_lr: 0.001755  loss: 3.4232 (3.1296)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0917 (1.2199)  time: 0.4990  data: 0.0005  max mem: 40080
Epoch: [170]  [1250/1251]  eta: 0:00:00  lr: 0.001754  min_lr: 0.001754  loss: 3.2790 (3.1289)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4469 (1.2297)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [170] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.001754  min_lr: 0.001754  loss: 3.2790 (3.1295)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4469 (1.2297)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.6533 (0.6533)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 5.6315  data: 5.3401  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8591 (0.8328)  acc1: 85.2000 (84.4000)  acc5: 97.6000 (97.4545)  time: 0.7499  data: 0.4858  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9500 (0.9714)  acc1: 80.4000 (81.3524)  acc5: 96.0000 (96.1143)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0362 (0.9848)  acc1: 79.6000 (80.9120)  acc5: 95.6000 (96.0480)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4792 s / it)
* Acc@1 81.414 Acc@5 95.998 loss 0.977
Accuracy of the model on the 50000 test images: 81.4%
Max accuracy: 81.44%
Epoch: [171]  [   0/1251]  eta: 1:13:01  lr: 0.001754  min_lr: 0.001754  loss: 3.6001 (3.6001)  weight_decay: 0.0500 (0.0500)  time: 3.5023  data: 2.2030  max mem: 40080
Epoch: [171]  [ 200/1251]  eta: 0:09:01  lr: 0.001751  min_lr: 0.001751  loss: 3.0689 (3.1379)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3781 (1.2509)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [171]  [ 400/1251]  eta: 0:07:10  lr: 0.001747  min_lr: 0.001747  loss: 3.1734 (3.0953)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0053 (1.2925)  time: 0.4957  data: 0.0004  max mem: 40080
Epoch: [171]  [ 600/1251]  eta: 0:05:27  lr: 0.001744  min_lr: 0.001744  loss: 3.0329 (3.1008)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9156 (1.2727)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [171]  [ 800/1251]  eta: 0:03:46  lr: 0.001740  min_lr: 0.001740  loss: 2.9558 (3.1025)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8344 (1.2389)  time: 0.5015  data: 0.0005  max mem: 40080
Epoch: [171]  [1000/1251]  eta: 0:02:05  lr: 0.001737  min_lr: 0.001737  loss: 3.4652 (3.1137)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1255 (1.2542)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [171]  [1200/1251]  eta: 0:00:25  lr: 0.001733  min_lr: 0.001733  loss: 3.4783 (3.1257)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1196 (1.2359)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [171]  [1250/1251]  eta: 0:00:00  lr: 0.001732  min_lr: 0.001732  loss: 2.9820 (3.1248)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0651 (1.2338)  time: 0.4210  data: 0.0006  max mem: 40080
Epoch: [171] Total time: 0:10:24 (0.4995 s / it)
Averaged stats: lr: 0.001732  min_lr: 0.001732  loss: 2.9820 (3.1283)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0651 (1.2338)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6224 (0.6224)  acc1: 88.4000 (88.4000)  acc5: 99.2000 (99.2000)  time: 5.5294  data: 5.2343  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7369 (0.7415)  acc1: 84.0000 (84.7273)  acc5: 98.0000 (97.6364)  time: 0.7404  data: 0.4761  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9006 (0.8830)  acc1: 80.4000 (81.5810)  acc5: 95.2000 (95.7905)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9784 (0.8955)  acc1: 79.2000 (81.2160)  acc5: 94.8000 (95.7760)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4750 s / it)
* Acc@1 81.546 Acc@5 96.006 loss 0.888
Accuracy of the model on the 50000 test images: 81.5%
Max accuracy: 81.55%
Epoch: [172]  [   0/1251]  eta: 0:59:10  lr: 0.001732  min_lr: 0.001732  loss: 3.4181 (3.4181)  weight_decay: 0.0500 (0.0500)  time: 2.8379  data: 2.3310  max mem: 40080
Epoch: [172]  [ 200/1251]  eta: 0:08:55  lr: 0.001729  min_lr: 0.001729  loss: 3.1687 (3.1186)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3791 (1.3325)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [172]  [ 400/1251]  eta: 0:07:08  lr: 0.001725  min_lr: 0.001725  loss: 3.1210 (3.1230)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2499 (1.3442)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [172]  [ 600/1251]  eta: 0:05:27  lr: 0.001721  min_lr: 0.001721  loss: 2.8192 (3.1204)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3102 (1.3586)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [172]  [ 800/1251]  eta: 0:03:46  lr: 0.001718  min_lr: 0.001718  loss: 2.9713 (3.1019)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2028 (1.3556)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [172]  [1000/1251]  eta: 0:02:05  lr: 0.001714  min_lr: 0.001714  loss: 3.2871 (3.1008)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9983 (1.2959)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [172]  [1200/1251]  eta: 0:00:25  lr: 0.001711  min_lr: 0.001711  loss: 3.2669 (3.1028)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0060 (1.2871)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [172]  [1250/1251]  eta: 0:00:00  lr: 0.001710  min_lr: 0.001710  loss: 3.3981 (3.1051)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0488 (1.2912)  time: 0.4219  data: 0.0005  max mem: 40080
Epoch: [172] Total time: 0:10:25 (0.4997 s / it)
Averaged stats: lr: 0.001710  min_lr: 0.001710  loss: 3.3981 (3.1186)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0488 (1.2912)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.6629 (0.6629)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 5.3502  data: 5.0258  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8290 (0.8495)  acc1: 84.8000 (84.4364)  acc5: 97.6000 (97.6000)  time: 0.7242  data: 0.4572  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0008 (0.9681)  acc1: 80.4000 (81.6952)  acc5: 96.0000 (96.1905)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0321 (0.9842)  acc1: 80.0000 (81.1360)  acc5: 95.6000 (96.0640)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4695 s / it)
* Acc@1 81.518 Acc@5 95.916 loss 0.974
Accuracy of the model on the 50000 test images: 81.5%
Max accuracy: 81.55%
Epoch: [173]  [   0/1251]  eta: 1:14:31  lr: 0.001710  min_lr: 0.001710  loss: 3.2097 (3.2097)  weight_decay: 0.0500 (0.0500)  time: 3.5745  data: 2.3825  max mem: 40080
Epoch: [173]  [ 200/1251]  eta: 0:08:58  lr: 0.001706  min_lr: 0.001706  loss: 3.2212 (3.1145)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1040 (1.2985)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [173]  [ 400/1251]  eta: 0:07:10  lr: 0.001703  min_lr: 0.001703  loss: 3.1437 (3.1038)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0981 (1.2565)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [173]  [ 600/1251]  eta: 0:05:27  lr: 0.001699  min_lr: 0.001699  loss: 3.3487 (3.0952)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1378 (1.3079)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [173]  [ 800/1251]  eta: 0:03:46  lr: 0.001696  min_lr: 0.001696  loss: 3.1342 (3.1055)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3085 (nan)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [173]  [1000/1251]  eta: 0:02:05  lr: 0.001692  min_lr: 0.001692  loss: 3.1338 (3.1061)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1874 (nan)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [173]  [1200/1251]  eta: 0:00:25  lr: 0.001689  min_lr: 0.001689  loss: 3.4217 (3.1184)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1462 (nan)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [173]  [1250/1251]  eta: 0:00:00  lr: 0.001688  min_lr: 0.001688  loss: 2.9500 (3.1162)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0833 (nan)  time: 0.4208  data: 0.0006  max mem: 40080
Epoch: [173] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.001688  min_lr: 0.001688  loss: 2.9500 (3.1128)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0833 (nan)
Test:  [ 0/25]  eta: 0:02:25  loss: 0.5992 (0.5992)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 5.8068  data: 5.4936  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7710 (0.7745)  acc1: 84.8000 (84.4000)  acc5: 98.0000 (97.6000)  time: 0.7657  data: 0.4997  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9227 (0.9055)  acc1: 78.8000 (81.3333)  acc5: 96.4000 (96.0381)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9598 (0.9182)  acc1: 78.8000 (80.9760)  acc5: 96.0000 (96.0160)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4863 s / it)
* Acc@1 81.486 Acc@5 96.020 loss 0.908
Accuracy of the model on the 50000 test images: 81.5%
Max accuracy: 81.55%
Epoch: [174]  [   0/1251]  eta: 1:11:05  lr: 0.001688  min_lr: 0.001688  loss: 2.3692 (2.3692)  weight_decay: 0.0500 (0.0500)  time: 3.4096  data: 2.8299  max mem: 40080
Epoch: [174]  [ 200/1251]  eta: 0:09:01  lr: 0.001684  min_lr: 0.001684  loss: 3.2563 (3.1241)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2714 (1.1516)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [174]  [ 400/1251]  eta: 0:07:11  lr: 0.001681  min_lr: 0.001681  loss: 2.9303 (3.1067)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0475 (1.1142)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [174]  [ 600/1251]  eta: 0:05:28  lr: 0.001677  min_lr: 0.001677  loss: 3.0194 (3.1122)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9748 (1.0885)  time: 0.5002  data: 0.0004  max mem: 40080
Epoch: [174]  [ 800/1251]  eta: 0:03:46  lr: 0.001674  min_lr: 0.001674  loss: 3.3113 (3.1194)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3003 (1.1280)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [174]  [1000/1251]  eta: 0:02:05  lr: 0.001670  min_lr: 0.001670  loss: 3.4016 (3.1328)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6130 (1.1950)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [174]  [1200/1251]  eta: 0:00:25  lr: 0.001666  min_lr: 0.001666  loss: 3.2476 (3.1256)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4277 (1.2201)  time: 0.5061  data: 0.0004  max mem: 40080
Epoch: [174]  [1250/1251]  eta: 0:00:00  lr: 0.001666  min_lr: 0.001666  loss: 2.9083 (3.1210)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8281 (1.2008)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [174] Total time: 0:10:26 (0.5006 s / it)
Averaged stats: lr: 0.001666  min_lr: 0.001666  loss: 2.9083 (3.1068)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8281 (1.2008)
Test:  [ 0/25]  eta: 0:01:51  loss: 0.5780 (0.5780)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 4.4542  data: 4.1018  max mem: 40080
Test:  [10/25]  eta: 0:00:09  loss: 0.7567 (0.7526)  acc1: 85.2000 (84.9455)  acc5: 97.6000 (97.4545)  time: 0.6509  data: 0.3788  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9325 (0.8780)  acc1: 81.2000 (82.0000)  acc5: 95.6000 (96.1333)  time: 0.2779  data: 0.0155  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9760 (0.8991)  acc1: 80.0000 (81.5200)  acc5: 95.2000 (96.0000)  time: 0.2739  data: 0.0123  max mem: 40080
Test: Total time: 0:00:11 (0.4456 s / it)
* Acc@1 81.610 Acc@5 96.112 loss 0.891
Accuracy of the model on the 50000 test images: 81.6%
Max accuracy: 81.61%
Epoch: [175]  [   0/1251]  eta: 0:55:32  lr: 0.001666  min_lr: 0.001666  loss: 3.4307 (3.4307)  weight_decay: 0.0500 (0.0500)  time: 2.6639  data: 2.1572  max mem: 40080
Epoch: [175]  [ 200/1251]  eta: 0:08:55  lr: 0.001662  min_lr: 0.001662  loss: 3.1221 (3.1040)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2358 (1.2333)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [175]  [ 400/1251]  eta: 0:07:08  lr: 0.001658  min_lr: 0.001658  loss: 3.3303 (3.1095)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9389 (1.1465)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [175]  [ 600/1251]  eta: 0:05:26  lr: 0.001655  min_lr: 0.001655  loss: 3.1579 (3.1183)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9663 (1.3072)  time: 0.5061  data: 0.0004  max mem: 40080
Epoch: [175]  [ 800/1251]  eta: 0:03:45  lr: 0.001651  min_lr: 0.001651  loss: 3.3741 (3.1116)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0067 (1.2725)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [175]  [1000/1251]  eta: 0:02:05  lr: 0.001648  min_lr: 0.001648  loss: 3.3169 (3.1137)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1560 (1.2785)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [175]  [1200/1251]  eta: 0:00:25  lr: 0.001644  min_lr: 0.001644  loss: 3.2551 (3.1102)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9320 (1.2897)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [175]  [1250/1251]  eta: 0:00:00  lr: 0.001644  min_lr: 0.001644  loss: 3.1252 (3.1081)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0428 (1.2870)  time: 0.4213  data: 0.0005  max mem: 40080
Epoch: [175] Total time: 0:10:24 (0.4989 s / it)
Averaged stats: lr: 0.001644  min_lr: 0.001644  loss: 3.1252 (3.1012)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0428 (1.2870)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.6124 (0.6124)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 5.6074  data: 5.2961  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7826 (0.7921)  acc1: 85.2000 (84.6909)  acc5: 97.2000 (97.4182)  time: 0.7476  data: 0.4818  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9581 (0.9131)  acc1: 80.4000 (82.0952)  acc5: 96.0000 (96.0000)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9784 (0.9241)  acc1: 80.4000 (81.6960)  acc5: 95.2000 (95.8720)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4795 s / it)
* Acc@1 81.682 Acc@5 96.022 loss 0.918
Accuracy of the model on the 50000 test images: 81.7%
Max accuracy: 81.68%
Epoch: [176]  [   0/1251]  eta: 1:01:49  lr: 0.001643  min_lr: 0.001643  loss: 3.4680 (3.4680)  weight_decay: 0.0500 (0.0500)  time: 2.9654  data: 2.4464  max mem: 40080
Epoch: [176]  [ 200/1251]  eta: 0:08:56  lr: 0.001640  min_lr: 0.001640  loss: 3.0531 (3.0767)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0575 (1.2319)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [176]  [ 400/1251]  eta: 0:07:08  lr: 0.001636  min_lr: 0.001636  loss: 3.1171 (3.0705)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0442 (1.2909)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [176]  [ 600/1251]  eta: 0:05:26  lr: 0.001633  min_lr: 0.001633  loss: 3.2144 (3.0693)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5871 (1.3450)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [176]  [ 800/1251]  eta: 0:03:45  lr: 0.001629  min_lr: 0.001629  loss: 3.3953 (3.0779)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2944 (1.3697)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [176]  [1000/1251]  eta: 0:02:05  lr: 0.001626  min_lr: 0.001626  loss: 3.1755 (3.0933)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1022 (1.3400)  time: 0.5085  data: 0.0005  max mem: 40080
Epoch: [176]  [1200/1251]  eta: 0:00:25  lr: 0.001622  min_lr: 0.001622  loss: 3.1855 (3.0926)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2169 (1.3063)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [176]  [1250/1251]  eta: 0:00:00  lr: 0.001621  min_lr: 0.001621  loss: 3.2239 (3.0950)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0820 (1.2978)  time: 0.4208  data: 0.0005  max mem: 40080
Epoch: [176] Total time: 0:10:24 (0.4989 s / it)
Averaged stats: lr: 0.001621  min_lr: 0.001621  loss: 3.2239 (3.1072)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0820 (1.2978)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6820 (0.6820)  acc1: 88.4000 (88.4000)  acc5: 97.6000 (97.6000)  time: 5.5232  data: 5.2032  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8528 (0.8399)  acc1: 83.2000 (84.3636)  acc5: 97.2000 (97.3091)  time: 0.7399  data: 0.4733  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0609 (0.9719)  acc1: 80.0000 (80.8952)  acc5: 95.6000 (95.8286)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0711 (0.9852)  acc1: 79.6000 (80.5440)  acc5: 94.8000 (95.6960)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4766 s / it)
* Acc@1 81.546 Acc@5 95.972 loss 0.959
Accuracy of the model on the 50000 test images: 81.5%
Max accuracy: 81.68%
Epoch: [177]  [   0/1251]  eta: 1:09:11  lr: 0.001621  min_lr: 0.001621  loss: 3.6361 (3.6361)  weight_decay: 0.0500 (0.0500)  time: 3.3185  data: 2.6023  max mem: 40080
Epoch: [177]  [ 200/1251]  eta: 0:08:59  lr: 0.001618  min_lr: 0.001618  loss: 3.1257 (3.0414)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6295 (1.5591)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [177]  [ 400/1251]  eta: 0:07:11  lr: 0.001614  min_lr: 0.001614  loss: 3.0175 (3.0563)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0465 (1.4627)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [177]  [ 600/1251]  eta: 0:05:27  lr: 0.001611  min_lr: 0.001611  loss: 3.2723 (3.0606)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1196 (1.3801)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [177]  [ 800/1251]  eta: 0:03:46  lr: 0.001607  min_lr: 0.001607  loss: 3.1909 (3.0807)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0155 (1.3417)  time: 0.4990  data: 0.0005  max mem: 40080
Epoch: [177]  [1000/1251]  eta: 0:02:05  lr: 0.001604  min_lr: 0.001604  loss: 2.9926 (3.0643)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1254 (1.3650)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [177]  [1200/1251]  eta: 0:00:25  lr: 0.001600  min_lr: 0.001600  loss: 3.2192 (3.0822)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1234 (1.3244)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [177]  [1250/1251]  eta: 0:00:00  lr: 0.001599  min_lr: 0.001599  loss: 3.3198 (3.0866)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6704 (1.3521)  time: 0.4224  data: 0.0007  max mem: 40080
Epoch: [177] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.001599  min_lr: 0.001599  loss: 3.3198 (3.0945)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6704 (1.3521)
Test:  [ 0/25]  eta: 0:02:23  loss: 0.6894 (0.6894)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 5.7304  data: 5.4355  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8353 (0.8443)  acc1: 84.0000 (84.4000)  acc5: 98.0000 (97.5636)  time: 0.7588  data: 0.4945  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0301 (0.9745)  acc1: 80.8000 (81.5238)  acc5: 96.0000 (95.9429)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0471 (0.9873)  acc1: 79.6000 (81.1680)  acc5: 94.8000 (95.8240)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4839 s / it)
* Acc@1 81.724 Acc@5 95.880 loss 0.976
Accuracy of the model on the 50000 test images: 81.7%
Max accuracy: 81.72%
Epoch: [178]  [   0/1251]  eta: 1:05:35  lr: 0.001599  min_lr: 0.001599  loss: 2.2286 (2.2286)  weight_decay: 0.0500 (0.0500)  time: 3.1458  data: 2.6338  max mem: 40080
Epoch: [178]  [ 200/1251]  eta: 0:09:00  lr: 0.001596  min_lr: 0.001596  loss: 3.2515 (3.0778)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0977 (1.2042)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [178]  [ 400/1251]  eta: 0:07:10  lr: 0.001592  min_lr: 0.001592  loss: 3.3375 (3.0798)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8406 (1.4829)  time: 0.4969  data: 0.0005  max mem: 40080
Epoch: [178]  [ 600/1251]  eta: 0:05:27  lr: 0.001589  min_lr: 0.001589  loss: 3.2828 (3.0734)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2458 (1.3787)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [178]  [ 800/1251]  eta: 0:03:46  lr: 0.001585  min_lr: 0.001585  loss: 3.2640 (3.0756)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1098 (1.3321)  time: 0.4975  data: 0.0005  max mem: 40080
Epoch: [178]  [1000/1251]  eta: 0:02:05  lr: 0.001582  min_lr: 0.001582  loss: 3.3909 (3.0877)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2760 (1.3211)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [178]  [1200/1251]  eta: 0:00:25  lr: 0.001578  min_lr: 0.001578  loss: 3.1287 (3.0781)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9973 (1.3120)  time: 0.5034  data: 0.0005  max mem: 40080
Epoch: [178]  [1250/1251]  eta: 0:00:00  lr: 0.001578  min_lr: 0.001578  loss: 3.3108 (3.0816)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9973 (1.3066)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [178] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.001578  min_lr: 0.001578  loss: 3.3108 (3.0929)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9973 (1.3066)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6742 (0.6742)  acc1: 90.4000 (90.4000)  acc5: 98.4000 (98.4000)  time: 5.5078  data: 5.2119  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8498 (0.8431)  acc1: 85.2000 (84.9818)  acc5: 98.0000 (97.4909)  time: 0.7384  data: 0.4741  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0041 (0.9837)  acc1: 80.4000 (81.5810)  acc5: 95.6000 (95.9429)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0335 (0.9946)  acc1: 80.4000 (81.2000)  acc5: 95.6000 (95.8400)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4747 s / it)
* Acc@1 81.590 Acc@5 95.970 loss 0.984
Accuracy of the model on the 50000 test images: 81.6%
Max accuracy: 81.72%
Epoch: [179]  [   0/1251]  eta: 1:13:51  lr: 0.001577  min_lr: 0.001577  loss: 3.5495 (3.5495)  weight_decay: 0.0500 (0.0500)  time: 3.5424  data: 1.7264  max mem: 40080
Epoch: [179]  [ 200/1251]  eta: 0:09:00  lr: 0.001574  min_lr: 0.001574  loss: 3.1179 (3.1221)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3470 (1.3341)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [179]  [ 400/1251]  eta: 0:07:10  lr: 0.001570  min_lr: 0.001570  loss: 3.3144 (3.1042)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0114 (1.3108)  time: 0.5052  data: 0.0004  max mem: 40080
Epoch: [179]  [ 600/1251]  eta: 0:05:28  lr: 0.001567  min_lr: 0.001567  loss: 3.2141 (3.1023)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1093 (1.3123)  time: 0.4985  data: 0.0005  max mem: 40080
Epoch: [179]  [ 800/1251]  eta: 0:03:46  lr: 0.001563  min_lr: 0.001563  loss: 3.3493 (3.0998)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0856 (1.2862)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [179]  [1000/1251]  eta: 0:02:05  lr: 0.001560  min_lr: 0.001560  loss: 3.1331 (3.0926)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7716 (1.3453)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [179]  [1200/1251]  eta: 0:00:25  lr: 0.001556  min_lr: 0.001556  loss: 3.1634 (3.0967)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0960 (1.3139)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [179]  [1250/1251]  eta: 0:00:00  lr: 0.001556  min_lr: 0.001556  loss: 2.9837 (3.0940)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2111 (1.3143)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [179] Total time: 0:10:26 (0.5004 s / it)
Averaged stats: lr: 0.001556  min_lr: 0.001556  loss: 2.9837 (3.0901)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2111 (1.3143)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6384 (0.6384)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 5.5303  data: 5.2092  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7552 (0.7688)  acc1: 86.4000 (85.4546)  acc5: 97.6000 (97.4909)  time: 0.7403  data: 0.4739  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9245 (0.8866)  acc1: 80.4000 (81.8476)  acc5: 95.6000 (96.1714)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9621 (0.8985)  acc1: 80.0000 (81.4880)  acc5: 95.6000 (96.0800)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4749 s / it)
* Acc@1 81.922 Acc@5 96.174 loss 0.891
Accuracy of the model on the 50000 test images: 81.9%
Max accuracy: 81.92%
Epoch: [180]  [   0/1251]  eta: 0:57:06  lr: 0.001556  min_lr: 0.001556  loss: 3.4360 (3.4360)  weight_decay: 0.0500 (0.0500)  time: 2.7388  data: 2.2177  max mem: 40080
Epoch: [180]  [ 200/1251]  eta: 0:08:55  lr: 0.001552  min_lr: 0.001552  loss: 2.9186 (3.0323)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5145 (1.6333)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [180]  [ 400/1251]  eta: 0:07:08  lr: 0.001549  min_lr: 0.001549  loss: 3.4384 (3.0504)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [180]  [ 600/1251]  eta: 0:05:27  lr: 0.001545  min_lr: 0.001545  loss: 3.0038 (3.0503)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2124 (nan)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [180]  [ 800/1251]  eta: 0:03:46  lr: 0.001542  min_lr: 0.001542  loss: 3.1857 (3.0535)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9006 (nan)  time: 0.4990  data: 0.0005  max mem: 40080
Epoch: [180]  [1000/1251]  eta: 0:02:05  lr: 0.001538  min_lr: 0.001538  loss: 3.1987 (3.0623)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7269 (nan)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [180]  [1200/1251]  eta: 0:00:25  lr: 0.001535  min_lr: 0.001535  loss: 3.3201 (3.0665)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2423 (nan)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [180]  [1250/1251]  eta: 0:00:00  lr: 0.001534  min_lr: 0.001534  loss: 3.3358 (3.0707)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4214 (nan)  time: 0.4212  data: 0.0007  max mem: 40080
Epoch: [180] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.001534  min_lr: 0.001534  loss: 3.3358 (3.0797)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4214 (nan)
Test:  [ 0/25]  eta: 0:02:21  loss: 0.6428 (0.6428)  acc1: 87.2000 (87.2000)  acc5: 98.8000 (98.8000)  time: 5.6515  data: 5.3411  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7954 (0.7971)  acc1: 85.2000 (84.4364)  acc5: 97.6000 (97.5273)  time: 0.7516  data: 0.4859  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9903 (0.9284)  acc1: 80.0000 (81.3333)  acc5: 95.6000 (96.0571)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0165 (0.9388)  acc1: 79.2000 (81.1360)  acc5: 95.2000 (95.9360)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4799 s / it)
* Acc@1 81.920 Acc@5 95.978 loss 0.928
Accuracy of the model on the 50000 test images: 81.9%
Max accuracy: 81.92%
Epoch: [181]  [   0/1251]  eta: 1:14:29  lr: 0.001534  min_lr: 0.001534  loss: 3.2357 (3.2357)  weight_decay: 0.0500 (0.0500)  time: 3.5724  data: 2.9453  max mem: 40080
Epoch: [181]  [ 200/1251]  eta: 0:09:00  lr: 0.001530  min_lr: 0.001530  loss: 2.9628 (3.1165)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7849 (1.1173)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [181]  [ 400/1251]  eta: 0:07:11  lr: 0.001527  min_lr: 0.001527  loss: 3.2394 (3.0891)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1889 (1.3113)  time: 0.4981  data: 0.0005  max mem: 40080
Epoch: [181]  [ 600/1251]  eta: 0:05:28  lr: 0.001523  min_lr: 0.001523  loss: 3.1785 (3.1061)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8386 (1.3111)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [181]  [ 800/1251]  eta: 0:03:46  lr: 0.001520  min_lr: 0.001520  loss: 3.1618 (3.1106)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2503 (1.3508)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [181]  [1000/1251]  eta: 0:02:05  lr: 0.001516  min_lr: 0.001516  loss: 3.2629 (3.1086)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2865 (1.3239)  time: 0.4987  data: 0.0005  max mem: 40080
Epoch: [181]  [1200/1251]  eta: 0:00:25  lr: 0.001513  min_lr: 0.001513  loss: 3.1552 (3.1101)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8738 (1.3280)  time: 0.4988  data: 0.0004  max mem: 40080
Epoch: [181]  [1250/1251]  eta: 0:00:00  lr: 0.001512  min_lr: 0.001512  loss: 3.2528 (3.1098)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0211 (1.3148)  time: 0.4210  data: 0.0005  max mem: 40080
Epoch: [181] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.001512  min_lr: 0.001512  loss: 3.2528 (3.0828)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0211 (1.3148)
Test:  [ 0/25]  eta: 0:02:00  loss: 0.6708 (0.6708)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 4.8134  data: 4.5128  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7971 (0.8010)  acc1: 85.6000 (84.9091)  acc5: 97.6000 (97.6364)  time: 0.6754  data: 0.4106  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9471 (0.9173)  acc1: 80.0000 (82.1905)  acc5: 96.4000 (96.1524)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9708 (0.9314)  acc1: 80.0000 (81.6480)  acc5: 95.6000 (96.0800)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4463 s / it)
* Acc@1 81.880 Acc@5 96.112 loss 0.923
Accuracy of the model on the 50000 test images: 81.9%
Max accuracy: 81.92%
Epoch: [182]  [   0/1251]  eta: 1:13:27  lr: 0.001512  min_lr: 0.001512  loss: 2.2238 (2.2238)  weight_decay: 0.0500 (0.0500)  time: 3.5234  data: 2.4462  max mem: 40080
Epoch: [182]  [ 200/1251]  eta: 0:08:59  lr: 0.001508  min_lr: 0.001508  loss: 2.9294 (3.0075)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1294 (1.4765)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [182]  [ 400/1251]  eta: 0:07:10  lr: 0.001505  min_lr: 0.001505  loss: 3.1562 (3.0414)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2243 (1.3304)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [182]  [ 600/1251]  eta: 0:05:27  lr: 0.001501  min_lr: 0.001501  loss: 3.2288 (3.0529)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2126 (1.3525)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [182]  [ 800/1251]  eta: 0:03:46  lr: 0.001498  min_lr: 0.001498  loss: 3.0987 (3.0588)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2412 (1.3227)  time: 0.5053  data: 0.0004  max mem: 40080
Epoch: [182]  [1000/1251]  eta: 0:02:05  lr: 0.001495  min_lr: 0.001495  loss: 3.0213 (3.0703)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9666 (1.2890)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [182]  [1200/1251]  eta: 0:00:25  lr: 0.001491  min_lr: 0.001491  loss: 3.0275 (3.0748)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9147 (1.2360)  time: 0.5004  data: 0.0005  max mem: 40080
Epoch: [182]  [1250/1251]  eta: 0:00:00  lr: 0.001490  min_lr: 0.001490  loss: 3.0748 (3.0745)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1380 (1.2510)  time: 0.4234  data: 0.0007  max mem: 40080
Epoch: [182] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.001490  min_lr: 0.001490  loss: 3.0748 (3.0798)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1380 (1.2510)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.6246 (0.6246)  acc1: 89.2000 (89.2000)  acc5: 97.6000 (97.6000)  time: 5.4636  data: 5.1543  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8157 (0.7853)  acc1: 85.6000 (85.0545)  acc5: 97.6000 (97.4546)  time: 0.7345  data: 0.4689  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0043 (0.9153)  acc1: 78.8000 (81.7714)  acc5: 96.0000 (96.0571)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0069 (0.9237)  acc1: 78.8000 (81.5040)  acc5: 95.6000 (96.0480)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4735 s / it)
* Acc@1 81.840 Acc@5 96.112 loss 0.914
Accuracy of the model on the 50000 test images: 81.8%
Max accuracy: 81.92%
Epoch: [183]  [   0/1251]  eta: 1:13:36  lr: 0.001490  min_lr: 0.001490  loss: 2.9353 (2.9353)  weight_decay: 0.0500 (0.0500)  time: 3.5307  data: 2.3442  max mem: 40080
Epoch: [183]  [ 200/1251]  eta: 0:09:01  lr: 0.001487  min_lr: 0.001487  loss: 3.1565 (3.0010)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6575 (1.5259)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [183]  [ 400/1251]  eta: 0:07:10  lr: 0.001483  min_lr: 0.001483  loss: 3.1276 (3.0664)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3799 (1.3433)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [183]  [ 600/1251]  eta: 0:05:27  lr: 0.001480  min_lr: 0.001480  loss: 3.0992 (3.0542)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8986 (1.3231)  time: 0.5043  data: 0.0004  max mem: 40080
Epoch: [183]  [ 800/1251]  eta: 0:03:46  lr: 0.001476  min_lr: 0.001476  loss: 3.3498 (3.0780)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2702 (1.3867)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [183]  [1000/1251]  eta: 0:02:05  lr: 0.001473  min_lr: 0.001473  loss: 2.7774 (3.0636)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6024 (1.3627)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [183]  [1200/1251]  eta: 0:00:25  lr: 0.001469  min_lr: 0.001469  loss: 2.9102 (3.0610)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0895 (1.3385)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [183]  [1250/1251]  eta: 0:00:00  lr: 0.001469  min_lr: 0.001469  loss: 3.3060 (3.0681)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9076 (1.3333)  time: 0.4212  data: 0.0007  max mem: 40080
Epoch: [183] Total time: 0:10:25 (0.4999 s / it)
Averaged stats: lr: 0.001469  min_lr: 0.001469  loss: 3.3060 (3.0686)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9076 (1.3333)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.6627 (0.6627)  acc1: 86.4000 (86.4000)  acc5: 97.6000 (97.6000)  time: 5.5764  data: 5.2656  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8534 (0.8317)  acc1: 84.8000 (84.0727)  acc5: 98.0000 (97.4546)  time: 0.7447  data: 0.4790  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0097 (0.9518)  acc1: 80.0000 (81.3905)  acc5: 96.0000 (96.2286)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0097 (0.9625)  acc1: 80.0000 (81.1840)  acc5: 95.6000 (96.0800)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4782 s / it)
* Acc@1 81.768 Acc@5 96.102 loss 0.954
Accuracy of the model on the 50000 test images: 81.8%
Max accuracy: 81.92%
Epoch: [184]  [   0/1251]  eta: 1:08:33  lr: 0.001469  min_lr: 0.001469  loss: 3.0460 (3.0460)  weight_decay: 0.0500 (0.0500)  time: 3.2882  data: 2.4555  max mem: 40080
Epoch: [184]  [ 200/1251]  eta: 0:08:58  lr: 0.001465  min_lr: 0.001465  loss: 3.3092 (3.0289)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9568 (1.0992)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [184]  [ 400/1251]  eta: 0:07:10  lr: 0.001462  min_lr: 0.001462  loss: 3.4015 (3.0477)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9466 (1.2798)  time: 0.4994  data: 0.0005  max mem: 40080
Epoch: [184]  [ 600/1251]  eta: 0:05:27  lr: 0.001458  min_lr: 0.001458  loss: 3.1614 (3.0340)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4480 (1.3852)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [184]  [ 800/1251]  eta: 0:03:46  lr: 0.001455  min_lr: 0.001455  loss: 3.2143 (3.0542)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9956 (1.3767)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [184]  [1000/1251]  eta: 0:02:05  lr: 0.001451  min_lr: 0.001451  loss: 3.2468 (3.0628)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2405 (1.3460)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [184]  [1200/1251]  eta: 0:00:25  lr: 0.001448  min_lr: 0.001448  loss: 3.2339 (3.0736)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4196 (1.3311)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [184]  [1250/1251]  eta: 0:00:00  lr: 0.001447  min_lr: 0.001447  loss: 3.2558 (3.0751)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0089 (1.3276)  time: 0.4214  data: 0.0008  max mem: 40080
Epoch: [184] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.001447  min_lr: 0.001447  loss: 3.2558 (3.0615)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0089 (1.3276)
Test:  [ 0/25]  eta: 0:02:14  loss: 0.6004 (0.6004)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 5.3978  data: 5.0964  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8123 (0.7802)  acc1: 85.6000 (84.6546)  acc5: 97.6000 (97.6000)  time: 0.7284  data: 0.4636  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9600 (0.9009)  acc1: 79.6000 (81.8476)  acc5: 96.0000 (96.2286)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9644 (0.9117)  acc1: 79.6000 (81.4720)  acc5: 96.0000 (96.1760)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4702 s / it)
* Acc@1 81.974 Acc@5 96.082 loss 0.899
Accuracy of the model on the 50000 test images: 82.0%
Max accuracy: 81.97%
Epoch: [185]  [   0/1251]  eta: 1:07:21  lr: 0.001447  min_lr: 0.001447  loss: 3.1720 (3.1720)  weight_decay: 0.0500 (0.0500)  time: 3.2305  data: 2.7153  max mem: 40080
Epoch: [185]  [ 200/1251]  eta: 0:08:57  lr: 0.001444  min_lr: 0.001444  loss: 3.2344 (3.0310)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3022 (1.3607)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [185]  [ 400/1251]  eta: 0:07:09  lr: 0.001440  min_lr: 0.001440  loss: 3.0308 (3.0326)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0135 (1.2774)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [185]  [ 600/1251]  eta: 0:05:27  lr: 0.001437  min_lr: 0.001437  loss: 3.0849 (3.0444)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1108 (1.2743)  time: 0.5029  data: 0.0004  max mem: 40080
Epoch: [185]  [ 800/1251]  eta: 0:03:45  lr: 0.001433  min_lr: 0.001433  loss: 3.2416 (3.0483)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7657 (1.2453)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [185]  [1000/1251]  eta: 0:02:05  lr: 0.001430  min_lr: 0.001430  loss: 3.3206 (3.0517)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9554 (1.2667)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [185]  [1200/1251]  eta: 0:00:25  lr: 0.001426  min_lr: 0.001426  loss: 3.2147 (3.0558)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3968 (1.3231)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [185]  [1250/1251]  eta: 0:00:00  lr: 0.001426  min_lr: 0.001426  loss: 3.1402 (3.0596)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1562 (1.3222)  time: 0.4211  data: 0.0006  max mem: 40080
Epoch: [185] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.001426  min_lr: 0.001426  loss: 3.1402 (3.0570)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1562 (1.3222)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.6633 (0.6633)  acc1: 90.0000 (90.0000)  acc5: 98.4000 (98.4000)  time: 5.6172  data: 5.3262  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8365 (0.8198)  acc1: 84.8000 (84.7273)  acc5: 98.0000 (97.5636)  time: 0.7484  data: 0.4845  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9785 (0.9347)  acc1: 80.4000 (82.0381)  acc5: 95.6000 (96.3048)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0248 (0.9488)  acc1: 80.0000 (81.7120)  acc5: 95.6000 (96.1600)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4786 s / it)
* Acc@1 82.056 Acc@5 96.120 loss 0.939
Accuracy of the model on the 50000 test images: 82.1%
Max accuracy: 82.06%
Epoch: [186]  [   0/1251]  eta: 0:56:40  lr: 0.001425  min_lr: 0.001425  loss: 3.1942 (3.1942)  weight_decay: 0.0500 (0.0500)  time: 2.7183  data: 2.2066  max mem: 40080
Epoch: [186]  [ 200/1251]  eta: 0:08:56  lr: 0.001422  min_lr: 0.001422  loss: 2.7969 (3.0655)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1272 (1.3597)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [186]  [ 400/1251]  eta: 0:07:09  lr: 0.001419  min_lr: 0.001419  loss: 2.9302 (3.0682)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2581 (1.4098)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [186]  [ 600/1251]  eta: 0:05:26  lr: 0.001415  min_lr: 0.001415  loss: 3.0013 (3.0764)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2559 (1.3767)  time: 0.4994  data: 0.0004  max mem: 40080
Epoch: [186]  [ 800/1251]  eta: 0:03:46  lr: 0.001412  min_lr: 0.001412  loss: 3.2019 (3.0778)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1720 (1.3862)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [186]  [1000/1251]  eta: 0:02:05  lr: 0.001408  min_lr: 0.001408  loss: 3.0864 (3.0794)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3050 (1.3820)  time: 0.4982  data: 0.0005  max mem: 40080
Epoch: [186]  [1200/1251]  eta: 0:00:25  lr: 0.001405  min_lr: 0.001405  loss: 3.0086 (3.0714)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1078 (1.3882)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [186]  [1250/1251]  eta: 0:00:00  lr: 0.001404  min_lr: 0.001404  loss: 3.3834 (3.0736)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1827 (1.3874)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [186] Total time: 0:10:24 (0.4996 s / it)
Averaged stats: lr: 0.001404  min_lr: 0.001404  loss: 3.3834 (3.0569)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1827 (1.3874)
Test:  [ 0/25]  eta: 0:01:44  loss: 0.7043 (0.7043)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 4.1753  data: 3.8853  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8563 (0.8673)  acc1: 86.4000 (85.1273)  acc5: 98.0000 (97.7455)  time: 0.7143  data: 0.4453  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0598 (0.9983)  acc1: 79.6000 (81.8667)  acc5: 95.6000 (96.0571)  time: 0.3204  data: 0.0507  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0598 (1.0067)  acc1: 79.2000 (81.5040)  acc5: 95.6000 (95.9840)  time: 0.2691  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4690 s / it)
* Acc@1 81.890 Acc@5 96.140 loss 0.996
Accuracy of the model on the 50000 test images: 81.9%
Max accuracy: 82.06%
Epoch: [187]  [   0/1251]  eta: 1:15:24  lr: 0.001404  min_lr: 0.001404  loss: 2.5692 (2.5692)  weight_decay: 0.0500 (0.0500)  time: 3.6170  data: 2.8578  max mem: 40080
Epoch: [187]  [ 200/1251]  eta: 0:09:01  lr: 0.001401  min_lr: 0.001401  loss: 3.2201 (3.0641)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3495 (1.4158)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [187]  [ 400/1251]  eta: 0:07:11  lr: 0.001397  min_lr: 0.001397  loss: 2.9575 (3.0198)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1671 (1.3902)  time: 0.4986  data: 0.0005  max mem: 40080
Epoch: [187]  [ 600/1251]  eta: 0:05:28  lr: 0.001394  min_lr: 0.001394  loss: 3.1373 (3.0298)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4607 (1.4427)  time: 0.4993  data: 0.0005  max mem: 40080
Epoch: [187]  [ 800/1251]  eta: 0:03:46  lr: 0.001390  min_lr: 0.001390  loss: 3.1235 (3.0377)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9491 (1.4313)  time: 0.4991  data: 0.0005  max mem: 40080
Epoch: [187]  [1000/1251]  eta: 0:02:05  lr: 0.001387  min_lr: 0.001387  loss: 3.3112 (3.0443)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1712 (1.3986)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [187]  [1200/1251]  eta: 0:00:25  lr: 0.001383  min_lr: 0.001383  loss: 2.8993 (3.0461)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3559 (1.4084)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [187]  [1250/1251]  eta: 0:00:00  lr: 0.001383  min_lr: 0.001383  loss: 3.0746 (3.0464)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0934 (1.3962)  time: 0.4212  data: 0.0007  max mem: 40080
Epoch: [187] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.001383  min_lr: 0.001383  loss: 3.0746 (3.0532)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0934 (1.3962)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.5993 (0.5993)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 5.3562  data: 5.0361  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7962 (0.7876)  acc1: 85.6000 (85.3091)  acc5: 98.0000 (97.6000)  time: 0.7246  data: 0.4581  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9997 (0.9174)  acc1: 80.8000 (82.1524)  acc5: 96.0000 (96.1905)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9997 (0.9301)  acc1: 78.8000 (81.5680)  acc5: 95.2000 (96.1120)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4682 s / it)
* Acc@1 82.010 Acc@5 96.064 loss 0.925
Accuracy of the model on the 50000 test images: 82.0%
Max accuracy: 82.06%
Epoch: [188]  [   0/1251]  eta: 1:11:57  lr: 0.001383  min_lr: 0.001383  loss: 3.2609 (3.2609)  weight_decay: 0.0500 (0.0500)  time: 3.4512  data: 2.2174  max mem: 40080
Epoch: [188]  [ 200/1251]  eta: 0:08:59  lr: 0.001379  min_lr: 0.001379  loss: 2.5559 (2.9509)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3556 (1.6093)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [188]  [ 400/1251]  eta: 0:07:10  lr: 0.001376  min_lr: 0.001376  loss: 3.2470 (3.0038)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8123 (1.4379)  time: 0.5060  data: 0.0004  max mem: 40080
Epoch: [188]  [ 600/1251]  eta: 0:05:27  lr: 0.001372  min_lr: 0.001372  loss: 3.1939 (3.0261)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1283 (nan)  time: 0.4965  data: 0.0005  max mem: 40080
Epoch: [188]  [ 800/1251]  eta: 0:03:46  lr: 0.001369  min_lr: 0.001369  loss: 3.0743 (3.0365)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3216 (nan)  time: 0.4986  data: 0.0005  max mem: 40080
Epoch: [188]  [1000/1251]  eta: 0:02:05  lr: 0.001366  min_lr: 0.001366  loss: 3.2657 (3.0478)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4655 (nan)  time: 0.4979  data: 0.0005  max mem: 40080
Epoch: [188]  [1200/1251]  eta: 0:00:25  lr: 0.001362  min_lr: 0.001362  loss: 3.1732 (3.0373)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3229 (nan)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [188]  [1250/1251]  eta: 0:00:00  lr: 0.001361  min_lr: 0.001361  loss: 3.1740 (3.0404)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1622 (nan)  time: 0.4212  data: 0.0007  max mem: 40080
Epoch: [188] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.001361  min_lr: 0.001361  loss: 3.1740 (3.0484)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1622 (nan)
Test:  [ 0/25]  eta: 0:02:27  loss: 0.6606 (0.6606)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 5.8821  data: 5.5915  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8290 (0.8176)  acc1: 85.6000 (85.3455)  acc5: 98.4000 (97.6727)  time: 0.7724  data: 0.5086  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9636 (0.9502)  acc1: 79.6000 (82.3238)  acc5: 96.0000 (96.3048)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0488 (0.9637)  acc1: 79.6000 (81.7920)  acc5: 95.6000 (96.2080)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4893 s / it)
* Acc@1 82.184 Acc@5 96.186 loss 0.955
Accuracy of the model on the 50000 test images: 82.2%
Max accuracy: 82.18%
Epoch: [189]  [   0/1251]  eta: 1:02:40  lr: 0.001361  min_lr: 0.001361  loss: 2.7377 (2.7377)  weight_decay: 0.0500 (0.0500)  time: 3.0062  data: 2.4861  max mem: 40080
Epoch: [189]  [ 200/1251]  eta: 0:08:58  lr: 0.001358  min_lr: 0.001358  loss: 3.2015 (3.0397)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9976 (1.1424)  time: 0.4995  data: 0.0004  max mem: 40080
Epoch: [189]  [ 400/1251]  eta: 0:07:10  lr: 0.001355  min_lr: 0.001355  loss: 3.0965 (3.0131)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4850 (1.3224)  time: 0.4986  data: 0.0004  max mem: 40080
Epoch: [189]  [ 600/1251]  eta: 0:05:27  lr: 0.001351  min_lr: 0.001351  loss: 2.8797 (3.0279)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9698 (1.2349)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [189]  [ 800/1251]  eta: 0:03:46  lr: 0.001348  min_lr: 0.001348  loss: 3.2704 (3.0376)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1644 (1.2741)  time: 0.4991  data: 0.0005  max mem: 40080
Epoch: [189]  [1000/1251]  eta: 0:02:06  lr: 0.001344  min_lr: 0.001344  loss: 2.9440 (3.0270)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2653 (1.3072)  time: 0.4974  data: 0.0005  max mem: 40080
Epoch: [189]  [1200/1251]  eta: 0:00:25  lr: 0.001341  min_lr: 0.001341  loss: 3.0190 (3.0191)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5432 (1.3603)  time: 0.5065  data: 0.0005  max mem: 40080
Epoch: [189]  [1250/1251]  eta: 0:00:00  lr: 0.001340  min_lr: 0.001340  loss: 3.0354 (3.0163)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2078 (1.3506)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [189] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.001340  min_lr: 0.001340  loss: 3.0354 (3.0313)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2078 (1.3506)
Test:  [ 0/25]  eta: 0:01:51  loss: 0.5916 (0.5916)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 4.4574  data: 4.1279  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7401 (0.7425)  acc1: 85.6000 (85.3091)  acc5: 98.0000 (97.7818)  time: 0.6979  data: 0.4308  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9410 (0.8696)  acc1: 80.4000 (82.0000)  acc5: 95.6000 (96.3429)  time: 0.2914  data: 0.0306  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9232 (0.8821)  acc1: 80.4000 (81.6000)  acc5: 95.2000 (96.1920)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4567 s / it)
* Acc@1 82.070 Acc@5 96.236 loss 0.874
Accuracy of the model on the 50000 test images: 82.1%
Max accuracy: 82.18%
Epoch: [190]  [   0/1251]  eta: 1:07:20  lr: 0.001340  min_lr: 0.001340  loss: 2.1610 (2.1610)  weight_decay: 0.0500 (0.0500)  time: 3.2297  data: 2.5584  max mem: 40080
Epoch: [190]  [ 200/1251]  eta: 0:09:00  lr: 0.001337  min_lr: 0.001337  loss: 2.9837 (3.0249)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0833 (1.1790)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [190]  [ 400/1251]  eta: 0:07:10  lr: 0.001333  min_lr: 0.001333  loss: 3.0979 (3.0009)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3149 (1.2836)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [190]  [ 600/1251]  eta: 0:05:27  lr: 0.001330  min_lr: 0.001330  loss: 3.0974 (3.0199)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1945 (1.3008)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [190]  [ 800/1251]  eta: 0:03:46  lr: 0.001327  min_lr: 0.001327  loss: 2.8746 (3.0272)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4019 (1.3414)  time: 0.5004  data: 0.0004  max mem: 40080
Epoch: [190]  [1000/1251]  eta: 0:02:05  lr: 0.001323  min_lr: 0.001323  loss: 3.1919 (3.0211)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6987 (1.4499)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [190]  [1200/1251]  eta: 0:00:25  lr: 0.001320  min_lr: 0.001320  loss: 3.0381 (3.0272)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2329 (1.4339)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [190]  [1250/1251]  eta: 0:00:00  lr: 0.001319  min_lr: 0.001319  loss: 3.1923 (3.0289)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0021 (1.4171)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [190] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.001319  min_lr: 0.001319  loss: 3.1923 (3.0387)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0021 (1.4171)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.6573 (0.6573)  acc1: 88.8000 (88.8000)  acc5: 98.0000 (98.0000)  time: 5.6010  data: 5.2919  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8204 (0.8256)  acc1: 85.6000 (85.3818)  acc5: 98.0000 (97.5636)  time: 0.7469  data: 0.4814  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9555 (0.9333)  acc1: 79.6000 (81.9810)  acc5: 96.0000 (96.2667)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9555 (0.9427)  acc1: 80.4000 (81.7760)  acc5: 96.0000 (96.1920)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4779 s / it)
* Acc@1 82.152 Acc@5 96.218 loss 0.935
Accuracy of the model on the 50000 test images: 82.2%
Max accuracy: 82.18%
Epoch: [191]  [   0/1251]  eta: 1:05:11  lr: 0.001319  min_lr: 0.001319  loss: 3.5629 (3.5629)  weight_decay: 0.0500 (0.0500)  time: 3.1270  data: 1.7921  max mem: 40080
Epoch: [191]  [ 200/1251]  eta: 0:08:59  lr: 0.001316  min_lr: 0.001316  loss: 3.0230 (3.0066)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2166 (1.3932)  time: 0.5070  data: 0.0004  max mem: 40080
Epoch: [191]  [ 400/1251]  eta: 0:07:10  lr: 0.001312  min_lr: 0.001312  loss: 3.0579 (3.0233)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8544 (1.2859)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [191]  [ 600/1251]  eta: 0:05:27  lr: 0.001309  min_lr: 0.001309  loss: 2.8530 (3.0125)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7597 (1.4626)  time: 0.5067  data: 0.0004  max mem: 40080
Epoch: [191]  [ 800/1251]  eta: 0:03:46  lr: 0.001305  min_lr: 0.001305  loss: 3.0078 (3.0207)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2480 (1.4339)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [191]  [1000/1251]  eta: 0:02:05  lr: 0.001302  min_lr: 0.001302  loss: 3.0324 (3.0372)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0194 (1.3606)  time: 0.4982  data: 0.0005  max mem: 40080
Epoch: [191]  [1200/1251]  eta: 0:00:25  lr: 0.001299  min_lr: 0.001299  loss: 3.1941 (3.0398)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0265 (1.3958)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [191]  [1250/1251]  eta: 0:00:00  lr: 0.001298  min_lr: 0.001298  loss: 3.1363 (3.0370)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8880 (1.3799)  time: 0.4210  data: 0.0007  max mem: 40080
Epoch: [191] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.001298  min_lr: 0.001298  loss: 3.1363 (3.0300)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8880 (1.3799)
Test:  [ 0/25]  eta: 0:01:39  loss: 0.6238 (0.6238)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 3.9830  data: 3.6725  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8025 (0.7661)  acc1: 85.6000 (85.2727)  acc5: 97.6000 (97.4545)  time: 0.7129  data: 0.4476  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9660 (0.8860)  acc1: 80.8000 (82.2286)  acc5: 95.6000 (96.2286)  time: 0.3233  data: 0.0626  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9532 (0.8959)  acc1: 81.2000 (81.8880)  acc5: 95.6000 (96.1280)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4632 s / it)
* Acc@1 82.292 Acc@5 96.172 loss 0.888
Accuracy of the model on the 50000 test images: 82.3%
Max accuracy: 82.29%
Epoch: [192]  [   0/1251]  eta: 1:01:27  lr: 0.001298  min_lr: 0.001298  loss: 3.0361 (3.0361)  weight_decay: 0.0500 (0.0500)  time: 2.9473  data: 2.4462  max mem: 40080
Epoch: [192]  [ 200/1251]  eta: 0:08:56  lr: 0.001295  min_lr: 0.001295  loss: 2.9748 (3.0350)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8308 (1.0999)  time: 0.4988  data: 0.0005  max mem: 40080
Epoch: [192]  [ 400/1251]  eta: 0:07:08  lr: 0.001291  min_lr: 0.001291  loss: 3.2431 (2.9977)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3959 (1.3790)  time: 0.4972  data: 0.0005  max mem: 40080
Epoch: [192]  [ 600/1251]  eta: 0:05:27  lr: 0.001288  min_lr: 0.001288  loss: 3.2247 (3.0106)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2466 (1.3299)  time: 0.4988  data: 0.0005  max mem: 40080
Epoch: [192]  [ 800/1251]  eta: 0:03:46  lr: 0.001284  min_lr: 0.001284  loss: 3.2537 (3.0136)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8800 (1.2754)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [192]  [1000/1251]  eta: 0:02:05  lr: 0.001281  min_lr: 0.001281  loss: 3.1813 (3.0151)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1169 (1.3682)  time: 0.5031  data: 0.0005  max mem: 40080
Epoch: [192]  [1200/1251]  eta: 0:00:25  lr: 0.001278  min_lr: 0.001278  loss: 2.9555 (3.0167)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5353 (1.3704)  time: 0.4962  data: 0.0005  max mem: 40080
Epoch: [192]  [1250/1251]  eta: 0:00:00  lr: 0.001277  min_lr: 0.001277  loss: 3.1293 (3.0182)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0998 (1.3691)  time: 0.4220  data: 0.0006  max mem: 40080
Epoch: [192] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.001277  min_lr: 0.001277  loss: 3.1293 (3.0337)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0998 (1.3691)
Test:  [ 0/25]  eta: 0:02:26  loss: 0.6577 (0.6577)  acc1: 89.2000 (89.2000)  acc5: 98.4000 (98.4000)  time: 5.8716  data: 5.5732  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8155 (0.7934)  acc1: 85.2000 (85.1273)  acc5: 98.0000 (97.7455)  time: 0.7715  data: 0.5070  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9754 (0.9221)  acc1: 80.0000 (81.8286)  acc5: 96.0000 (96.3048)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9842 (0.9313)  acc1: 79.6000 (81.4880)  acc5: 95.6000 (96.2400)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4904 s / it)
* Acc@1 82.150 Acc@5 96.196 loss 0.924
Accuracy of the model on the 50000 test images: 82.2%
Max accuracy: 82.29%
Epoch: [193]  [   0/1251]  eta: 1:13:23  lr: 0.001277  min_lr: 0.001277  loss: 3.0665 (3.0665)  weight_decay: 0.0500 (0.0500)  time: 3.5202  data: 1.8443  max mem: 40080
Epoch: [193]  [ 200/1251]  eta: 0:08:59  lr: 0.001274  min_lr: 0.001274  loss: 3.2363 (3.0843)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3284 (1.7317)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [193]  [ 400/1251]  eta: 0:07:10  lr: 0.001270  min_lr: 0.001270  loss: 2.9854 (3.0459)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0601 (1.4658)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [193]  [ 600/1251]  eta: 0:05:27  lr: 0.001267  min_lr: 0.001267  loss: 3.2347 (3.0517)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0823 (1.4463)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [193]  [ 800/1251]  eta: 0:03:46  lr: 0.001264  min_lr: 0.001264  loss: 3.0398 (3.0554)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9369 (1.4135)  time: 0.4991  data: 0.0004  max mem: 40080
Epoch: [193]  [1000/1251]  eta: 0:02:05  lr: 0.001260  min_lr: 0.001260  loss: 2.9640 (3.0411)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1663 (1.3920)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [193]  [1200/1251]  eta: 0:00:25  lr: 0.001257  min_lr: 0.001257  loss: 3.0574 (3.0363)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9856 (1.3995)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [193]  [1250/1251]  eta: 0:00:00  lr: 0.001256  min_lr: 0.001256  loss: 3.2377 (3.0361)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9686 (1.3933)  time: 0.4215  data: 0.0007  max mem: 40080
Epoch: [193] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.001256  min_lr: 0.001256  loss: 3.2377 (3.0269)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9686 (1.3933)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.7525 (0.7525)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 5.2144  data: 4.8968  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8913 (0.9005)  acc1: 84.4000 (84.6182)  acc5: 98.0000 (97.4909)  time: 0.7118  data: 0.4455  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.1009 (1.0105)  acc1: 78.8000 (81.4286)  acc5: 96.0000 (96.3048)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.1070 (1.0268)  acc1: 78.8000 (80.9440)  acc5: 96.0000 (96.2400)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4629 s / it)
* Acc@1 82.174 Acc@5 96.284 loss 1.010
Accuracy of the model on the 50000 test images: 82.2%
Max accuracy: 82.29%
Epoch: [194]  [   0/1251]  eta: 1:13:06  lr: 0.001256  min_lr: 0.001256  loss: 2.5648 (2.5648)  weight_decay: 0.0500 (0.0500)  time: 3.5066  data: 2.3639  max mem: 40080
Epoch: [194]  [ 200/1251]  eta: 0:09:00  lr: 0.001253  min_lr: 0.001253  loss: 2.8903 (3.0007)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8710 (1.4243)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [194]  [ 400/1251]  eta: 0:07:10  lr: 0.001249  min_lr: 0.001249  loss: 3.1215 (3.0148)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4242 (1.5137)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [194]  [ 600/1251]  eta: 0:05:27  lr: 0.001246  min_lr: 0.001246  loss: 2.8718 (2.9964)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1217 (1.5367)  time: 0.5029  data: 0.0005  max mem: 40080
Epoch: [194]  [ 800/1251]  eta: 0:03:46  lr: 0.001243  min_lr: 0.001243  loss: 2.9926 (3.0055)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9962 (1.4625)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [194]  [1000/1251]  eta: 0:02:05  lr: 0.001239  min_lr: 0.001239  loss: 3.0455 (3.0047)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1122 (1.4207)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [194]  [1200/1251]  eta: 0:00:25  lr: 0.001236  min_lr: 0.001236  loss: 2.7657 (3.0085)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5764 (1.4732)  time: 0.4986  data: 0.0005  max mem: 40080
Epoch: [194]  [1250/1251]  eta: 0:00:00  lr: 0.001235  min_lr: 0.001235  loss: 3.1428 (3.0082)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4207  data: 0.0007  max mem: 40080
Epoch: [194] Total time: 0:10:24 (0.4996 s / it)
Averaged stats: lr: 0.001235  min_lr: 0.001235  loss: 3.1428 (3.0181)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.6142 (0.6142)  acc1: 88.8000 (88.8000)  acc5: 98.0000 (98.0000)  time: 5.6095  data: 5.3020  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7790 (0.7636)  acc1: 85.6000 (84.9818)  acc5: 97.6000 (97.6727)  time: 0.7477  data: 0.4823  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9226 (0.8887)  acc1: 79.6000 (81.8095)  acc5: 96.0000 (96.3048)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9855 (0.9013)  acc1: 79.6000 (81.4080)  acc5: 95.6000 (96.1600)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4787 s / it)
* Acc@1 82.284 Acc@5 96.292 loss 0.881
Accuracy of the model on the 50000 test images: 82.3%
Max accuracy: 82.29%
Epoch: [195]  [   0/1251]  eta: 1:08:49  lr: 0.001235  min_lr: 0.001235  loss: 2.3150 (2.3150)  weight_decay: 0.0500 (0.0500)  time: 3.3012  data: 2.4868  max mem: 40080
Epoch: [195]  [ 200/1251]  eta: 0:09:01  lr: 0.001232  min_lr: 0.001232  loss: 2.5349 (2.9341)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3933 (1.4029)  time: 0.4991  data: 0.0004  max mem: 40080
Epoch: [195]  [ 400/1251]  eta: 0:07:11  lr: 0.001229  min_lr: 0.001229  loss: 3.2895 (2.9672)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1536 (1.3486)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [195]  [ 600/1251]  eta: 0:05:28  lr: 0.001225  min_lr: 0.001225  loss: 3.1121 (2.9589)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1755 (1.3294)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [195]  [ 800/1251]  eta: 0:03:46  lr: 0.001222  min_lr: 0.001222  loss: 3.1528 (2.9836)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5422 (1.3701)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [195]  [1000/1251]  eta: 0:02:05  lr: 0.001219  min_lr: 0.001219  loss: 3.0929 (2.9933)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9384 (1.3781)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [195]  [1200/1251]  eta: 0:00:25  lr: 0.001215  min_lr: 0.001215  loss: 2.9392 (2.9955)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3118 (1.3591)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [195]  [1250/1251]  eta: 0:00:00  lr: 0.001215  min_lr: 0.001215  loss: 3.0645 (2.9995)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5142 (1.3674)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [195] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.001215  min_lr: 0.001215  loss: 3.0645 (3.0061)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5142 (1.3674)
Test:  [ 0/25]  eta: 0:02:29  loss: 0.7304 (0.7304)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 5.9965  data: 5.7068  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8542 (0.8527)  acc1: 84.8000 (85.2364)  acc5: 98.0000 (97.4182)  time: 0.7828  data: 0.5191  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0374 (0.9817)  acc1: 79.6000 (82.1333)  acc5: 96.0000 (96.0952)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0515 (0.9922)  acc1: 79.6000 (81.5840)  acc5: 96.0000 (96.0640)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4950 s / it)
* Acc@1 82.384 Acc@5 96.242 loss 0.979
Accuracy of the model on the 50000 test images: 82.4%
Max accuracy: 82.38%
Epoch: [196]  [   0/1251]  eta: 1:03:05  lr: 0.001215  min_lr: 0.001215  loss: 3.3817 (3.3817)  weight_decay: 0.0500 (0.0500)  time: 3.0260  data: 2.5164  max mem: 40080
Epoch: [196]  [ 200/1251]  eta: 0:08:58  lr: 0.001211  min_lr: 0.001211  loss: 2.7223 (2.9878)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6625 (1.5836)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [196]  [ 400/1251]  eta: 0:07:09  lr: 0.001208  min_lr: 0.001208  loss: 3.0255 (3.0168)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0210 (1.4521)  time: 0.4990  data: 0.0005  max mem: 40080
Epoch: [196]  [ 600/1251]  eta: 0:05:27  lr: 0.001205  min_lr: 0.001205  loss: 3.1330 (3.0013)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2956 (1.4808)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [196]  [ 800/1251]  eta: 0:03:46  lr: 0.001201  min_lr: 0.001201  loss: 2.8812 (2.9899)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1186 (1.4314)  time: 0.4965  data: 0.0005  max mem: 40080
Epoch: [196]  [1000/1251]  eta: 0:02:05  lr: 0.001198  min_lr: 0.001198  loss: 3.0235 (2.9820)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0435 (1.3780)  time: 0.4997  data: 0.0005  max mem: 40080
Epoch: [196]  [1200/1251]  eta: 0:00:25  lr: 0.001195  min_lr: 0.001195  loss: 3.3079 (2.9968)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1806 (1.3580)  time: 0.5048  data: 0.0005  max mem: 40080
Epoch: [196]  [1250/1251]  eta: 0:00:00  lr: 0.001194  min_lr: 0.001194  loss: 3.2090 (3.0027)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0440 (1.3538)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [196] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.001194  min_lr: 0.001194  loss: 3.2090 (3.0052)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0440 (1.3538)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.7073 (0.7073)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 5.5635  data: 5.2487  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8409 (0.8447)  acc1: 86.0000 (85.7455)  acc5: 98.0000 (97.5273)  time: 0.7434  data: 0.4775  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0055 (0.9687)  acc1: 80.4000 (82.3810)  acc5: 95.6000 (96.3048)  time: 0.2612  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0482 (0.9816)  acc1: 79.6000 (81.8400)  acc5: 95.6000 (96.2400)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4772 s / it)
* Acc@1 82.236 Acc@5 96.238 loss 0.972
Accuracy of the model on the 50000 test images: 82.2%
Max accuracy: 82.38%
Epoch: [197]  [   0/1251]  eta: 1:13:31  lr: 0.001194  min_lr: 0.001194  loss: 3.3961 (3.3961)  weight_decay: 0.0500 (0.0500)  time: 3.5260  data: 2.2356  max mem: 40080
Epoch: [197]  [ 200/1251]  eta: 0:08:57  lr: 0.001191  min_lr: 0.001191  loss: 2.8304 (2.9843)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2981 (1.4699)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [197]  [ 400/1251]  eta: 0:07:10  lr: 0.001187  min_lr: 0.001187  loss: 3.0942 (3.0030)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3292 (1.6198)  time: 0.5082  data: 0.0004  max mem: 40080
Epoch: [197]  [ 600/1251]  eta: 0:05:27  lr: 0.001184  min_lr: 0.001184  loss: 3.1119 (3.0042)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2689 (1.5158)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [197]  [ 800/1251]  eta: 0:03:46  lr: 0.001181  min_lr: 0.001181  loss: 3.2049 (3.0138)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1063 (1.4598)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [197]  [1000/1251]  eta: 0:02:05  lr: 0.001178  min_lr: 0.001178  loss: 3.0601 (3.0116)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6043 (nan)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [197]  [1200/1251]  eta: 0:00:25  lr: 0.001174  min_lr: 0.001174  loss: 3.2944 (3.0039)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2857 (nan)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [197]  [1250/1251]  eta: 0:00:00  lr: 0.001174  min_lr: 0.001174  loss: 3.1061 (3.0059)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2186 (nan)  time: 0.4218  data: 0.0007  max mem: 40080
Epoch: [197] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.001174  min_lr: 0.001174  loss: 3.1061 (3.0055)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2186 (nan)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6711 (0.6711)  acc1: 87.2000 (87.2000)  acc5: 98.0000 (98.0000)  time: 5.5417  data: 5.2401  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8192 (0.8132)  acc1: 85.6000 (85.0182)  acc5: 98.0000 (97.7455)  time: 0.7417  data: 0.4768  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9960 (0.9267)  acc1: 79.6000 (81.9048)  acc5: 96.4000 (96.3810)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0004 (0.9381)  acc1: 79.2000 (81.4240)  acc5: 95.2000 (96.3040)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4777 s / it)
* Acc@1 82.350 Acc@5 96.294 loss 0.922
Accuracy of the model on the 50000 test images: 82.4%
Max accuracy: 82.38%
Epoch: [198]  [   0/1251]  eta: 1:11:05  lr: 0.001174  min_lr: 0.001174  loss: 2.1452 (2.1452)  weight_decay: 0.0500 (0.0500)  time: 3.4093  data: 2.4519  max mem: 40080
Epoch: [198]  [ 200/1251]  eta: 0:09:02  lr: 0.001170  min_lr: 0.001170  loss: 2.9304 (3.0128)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5341 (1.7483)  time: 0.5080  data: 0.0004  max mem: 40080
Epoch: [198]  [ 400/1251]  eta: 0:07:12  lr: 0.001167  min_lr: 0.001167  loss: 3.1107 (3.0009)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0453 (1.4827)  time: 0.4996  data: 0.0004  max mem: 40080
Epoch: [198]  [ 600/1251]  eta: 0:05:28  lr: 0.001164  min_lr: 0.001164  loss: 3.0315 (3.0113)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4070 (1.4129)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [198]  [ 800/1251]  eta: 0:03:47  lr: 0.001161  min_lr: 0.001161  loss: 3.0999 (3.0150)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3535 (1.3985)  time: 0.4975  data: 0.0005  max mem: 40080
Epoch: [198]  [1000/1251]  eta: 0:02:06  lr: 0.001157  min_lr: 0.001157  loss: 3.2818 (3.0129)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3112 (1.4720)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [198]  [1200/1251]  eta: 0:00:25  lr: 0.001154  min_lr: 0.001154  loss: 2.9013 (3.0109)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2080 (1.4918)  time: 0.4965  data: 0.0005  max mem: 40080
Epoch: [198]  [1250/1251]  eta: 0:00:00  lr: 0.001153  min_lr: 0.001153  loss: 3.0474 (3.0090)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2081 (1.4841)  time: 0.4212  data: 0.0007  max mem: 40080
Epoch: [198] Total time: 0:10:25 (0.5004 s / it)
Averaged stats: lr: 0.001153  min_lr: 0.001153  loss: 3.0474 (3.0001)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2081 (1.4841)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.6330 (0.6330)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 5.2837  data: 4.9665  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7774 (0.7870)  acc1: 84.4000 (84.7273)  acc5: 98.0000 (97.6000)  time: 0.7179  data: 0.4518  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9583 (0.9008)  acc1: 80.4000 (82.0191)  acc5: 95.6000 (96.2476)  time: 0.2612  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9583 (0.9127)  acc1: 80.4000 (81.6320)  acc5: 95.6000 (96.2560)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4653 s / it)
* Acc@1 82.526 Acc@5 96.308 loss 0.897
Accuracy of the model on the 50000 test images: 82.5%
Max accuracy: 82.53%
Epoch: [199]  [   0/1251]  eta: 0:57:13  lr: 0.001153  min_lr: 0.001153  loss: 3.1972 (3.1972)  weight_decay: 0.0500 (0.0500)  time: 2.7444  data: 2.2409  max mem: 40080
Epoch: [199]  [ 200/1251]  eta: 0:08:55  lr: 0.001150  min_lr: 0.001150  loss: 3.0283 (2.9678)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1635 (1.3744)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [199]  [ 400/1251]  eta: 0:07:08  lr: 0.001147  min_lr: 0.001147  loss: 2.7346 (2.9502)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1364 (1.3444)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [199]  [ 600/1251]  eta: 0:05:27  lr: 0.001143  min_lr: 0.001143  loss: 2.8540 (2.9773)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5682 (1.3965)  time: 0.5065  data: 0.0004  max mem: 40080
Epoch: [199]  [ 800/1251]  eta: 0:03:45  lr: 0.001140  min_lr: 0.001140  loss: 2.9998 (2.9803)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1024 (1.4150)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [199]  [1000/1251]  eta: 0:02:05  lr: 0.001137  min_lr: 0.001137  loss: 2.9841 (2.9817)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1487 (1.3963)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [199]  [1200/1251]  eta: 0:00:25  lr: 0.001134  min_lr: 0.001134  loss: 2.9924 (2.9769)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1887 (1.3891)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [199]  [1250/1251]  eta: 0:00:00  lr: 0.001133  min_lr: 0.001133  loss: 3.3665 (2.9790)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0989 (1.3781)  time: 0.4220  data: 0.0004  max mem: 40080
Epoch: [199] Total time: 0:10:25 (0.4996 s / it)
Averaged stats: lr: 0.001133  min_lr: 0.001133  loss: 3.3665 (2.9952)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0989 (1.3781)
Test:  [ 0/25]  eta: 0:02:25  loss: 0.7421 (0.7421)  acc1: 88.8000 (88.8000)  acc5: 97.6000 (97.6000)  time: 5.8257  data: 5.5342  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8574 (0.8289)  acc1: 86.0000 (85.4909)  acc5: 97.6000 (97.5273)  time: 0.7673  data: 0.5034  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0133 (0.9620)  acc1: 81.2000 (82.4191)  acc5: 96.0000 (96.1905)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0133 (0.9699)  acc1: 81.2000 (82.1120)  acc5: 96.0000 (96.2080)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4874 s / it)
* Acc@1 82.472 Acc@5 96.250 loss 0.963
Accuracy of the model on the 50000 test images: 82.5%
Max accuracy: 82.53%
Epoch: [200]  [   0/1251]  eta: 1:07:41  lr: 0.001133  min_lr: 0.001133  loss: 3.0883 (3.0883)  weight_decay: 0.0500 (0.0500)  time: 3.2470  data: 2.3517  max mem: 40080
Epoch: [200]  [ 200/1251]  eta: 0:08:59  lr: 0.001130  min_lr: 0.001130  loss: 3.2507 (3.0175)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0264 (1.2910)  time: 0.5006  data: 0.0005  max mem: 40080
Epoch: [200]  [ 400/1251]  eta: 0:07:10  lr: 0.001126  min_lr: 0.001126  loss: 3.0797 (2.9770)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4410 (1.6144)  time: 0.4972  data: 0.0005  max mem: 40080
Epoch: [200]  [ 600/1251]  eta: 0:05:27  lr: 0.001123  min_lr: 0.001123  loss: 3.0669 (2.9557)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1168 (1.4708)  time: 0.4990  data: 0.0005  max mem: 40080
Epoch: [200]  [ 800/1251]  eta: 0:03:46  lr: 0.001120  min_lr: 0.001120  loss: 3.0368 (2.9619)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6148 (1.5114)  time: 0.4999  data: 0.0005  max mem: 40080
Epoch: [200]  [1000/1251]  eta: 0:02:05  lr: 0.001117  min_lr: 0.001117  loss: 2.8811 (2.9647)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1171 (1.4708)  time: 0.4987  data: 0.0005  max mem: 40080
Epoch: [200]  [1200/1251]  eta: 0:00:25  lr: 0.001114  min_lr: 0.001114  loss: 3.0621 (2.9661)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2714 (1.4524)  time: 0.4994  data: 0.0005  max mem: 40080
Epoch: [200]  [1250/1251]  eta: 0:00:00  lr: 0.001113  min_lr: 0.001113  loss: 2.9539 (2.9682)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3035 (1.4427)  time: 0.4224  data: 0.0006  max mem: 40080
Epoch: [200] Total time: 0:10:26 (0.5006 s / it)
Averaged stats: lr: 0.001113  min_lr: 0.001113  loss: 2.9539 (2.9823)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3035 (1.4427)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.6086 (0.6086)  acc1: 88.4000 (88.4000)  acc5: 98.4000 (98.4000)  time: 5.4422  data: 5.1373  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7756 (0.7429)  acc1: 84.8000 (85.0909)  acc5: 98.4000 (97.8909)  time: 0.7324  data: 0.4673  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9472 (0.8625)  acc1: 81.2000 (82.4191)  acc5: 95.6000 (96.5524)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9472 (0.8773)  acc1: 80.4000 (81.9040)  acc5: 95.6000 (96.4160)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4718 s / it)
* Acc@1 82.372 Acc@5 96.388 loss 0.867
Accuracy of the model on the 50000 test images: 82.4%
Max accuracy: 82.53%
Epoch: [201]  [   0/1251]  eta: 1:12:01  lr: 0.001113  min_lr: 0.001113  loss: 3.5483 (3.5483)  weight_decay: 0.0500 (0.0500)  time: 3.4544  data: 1.6080  max mem: 40080
Epoch: [201]  [ 200/1251]  eta: 0:09:00  lr: 0.001110  min_lr: 0.001110  loss: 3.0928 (3.0241)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2030 (1.3400)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [201]  [ 400/1251]  eta: 0:07:10  lr: 0.001106  min_lr: 0.001106  loss: 3.0732 (3.0025)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7981 (1.5500)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [201]  [ 600/1251]  eta: 0:05:27  lr: 0.001103  min_lr: 0.001103  loss: 3.1559 (3.0119)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9240 (1.5147)  time: 0.4962  data: 0.0005  max mem: 40080
Epoch: [201]  [ 800/1251]  eta: 0:03:46  lr: 0.001100  min_lr: 0.001100  loss: 2.9927 (3.0225)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1206 (1.4441)  time: 0.4958  data: 0.0005  max mem: 40080
Epoch: [201]  [1000/1251]  eta: 0:02:05  lr: 0.001097  min_lr: 0.001097  loss: 2.8614 (3.0078)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1615 (1.4338)  time: 0.4960  data: 0.0005  max mem: 40080
Epoch: [201]  [1200/1251]  eta: 0:00:25  lr: 0.001094  min_lr: 0.001094  loss: 2.7903 (3.0040)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1962 (1.3959)  time: 0.4966  data: 0.0005  max mem: 40080
Epoch: [201]  [1250/1251]  eta: 0:00:00  lr: 0.001093  min_lr: 0.001093  loss: 2.9434 (3.0047)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4579 (1.3981)  time: 0.4211  data: 0.0006  max mem: 40080
Epoch: [201] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.001093  min_lr: 0.001093  loss: 2.9434 (2.9872)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4579 (1.3981)
Test:  [ 0/25]  eta: 0:02:23  loss: 0.6123 (0.6123)  acc1: 89.6000 (89.6000)  acc5: 98.4000 (98.4000)  time: 5.7228  data: 5.4152  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7550 (0.7828)  acc1: 85.2000 (85.0182)  acc5: 97.6000 (97.5273)  time: 0.7578  data: 0.4926  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9194 (0.8936)  acc1: 81.2000 (82.4571)  acc5: 96.0000 (96.2286)  time: 0.2611  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9394 (0.9033)  acc1: 80.0000 (82.0480)  acc5: 95.6000 (96.2880)  time: 0.2610  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4825 s / it)
* Acc@1 82.388 Acc@5 96.322 loss 0.891
Accuracy of the model on the 50000 test images: 82.4%
Max accuracy: 82.53%
Epoch: [202]  [   0/1251]  eta: 1:15:54  lr: 0.001093  min_lr: 0.001093  loss: 2.1173 (2.1173)  weight_decay: 0.0500 (0.0500)  time: 3.6405  data: 2.8164  max mem: 40080
Epoch: [202]  [ 200/1251]  eta: 0:09:00  lr: 0.001090  min_lr: 0.001090  loss: 3.0989 (3.0006)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3993 (1.5268)  time: 0.4964  data: 0.0005  max mem: 40080
Epoch: [202]  [ 400/1251]  eta: 0:07:10  lr: 0.001086  min_lr: 0.001086  loss: 2.8306 (2.9813)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9655 (1.4971)  time: 0.4991  data: 0.0004  max mem: 40080
Epoch: [202]  [ 600/1251]  eta: 0:05:27  lr: 0.001083  min_lr: 0.001083  loss: 3.0473 (2.9814)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0476 (1.4529)  time: 0.5001  data: 0.0004  max mem: 40080
Epoch: [202]  [ 800/1251]  eta: 0:03:46  lr: 0.001080  min_lr: 0.001080  loss: 3.2168 (2.9908)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4883 (1.4877)  time: 0.4979  data: 0.0005  max mem: 40080
Epoch: [202]  [1000/1251]  eta: 0:02:05  lr: 0.001077  min_lr: 0.001077  loss: 2.8653 (2.9823)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4303 (1.4854)  time: 0.4993  data: 0.0005  max mem: 40080
Epoch: [202]  [1200/1251]  eta: 0:00:25  lr: 0.001074  min_lr: 0.001074  loss: 3.1155 (2.9926)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9930 (1.4445)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [202]  [1250/1251]  eta: 0:00:00  lr: 0.001073  min_lr: 0.001073  loss: 3.1978 (2.9963)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3997 (1.4614)  time: 0.4212  data: 0.0007  max mem: 40080
Epoch: [202] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.001073  min_lr: 0.001073  loss: 3.1978 (2.9726)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3997 (1.4614)
Test:  [ 0/25]  eta: 0:02:26  loss: 0.6729 (0.6729)  acc1: 90.4000 (90.4000)  acc5: 98.4000 (98.4000)  time: 5.8591  data: 5.5751  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8134 (0.8269)  acc1: 85.6000 (85.5636)  acc5: 98.0000 (97.8182)  time: 0.7704  data: 0.5071  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9616 (0.9502)  acc1: 80.4000 (82.2857)  acc5: 96.0000 (96.4952)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0539 (0.9650)  acc1: 80.0000 (81.7920)  acc5: 96.0000 (96.3680)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4883 s / it)
* Acc@1 82.582 Acc@5 96.350 loss 0.955
Accuracy of the model on the 50000 test images: 82.6%
Max accuracy: 82.58%
Epoch: [203]  [   0/1251]  eta: 0:54:49  lr: 0.001073  min_lr: 0.001073  loss: 2.4342 (2.4342)  weight_decay: 0.0500 (0.0500)  time: 2.6293  data: 2.1228  max mem: 40080
Epoch: [203]  [ 200/1251]  eta: 0:08:56  lr: 0.001070  min_lr: 0.001070  loss: 3.0250 (2.9150)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2814 (1.5246)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [203]  [ 400/1251]  eta: 0:07:08  lr: 0.001066  min_lr: 0.001066  loss: 2.9111 (2.9130)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6623 (1.5360)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [203]  [ 600/1251]  eta: 0:05:26  lr: 0.001063  min_lr: 0.001063  loss: 3.0131 (2.9434)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0533 (1.4404)  time: 0.4981  data: 0.0005  max mem: 40080
Epoch: [203]  [ 800/1251]  eta: 0:03:46  lr: 0.001060  min_lr: 0.001060  loss: 3.2501 (2.9654)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1672 (1.5397)  time: 0.4999  data: 0.0005  max mem: 40080
Epoch: [203]  [1000/1251]  eta: 0:02:05  lr: 0.001057  min_lr: 0.001057  loss: 2.9968 (2.9546)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0179 (1.5370)  time: 0.4986  data: 0.0005  max mem: 40080
Epoch: [203]  [1200/1251]  eta: 0:00:25  lr: 0.001054  min_lr: 0.001054  loss: 3.1797 (2.9627)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3422 (1.4733)  time: 0.5074  data: 0.0005  max mem: 40080
Epoch: [203]  [1250/1251]  eta: 0:00:00  lr: 0.001053  min_lr: 0.001053  loss: 3.1321 (2.9649)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1427 (1.4601)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [203] Total time: 0:10:26 (0.5004 s / it)
Averaged stats: lr: 0.001053  min_lr: 0.001053  loss: 3.1321 (2.9749)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1427 (1.4601)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.6713 (0.6713)  acc1: 88.0000 (88.0000)  acc5: 98.0000 (98.0000)  time: 5.2179  data: 4.9014  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7941 (0.7689)  acc1: 85.6000 (85.1636)  acc5: 97.6000 (97.5636)  time: 0.7331  data: 0.4672  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9405 (0.8867)  acc1: 80.8000 (82.3429)  acc5: 96.4000 (96.4571)  time: 0.2727  data: 0.0119  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9511 (0.9005)  acc1: 80.0000 (81.8400)  acc5: 96.0000 (96.3680)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4743 s / it)
* Acc@1 82.426 Acc@5 96.374 loss 0.888
Accuracy of the model on the 50000 test images: 82.4%
Max accuracy: 82.58%
Epoch: [204]  [   0/1251]  eta: 1:12:13  lr: 0.001053  min_lr: 0.001053  loss: 1.7773 (1.7773)  weight_decay: 0.0500 (0.0500)  time: 3.4637  data: 2.4754  max mem: 40080
Epoch: [204]  [ 200/1251]  eta: 0:08:59  lr: 0.001050  min_lr: 0.001050  loss: 3.1962 (2.9954)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0436 (1.5675)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [204]  [ 400/1251]  eta: 0:07:10  lr: 0.001047  min_lr: 0.001047  loss: 2.8307 (2.9989)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9559 (1.4677)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [204]  [ 600/1251]  eta: 0:05:27  lr: 0.001044  min_lr: 0.001044  loss: 3.0262 (3.0002)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2458 (1.4606)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [204]  [ 800/1251]  eta: 0:03:46  lr: 0.001040  min_lr: 0.001040  loss: 2.7747 (2.9913)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4607 (1.4257)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [204]  [1000/1251]  eta: 0:02:05  lr: 0.001037  min_lr: 0.001037  loss: 3.1576 (3.0061)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6311 (1.4459)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [204]  [1200/1251]  eta: 0:00:25  lr: 0.001034  min_lr: 0.001034  loss: 3.0683 (3.0049)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3601 (1.4487)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [204]  [1250/1251]  eta: 0:00:00  lr: 0.001033  min_lr: 0.001033  loss: 3.2017 (3.0045)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4730 (1.4717)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [204] Total time: 0:10:25 (0.4997 s / it)
Averaged stats: lr: 0.001033  min_lr: 0.001033  loss: 3.2017 (2.9678)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4730 (1.4717)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.6523 (0.6523)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 5.2352  data: 4.9470  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7823 (0.7786)  acc1: 85.6000 (85.3455)  acc5: 97.6000 (97.4909)  time: 0.7138  data: 0.4500  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9923 (0.9016)  acc1: 79.2000 (82.1524)  acc5: 96.0000 (96.4571)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9923 (0.9159)  acc1: 79.2000 (81.7920)  acc5: 96.0000 (96.3840)  time: 0.2615  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4648 s / it)
* Acc@1 82.474 Acc@5 96.392 loss 0.907
Accuracy of the model on the 50000 test images: 82.5%
Max accuracy: 82.58%
Epoch: [205]  [   0/1251]  eta: 1:10:49  lr: 0.001033  min_lr: 0.001033  loss: 2.7205 (2.7205)  weight_decay: 0.0500 (0.0500)  time: 3.3966  data: 2.4308  max mem: 40080
Epoch: [205]  [ 200/1251]  eta: 0:08:59  lr: 0.001030  min_lr: 0.001030  loss: 3.1744 (3.0001)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1780 (1.2245)  time: 0.5036  data: 0.0004  max mem: 40080
Epoch: [205]  [ 400/1251]  eta: 0:07:10  lr: 0.001027  min_lr: 0.001027  loss: 3.0671 (2.9764)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2778 (1.4475)  time: 0.4957  data: 0.0003  max mem: 40080
Epoch: [205]  [ 600/1251]  eta: 0:05:27  lr: 0.001024  min_lr: 0.001024  loss: 2.7845 (2.9760)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2447 (1.4623)  time: 0.4969  data: 0.0003  max mem: 40080
Epoch: [205]  [ 800/1251]  eta: 0:03:46  lr: 0.001021  min_lr: 0.001021  loss: 2.9306 (2.9861)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1001 (1.4375)  time: 0.4998  data: 0.0004  max mem: 40080
Epoch: [205]  [1000/1251]  eta: 0:02:05  lr: 0.001018  min_lr: 0.001018  loss: 2.8223 (2.9755)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4717 (1.3991)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [205]  [1200/1251]  eta: 0:00:25  lr: 0.001014  min_lr: 0.001014  loss: 2.9550 (2.9807)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9580 (1.3994)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [205]  [1250/1251]  eta: 0:00:00  lr: 0.001014  min_lr: 0.001014  loss: 2.9311 (2.9810)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9746 (1.3895)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [205] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.001014  min_lr: 0.001014  loss: 2.9311 (2.9671)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9746 (1.3895)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.6241 (0.6241)  acc1: 88.4000 (88.4000)  acc5: 98.4000 (98.4000)  time: 5.3305  data: 5.0244  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7281 (0.7494)  acc1: 84.8000 (85.3091)  acc5: 98.0000 (97.6727)  time: 0.7223  data: 0.4571  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9431 (0.8711)  acc1: 81.2000 (82.1714)  acc5: 96.0000 (96.4571)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9431 (0.8840)  acc1: 80.8000 (81.6960)  acc5: 96.0000 (96.3840)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4672 s / it)
* Acc@1 82.596 Acc@5 96.356 loss 0.869
Accuracy of the model on the 50000 test images: 82.6%
Max accuracy: 82.60%
Epoch: [206]  [   0/1251]  eta: 1:02:23  lr: 0.001014  min_lr: 0.001014  loss: 2.9848 (2.9848)  weight_decay: 0.0500 (0.0500)  time: 2.9926  data: 2.4912  max mem: 40080
Epoch: [206]  [ 200/1251]  eta: 0:08:56  lr: 0.001011  min_lr: 0.001011  loss: 3.0865 (2.9149)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5931 (1.7320)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [206]  [ 400/1251]  eta: 0:07:08  lr: 0.001007  min_lr: 0.001007  loss: 2.9173 (2.9256)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4569 (1.5508)  time: 0.4990  data: 0.0005  max mem: 40080
Epoch: [206]  [ 600/1251]  eta: 0:05:27  lr: 0.001004  min_lr: 0.001004  loss: 3.1215 (2.9433)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3026 (1.5888)  time: 0.4995  data: 0.0004  max mem: 40080
Epoch: [206]  [ 800/1251]  eta: 0:03:46  lr: 0.001001  min_lr: 0.001001  loss: 3.0615 (2.9486)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0693 (1.5345)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [206]  [1000/1251]  eta: 0:02:05  lr: 0.000998  min_lr: 0.000998  loss: 2.8757 (2.9511)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0181 (1.4787)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [206]  [1200/1251]  eta: 0:00:25  lr: 0.000995  min_lr: 0.000995  loss: 2.7376 (2.9445)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3972 (1.5149)  time: 0.4965  data: 0.0005  max mem: 40080
Epoch: [206]  [1250/1251]  eta: 0:00:00  lr: 0.000994  min_lr: 0.000994  loss: 3.1373 (2.9460)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5163 (1.5245)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [206] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.000994  min_lr: 0.000994  loss: 3.1373 (2.9586)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5163 (1.5245)
Test:  [ 0/25]  eta: 0:02:27  loss: 0.5666 (0.5666)  acc1: 90.4000 (90.4000)  acc5: 98.4000 (98.4000)  time: 5.9045  data: 5.5873  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7511 (0.7247)  acc1: 84.4000 (85.8182)  acc5: 97.6000 (97.4909)  time: 0.7744  data: 0.5082  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9348 (0.8467)  acc1: 80.8000 (82.5143)  acc5: 96.4000 (96.4571)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9607 (0.8615)  acc1: 80.4000 (82.0640)  acc5: 96.0000 (96.3360)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4908 s / it)
* Acc@1 82.620 Acc@5 96.466 loss 0.844
Accuracy of the model on the 50000 test images: 82.6%
Max accuracy: 82.62%
Epoch: [207]  [   0/1251]  eta: 0:59:08  lr: 0.000994  min_lr: 0.000994  loss: 3.0230 (3.0230)  weight_decay: 0.0500 (0.0500)  time: 2.8362  data: 2.3211  max mem: 40080
Epoch: [207]  [ 200/1251]  eta: 0:08:57  lr: 0.000991  min_lr: 0.000991  loss: 3.1760 (2.9318)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2130 (1.3156)  time: 0.4986  data: 0.0004  max mem: 40080
Epoch: [207]  [ 400/1251]  eta: 0:07:09  lr: 0.000988  min_lr: 0.000988  loss: 3.1025 (2.9592)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2310 (1.3820)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [207]  [ 600/1251]  eta: 0:05:26  lr: 0.000985  min_lr: 0.000985  loss: 3.1218 (2.9737)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3185 (1.5050)  time: 0.5055  data: 0.0004  max mem: 40080
Epoch: [207]  [ 800/1251]  eta: 0:03:46  lr: 0.000982  min_lr: 0.000982  loss: 3.0248 (2.9617)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0280 (1.4548)  time: 0.4993  data: 0.0004  max mem: 40080
Epoch: [207]  [1000/1251]  eta: 0:02:05  lr: 0.000979  min_lr: 0.000979  loss: 3.1642 (2.9677)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4037 (1.4299)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [207]  [1200/1251]  eta: 0:00:25  lr: 0.000976  min_lr: 0.000976  loss: 2.7361 (2.9667)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6199 (1.4773)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [207]  [1250/1251]  eta: 0:00:00  lr: 0.000975  min_lr: 0.000975  loss: 3.0585 (2.9662)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6199 (1.4753)  time: 0.4211  data: 0.0006  max mem: 40080
Epoch: [207] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.000975  min_lr: 0.000975  loss: 3.0585 (2.9536)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6199 (1.4753)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.6357 (0.6357)  acc1: 88.4000 (88.4000)  acc5: 99.2000 (99.2000)  time: 5.2861  data: 4.9930  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7931 (0.7688)  acc1: 86.0000 (85.1273)  acc5: 98.0000 (97.6727)  time: 0.7184  data: 0.4542  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9478 (0.8882)  acc1: 80.4000 (82.3238)  acc5: 96.0000 (96.5143)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9761 (0.9022)  acc1: 80.4000 (81.7600)  acc5: 96.0000 (96.4480)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4655 s / it)
* Acc@1 82.716 Acc@5 96.472 loss 0.884
Accuracy of the model on the 50000 test images: 82.7%
Max accuracy: 82.72%
Epoch: [208]  [   0/1251]  eta: 0:52:28  lr: 0.000975  min_lr: 0.000975  loss: 3.9024 (3.9024)  weight_decay: 0.0500 (0.0500)  time: 2.5165  data: 2.0086  max mem: 40080
Epoch: [208]  [ 200/1251]  eta: 0:08:54  lr: 0.000972  min_lr: 0.000972  loss: 3.1382 (2.9176)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2003 (1.5353)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [208]  [ 400/1251]  eta: 0:07:08  lr: 0.000969  min_lr: 0.000969  loss: 3.0529 (2.9428)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1204 (1.4337)  time: 0.4998  data: 0.0004  max mem: 40080
Epoch: [208]  [ 600/1251]  eta: 0:05:26  lr: 0.000966  min_lr: 0.000966  loss: 2.9668 (2.9383)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3353 (1.4499)  time: 0.4988  data: 0.0005  max mem: 40080
Epoch: [208]  [ 800/1251]  eta: 0:03:46  lr: 0.000963  min_lr: 0.000963  loss: 2.9686 (2.9402)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1398 (1.4312)  time: 0.4984  data: 0.0006  max mem: 40080
Epoch: [208]  [1000/1251]  eta: 0:02:05  lr: 0.000960  min_lr: 0.000960  loss: 3.0925 (2.9339)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5423 (1.4992)  time: 0.5082  data: 0.0005  max mem: 40080
Epoch: [208]  [1200/1251]  eta: 0:00:25  lr: 0.000956  min_lr: 0.000956  loss: 3.1829 (2.9368)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1042 (1.4834)  time: 0.4979  data: 0.0005  max mem: 40080
Epoch: [208]  [1250/1251]  eta: 0:00:00  lr: 0.000956  min_lr: 0.000956  loss: 3.0582 (2.9397)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4617 (1.5083)  time: 0.4223  data: 0.0006  max mem: 40080
Epoch: [208] Total time: 0:10:25 (0.4999 s / it)
Averaged stats: lr: 0.000956  min_lr: 0.000956  loss: 3.0582 (2.9524)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4617 (1.5083)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.6521 (0.6521)  acc1: 89.2000 (89.2000)  acc5: 97.6000 (97.6000)  time: 5.2092  data: 4.9177  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7641 (0.7860)  acc1: 85.6000 (85.6727)  acc5: 97.6000 (97.6364)  time: 0.7113  data: 0.4474  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9426 (0.8983)  acc1: 80.4000 (82.3619)  acc5: 96.4000 (96.2857)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9591 (0.9106)  acc1: 80.4000 (82.0800)  acc5: 95.6000 (96.3200)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4629 s / it)
* Acc@1 82.530 Acc@5 96.292 loss 0.900
Accuracy of the model on the 50000 test images: 82.5%
Max accuracy: 82.72%
Epoch: [209]  [   0/1251]  eta: 1:13:58  lr: 0.000956  min_lr: 0.000956  loss: 2.1842 (2.1842)  weight_decay: 0.0500 (0.0500)  time: 3.5479  data: 3.0123  max mem: 40080
Epoch: [209]  [ 200/1251]  eta: 0:09:00  lr: 0.000953  min_lr: 0.000953  loss: 2.9224 (2.8985)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2415 (1.5706)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [209]  [ 400/1251]  eta: 0:07:11  lr: 0.000950  min_lr: 0.000950  loss: 2.8359 (2.8998)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3556 (1.5089)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [209]  [ 600/1251]  eta: 0:05:28  lr: 0.000947  min_lr: 0.000947  loss: 3.0839 (2.9213)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0680 (1.5075)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [209]  [ 800/1251]  eta: 0:03:46  lr: 0.000944  min_lr: 0.000944  loss: 3.1104 (2.9347)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4968 (1.5267)  time: 0.5035  data: 0.0005  max mem: 40080
Epoch: [209]  [1000/1251]  eta: 0:02:06  lr: 0.000940  min_lr: 0.000940  loss: 3.0881 (2.9306)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2010 (1.5283)  time: 0.4996  data: 0.0005  max mem: 40080
Epoch: [209]  [1200/1251]  eta: 0:00:25  lr: 0.000937  min_lr: 0.000937  loss: 3.0700 (2.9296)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4309 (1.5424)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [209]  [1250/1251]  eta: 0:00:00  lr: 0.000937  min_lr: 0.000937  loss: 3.0808 (2.9276)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2805 (1.5380)  time: 0.4216  data: 0.0006  max mem: 40080
Epoch: [209] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.000937  min_lr: 0.000937  loss: 3.0808 (2.9351)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2805 (1.5380)
Test:  [ 0/25]  eta: 0:02:06  loss: 0.6446 (0.6446)  acc1: 87.6000 (87.6000)  acc5: 99.2000 (99.2000)  time: 5.0509  data: 4.7520  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7310 (0.7605)  acc1: 86.0000 (85.6364)  acc5: 98.0000 (97.9273)  time: 0.6971  data: 0.4324  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9405 (0.8757)  acc1: 80.8000 (82.7048)  acc5: 96.0000 (96.6667)  time: 0.2615  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9534 (0.8870)  acc1: 80.4000 (82.0640)  acc5: 96.0000 (96.6400)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4564 s / it)
* Acc@1 82.700 Acc@5 96.442 loss 0.880
Accuracy of the model on the 50000 test images: 82.7%
Max accuracy: 82.72%
Epoch: [210]  [   0/1251]  eta: 1:13:25  lr: 0.000937  min_lr: 0.000937  loss: 3.4020 (3.4020)  weight_decay: 0.0500 (0.0500)  time: 3.5212  data: 2.3211  max mem: 40080
Epoch: [210]  [ 200/1251]  eta: 0:09:01  lr: 0.000934  min_lr: 0.000934  loss: 3.0558 (2.9469)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0878 (1.2554)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [210]  [ 400/1251]  eta: 0:07:10  lr: 0.000931  min_lr: 0.000931  loss: 2.9872 (2.9633)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4797 (1.3468)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [210]  [ 600/1251]  eta: 0:05:27  lr: 0.000928  min_lr: 0.000928  loss: 2.7866 (2.9548)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2482 (1.3709)  time: 0.5089  data: 0.0005  max mem: 40080
Epoch: [210]  [ 800/1251]  eta: 0:03:46  lr: 0.000925  min_lr: 0.000925  loss: 3.0263 (2.9372)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1931 (1.3844)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [210]  [1000/1251]  eta: 0:02:05  lr: 0.000922  min_lr: 0.000922  loss: 3.1885 (2.9511)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1179 (1.3952)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [210]  [1200/1251]  eta: 0:00:25  lr: 0.000918  min_lr: 0.000918  loss: 3.1491 (2.9487)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7920 (1.4518)  time: 0.4982  data: 0.0005  max mem: 40080
Epoch: [210]  [1250/1251]  eta: 0:00:00  lr: 0.000918  min_lr: 0.000918  loss: 3.0509 (2.9476)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5760 (1.4589)  time: 0.4210  data: 0.0006  max mem: 40080
Epoch: [210] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.000918  min_lr: 0.000918  loss: 3.0509 (2.9433)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5760 (1.4589)
Test:  [ 0/25]  eta: 0:02:22  loss: 0.6682 (0.6682)  acc1: 89.6000 (89.6000)  acc5: 98.4000 (98.4000)  time: 5.7170  data: 5.4149  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8161 (0.8092)  acc1: 86.4000 (85.5273)  acc5: 97.6000 (97.6727)  time: 0.7575  data: 0.4926  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9668 (0.9230)  acc1: 81.6000 (82.8571)  acc5: 96.0000 (96.2857)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9961 (0.9314)  acc1: 80.4000 (82.2720)  acc5: 95.6000 (96.2400)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4827 s / it)
* Acc@1 82.682 Acc@5 96.386 loss 0.920
Accuracy of the model on the 50000 test images: 82.7%
Max accuracy: 82.72%
Epoch: [211]  [   0/1251]  eta: 1:13:47  lr: 0.000918  min_lr: 0.000918  loss: 3.4237 (3.4237)  weight_decay: 0.0500 (0.0500)  time: 3.5392  data: 3.0000  max mem: 40080
Epoch: [211]  [ 200/1251]  eta: 0:09:01  lr: 0.000915  min_lr: 0.000915  loss: 2.8461 (2.9467)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [211]  [ 400/1251]  eta: 0:07:11  lr: 0.000912  min_lr: 0.000912  loss: 3.0721 (2.9572)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3833 (nan)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [211]  [ 600/1251]  eta: 0:05:28  lr: 0.000909  min_lr: 0.000909  loss: 2.6272 (2.9337)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3314 (nan)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [211]  [ 800/1251]  eta: 0:03:46  lr: 0.000906  min_lr: 0.000906  loss: 2.8510 (2.9171)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0702 (nan)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [211]  [1000/1251]  eta: 0:02:05  lr: 0.000903  min_lr: 0.000903  loss: 2.8638 (2.9191)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2917 (nan)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [211]  [1200/1251]  eta: 0:00:25  lr: 0.000900  min_lr: 0.000900  loss: 2.7987 (2.9257)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1473 (nan)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [211]  [1250/1251]  eta: 0:00:00  lr: 0.000899  min_lr: 0.000899  loss: 3.1191 (2.9274)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5336 (nan)  time: 0.4207  data: 0.0005  max mem: 40080
Epoch: [211] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.000899  min_lr: 0.000899  loss: 3.1191 (2.9374)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5336 (nan)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.7140 (0.7140)  acc1: 88.4000 (88.4000)  acc5: 98.0000 (98.0000)  time: 5.6112  data: 5.3003  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8452 (0.8374)  acc1: 86.4000 (85.4909)  acc5: 97.6000 (97.4546)  time: 0.7480  data: 0.4822  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0069 (0.9522)  acc1: 81.2000 (82.5905)  acc5: 96.4000 (96.4000)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0182 (0.9624)  acc1: 80.0000 (82.2080)  acc5: 95.6000 (96.2400)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4784 s / it)
* Acc@1 82.794 Acc@5 96.450 loss 0.956
Accuracy of the model on the 50000 test images: 82.8%
Max accuracy: 82.79%
Epoch: [212]  [   0/1251]  eta: 0:53:18  lr: 0.000899  min_lr: 0.000899  loss: 3.4367 (3.4367)  weight_decay: 0.0500 (0.0500)  time: 2.5565  data: 2.0522  max mem: 40080
Epoch: [212]  [ 200/1251]  eta: 0:08:54  lr: 0.000896  min_lr: 0.000896  loss: 3.1637 (2.9257)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9889 (1.6137)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [212]  [ 400/1251]  eta: 0:07:08  lr: 0.000893  min_lr: 0.000893  loss: 3.0842 (2.9279)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2154 (1.5822)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [212]  [ 600/1251]  eta: 0:05:26  lr: 0.000890  min_lr: 0.000890  loss: 2.6340 (2.9083)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3370 (1.5732)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [212]  [ 800/1251]  eta: 0:03:45  lr: 0.000887  min_lr: 0.000887  loss: 3.0891 (2.9187)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6467 (1.5364)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [212]  [1000/1251]  eta: 0:02:05  lr: 0.000884  min_lr: 0.000884  loss: 3.2773 (2.9140)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3400 (1.5658)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [212]  [1200/1251]  eta: 0:00:25  lr: 0.000881  min_lr: 0.000881  loss: 2.9353 (2.9080)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0314 (1.5631)  time: 0.5015  data: 0.0004  max mem: 40080
Epoch: [212]  [1250/1251]  eta: 0:00:00  lr: 0.000880  min_lr: 0.000880  loss: 2.9915 (2.9102)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0082 (1.5487)  time: 0.4214  data: 0.0007  max mem: 40080
Epoch: [212] Total time: 0:10:24 (0.4990 s / it)
Averaged stats: lr: 0.000880  min_lr: 0.000880  loss: 2.9915 (2.9250)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0082 (1.5487)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.6497 (0.6497)  acc1: 90.8000 (90.8000)  acc5: 98.4000 (98.4000)  time: 5.6051  data: 5.3048  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8069 (0.7914)  acc1: 86.0000 (85.2364)  acc5: 97.6000 (97.4182)  time: 0.7474  data: 0.4826  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9860 (0.9066)  acc1: 81.2000 (82.6857)  acc5: 96.0000 (96.3238)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9860 (0.9205)  acc1: 80.8000 (82.3040)  acc5: 95.6000 (96.2880)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4780 s / it)
* Acc@1 82.800 Acc@5 96.296 loss 0.911
Accuracy of the model on the 50000 test images: 82.8%
Max accuracy: 82.80%
Epoch: [213]  [   0/1251]  eta: 0:58:20  lr: 0.000880  min_lr: 0.000880  loss: 3.6147 (3.6147)  weight_decay: 0.0500 (0.0500)  time: 2.7982  data: 2.2902  max mem: 40080
Epoch: [213]  [ 200/1251]  eta: 0:08:54  lr: 0.000877  min_lr: 0.000877  loss: 2.8203 (2.9162)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4781 (1.7103)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [213]  [ 400/1251]  eta: 0:07:08  lr: 0.000874  min_lr: 0.000874  loss: 2.9043 (2.9054)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4356 (1.6782)  time: 0.4994  data: 0.0005  max mem: 40080
Epoch: [213]  [ 600/1251]  eta: 0:05:26  lr: 0.000871  min_lr: 0.000871  loss: 3.0177 (2.9035)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0256 (1.6077)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [213]  [ 800/1251]  eta: 0:03:45  lr: 0.000868  min_lr: 0.000868  loss: 2.9921 (2.9032)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8842 (1.7129)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [213]  [1000/1251]  eta: 0:02:05  lr: 0.000865  min_lr: 0.000865  loss: 2.8504 (2.9099)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2166 (1.6701)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [213]  [1200/1251]  eta: 0:00:25  lr: 0.000863  min_lr: 0.000863  loss: 3.0326 (2.9032)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2174 (1.6383)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [213]  [1250/1251]  eta: 0:00:00  lr: 0.000862  min_lr: 0.000862  loss: 3.0959 (2.9097)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0197 (1.6173)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [213] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.000862  min_lr: 0.000862  loss: 3.0959 (2.9249)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0197 (1.6173)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.7416 (0.7416)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 5.2890  data: 4.9935  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8342 (0.8445)  acc1: 87.2000 (85.7091)  acc5: 98.0000 (97.4909)  time: 0.7188  data: 0.4544  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0125 (0.9544)  acc1: 81.2000 (82.5714)  acc5: 95.6000 (96.2476)  time: 0.2615  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9917 (0.9640)  acc1: 81.2000 (82.2720)  acc5: 95.6000 (96.2240)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4660 s / it)
* Acc@1 82.898 Acc@5 96.418 loss 0.952
Accuracy of the model on the 50000 test images: 82.9%
Max accuracy: 82.90%
Epoch: [214]  [   0/1251]  eta: 0:45:45  lr: 0.000862  min_lr: 0.000862  loss: 2.9074 (2.9074)  weight_decay: 0.0500 (0.0500)  time: 2.1948  data: 1.6937  max mem: 40080
Epoch: [214]  [ 200/1251]  eta: 0:08:53  lr: 0.000859  min_lr: 0.000859  loss: 3.0148 (2.9029)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7400 (1.8132)  time: 0.4988  data: 0.0004  max mem: 40080
Epoch: [214]  [ 400/1251]  eta: 0:07:07  lr: 0.000856  min_lr: 0.000856  loss: 2.9865 (2.9063)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0329 (1.4964)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [214]  [ 600/1251]  eta: 0:05:26  lr: 0.000853  min_lr: 0.000853  loss: 3.0437 (2.9114)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3191 (1.5122)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [214]  [ 800/1251]  eta: 0:03:45  lr: 0.000850  min_lr: 0.000850  loss: 3.0578 (2.9231)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2642 (1.5120)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [214]  [1000/1251]  eta: 0:02:05  lr: 0.000847  min_lr: 0.000847  loss: 2.8450 (2.9229)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0519 (1.4951)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [214]  [1200/1251]  eta: 0:00:25  lr: 0.000844  min_lr: 0.000844  loss: 3.1305 (2.9319)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7081 (1.4847)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [214]  [1250/1251]  eta: 0:00:00  lr: 0.000844  min_lr: 0.000844  loss: 3.0547 (2.9354)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9889 (1.5129)  time: 0.4224  data: 0.0006  max mem: 40080
Epoch: [214] Total time: 0:10:24 (0.4989 s / it)
Averaged stats: lr: 0.000844  min_lr: 0.000844  loss: 3.0547 (2.9225)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9889 (1.5129)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.7283 (0.7283)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 5.6242  data: 5.3263  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8651 (0.8591)  acc1: 85.2000 (85.3818)  acc5: 98.0000 (97.8182)  time: 0.7491  data: 0.4845  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0518 (0.9892)  acc1: 80.8000 (82.4191)  acc5: 96.0000 (96.2857)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0627 (1.0021)  acc1: 80.0000 (82.0160)  acc5: 96.0000 (96.1760)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4793 s / it)
* Acc@1 82.856 Acc@5 96.396 loss 0.985
Accuracy of the model on the 50000 test images: 82.9%
Max accuracy: 82.90%
Epoch: [215]  [   0/1251]  eta: 1:11:54  lr: 0.000843  min_lr: 0.000843  loss: 3.5757 (3.5757)  weight_decay: 0.0500 (0.0500)  time: 3.4490  data: 2.1685  max mem: 40080
Epoch: [215]  [ 200/1251]  eta: 0:09:00  lr: 0.000841  min_lr: 0.000841  loss: 3.1245 (2.8866)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0753 (1.7211)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [215]  [ 400/1251]  eta: 0:07:10  lr: 0.000838  min_lr: 0.000838  loss: 2.9570 (2.9153)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5198 (1.5754)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [215]  [ 600/1251]  eta: 0:05:27  lr: 0.000835  min_lr: 0.000835  loss: 2.9737 (2.9164)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9645 (1.4710)  time: 0.5138  data: 0.0004  max mem: 40080
Epoch: [215]  [ 800/1251]  eta: 0:03:46  lr: 0.000832  min_lr: 0.000832  loss: 2.9106 (2.9210)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3625 (1.4666)  time: 0.4986  data: 0.0004  max mem: 40080
Epoch: [215]  [1000/1251]  eta: 0:02:05  lr: 0.000829  min_lr: 0.000829  loss: 3.0034 (2.9240)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1806 (1.5017)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [215]  [1200/1251]  eta: 0:00:25  lr: 0.000826  min_lr: 0.000826  loss: 3.1719 (2.9293)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3666 (1.5348)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [215]  [1250/1251]  eta: 0:00:00  lr: 0.000825  min_lr: 0.000825  loss: 2.9351 (2.9283)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9666 (1.5146)  time: 0.4212  data: 0.0005  max mem: 40080
Epoch: [215] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.000825  min_lr: 0.000825  loss: 2.9351 (2.9160)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9666 (1.5146)
Test:  [ 0/25]  eta: 0:01:54  loss: 0.5938 (0.5938)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 4.5915  data: 4.2452  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7410 (0.7328)  acc1: 86.8000 (85.7091)  acc5: 97.6000 (97.7091)  time: 0.7286  data: 0.4601  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9257 (0.8498)  acc1: 81.2000 (82.9143)  acc5: 96.4000 (96.6095)  time: 0.3015  data: 0.0408  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9257 (0.8645)  acc1: 80.8000 (82.4320)  acc5: 96.0000 (96.4960)  time: 0.2608  data: 0.0002  max mem: 40080
Test: Total time: 0:00:11 (0.4698 s / it)
* Acc@1 82.984 Acc@5 96.492 loss 0.848
Accuracy of the model on the 50000 test images: 83.0%
Max accuracy: 82.98%
Epoch: [216]  [   0/1251]  eta: 0:57:51  lr: 0.000825  min_lr: 0.000825  loss: 2.7829 (2.7829)  weight_decay: 0.0500 (0.0500)  time: 2.7753  data: 2.2755  max mem: 40080
Epoch: [216]  [ 200/1251]  eta: 0:08:56  lr: 0.000822  min_lr: 0.000822  loss: 2.9576 (2.9162)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3553 (1.4652)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [216]  [ 400/1251]  eta: 0:07:08  lr: 0.000819  min_lr: 0.000819  loss: 3.0085 (2.9102)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0714 (1.4516)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [216]  [ 600/1251]  eta: 0:05:26  lr: 0.000817  min_lr: 0.000817  loss: 2.9965 (2.9037)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4169 (1.4822)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [216]  [ 800/1251]  eta: 0:03:45  lr: 0.000814  min_lr: 0.000814  loss: 2.6456 (2.8948)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2346 (1.4531)  time: 0.4958  data: 0.0004  max mem: 40080
Epoch: [216]  [1000/1251]  eta: 0:02:05  lr: 0.000811  min_lr: 0.000811  loss: 2.9677 (2.8909)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2673 (1.4365)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [216]  [1200/1251]  eta: 0:00:25  lr: 0.000808  min_lr: 0.000808  loss: 2.9675 (2.8920)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3749 (1.4428)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [216]  [1250/1251]  eta: 0:00:00  lr: 0.000807  min_lr: 0.000807  loss: 2.7279 (2.8856)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2847 (1.4521)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [216] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.000807  min_lr: 0.000807  loss: 2.7279 (2.9088)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2847 (1.4521)
Test:  [ 0/25]  eta: 0:02:27  loss: 0.5527 (0.5527)  acc1: 90.4000 (90.4000)  acc5: 98.4000 (98.4000)  time: 5.9100  data: 5.6088  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7047 (0.6923)  acc1: 87.2000 (86.4000)  acc5: 98.0000 (97.7455)  time: 0.7750  data: 0.5102  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.8727 (0.8191)  acc1: 80.4000 (82.9905)  acc5: 96.4000 (96.4381)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.8727 (0.8327)  acc1: 80.4000 (82.4160)  acc5: 96.0000 (96.3680)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4906 s / it)
* Acc@1 83.188 Acc@5 96.478 loss 0.817
Accuracy of the model on the 50000 test images: 83.2%
Max accuracy: 83.19%
Epoch: [217]  [   0/1251]  eta: 0:54:13  lr: 0.000807  min_lr: 0.000807  loss: 2.8836 (2.8836)  weight_decay: 0.0500 (0.0500)  time: 2.6004  data: 2.0880  max mem: 40080
Epoch: [217]  [ 200/1251]  eta: 0:08:54  lr: 0.000804  min_lr: 0.000804  loss: 2.8266 (2.8619)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1135 (1.7183)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [217]  [ 400/1251]  eta: 0:07:09  lr: 0.000801  min_lr: 0.000801  loss: 2.8659 (2.8916)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6986 (1.7346)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [217]  [ 600/1251]  eta: 0:05:27  lr: 0.000799  min_lr: 0.000799  loss: 2.9687 (2.9161)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2557 (1.6150)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [217]  [ 800/1251]  eta: 0:03:46  lr: 0.000796  min_lr: 0.000796  loss: 3.0669 (2.9162)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7622 (1.6236)  time: 0.4970  data: 0.0005  max mem: 40080
Epoch: [217]  [1000/1251]  eta: 0:02:05  lr: 0.000793  min_lr: 0.000793  loss: 3.0148 (2.9137)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4123 (nan)  time: 0.4966  data: 0.0005  max mem: 40080
Epoch: [217]  [1200/1251]  eta: 0:00:25  lr: 0.000790  min_lr: 0.000790  loss: 3.0408 (2.9128)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0800 (nan)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [217]  [1250/1251]  eta: 0:00:00  lr: 0.000789  min_lr: 0.000789  loss: 3.1565 (2.9142)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [217] Total time: 0:10:25 (0.4998 s / it)
Averaged stats: lr: 0.000789  min_lr: 0.000789  loss: 3.1565 (2.9118)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:02:29  loss: 0.6063 (0.6063)  acc1: 90.0000 (90.0000)  acc5: 98.4000 (98.4000)  time: 5.9994  data: 5.7058  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7581 (0.7604)  acc1: 86.8000 (85.8182)  acc5: 98.0000 (97.6364)  time: 0.7831  data: 0.5190  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9431 (0.8808)  acc1: 82.4000 (83.0286)  acc5: 96.0000 (96.3810)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9441 (0.8964)  acc1: 82.0000 (82.4640)  acc5: 96.0000 (96.2880)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4942 s / it)
* Acc@1 83.002 Acc@5 96.422 loss 0.881
Accuracy of the model on the 50000 test images: 83.0%
Max accuracy: 83.19%
Epoch: [218]  [   0/1251]  eta: 1:11:28  lr: 0.000789  min_lr: 0.000789  loss: 3.0326 (3.0326)  weight_decay: 0.0500 (0.0500)  time: 3.4283  data: 2.6078  max mem: 40080
Epoch: [218]  [ 200/1251]  eta: 0:09:01  lr: 0.000786  min_lr: 0.000786  loss: 2.9555 (2.8995)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4781 (1.7508)  time: 0.5058  data: 0.0005  max mem: 40080
Epoch: [218]  [ 400/1251]  eta: 0:07:11  lr: 0.000784  min_lr: 0.000784  loss: 2.7622 (2.8731)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8705 (1.8863)  time: 0.4983  data: 0.0005  max mem: 40080
Epoch: [218]  [ 600/1251]  eta: 0:05:28  lr: 0.000781  min_lr: 0.000781  loss: 2.9457 (2.8524)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4454 (1.7732)  time: 0.4992  data: 0.0005  max mem: 40080
Epoch: [218]  [ 800/1251]  eta: 0:03:46  lr: 0.000778  min_lr: 0.000778  loss: 2.9150 (2.8737)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6609 (1.7125)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [218]  [1000/1251]  eta: 0:02:06  lr: 0.000775  min_lr: 0.000775  loss: 2.9573 (2.8817)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1599 (1.7527)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [218]  [1200/1251]  eta: 0:00:25  lr: 0.000772  min_lr: 0.000772  loss: 3.1249 (2.8878)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2784 (1.7116)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [218]  [1250/1251]  eta: 0:00:00  lr: 0.000772  min_lr: 0.000772  loss: 3.2545 (2.8877)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4988 (1.7066)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [218] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.000772  min_lr: 0.000772  loss: 3.2545 (2.8970)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4988 (1.7066)
Test:  [ 0/25]  eta: 0:02:22  loss: 0.6558 (0.6558)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 5.7109  data: 5.4136  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7722 (0.7896)  acc1: 85.2000 (85.8909)  acc5: 97.6000 (97.5636)  time: 0.7569  data: 0.4924  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9519 (0.9060)  acc1: 81.2000 (83.0286)  acc5: 96.0000 (96.4000)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9519 (0.9174)  acc1: 80.8000 (82.4800)  acc5: 95.6000 (96.3840)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4823 s / it)
* Acc@1 83.040 Acc@5 96.472 loss 0.904
Accuracy of the model on the 50000 test images: 83.0%
Max accuracy: 83.19%
Epoch: [219]  [   0/1251]  eta: 1:10:41  lr: 0.000771  min_lr: 0.000771  loss: 2.8008 (2.8008)  weight_decay: 0.0500 (0.0500)  time: 3.3903  data: 2.2083  max mem: 40080
Epoch: [219]  [ 200/1251]  eta: 0:08:59  lr: 0.000769  min_lr: 0.000769  loss: 2.9706 (2.8782)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4812 (1.7841)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [219]  [ 400/1251]  eta: 0:07:09  lr: 0.000766  min_lr: 0.000766  loss: 2.9150 (2.8852)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0210 (1.5417)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [219]  [ 600/1251]  eta: 0:05:27  lr: 0.000763  min_lr: 0.000763  loss: 2.8623 (2.8849)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4149 (1.5261)  time: 0.5065  data: 0.0004  max mem: 40080
Epoch: [219]  [ 800/1251]  eta: 0:03:46  lr: 0.000760  min_lr: 0.000760  loss: 2.8504 (2.8850)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6055 (1.6473)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [219]  [1000/1251]  eta: 0:02:05  lr: 0.000757  min_lr: 0.000757  loss: 2.9517 (2.8877)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1032 (1.5912)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [219]  [1200/1251]  eta: 0:00:25  lr: 0.000755  min_lr: 0.000755  loss: 2.9654 (2.8875)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3757 (1.5991)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [219]  [1250/1251]  eta: 0:00:00  lr: 0.000754  min_lr: 0.000754  loss: 2.8701 (2.8907)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4218  data: 0.0005  max mem: 40080
Epoch: [219] Total time: 0:10:25 (0.4999 s / it)
Averaged stats: lr: 0.000754  min_lr: 0.000754  loss: 2.8701 (2.8934)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6097 (0.6097)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 5.5133  data: 5.2192  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7403 (0.7287)  acc1: 86.8000 (86.0364)  acc5: 97.6000 (97.5273)  time: 0.7389  data: 0.4747  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9264 (0.8490)  acc1: 80.8000 (83.0476)  acc5: 96.0000 (96.5143)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9264 (0.8651)  acc1: 80.4000 (82.5120)  acc5: 95.6000 (96.3840)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4753 s / it)
* Acc@1 83.202 Acc@5 96.452 loss 0.847
Accuracy of the model on the 50000 test images: 83.2%
Max accuracy: 83.20%
Epoch: [220]  [   0/1251]  eta: 0:56:39  lr: 0.000754  min_lr: 0.000754  loss: 2.7351 (2.7351)  weight_decay: 0.0500 (0.0500)  time: 2.7177  data: 2.2007  max mem: 40080
Epoch: [220]  [ 200/1251]  eta: 0:08:56  lr: 0.000751  min_lr: 0.000751  loss: 3.0939 (2.8570)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1678 (1.4908)  time: 0.4997  data: 0.0005  max mem: 40080
Epoch: [220]  [ 400/1251]  eta: 0:07:08  lr: 0.000748  min_lr: 0.000748  loss: 2.9618 (2.8798)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3034 (1.5333)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [220]  [ 600/1251]  eta: 0:05:27  lr: 0.000745  min_lr: 0.000745  loss: 2.9845 (2.8758)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2213 (1.5185)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [220]  [ 800/1251]  eta: 0:03:46  lr: 0.000743  min_lr: 0.000743  loss: 2.9044 (2.8756)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1824 (1.5618)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [220]  [1000/1251]  eta: 0:02:05  lr: 0.000740  min_lr: 0.000740  loss: 2.9036 (2.8848)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0229 (1.5826)  time: 0.5066  data: 0.0005  max mem: 40080
Epoch: [220]  [1200/1251]  eta: 0:00:25  lr: 0.000737  min_lr: 0.000737  loss: 2.9141 (2.8839)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2194 (1.5843)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [220]  [1250/1251]  eta: 0:00:00  lr: 0.000736  min_lr: 0.000736  loss: 2.9990 (2.8839)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2634 (1.5732)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [220] Total time: 0:10:24 (0.4994 s / it)
Averaged stats: lr: 0.000736  min_lr: 0.000736  loss: 2.9990 (2.8915)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2634 (1.5732)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6118 (0.6118)  acc1: 90.8000 (90.8000)  acc5: 98.4000 (98.4000)  time: 5.5481  data: 5.2405  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7306 (0.7348)  acc1: 86.0000 (86.4364)  acc5: 98.0000 (97.7818)  time: 0.7418  data: 0.4767  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9029 (0.8505)  acc1: 80.8000 (83.3143)  acc5: 96.0000 (96.5714)  time: 0.2610  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9172 (0.8682)  acc1: 80.8000 (82.7840)  acc5: 96.0000 (96.4640)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4763 s / it)
* Acc@1 83.080 Acc@5 96.520 loss 0.853
Accuracy of the model on the 50000 test images: 83.1%
Max accuracy: 83.20%
Epoch: [221]  [   0/1251]  eta: 1:10:15  lr: 0.000736  min_lr: 0.000736  loss: 2.9425 (2.9425)  weight_decay: 0.0500 (0.0500)  time: 3.3698  data: 2.8369  max mem: 40080
Epoch: [221]  [ 200/1251]  eta: 0:08:59  lr: 0.000734  min_lr: 0.000734  loss: 2.8484 (2.9184)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7245 (1.8464)  time: 0.4994  data: 0.0004  max mem: 40080
Epoch: [221]  [ 400/1251]  eta: 0:07:11  lr: 0.000731  min_lr: 0.000731  loss: 3.0536 (2.9154)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4345 (1.7047)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [221]  [ 600/1251]  eta: 0:05:28  lr: 0.000728  min_lr: 0.000728  loss: 2.8964 (2.8870)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2827 (1.6884)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [221]  [ 800/1251]  eta: 0:03:46  lr: 0.000725  min_lr: 0.000725  loss: 3.0475 (2.8918)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2339 (1.6465)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [221]  [1000/1251]  eta: 0:02:05  lr: 0.000722  min_lr: 0.000722  loss: 3.1296 (2.8956)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0671 (1.5758)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [221]  [1200/1251]  eta: 0:00:25  lr: 0.000720  min_lr: 0.000720  loss: 2.8865 (2.8883)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4711 (1.5540)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [221]  [1250/1251]  eta: 0:00:00  lr: 0.000719  min_lr: 0.000719  loss: 2.9696 (2.8894)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5170 (1.5682)  time: 0.4215  data: 0.0007  max mem: 40080
Epoch: [221] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.000719  min_lr: 0.000719  loss: 2.9696 (2.8864)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5170 (1.5682)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.6051 (0.6051)  acc1: 89.2000 (89.2000)  acc5: 98.4000 (98.4000)  time: 5.2256  data: 4.9119  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7299 (0.7432)  acc1: 86.0000 (85.3091)  acc5: 97.6000 (97.5273)  time: 0.7188  data: 0.4529  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9400 (0.8570)  acc1: 82.0000 (82.8571)  acc5: 96.0000 (96.4762)  time: 0.2647  data: 0.0035  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9226 (0.8685)  acc1: 81.6000 (82.5600)  acc5: 95.6000 (96.4160)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4725 s / it)
* Acc@1 83.098 Acc@5 96.624 loss 0.855
Accuracy of the model on the 50000 test images: 83.1%
Max accuracy: 83.20%
Epoch: [222]  [   0/1251]  eta: 1:11:24  lr: 0.000719  min_lr: 0.000719  loss: 3.1409 (3.1409)  weight_decay: 0.0500 (0.0500)  time: 3.4252  data: 2.2011  max mem: 40080
Epoch: [222]  [ 200/1251]  eta: 0:09:02  lr: 0.000716  min_lr: 0.000716  loss: 2.8094 (2.8821)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3471 (2.2014)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [222]  [ 400/1251]  eta: 0:07:11  lr: 0.000714  min_lr: 0.000714  loss: 2.8746 (2.8496)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3030 (1.7526)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [222]  [ 600/1251]  eta: 0:05:28  lr: 0.000711  min_lr: 0.000711  loss: 2.6310 (2.8487)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1279 (1.6732)  time: 0.4995  data: 0.0004  max mem: 40080
Epoch: [222]  [ 800/1251]  eta: 0:03:46  lr: 0.000708  min_lr: 0.000708  loss: 2.8871 (2.8509)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3471 (1.6949)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [222]  [1000/1251]  eta: 0:02:06  lr: 0.000705  min_lr: 0.000705  loss: 2.8777 (2.8531)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8305 (1.7510)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [222]  [1200/1251]  eta: 0:00:25  lr: 0.000703  min_lr: 0.000703  loss: 2.8629 (2.8466)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6751 (1.7266)  time: 0.4982  data: 0.0005  max mem: 40080
Epoch: [222]  [1250/1251]  eta: 0:00:00  lr: 0.000702  min_lr: 0.000702  loss: 2.9363 (2.8482)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5296 (1.7225)  time: 0.4216  data: 0.0006  max mem: 40080
Epoch: [222] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.000702  min_lr: 0.000702  loss: 2.9363 (2.8720)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5296 (1.7225)
Test:  [ 0/25]  eta: 0:02:27  loss: 0.5891 (0.5891)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 5.9170  data: 5.6114  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.6902 (0.7103)  acc1: 86.0000 (86.2545)  acc5: 98.0000 (97.8909)  time: 0.7756  data: 0.5104  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.8711 (0.8217)  acc1: 83.2000 (83.3524)  acc5: 96.4000 (96.7238)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.8879 (0.8379)  acc1: 82.0000 (82.6080)  acc5: 96.0000 (96.6080)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4916 s / it)
* Acc@1 83.124 Acc@5 96.648 loss 0.827
Accuracy of the model on the 50000 test images: 83.1%
Max accuracy: 83.20%
Epoch: [223]  [   0/1251]  eta: 1:12:32  lr: 0.000702  min_lr: 0.000702  loss: 3.2341 (3.2341)  weight_decay: 0.0500 (0.0500)  time: 3.4795  data: 2.6628  max mem: 40080
Epoch: [223]  [ 200/1251]  eta: 0:09:03  lr: 0.000699  min_lr: 0.000699  loss: 2.8083 (2.8039)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3831 (1.5842)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [223]  [ 400/1251]  eta: 0:07:11  lr: 0.000696  min_lr: 0.000696  loss: 3.0311 (2.8490)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1973 (1.5352)  time: 0.4995  data: 0.0004  max mem: 40080
Epoch: [223]  [ 600/1251]  eta: 0:05:29  lr: 0.000694  min_lr: 0.000694  loss: 2.7199 (2.8448)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2903 (1.5681)  time: 0.5078  data: 0.0004  max mem: 40080
Epoch: [223]  [ 800/1251]  eta: 0:03:47  lr: 0.000691  min_lr: 0.000691  loss: 2.9284 (2.8514)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2187 (1.5826)  time: 0.4993  data: 0.0004  max mem: 40080
Epoch: [223]  [1000/1251]  eta: 0:02:06  lr: 0.000688  min_lr: 0.000688  loss: 2.8677 (2.8503)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2438 (1.5678)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [223]  [1200/1251]  eta: 0:00:25  lr: 0.000686  min_lr: 0.000686  loss: 2.9102 (2.8661)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7011 (1.5836)  time: 0.5046  data: 0.0004  max mem: 40080
Epoch: [223]  [1250/1251]  eta: 0:00:00  lr: 0.000685  min_lr: 0.000685  loss: 3.1431 (2.8677)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5855 (1.5921)  time: 0.4214  data: 0.0007  max mem: 40080
Epoch: [223] Total time: 0:10:27 (0.5017 s / it)
Averaged stats: lr: 0.000685  min_lr: 0.000685  loss: 3.1431 (2.8758)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5855 (1.5921)
Test:  [ 0/25]  eta: 0:02:14  loss: 0.6138 (0.6138)  acc1: 90.4000 (90.4000)  acc5: 98.4000 (98.4000)  time: 5.3626  data: 5.0322  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7861 (0.7646)  acc1: 86.4000 (86.2545)  acc5: 98.0000 (97.7455)  time: 0.7254  data: 0.4578  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9185 (0.8791)  acc1: 82.4000 (83.4667)  acc5: 96.8000 (96.7048)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9410 (0.8935)  acc1: 82.0000 (82.8000)  acc5: 96.8000 (96.6400)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4692 s / it)
* Acc@1 83.174 Acc@5 96.548 loss 0.887
Accuracy of the model on the 50000 test images: 83.2%
Max accuracy: 83.20%
Epoch: [224]  [   0/1251]  eta: 1:14:58  lr: 0.000685  min_lr: 0.000685  loss: 3.6143 (3.6143)  weight_decay: 0.0500 (0.0500)  time: 3.5958  data: 1.8565  max mem: 40080
Epoch: [224]  [ 200/1251]  eta: 0:08:59  lr: 0.000682  min_lr: 0.000682  loss: 2.9465 (2.9071)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0961 (1.3126)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [224]  [ 400/1251]  eta: 0:07:10  lr: 0.000680  min_lr: 0.000680  loss: 2.9480 (2.8651)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2093 (1.4215)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [224]  [ 600/1251]  eta: 0:05:28  lr: 0.000677  min_lr: 0.000677  loss: 2.9157 (2.8624)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2499 (1.3673)  time: 0.4987  data: 0.0005  max mem: 40080
Epoch: [224]  [ 800/1251]  eta: 0:03:46  lr: 0.000674  min_lr: 0.000674  loss: 2.9571 (2.8737)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3513 (1.5215)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [224]  [1000/1251]  eta: 0:02:05  lr: 0.000671  min_lr: 0.000671  loss: 3.1161 (2.8692)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4722 (1.5343)  time: 0.4978  data: 0.0004  max mem: 40080
Epoch: [224]  [1200/1251]  eta: 0:00:25  lr: 0.000669  min_lr: 0.000669  loss: 2.6572 (2.8711)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5349 (1.5383)  time: 0.4983  data: 0.0004  max mem: 40080
Epoch: [224]  [1250/1251]  eta: 0:00:00  lr: 0.000668  min_lr: 0.000668  loss: 3.0467 (2.8727)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6578 (1.5536)  time: 0.4215  data: 0.0005  max mem: 40080
Epoch: [224] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.000668  min_lr: 0.000668  loss: 3.0467 (2.8621)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6578 (1.5536)
Test:  [ 0/25]  eta: 0:02:11  loss: 0.6350 (0.6350)  acc1: 87.6000 (87.6000)  acc5: 98.4000 (98.4000)  time: 5.2734  data: 4.9622  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7422 (0.7611)  acc1: 86.4000 (85.7455)  acc5: 98.0000 (97.7818)  time: 0.7170  data: 0.4514  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9437 (0.8771)  acc1: 81.6000 (83.1048)  acc5: 96.0000 (96.4952)  time: 0.2612  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9696 (0.8918)  acc1: 81.6000 (82.7680)  acc5: 96.0000 (96.4480)  time: 0.2611  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4649 s / it)
* Acc@1 83.230 Acc@5 96.456 loss 0.884
Accuracy of the model on the 50000 test images: 83.2%
Max accuracy: 83.23%
Epoch: [225]  [   0/1251]  eta: 0:58:08  lr: 0.000668  min_lr: 0.000668  loss: 2.1742 (2.1742)  weight_decay: 0.0500 (0.0500)  time: 2.7888  data: 2.2793  max mem: 40080
Epoch: [225]  [ 200/1251]  eta: 0:08:57  lr: 0.000665  min_lr: 0.000665  loss: 2.6895 (2.8202)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3332 (2.0799)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [225]  [ 400/1251]  eta: 0:07:10  lr: 0.000663  min_lr: 0.000663  loss: 3.0226 (2.8436)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1514 (1.7301)  time: 0.4992  data: 0.0004  max mem: 40080
Epoch: [225]  [ 600/1251]  eta: 0:05:27  lr: 0.000660  min_lr: 0.000660  loss: 2.9916 (2.8504)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5995 (1.6803)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [225]  [ 800/1251]  eta: 0:03:46  lr: 0.000657  min_lr: 0.000657  loss: 2.8492 (2.8417)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4535 (1.6879)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [225]  [1000/1251]  eta: 0:02:05  lr: 0.000655  min_lr: 0.000655  loss: 2.8162 (2.8304)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4048 (1.6342)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [225]  [1200/1251]  eta: 0:00:25  lr: 0.000652  min_lr: 0.000652  loss: 2.7687 (2.8304)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1737 (1.5834)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [225]  [1250/1251]  eta: 0:00:00  lr: 0.000652  min_lr: 0.000652  loss: 2.7562 (2.8306)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3693 (1.5931)  time: 0.4213  data: 0.0006  max mem: 40080
Epoch: [225] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.000652  min_lr: 0.000652  loss: 2.7562 (2.8622)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3693 (1.5931)
Test:  [ 0/25]  eta: 0:02:28  loss: 0.5548 (0.5548)  acc1: 90.8000 (90.8000)  acc5: 99.2000 (99.2000)  time: 5.9221  data: 5.6023  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7074 (0.7091)  acc1: 86.0000 (86.7636)  acc5: 97.6000 (97.7818)  time: 0.7762  data: 0.5096  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9181 (0.8270)  acc1: 81.2000 (83.4095)  acc5: 96.4000 (96.5714)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9217 (0.8449)  acc1: 80.4000 (82.9760)  acc5: 96.0000 (96.4480)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4931 s / it)
* Acc@1 83.324 Acc@5 96.546 loss 0.839
Accuracy of the model on the 50000 test images: 83.3%
Max accuracy: 83.32%
Epoch: [226]  [   0/1251]  eta: 0:55:56  lr: 0.000651  min_lr: 0.000651  loss: 3.4835 (3.4835)  weight_decay: 0.0500 (0.0500)  time: 2.6828  data: 2.1675  max mem: 40080
Epoch: [226]  [ 200/1251]  eta: 0:08:56  lr: 0.000649  min_lr: 0.000649  loss: 2.8732 (2.8288)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3845 (1.5706)  time: 0.5049  data: 0.0004  max mem: 40080
Epoch: [226]  [ 400/1251]  eta: 0:07:09  lr: 0.000646  min_lr: 0.000646  loss: 2.9059 (2.8478)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3123 (1.7090)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [226]  [ 600/1251]  eta: 0:05:26  lr: 0.000644  min_lr: 0.000644  loss: 2.9039 (2.8651)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7773 (1.7894)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [226]  [ 800/1251]  eta: 0:03:46  lr: 0.000641  min_lr: 0.000641  loss: 3.0901 (2.8620)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1854 (1.7206)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [226]  [1000/1251]  eta: 0:02:05  lr: 0.000638  min_lr: 0.000638  loss: 2.9700 (2.8596)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8105 (1.7616)  time: 0.4972  data: 0.0005  max mem: 40080
Epoch: [226]  [1200/1251]  eta: 0:00:25  lr: 0.000636  min_lr: 0.000636  loss: 2.9394 (2.8550)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2245 (1.6966)  time: 0.4985  data: 0.0005  max mem: 40080
Epoch: [226]  [1250/1251]  eta: 0:00:00  lr: 0.000635  min_lr: 0.000635  loss: 3.0216 (2.8551)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1842 (1.6873)  time: 0.4216  data: 0.0006  max mem: 40080
Epoch: [226] Total time: 0:10:25 (0.4997 s / it)
Averaged stats: lr: 0.000635  min_lr: 0.000635  loss: 3.0216 (2.8640)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1842 (1.6873)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.7124 (0.7124)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 5.5827  data: 5.2841  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.8499 (0.8318)  acc1: 86.0000 (86.1818)  acc5: 98.0000 (97.7455)  time: 0.7453  data: 0.4807  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0211 (0.9478)  acc1: 81.2000 (83.1810)  acc5: 96.0000 (96.4381)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0301 (0.9648)  acc1: 80.4000 (82.6240)  acc5: 96.0000 (96.3040)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4789 s / it)
* Acc@1 83.188 Acc@5 96.386 loss 0.952
Accuracy of the model on the 50000 test images: 83.2%
Max accuracy: 83.32%
Epoch: [227]  [   0/1251]  eta: 1:12:19  lr: 0.000635  min_lr: 0.000635  loss: 2.4260 (2.4260)  weight_decay: 0.0500 (0.0500)  time: 3.4688  data: 1.9960  max mem: 40080
Epoch: [227]  [ 200/1251]  eta: 0:09:01  lr: 0.000632  min_lr: 0.000632  loss: 3.2454 (2.8845)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4283 (nan)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [227]  [ 400/1251]  eta: 0:07:11  lr: 0.000630  min_lr: 0.000630  loss: 2.9110 (2.9002)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7268 (nan)  time: 0.4978  data: 0.0005  max mem: 40080
Epoch: [227]  [ 600/1251]  eta: 0:05:28  lr: 0.000627  min_lr: 0.000627  loss: 2.7511 (2.8853)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4639 (nan)  time: 0.5064  data: 0.0004  max mem: 40080
Epoch: [227]  [ 800/1251]  eta: 0:03:46  lr: 0.000625  min_lr: 0.000625  loss: 3.0563 (2.8890)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3182 (nan)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [227]  [1000/1251]  eta: 0:02:06  lr: 0.000622  min_lr: 0.000622  loss: 2.7910 (2.8802)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1690 (nan)  time: 0.5003  data: 0.0004  max mem: 40080
Epoch: [227]  [1200/1251]  eta: 0:00:25  lr: 0.000619  min_lr: 0.000619  loss: 3.0094 (2.8712)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1699 (nan)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [227]  [1250/1251]  eta: 0:00:00  lr: 0.000619  min_lr: 0.000619  loss: 2.9381 (2.8701)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3086 (nan)  time: 0.4217  data: 0.0006  max mem: 40080
Epoch: [227] Total time: 0:10:26 (0.5009 s / it)
Averaged stats: lr: 0.000619  min_lr: 0.000619  loss: 2.9381 (2.8623)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3086 (nan)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.6358 (0.6358)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 5.4061  data: 5.1165  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7632 (0.7615)  acc1: 86.4000 (86.5091)  acc5: 98.0000 (97.8182)  time: 0.7293  data: 0.4654  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9125 (0.8742)  acc1: 82.4000 (83.6191)  acc5: 96.4000 (96.5905)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9572 (0.8918)  acc1: 81.6000 (83.0080)  acc5: 96.4000 (96.5280)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4702 s / it)
* Acc@1 83.364 Acc@5 96.522 loss 0.880
Accuracy of the model on the 50000 test images: 83.4%
Max accuracy: 83.36%
Epoch: [228]  [   0/1251]  eta: 0:59:17  lr: 0.000619  min_lr: 0.000619  loss: 3.2535 (3.2535)  weight_decay: 0.0500 (0.0500)  time: 2.8439  data: 2.3449  max mem: 40080
Epoch: [228]  [ 200/1251]  eta: 0:08:57  lr: 0.000616  min_lr: 0.000616  loss: 2.8497 (2.8565)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5469 (2.0867)  time: 0.4987  data: 0.0005  max mem: 40080
Epoch: [228]  [ 400/1251]  eta: 0:07:09  lr: 0.000614  min_lr: 0.000614  loss: 2.5175 (2.8412)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1918 (1.9872)  time: 0.5001  data: 0.0005  max mem: 40080
Epoch: [228]  [ 600/1251]  eta: 0:05:27  lr: 0.000611  min_lr: 0.000611  loss: 2.9723 (2.8391)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3042 (1.7941)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [228]  [ 800/1251]  eta: 0:03:46  lr: 0.000608  min_lr: 0.000608  loss: 2.8800 (2.8453)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9929 (1.8301)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [228]  [1000/1251]  eta: 0:02:06  lr: 0.000606  min_lr: 0.000606  loss: 3.0030 (2.8513)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3453 (1.7726)  time: 0.5182  data: 0.0005  max mem: 40080
Epoch: [228]  [1200/1251]  eta: 0:00:25  lr: 0.000603  min_lr: 0.000603  loss: 2.9359 (2.8495)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4395 (1.7217)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [228]  [1250/1251]  eta: 0:00:00  lr: 0.000603  min_lr: 0.000603  loss: 2.9798 (2.8492)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2764 (1.7092)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [228] Total time: 0:10:26 (0.5010 s / it)
Averaged stats: lr: 0.000603  min_lr: 0.000603  loss: 2.9798 (2.8525)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2764 (1.7092)
Test:  [ 0/25]  eta: 0:02:32  loss: 0.6046 (0.6046)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 6.0837  data: 5.7605  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7246 (0.7338)  acc1: 85.6000 (86.2545)  acc5: 98.0000 (97.7091)  time: 0.7907  data: 0.5240  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9224 (0.8506)  acc1: 81.2000 (83.3714)  acc5: 96.0000 (96.4952)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9224 (0.8648)  acc1: 81.2000 (82.8960)  acc5: 96.0000 (96.4320)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4983 s / it)
* Acc@1 83.530 Acc@5 96.572 loss 0.857
Accuracy of the model on the 50000 test images: 83.5%
Max accuracy: 83.53%
Epoch: [229]  [   0/1251]  eta: 1:01:02  lr: 0.000603  min_lr: 0.000603  loss: 2.1153 (2.1153)  weight_decay: 0.0500 (0.0500)  time: 2.9276  data: 2.4187  max mem: 40080
Epoch: [229]  [ 200/1251]  eta: 0:08:57  lr: 0.000600  min_lr: 0.000600  loss: 2.8367 (2.8577)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5566 (1.7690)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [229]  [ 400/1251]  eta: 0:07:10  lr: 0.000597  min_lr: 0.000597  loss: 2.9912 (2.8457)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7108 (1.7423)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [229]  [ 600/1251]  eta: 0:05:27  lr: 0.000595  min_lr: 0.000595  loss: 2.9767 (2.8569)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2441 (1.6902)  time: 0.4961  data: 0.0004  max mem: 40080
Epoch: [229]  [ 800/1251]  eta: 0:03:46  lr: 0.000592  min_lr: 0.000592  loss: 2.9074 (2.8454)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3968 (1.6379)  time: 0.4988  data: 0.0004  max mem: 40080
Epoch: [229]  [1000/1251]  eta: 0:02:05  lr: 0.000590  min_lr: 0.000590  loss: 2.8902 (2.8455)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1713 (1.6929)  time: 0.4968  data: 0.0005  max mem: 40080
Epoch: [229]  [1200/1251]  eta: 0:00:25  lr: 0.000587  min_lr: 0.000587  loss: 2.9099 (2.8363)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5397 (1.6769)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [229]  [1250/1251]  eta: 0:00:00  lr: 0.000587  min_lr: 0.000587  loss: 3.0064 (2.8411)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5397 (1.6717)  time: 0.4214  data: 0.0006  max mem: 40080
Epoch: [229] Total time: 0:10:25 (0.4997 s / it)
Averaged stats: lr: 0.000587  min_lr: 0.000587  loss: 3.0064 (2.8453)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5397 (1.6717)
Test:  [ 0/25]  eta: 0:02:22  loss: 0.6568 (0.6568)  acc1: 89.2000 (89.2000)  acc5: 99.6000 (99.6000)  time: 5.6950  data: 5.3859  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7870 (0.7880)  acc1: 86.4000 (86.0000)  acc5: 98.0000 (97.6364)  time: 0.7554  data: 0.4899  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9421 (0.8996)  acc1: 81.6000 (83.3143)  acc5: 96.0000 (96.3048)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9498 (0.9109)  acc1: 81.6000 (82.8800)  acc5: 95.6000 (96.2240)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4815 s / it)
* Acc@1 83.350 Acc@5 96.492 loss 0.900
Accuracy of the model on the 50000 test images: 83.4%
Max accuracy: 83.53%
Epoch: [230]  [   0/1251]  eta: 1:13:00  lr: 0.000587  min_lr: 0.000587  loss: 3.7789 (3.7789)  weight_decay: 0.0500 (0.0500)  time: 3.5019  data: 2.9059  max mem: 40080
Epoch: [230]  [ 200/1251]  eta: 0:09:01  lr: 0.000584  min_lr: 0.000584  loss: 2.7699 (2.7831)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2669 (1.7116)  time: 0.5051  data: 0.0004  max mem: 40080
Epoch: [230]  [ 400/1251]  eta: 0:07:10  lr: 0.000582  min_lr: 0.000582  loss: 2.8500 (2.7752)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9327 (1.6263)  time: 0.4984  data: 0.0004  max mem: 40080
Epoch: [230]  [ 600/1251]  eta: 0:05:28  lr: 0.000579  min_lr: 0.000579  loss: 3.1168 (2.8043)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6068 (1.7527)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [230]  [ 800/1251]  eta: 0:03:46  lr: 0.000577  min_lr: 0.000577  loss: 2.9292 (2.8067)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6803 (1.7821)  time: 0.4992  data: 0.0004  max mem: 40080
Epoch: [230]  [1000/1251]  eta: 0:02:06  lr: 0.000574  min_lr: 0.000574  loss: 2.7987 (2.8013)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9900 (1.6589)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [230]  [1200/1251]  eta: 0:00:25  lr: 0.000571  min_lr: 0.000571  loss: 3.0212 (2.8006)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6482 (1.6621)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [230]  [1250/1251]  eta: 0:00:00  lr: 0.000571  min_lr: 0.000571  loss: 2.9820 (2.8032)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9565 (1.6790)  time: 0.4216  data: 0.0005  max mem: 40080
Epoch: [230] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.000571  min_lr: 0.000571  loss: 2.9820 (2.8356)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9565 (1.6790)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.6601 (0.6601)  acc1: 88.8000 (88.8000)  acc5: 99.2000 (99.2000)  time: 5.3224  data: 5.0104  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7888 (0.7892)  acc1: 86.4000 (86.0000)  acc5: 98.0000 (97.7818)  time: 0.7217  data: 0.4558  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9331 (0.9036)  acc1: 82.4000 (83.4476)  acc5: 96.4000 (96.4000)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9840 (0.9179)  acc1: 82.4000 (82.9440)  acc5: 96.0000 (96.3680)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4670 s / it)
* Acc@1 83.498 Acc@5 96.506 loss 0.907
Accuracy of the model on the 50000 test images: 83.5%
Max accuracy: 83.53%
Epoch: [231]  [   0/1251]  eta: 1:07:01  lr: 0.000571  min_lr: 0.000571  loss: 2.9220 (2.9220)  weight_decay: 0.0500 (0.0500)  time: 3.2149  data: 2.5989  max mem: 40080
Epoch: [231]  [ 200/1251]  eta: 0:09:01  lr: 0.000568  min_lr: 0.000568  loss: 2.8823 (2.8096)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9616 (1.9823)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [231]  [ 400/1251]  eta: 0:07:11  lr: 0.000566  min_lr: 0.000566  loss: 2.7956 (2.7956)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5213 (1.7526)  time: 0.5001  data: 0.0004  max mem: 40080
Epoch: [231]  [ 600/1251]  eta: 0:05:28  lr: 0.000563  min_lr: 0.000563  loss: 2.9305 (2.8113)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0759 (1.5912)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [231]  [ 800/1251]  eta: 0:03:47  lr: 0.000561  min_lr: 0.000561  loss: 2.7076 (2.8305)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4210 (1.6407)  time: 0.5027  data: 0.0005  max mem: 40080
Epoch: [231]  [1000/1251]  eta: 0:02:06  lr: 0.000558  min_lr: 0.000558  loss: 2.7798 (2.8301)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3700 (1.6167)  time: 0.4992  data: 0.0005  max mem: 40080
Epoch: [231]  [1200/1251]  eta: 0:00:25  lr: 0.000556  min_lr: 0.000556  loss: 2.9607 (2.8322)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4258 (1.6224)  time: 0.4966  data: 0.0005  max mem: 40080
Epoch: [231]  [1250/1251]  eta: 0:00:00  lr: 0.000555  min_lr: 0.000555  loss: 2.8741 (2.8331)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7187 (1.6249)  time: 0.4217  data: 0.0007  max mem: 40080
Epoch: [231] Total time: 0:10:27 (0.5013 s / it)
Averaged stats: lr: 0.000555  min_lr: 0.000555  loss: 2.8741 (2.8336)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7187 (1.6249)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.5840 (0.5840)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.3585  data: 5.0539  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.6885 (0.7214)  acc1: 87.2000 (86.5091)  acc5: 98.0000 (97.8182)  time: 0.7248  data: 0.4597  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.8973 (0.8434)  acc1: 81.6000 (83.4667)  acc5: 96.4000 (96.5714)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9008 (0.8553)  acc1: 81.6000 (83.2320)  acc5: 96.0000 (96.4800)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4685 s / it)
* Acc@1 83.484 Acc@5 96.546 loss 0.844
Accuracy of the model on the 50000 test images: 83.5%
Max accuracy: 83.53%
Epoch: [232]  [   0/1251]  eta: 1:09:34  lr: 0.000555  min_lr: 0.000555  loss: 3.0838 (3.0838)  weight_decay: 0.0500 (0.0500)  time: 3.3366  data: 2.0929  max mem: 40080
Epoch: [232]  [ 200/1251]  eta: 0:09:00  lr: 0.000553  min_lr: 0.000553  loss: 3.0022 (2.8373)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6342 (1.5353)  time: 0.5009  data: 0.0005  max mem: 40080
Epoch: [232]  [ 400/1251]  eta: 0:07:11  lr: 0.000550  min_lr: 0.000550  loss: 2.9211 (2.8172)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1894 (1.6071)  time: 0.5000  data: 0.0004  max mem: 40080
Epoch: [232]  [ 600/1251]  eta: 0:05:28  lr: 0.000548  min_lr: 0.000548  loss: 2.9708 (2.8054)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7118 (1.7201)  time: 0.4985  data: 0.0004  max mem: 40080
Epoch: [232]  [ 800/1251]  eta: 0:03:46  lr: 0.000545  min_lr: 0.000545  loss: 2.9232 (2.8217)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5437 (1.6890)  time: 0.4995  data: 0.0004  max mem: 40080
Epoch: [232]  [1000/1251]  eta: 0:02:05  lr: 0.000543  min_lr: 0.000543  loss: 2.3962 (2.8147)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3443 (1.6409)  time: 0.4976  data: 0.0005  max mem: 40080
Epoch: [232]  [1200/1251]  eta: 0:00:25  lr: 0.000540  min_lr: 0.000540  loss: 2.9589 (2.8151)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7885 (1.6864)  time: 0.5066  data: 0.0004  max mem: 40080
Epoch: [232]  [1250/1251]  eta: 0:00:00  lr: 0.000540  min_lr: 0.000540  loss: 3.0499 (2.8196)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7365 (1.6870)  time: 0.4214  data: 0.0005  max mem: 40080
Epoch: [232] Total time: 0:10:26 (0.5008 s / it)
Averaged stats: lr: 0.000540  min_lr: 0.000540  loss: 3.0499 (2.8235)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7365 (1.6870)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.6030 (0.6030)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 5.4165  data: 5.1055  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7076 (0.7337)  acc1: 85.2000 (85.9273)  acc5: 98.0000 (98.0000)  time: 0.7302  data: 0.4645  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.8936 (0.8553)  acc1: 82.4000 (83.1238)  acc5: 96.0000 (96.6476)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9348 (0.8725)  acc1: 81.6000 (82.6080)  acc5: 96.0000 (96.6080)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4708 s / it)
* Acc@1 83.336 Acc@5 96.538 loss 0.863
Accuracy of the model on the 50000 test images: 83.3%
Max accuracy: 83.53%
Epoch: [233]  [   0/1251]  eta: 1:15:47  lr: 0.000540  min_lr: 0.000540  loss: 1.8402 (1.8402)  weight_decay: 0.0500 (0.0500)  time: 3.6353  data: 2.7852  max mem: 40080
Epoch: [233]  [ 200/1251]  eta: 0:09:00  lr: 0.000537  min_lr: 0.000537  loss: 2.9685 (2.8087)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4807 (1.5958)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [233]  [ 400/1251]  eta: 0:07:11  lr: 0.000535  min_lr: 0.000535  loss: 3.0570 (2.7857)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2501 (1.5474)  time: 0.5065  data: 0.0004  max mem: 40080
Epoch: [233]  [ 600/1251]  eta: 0:05:28  lr: 0.000533  min_lr: 0.000533  loss: 2.8868 (2.7967)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0512 (1.6735)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [233]  [ 800/1251]  eta: 0:03:46  lr: 0.000530  min_lr: 0.000530  loss: 2.7080 (2.8136)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9706 (1.7022)  time: 0.4965  data: 0.0004  max mem: 40080
Epoch: [233]  [1000/1251]  eta: 0:02:05  lr: 0.000528  min_lr: 0.000528  loss: 2.7528 (2.8200)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2276 (1.7058)  time: 0.4971  data: 0.0005  max mem: 40080
Epoch: [233]  [1200/1251]  eta: 0:00:25  lr: 0.000525  min_lr: 0.000525  loss: 2.9952 (2.8344)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4666 (1.6871)  time: 0.4967  data: 0.0005  max mem: 40080
Epoch: [233]  [1250/1251]  eta: 0:00:00  lr: 0.000525  min_lr: 0.000525  loss: 2.9902 (2.8378)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6205 (1.7034)  time: 0.4214  data: 0.0007  max mem: 40080
Epoch: [233] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.000525  min_lr: 0.000525  loss: 2.9902 (2.8278)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6205 (1.7034)
Test:  [ 0/25]  eta: 0:02:24  loss: 0.6899 (0.6899)  acc1: 90.0000 (90.0000)  acc5: 99.6000 (99.6000)  time: 5.7970  data: 5.5114  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7770 (0.8179)  acc1: 86.4000 (86.1818)  acc5: 98.0000 (97.8546)  time: 0.7645  data: 0.5014  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 1.0132 (0.9320)  acc1: 81.6000 (83.0667)  acc5: 95.6000 (96.5333)  time: 0.2610  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0150 (0.9471)  acc1: 80.8000 (82.6560)  acc5: 95.6000 (96.4640)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4853 s / it)
* Acc@1 83.438 Acc@5 96.580 loss 0.935
Accuracy of the model on the 50000 test images: 83.4%
Max accuracy: 83.53%
Epoch: [234]  [   0/1251]  eta: 1:11:38  lr: 0.000525  min_lr: 0.000525  loss: 1.9422 (1.9422)  weight_decay: 0.0500 (0.0500)  time: 3.4360  data: 2.5493  max mem: 40080
Epoch: [234]  [ 200/1251]  eta: 0:09:02  lr: 0.000522  min_lr: 0.000522  loss: 2.8289 (2.7753)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4498 (1.7925)  time: 0.5168  data: 0.0004  max mem: 40080
Epoch: [234]  [ 400/1251]  eta: 0:07:11  lr: 0.000520  min_lr: 0.000520  loss: 3.0943 (2.8051)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7584 (1.7777)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [234]  [ 600/1251]  eta: 0:05:27  lr: 0.000517  min_lr: 0.000517  loss: 2.8283 (2.8393)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3842 (1.9236)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [234]  [ 800/1251]  eta: 0:03:46  lr: 0.000515  min_lr: 0.000515  loss: 3.0458 (2.8589)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3359 (1.7813)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [234]  [1000/1251]  eta: 0:02:05  lr: 0.000513  min_lr: 0.000513  loss: 2.8734 (2.8429)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4232 (1.7358)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [234]  [1200/1251]  eta: 0:00:25  lr: 0.000510  min_lr: 0.000510  loss: 2.9812 (2.8402)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3625 (1.7027)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [234]  [1250/1251]  eta: 0:00:00  lr: 0.000510  min_lr: 0.000510  loss: 2.9302 (2.8426)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3690 (1.6965)  time: 0.4209  data: 0.0005  max mem: 40080
Epoch: [234] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.000510  min_lr: 0.000510  loss: 2.9302 (2.8232)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3690 (1.6965)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.6363 (0.6363)  acc1: 91.2000 (91.2000)  acc5: 98.8000 (98.8000)  time: 5.4276  data: 5.1350  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7660 (0.7782)  acc1: 86.0000 (86.1818)  acc5: 98.0000 (97.8182)  time: 0.7311  data: 0.4671  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9896 (0.9111)  acc1: 81.2000 (83.0476)  acc5: 96.0000 (96.4762)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 1.0076 (0.9249)  acc1: 80.4000 (82.4480)  acc5: 95.6000 (96.3840)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4715 s / it)
* Acc@1 83.422 Acc@5 96.562 loss 0.910
Accuracy of the model on the 50000 test images: 83.4%
Max accuracy: 83.53%
Epoch: [235]  [   0/1251]  eta: 1:13:05  lr: 0.000510  min_lr: 0.000510  loss: 3.1661 (3.1661)  weight_decay: 0.0500 (0.0500)  time: 3.5059  data: 2.7778  max mem: 40080
Epoch: [235]  [ 200/1251]  eta: 0:09:01  lr: 0.000507  min_lr: 0.000507  loss: 2.7138 (2.8086)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7931 (1.9815)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [235]  [ 400/1251]  eta: 0:07:11  lr: 0.000505  min_lr: 0.000505  loss: 2.9314 (2.8293)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2508 (1.8049)  time: 0.4986  data: 0.0004  max mem: 40080
Epoch: [235]  [ 600/1251]  eta: 0:05:28  lr: 0.000502  min_lr: 0.000502  loss: 2.8790 (2.8226)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5138 (1.7901)  time: 0.5041  data: 0.0004  max mem: 40080
Epoch: [235]  [ 800/1251]  eta: 0:03:46  lr: 0.000500  min_lr: 0.000500  loss: 2.7743 (2.8138)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2194 (1.7470)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [235]  [1000/1251]  eta: 0:02:05  lr: 0.000498  min_lr: 0.000498  loss: 3.0622 (2.8207)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3928 (1.7455)  time: 0.4982  data: 0.0004  max mem: 40080
Epoch: [235]  [1200/1251]  eta: 0:00:25  lr: 0.000495  min_lr: 0.000495  loss: 2.5459 (2.8107)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2073 (1.6781)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [235]  [1250/1251]  eta: 0:00:00  lr: 0.000495  min_lr: 0.000495  loss: 3.0647 (2.8124)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3742 (1.6683)  time: 0.4209  data: 0.0005  max mem: 40080
Epoch: [235] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.000495  min_lr: 0.000495  loss: 3.0647 (2.8148)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3742 (1.6683)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.6679 (0.6679)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.4360  data: 5.1373  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8141 (0.8111)  acc1: 85.2000 (85.8182)  acc5: 97.6000 (97.9273)  time: 0.7318  data: 0.4673  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9403 (0.9136)  acc1: 81.6000 (82.9905)  acc5: 96.0000 (96.6286)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9958 (0.9334)  acc1: 81.6000 (82.4000)  acc5: 96.0000 (96.5120)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4718 s / it)
* Acc@1 83.478 Acc@5 96.564 loss 0.916
Accuracy of the model on the 50000 test images: 83.5%
Max accuracy: 83.53%
Epoch: [236]  [   0/1251]  eta: 1:09:07  lr: 0.000495  min_lr: 0.000495  loss: 2.8001 (2.8001)  weight_decay: 0.0500 (0.0500)  time: 3.3156  data: 2.1907  max mem: 40080
Epoch: [236]  [ 200/1251]  eta: 0:08:58  lr: 0.000492  min_lr: 0.000492  loss: 2.5688 (2.7887)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5397 (1.5183)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [236]  [ 400/1251]  eta: 0:07:10  lr: 0.000490  min_lr: 0.000490  loss: 2.5825 (2.8047)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6503 (1.5806)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [236]  [ 600/1251]  eta: 0:05:27  lr: 0.000488  min_lr: 0.000488  loss: 2.8888 (2.8237)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4846 (1.7709)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [236]  [ 800/1251]  eta: 0:03:46  lr: 0.000485  min_lr: 0.000485  loss: 2.7830 (2.8153)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1706 (1.7111)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [236]  [1000/1251]  eta: 0:02:05  lr: 0.000483  min_lr: 0.000483  loss: 2.8995 (2.8053)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2286 (1.6698)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [236]  [1200/1251]  eta: 0:00:25  lr: 0.000481  min_lr: 0.000481  loss: 2.9642 (2.8087)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2490 (1.6245)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [236]  [1250/1251]  eta: 0:00:00  lr: 0.000480  min_lr: 0.000480  loss: 3.0655 (2.8079)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2895 (1.6210)  time: 0.4211  data: 0.0007  max mem: 40080
Epoch: [236] Total time: 0:10:25 (0.4997 s / it)
Averaged stats: lr: 0.000480  min_lr: 0.000480  loss: 3.0655 (2.8109)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2895 (1.6210)
Test:  [ 0/25]  eta: 0:02:07  loss: 0.6540 (0.6540)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 5.1158  data: 4.8067  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8060 (0.8053)  acc1: 86.4000 (86.1091)  acc5: 97.6000 (97.8909)  time: 0.7116  data: 0.4461  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9694 (0.9168)  acc1: 81.6000 (83.0857)  acc5: 96.4000 (96.5524)  time: 0.2662  data: 0.0051  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9883 (0.9299)  acc1: 80.4000 (82.6240)  acc5: 95.6000 (96.4640)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4668 s / it)
* Acc@1 83.506 Acc@5 96.606 loss 0.915
Accuracy of the model on the 50000 test images: 83.5%
Max accuracy: 83.53%
Epoch: [237]  [   0/1251]  eta: 1:13:56  lr: 0.000480  min_lr: 0.000480  loss: 3.0235 (3.0235)  weight_decay: 0.0500 (0.0500)  time: 3.5467  data: 1.6244  max mem: 40080
Epoch: [237]  [ 200/1251]  eta: 0:09:00  lr: 0.000478  min_lr: 0.000478  loss: 3.0554 (2.7662)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7752 (1.7599)  time: 0.4976  data: 0.0004  max mem: 40080
Epoch: [237]  [ 400/1251]  eta: 0:07:11  lr: 0.000475  min_lr: 0.000475  loss: 2.9340 (2.7637)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2030 (1.8883)  time: 0.4980  data: 0.0005  max mem: 40080
Epoch: [237]  [ 600/1251]  eta: 0:05:28  lr: 0.000473  min_lr: 0.000473  loss: 2.9021 (2.7791)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5831 (1.9032)  time: 0.4991  data: 0.0005  max mem: 40080
Epoch: [237]  [ 800/1251]  eta: 0:03:46  lr: 0.000471  min_lr: 0.000471  loss: 2.7851 (2.7912)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4109 (1.8097)  time: 0.4972  data: 0.0004  max mem: 40080
Epoch: [237]  [1000/1251]  eta: 0:02:06  lr: 0.000468  min_lr: 0.000468  loss: 2.8439 (2.7904)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6296 (1.9164)  time: 0.4981  data: 0.0005  max mem: 40080
Epoch: [237]  [1200/1251]  eta: 0:00:25  lr: 0.000466  min_lr: 0.000466  loss: 2.9576 (2.7993)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9040 (1.8977)  time: 0.4973  data: 0.0005  max mem: 40080
Epoch: [237]  [1250/1251]  eta: 0:00:00  lr: 0.000466  min_lr: 0.000466  loss: 2.8209 (2.7986)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9038 (1.9127)  time: 0.4262  data: 0.0007  max mem: 40080
Epoch: [237] Total time: 0:10:26 (0.5006 s / it)
Averaged stats: lr: 0.000466  min_lr: 0.000466  loss: 2.8209 (2.7999)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9038 (1.9127)
Test:  [ 0/25]  eta: 0:02:25  loss: 0.6190 (0.6190)  acc1: 90.0000 (90.0000)  acc5: 98.4000 (98.4000)  time: 5.8130  data: 5.4970  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7435 (0.7482)  acc1: 86.0000 (85.8546)  acc5: 97.2000 (97.7091)  time: 0.7663  data: 0.5000  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9114 (0.8548)  acc1: 82.0000 (83.1048)  acc5: 96.8000 (96.7429)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9148 (0.8681)  acc1: 81.2000 (82.7520)  acc5: 96.4000 (96.6720)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4866 s / it)
* Acc@1 83.512 Acc@5 96.618 loss 0.854
Accuracy of the model on the 50000 test images: 83.5%
Max accuracy: 83.53%
Epoch: [238]  [   0/1251]  eta: 1:12:23  lr: 0.000466  min_lr: 0.000466  loss: 2.7768 (2.7768)  weight_decay: 0.0500 (0.0500)  time: 3.4719  data: 2.4206  max mem: 40080
Epoch: [238]  [ 200/1251]  eta: 0:09:02  lr: 0.000463  min_lr: 0.000463  loss: 2.8356 (2.7838)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1791 (1.8251)  time: 0.5069  data: 0.0004  max mem: 40080
Epoch: [238]  [ 400/1251]  eta: 0:07:11  lr: 0.000461  min_lr: 0.000461  loss: 2.7601 (2.7888)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8273 (1.8110)  time: 0.4973  data: 0.0004  max mem: 40080
Epoch: [238]  [ 600/1251]  eta: 0:05:28  lr: 0.000459  min_lr: 0.000459  loss: 2.7973 (2.7892)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4631 (1.7684)  time: 0.4984  data: 0.0005  max mem: 40080
Epoch: [238]  [ 800/1251]  eta: 0:03:46  lr: 0.000456  min_lr: 0.000456  loss: 2.9373 (2.8052)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3587 (1.7355)  time: 0.4982  data: 0.0005  max mem: 40080
Epoch: [238]  [1000/1251]  eta: 0:02:05  lr: 0.000454  min_lr: 0.000454  loss: 2.8924 (2.8039)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0369 (1.7413)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [238]  [1200/1251]  eta: 0:00:25  lr: 0.000452  min_lr: 0.000452  loss: 2.5562 (2.8050)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5511 (1.7061)  time: 0.4974  data: 0.0004  max mem: 40080
Epoch: [238]  [1250/1251]  eta: 0:00:00  lr: 0.000451  min_lr: 0.000451  loss: 2.8221 (2.8034)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4411 (1.6938)  time: 0.4215  data: 0.0007  max mem: 40080
Epoch: [238] Total time: 0:10:26 (0.5005 s / it)
Averaged stats: lr: 0.000451  min_lr: 0.000451  loss: 2.8221 (2.8006)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4411 (1.6938)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6187 (0.6187)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 5.4890  data: 5.1856  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7379 (0.7464)  acc1: 85.6000 (85.6727)  acc5: 98.0000 (97.7818)  time: 0.7368  data: 0.4717  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.8999 (0.8641)  acc1: 80.8000 (83.0857)  acc5: 96.0000 (96.5905)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9408 (0.8752)  acc1: 80.8000 (82.7360)  acc5: 96.4000 (96.5440)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4738 s / it)
* Acc@1 83.678 Acc@5 96.656 loss 0.858
Accuracy of the model on the 50000 test images: 83.7%
Max accuracy: 83.68%
Epoch: [239]  [   0/1251]  eta: 1:06:44  lr: 0.000451  min_lr: 0.000451  loss: 2.5106 (2.5106)  weight_decay: 0.0500 (0.0500)  time: 3.2007  data: 2.6882  max mem: 40080
Epoch: [239]  [ 200/1251]  eta: 0:09:00  lr: 0.000449  min_lr: 0.000449  loss: 2.8640 (2.7786)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8653 (2.0957)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [239]  [ 400/1251]  eta: 0:07:10  lr: 0.000447  min_lr: 0.000447  loss: 2.8290 (2.7886)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3356 (1.9477)  time: 0.4977  data: 0.0004  max mem: 40080
Epoch: [239]  [ 600/1251]  eta: 0:05:27  lr: 0.000445  min_lr: 0.000445  loss: 2.9876 (2.7998)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4661 (1.8488)  time: 0.5130  data: 0.0004  max mem: 40080
Epoch: [239]  [ 800/1251]  eta: 0:03:46  lr: 0.000442  min_lr: 0.000442  loss: 2.8256 (2.7938)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2184 (1.8562)  time: 0.4970  data: 0.0004  max mem: 40080
Epoch: [239]  [1000/1251]  eta: 0:02:05  lr: 0.000440  min_lr: 0.000440  loss: 2.9695 (2.8068)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4258 (1.8963)  time: 0.4964  data: 0.0005  max mem: 40080
Epoch: [239]  [1200/1251]  eta: 0:00:25  lr: 0.000438  min_lr: 0.000438  loss: 2.7307 (2.8096)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5057 (1.8324)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [239]  [1250/1251]  eta: 0:00:00  lr: 0.000437  min_lr: 0.000437  loss: 2.9072 (2.8089)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1486 (1.8069)  time: 0.4215  data: 0.0006  max mem: 40080
Epoch: [239] Total time: 0:10:25 (0.5001 s / it)
Averaged stats: lr: 0.000437  min_lr: 0.000437  loss: 2.9072 (2.8003)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1486 (1.8069)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.6211 (0.6211)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.2997  data: 5.0099  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7541 (0.7550)  acc1: 86.4000 (86.4364)  acc5: 97.6000 (97.7455)  time: 0.7197  data: 0.4558  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.8768 (0.8672)  acc1: 82.0000 (83.4095)  acc5: 96.4000 (96.5905)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9228 (0.8767)  acc1: 81.2000 (83.0720)  acc5: 96.4000 (96.6080)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4659 s / it)
* Acc@1 83.690 Acc@5 96.758 loss 0.858
Accuracy of the model on the 50000 test images: 83.7%
Max accuracy: 83.69%
Epoch: [240]  [   0/1251]  eta: 0:54:55  lr: 0.000437  min_lr: 0.000437  loss: 2.4850 (2.4850)  weight_decay: 0.0500 (0.0500)  time: 2.6346  data: 2.1244  max mem: 40080
Epoch: [240]  [ 200/1251]  eta: 0:08:55  lr: 0.000435  min_lr: 0.000435  loss: 2.7005 (2.7836)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5926 (1.5625)  time: 0.4977  data: 0.0005  max mem: 40080
Epoch: [240]  [ 400/1251]  eta: 0:07:08  lr: 0.000433  min_lr: 0.000433  loss: 2.8083 (2.7803)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6027 (1.6332)  time: 0.4977  data: 0.0005  max mem: 40080
Epoch: [240]  [ 600/1251]  eta: 0:05:27  lr: 0.000431  min_lr: 0.000431  loss: 2.9351 (2.7709)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4879 (1.8000)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [240]  [ 800/1251]  eta: 0:03:46  lr: 0.000428  min_lr: 0.000428  loss: 2.9556 (2.7875)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2109 (1.7349)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [240]  [1000/1251]  eta: 0:02:05  lr: 0.000426  min_lr: 0.000426  loss: 2.8180 (2.7865)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8279 (1.7891)  time: 0.5050  data: 0.0004  max mem: 40080
Epoch: [240]  [1200/1251]  eta: 0:00:25  lr: 0.000424  min_lr: 0.000424  loss: 2.8935 (2.7910)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7258 (1.7742)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [240]  [1250/1251]  eta: 0:00:00  lr: 0.000423  min_lr: 0.000423  loss: 2.6881 (2.7925)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5343 (1.7657)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [240] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.000423  min_lr: 0.000423  loss: 2.6881 (2.7920)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5343 (1.7657)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.6008 (0.6008)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 5.5638  data: 5.2518  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7062 (0.7147)  acc1: 86.8000 (86.1455)  acc5: 98.0000 (97.7091)  time: 0.7436  data: 0.4777  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.8569 (0.8245)  acc1: 81.6000 (83.2571)  acc5: 96.4000 (96.6857)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.8644 (0.8371)  acc1: 81.6000 (82.8160)  acc5: 96.4000 (96.6560)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4767 s / it)
* Acc@1 83.698 Acc@5 96.760 loss 0.820
Accuracy of the model on the 50000 test images: 83.7%
Max accuracy: 83.70%
Epoch: [241]  [   0/1251]  eta: 1:01:30  lr: 0.000423  min_lr: 0.000423  loss: 2.9891 (2.9891)  weight_decay: 0.0500 (0.0500)  time: 2.9501  data: 2.4445  max mem: 40080
Epoch: [241]  [ 200/1251]  eta: 0:08:57  lr: 0.000421  min_lr: 0.000421  loss: 3.0490 (2.7876)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3898 (1.6385)  time: 0.4979  data: 0.0004  max mem: 40080
Epoch: [241]  [ 400/1251]  eta: 0:07:10  lr: 0.000419  min_lr: 0.000419  loss: 2.6928 (2.8016)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2038 (1.7082)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [241]  [ 600/1251]  eta: 0:05:27  lr: 0.000417  min_lr: 0.000417  loss: 2.6622 (2.7906)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4062 (1.6237)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [241]  [ 800/1251]  eta: 0:03:46  lr: 0.000415  min_lr: 0.000415  loss: 2.7807 (2.7861)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7290 (1.6524)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [241]  [1000/1251]  eta: 0:02:05  lr: 0.000412  min_lr: 0.000412  loss: 2.8518 (2.7979)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3413 (1.7261)  time: 0.4969  data: 0.0004  max mem: 40080
Epoch: [241]  [1200/1251]  eta: 0:00:25  lr: 0.000410  min_lr: 0.000410  loss: 3.0338 (2.7981)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8143 (1.7187)  time: 0.4987  data: 0.0004  max mem: 40080
Epoch: [241]  [1250/1251]  eta: 0:00:00  lr: 0.000410  min_lr: 0.000410  loss: 2.7907 (2.7987)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3898 (1.7120)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [241] Total time: 0:10:24 (0.4992 s / it)
Averaged stats: lr: 0.000410  min_lr: 0.000410  loss: 2.7907 (2.7897)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3898 (1.7120)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.6183 (0.6183)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 5.3181  data: 5.0028  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.7361 (0.7270)  acc1: 86.0000 (86.2545)  acc5: 98.0000 (97.8182)  time: 0.7212  data: 0.4551  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.8854 (0.8429)  acc1: 81.2000 (83.3524)  acc5: 96.4000 (96.6286)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9174 (0.8560)  acc1: 81.2000 (82.8320)  acc5: 96.0000 (96.5760)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4671 s / it)
* Acc@1 83.650 Acc@5 96.556 loss 0.839
Accuracy of the model on the 50000 test images: 83.7%
Max accuracy: 83.70%
Epoch: [242]  [   0/1251]  eta: 1:11:46  lr: 0.000410  min_lr: 0.000410  loss: 2.8979 (2.8979)  weight_decay: 0.0500 (0.0500)  time: 3.4426  data: 1.6100  max mem: 40080
Epoch: [242]  [ 200/1251]  eta: 0:08:59  lr: 0.000407  min_lr: 0.000407  loss: 2.7225 (2.7477)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3608 (1.8206)  time: 0.5050  data: 0.0003  max mem: 40080
Epoch: [242]  [ 400/1251]  eta: 0:07:09  lr: 0.000405  min_lr: 0.000405  loss: 2.9745 (2.7827)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2540 (1.8175)  time: 0.4962  data: 0.0003  max mem: 40080
Epoch: [242]  [ 600/1251]  eta: 0:05:27  lr: 0.000403  min_lr: 0.000403  loss: 2.6663 (2.7727)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6786 (1.9601)  time: 0.4968  data: 0.0004  max mem: 40080
Epoch: [242]  [ 800/1251]  eta: 0:03:46  lr: 0.000401  min_lr: 0.000401  loss: 2.9002 (2.7751)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2078 (1.8390)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [242]  [1000/1251]  eta: 0:02:05  lr: 0.000399  min_lr: 0.000399  loss: 2.7135 (2.7745)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4298 (1.8366)  time: 0.4971  data: 0.0004  max mem: 40080
Epoch: [242]  [1200/1251]  eta: 0:00:25  lr: 0.000397  min_lr: 0.000397  loss: 2.8426 (2.7766)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8568 (1.8284)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [242]  [1250/1251]  eta: 0:00:00  lr: 0.000396  min_lr: 0.000396  loss: 2.9021 (2.7793)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7637 (1.8170)  time: 0.4212  data: 0.0006  max mem: 40080
Epoch: [242] Total time: 0:10:25 (0.4996 s / it)
Averaged stats: lr: 0.000396  min_lr: 0.000396  loss: 2.9021 (2.7786)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7637 (1.8170)
Test:  [ 0/25]  eta: 0:01:53  loss: 0.6869 (0.6869)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 4.5419  data: 4.2131  max mem: 40080
Test:  [10/25]  eta: 0:00:10  loss: 0.8159 (0.8133)  acc1: 86.4000 (86.0000)  acc5: 98.0000 (97.7091)  time: 0.6822  data: 0.4152  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9596 (0.9242)  acc1: 82.0000 (83.4095)  acc5: 96.4000 (96.5143)  time: 0.2785  data: 0.0178  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9596 (0.9364)  acc1: 82.0000 (82.8160)  acc5: 96.0000 (96.5120)  time: 0.2609  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4495 s / it)
* Acc@1 83.756 Acc@5 96.630 loss 0.919
Accuracy of the model on the 50000 test images: 83.8%
Max accuracy: 83.76%
Epoch: [243]  [   0/1251]  eta: 0:56:12  lr: 0.000396  min_lr: 0.000396  loss: 3.0348 (3.0348)  weight_decay: 0.0500 (0.0500)  time: 2.6959  data: 2.1943  max mem: 40080
Epoch: [243]  [ 200/1251]  eta: 0:08:57  lr: 0.000394  min_lr: 0.000394  loss: 2.5693 (2.7530)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6412 (2.1513)  time: 0.5051  data: 0.0004  max mem: 40080
Epoch: [243]  [ 400/1251]  eta: 0:07:09  lr: 0.000392  min_lr: 0.000392  loss: 2.7921 (2.7677)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5942 (2.0020)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [243]  [ 600/1251]  eta: 0:05:27  lr: 0.000390  min_lr: 0.000390  loss: 2.5074 (2.7489)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6015 (1.9103)  time: 0.5165  data: 0.0004  max mem: 40080
Epoch: [243]  [ 800/1251]  eta: 0:03:46  lr: 0.000388  min_lr: 0.000388  loss: 2.7347 (2.7493)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6491 (1.9168)  time: 0.4981  data: 0.0004  max mem: 40080
Epoch: [243]  [1000/1251]  eta: 0:02:05  lr: 0.000385  min_lr: 0.000385  loss: 2.8024 (2.7569)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5232 (1.8889)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [243]  [1200/1251]  eta: 0:00:25  lr: 0.000383  min_lr: 0.000383  loss: 2.7385 (2.7646)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4144 (1.8238)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [243]  [1250/1251]  eta: 0:00:00  lr: 0.000383  min_lr: 0.000383  loss: 2.8733 (2.7670)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7638 (1.8382)  time: 0.4210  data: 0.0006  max mem: 40080
Epoch: [243] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.000383  min_lr: 0.000383  loss: 2.8733 (2.7744)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7638 (1.8382)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6416 (0.6416)  acc1: 90.8000 (90.8000)  acc5: 99.2000 (99.2000)  time: 5.5049  data: 5.2182  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7815 (0.7883)  acc1: 86.0000 (86.0727)  acc5: 98.0000 (97.7818)  time: 0.7384  data: 0.4748  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9571 (0.8977)  acc1: 82.0000 (83.5048)  acc5: 96.0000 (96.5524)  time: 0.2615  data: 0.0003  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9591 (0.9117)  acc1: 82.0000 (83.0080)  acc5: 96.0000 (96.4480)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4744 s / it)
* Acc@1 83.748 Acc@5 96.620 loss 0.893
Accuracy of the model on the 50000 test images: 83.7%
Max accuracy: 83.76%
Epoch: [244]  [   0/1251]  eta: 1:14:26  lr: 0.000383  min_lr: 0.000383  loss: 2.3739 (2.3739)  weight_decay: 0.0500 (0.0500)  time: 3.5701  data: 2.9571  max mem: 40080
Epoch: [244]  [ 200/1251]  eta: 0:08:59  lr: 0.000381  min_lr: 0.000381  loss: 2.6610 (2.7483)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5475 (1.6699)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [244]  [ 400/1251]  eta: 0:07:09  lr: 0.000379  min_lr: 0.000379  loss: 2.9391 (2.7509)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3143 (1.6297)  time: 0.4975  data: 0.0004  max mem: 40080
Epoch: [244]  [ 600/1251]  eta: 0:05:27  lr: 0.000377  min_lr: 0.000377  loss: 2.6655 (2.7729)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5747 (1.6390)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [244]  [ 800/1251]  eta: 0:03:46  lr: 0.000374  min_lr: 0.000374  loss: 2.9824 (2.7611)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2673 (1.6917)  time: 0.4964  data: 0.0004  max mem: 40080
Epoch: [244]  [1000/1251]  eta: 0:02:05  lr: 0.000372  min_lr: 0.000372  loss: 2.6718 (2.7639)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1539 (1.6461)  time: 0.4967  data: 0.0004  max mem: 40080
Epoch: [244]  [1200/1251]  eta: 0:00:25  lr: 0.000370  min_lr: 0.000370  loss: 2.6023 (2.7666)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7329 (1.6480)  time: 0.4959  data: 0.0004  max mem: 40080
Epoch: [244]  [1250/1251]  eta: 0:00:00  lr: 0.000370  min_lr: 0.000370  loss: 2.8604 (2.7661)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9156 (1.6730)  time: 0.4215  data: 0.0007  max mem: 40080
Epoch: [244] Total time: 0:10:24 (0.4993 s / it)
Averaged stats: lr: 0.000370  min_lr: 0.000370  loss: 2.8604 (2.7616)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9156 (1.6730)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.6175 (0.6175)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 5.5820  data: 5.2806  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7575 (0.7433)  acc1: 85.6000 (86.0727)  acc5: 98.0000 (97.7455)  time: 0.7453  data: 0.4804  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9169 (0.8528)  acc1: 82.0000 (83.3333)  acc5: 96.4000 (96.7429)  time: 0.2615  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9169 (0.8642)  acc1: 81.6000 (82.9280)  acc5: 96.4000 (96.6560)  time: 0.2614  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4778 s / it)
* Acc@1 83.646 Acc@5 96.668 loss 0.850
Accuracy of the model on the 50000 test images: 83.6%
Max accuracy: 83.76%
Epoch: [245]  [   0/1251]  eta: 1:08:34  lr: 0.000370  min_lr: 0.000370  loss: 3.0158 (3.0158)  weight_decay: 0.0500 (0.0500)  time: 3.2886  data: 2.7002  max mem: 40080
Epoch: [245]  [ 200/1251]  eta: 0:08:58  lr: 0.000368  min_lr: 0.000368  loss: 2.8790 (2.7218)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3405 (2.0057)  time: 0.4996  data: 0.0005  max mem: 40080
Epoch: [245]  [ 400/1251]  eta: 0:07:11  lr: 0.000366  min_lr: 0.000366  loss: 2.9778 (2.7441)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.6966 (2.0486)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [245]  [ 600/1251]  eta: 0:05:27  lr: 0.000364  min_lr: 0.000364  loss: 2.8033 (2.7568)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3216 (1.8615)  time: 0.4972  data: 0.0005  max mem: 40080
Epoch: [245]  [ 800/1251]  eta: 0:03:46  lr: 0.000362  min_lr: 0.000362  loss: 2.8567 (2.7694)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3627 (1.8481)  time: 0.4981  data: 0.0005  max mem: 40080
Epoch: [245]  [1000/1251]  eta: 0:02:05  lr: 0.000359  min_lr: 0.000359  loss: 2.6727 (2.7609)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3934 (1.8336)  time: 0.4963  data: 0.0004  max mem: 40080
Epoch: [245]  [1200/1251]  eta: 0:00:25  lr: 0.000357  min_lr: 0.000357  loss: 2.8199 (2.7625)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6315 (1.8331)  time: 0.4981  data: 0.0005  max mem: 40080
Epoch: [245]  [1250/1251]  eta: 0:00:00  lr: 0.000357  min_lr: 0.000357  loss: 2.8380 (2.7618)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3612 (1.8153)  time: 0.4216  data: 0.0006  max mem: 40080
Epoch: [245] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.000357  min_lr: 0.000357  loss: 2.8380 (2.7675)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3612 (1.8153)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6251 (0.6251)  acc1: 90.4000 (90.4000)  acc5: 98.4000 (98.4000)  time: 5.5495  data: 5.2468  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7394 (0.7604)  acc1: 86.8000 (86.2182)  acc5: 98.0000 (97.6727)  time: 0.7422  data: 0.4773  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9192 (0.8659)  acc1: 81.6000 (83.4857)  acc5: 96.4000 (96.5143)  time: 0.2613  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9192 (0.8780)  acc1: 80.8000 (83.0400)  acc5: 96.0000 (96.4320)  time: 0.2612  data: 0.0001  max mem: 40080
Test: Total time: 0:00:11 (0.4771 s / it)
* Acc@1 83.774 Acc@5 96.584 loss 0.857
Accuracy of the model on the 50000 test images: 83.8%
Max accuracy: 83.77%
Epoch: [246]  [   0/1251]  eta: 0:58:02  lr: 0.000357  min_lr: 0.000357  loss: 2.7950 (2.7950)  weight_decay: 0.0500 (0.0500)  time: 2.7836  data: 2.2824  max mem: 40080
Epoch: [246]  [ 200/1251]  eta: 0:08:58  lr: 0.000355  min_lr: 0.000355  loss: 2.9724 (2.7998)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6334 (1.7720)  time: 0.4980  data: 0.0004  max mem: 40080
Epoch: [246]  [ 400/1251]  eta: 0:07:09  lr: 0.000353  min_lr: 0.000353  loss: 2.9020 (2.7735)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4059 (1.7146)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [246]  [ 600/1251]  eta: 0:05:26  lr: 0.000351  min_lr: 0.000351  loss: 2.7008 (2.7683)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4321 (1.7463)  time: 0.4966  data: 0.0004  max mem: 40080
Epoch: [246]  [ 800/1251]  eta: 0:03:46  lr: 0.000349  min_lr: 0.000349  loss: 2.7041 (2.7682)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4962  data: 0.0004  max mem: 40080
Epoch: [246]  [1000/1251]  eta: 0:02:05  lr: 0.000347  min_lr: 0.000347  loss: 2.9741 (2.7650)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8356 (nan)  time: 0.4960  data: 0.0004  max mem: 40080
Epoch: [246]  [1200/1251]  eta: 0:00:25  lr: 0.000345  min_lr: 0.000345  loss: 2.8826 (2.7739)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3315 (nan)  time: 0.5022  data: 0.0004  max mem: 40080
Epoch: [246]  [1250/1251]  eta: 0:00:00  lr: 0.000344  min_lr: 0.000344  loss: 2.8087 (2.7780)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7035 (nan)  time: 0.4211  data: 0.0005  max mem: 40080
Epoch: [246] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.000344  min_lr: 0.000344  loss: 2.8087 (2.7586)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7035 (nan)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.6500 (0.6500)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.6276  data: 5.3199  max mem: 40080
Test:  [10/25]  eta: 0:00:11  loss: 0.7545 (0.7601)  acc1: 86.4000 (86.3636)  acc5: 98.0000 (97.8909)  time: 0.7493  data: 0.4839  max mem: 40080
Test:  [20/25]  eta: 0:00:02  loss: 0.9384 (0.8723)  acc1: 82.4000 (83.6762)  acc5: 96.0000 (96.6095)  time: 0.2614  data: 0.0002  max mem: 40080
Test:  [24/25]  eta: 0:00:00  loss: 0.9459 (0.8852)  acc1: 82.0000 (83.2640)  acc5: 96.0000 (96.5600)  time: 0.2613  data: 0.0001  max mem: 40080
Test: Total time: 0:00:12 (0.4805 s / it)
* Acc@1 83.864 Acc@5 96.604 loss 0.870
Accuracy of the model on the 50000 test images: 83.9%
Max accuracy: 83.86%
Epoch: [247]  [   0/1251]  eta: 0:53:07  lr: 0.000344  min_lr: 0.000344  loss: 2.6061 (2.6061)  weight_decay: 0.0500 (0.0500)  time: 2.5477  data: 2.0334  max mem: 40080
Epoch: [247]  [ 200/1251]  eta: 0:08:55  lr: 0.000342  min_lr: 0.000342  loss: 2.1808 (2.6442)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4425 (1.7452)  time: 0.4970  data: 0.0003  max mem: 40080
| distributed init (rank 0): env://, gpu 0
| distributed init (rank 2): env://, gpu 2
| distributed init (rank 1): env://, gpu 1
| distributed init (rank 7): env://, gpu 7
| distributed init (rank 5): env://, gpu 5
| distributed init (rank 4): env://, gpu 4
| distributed init (rank 6): env://, gpu 6
| distributed init (rank 3): env://, gpu 3
Namespace(batch_size=128, epochs=300, update_freq=4, model='base', drop_path=0, input_size=224, layer_scale_init_value=1e-06, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, model_ema_eval=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=5.0, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=0.004, layer_decay=1.0, min_lr=1e-06, warmup_epochs=20, warmup_steps=-1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', crop_pct=None, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', head_init_scale=1.0, model_key='model|module', model_prefix='', data_path='/dev/shm/imagenet', eval_data_path=None, nb_classes=1000, imagenet_default_mean_and_std=True, data_set='IMNET', output_dir='./checkpoint_base_8.5G', log_dir=None, device='cuda', seed=0, resume='', auto_resume=True, save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, start_epoch=0, eval=False, dist_eval=True, disable_eval=False, num_workers=10, pin_mem=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', use_amp=True, enable_wandb=False, project='convnext', wandb_ckpt=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
Transform = 
RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic)
RandomHorizontalFlip(p=0.5)
RandAugment(n=2, ops=
	AugmentOp(name=AutoContrast, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Equalize, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Invert, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Rotate, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=PosterizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeAdd, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ColorIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ContrastIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=BrightnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SharpnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearX, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearY, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateXRel, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateYRel, p=0.5, m=9, mstd=0.5))
ToTensor()
Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))
RandomErasing(p=0.25, mode=pixel, count=(1, 1))
---------------------------
reading from datapath /dev/shm/imagenet
Number of the class = 1000
Transform = 
Resize(size=256, interpolation=bicubic, max_size=None, antialias=True)
CenterCrop(size=(224, 224))
ToTensor()
Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
---------------------------
reading from datapath /dev/shm/imagenet
Number of the class = 1000
Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7fd4180d4310>
Mixup is activated!
Model = SPCNN(
  (first_conv): ConvX(
    (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
  )
  (layer1): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): Identity()
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.010)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.020)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.030)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.040)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer2): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.050)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.060)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.070)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.080)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.090)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (5): BottleNeck(
      (drop_path): DropPath(drop_prob=0.100)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (6): BottleNeck(
      (drop_path): DropPath(drop_prob=0.110)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (7): BottleNeck(
      (drop_path): DropPath(drop_prob=0.120)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (8): BottleNeck(
      (drop_path): DropPath(drop_prob=0.130)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer3): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=768, bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.140)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.150)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.160)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.170)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.180)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (5): BottleNeck(
      (drop_path): DropPath(drop_prob=0.190)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (6): BottleNeck(
      (drop_path): DropPath(drop_prob=0.200)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (7): BottleNeck(
      (drop_path): DropPath(drop_prob=0.210)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (8): BottleNeck(
      (drop_path): DropPath(drop_prob=0.220)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (9): BottleNeck(
      (drop_path): DropPath(drop_prob=0.230)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (10): BottleNeck(
      (drop_path): DropPath(drop_prob=0.240)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (11): BottleNeck(
      (drop_path): DropPath(drop_prob=0.250)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (12): BottleNeck(
      (drop_path): DropPath(drop_prob=0.260)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (13): BottleNeck(
      (drop_path): DropPath(drop_prob=0.270)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (14): BottleNeck(
      (drop_path): DropPath(drop_prob=0.280)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (15): BottleNeck(
      (drop_path): DropPath(drop_prob=0.290)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (16): BottleNeck(
      (drop_path): DropPath(drop_prob=0.300)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer4): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1536, bias=False)
          (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.310)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.320)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.330)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.340)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.350)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (head): ConvX(
    (conv): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (classifier): MlpHead(
    (fc1): Linear(in_features=1024, out_features=2048, bias=False)
    (norm): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
    (drop): Dropout(p=0.2, inplace=False)
    (fc2): Linear(in_features=2048, out_features=1000, bias=False)
  )
)
number of params: 48903328
LR = 0.00400000
Batch size = 4096
Update frequent = 4
Number of training examples = 1281167
Number of training training per epoch = 312
Param groups = {
  "decay": {
    "weight_decay": 0.05,
    "params": [
      "first_conv.conv.weight",
      "layer1.0.mlp.0.conv.weight",
      "layer1.0.mlp.1.conv.weight",
      "layer1.0.mlp.2.conv.weight",
      "layer1.0.skip.0.conv.weight",
      "layer1.0.skip.1.conv.weight",
      "layer1.1.sblock_in.conv.weight",
      "layer1.1.sblock_dw.conv.weight",
      "layer1.1.sblock_proj.conv.weight",
      "layer1.1.mblock.0.conv.weight",
      "layer1.1.mblock.1.branch_1.1.conv.weight",
      "layer1.1.mblock.1.branch_2.1.conv.weight",
      "layer1.1.mblock.1.branch_3.1.conv.weight",
      "layer1.1.mblock.2.conv.weight",
      "layer1.2.sblock_in.conv.weight",
      "layer1.2.sblock_dw.conv.weight",
      "layer1.2.sblock_proj.conv.weight",
      "layer1.2.mblock.0.conv.weight",
      "layer1.2.mblock.1.branch_1.1.conv.weight",
      "layer1.2.mblock.1.branch_2.1.conv.weight",
      "layer1.2.mblock.1.branch_3.1.conv.weight",
      "layer1.2.mblock.2.conv.weight",
      "layer1.3.sblock_in.conv.weight",
      "layer1.3.sblock_dw.conv.weight",
      "layer1.3.sblock_proj.conv.weight",
      "layer1.3.mblock.0.conv.weight",
      "layer1.3.mblock.1.branch_1.1.conv.weight",
      "layer1.3.mblock.1.branch_2.1.conv.weight",
      "layer1.3.mblock.1.branch_3.1.conv.weight",
      "layer1.3.mblock.2.conv.weight",
      "layer1.4.sblock_in.conv.weight",
      "layer1.4.sblock_dw.conv.weight",
      "layer1.4.sblock_proj.conv.weight",
      "layer1.4.mblock.0.conv.weight",
      "layer1.4.mblock.1.branch_1.1.conv.weight",
      "layer1.4.mblock.1.branch_2.1.conv.weight",
      "layer1.4.mblock.1.branch_3.1.conv.weight",
      "layer1.4.mblock.2.conv.weight",
      "layer2.0.mlp.0.conv.weight",
      "layer2.0.mlp.1.conv.weight",
      "layer2.0.mlp.2.conv.weight",
      "layer2.0.skip.0.conv.weight",
      "layer2.0.skip.1.conv.weight",
      "layer2.1.sblock_in.conv.weight",
      "layer2.1.sblock_dw.conv.weight",
      "layer2.1.sblock_proj.conv.weight",
      "layer2.1.mblock.0.conv.weight",
      "layer2.1.mblock.1.branch_1.1.conv.weight",
      "layer2.1.mblock.1.branch_2.1.conv.weight",
      "layer2.1.mblock.1.branch_3.1.conv.weight",
      "layer2.1.mblock.2.conv.weight",
      "layer2.2.sblock_in.conv.weight",
      "layer2.2.sblock_dw.conv.weight",
      "layer2.2.sblock_proj.conv.weight",
      "layer2.2.mblock.0.conv.weight",
      "layer2.2.mblock.1.branch_1.1.conv.weight",
      "layer2.2.mblock.1.branch_2.1.conv.weight",
      "layer2.2.mblock.1.branch_3.1.conv.weight",
      "layer2.2.mblock.2.conv.weight",
      "layer2.3.sblock_in.conv.weight",
      "layer2.3.sblock_dw.conv.weight",
      "layer2.3.sblock_proj.conv.weight",
      "layer2.3.mblock.0.conv.weight",
      "layer2.3.mblock.1.branch_1.1.conv.weight",
      "layer2.3.mblock.1.branch_2.1.conv.weight",
      "layer2.3.mblock.1.branch_3.1.conv.weight",
      "layer2.3.mblock.2.conv.weight",
      "layer2.4.sblock_in.conv.weight",
      "layer2.4.sblock_dw.conv.weight",
      "layer2.4.sblock_proj.conv.weight",
      "layer2.4.mblock.0.conv.weight",
      "layer2.4.mblock.1.branch_1.1.conv.weight",
      "layer2.4.mblock.1.branch_2.1.conv.weight",
      "layer2.4.mblock.1.branch_3.1.conv.weight",
      "layer2.4.mblock.2.conv.weight",
      "layer2.5.sblock_in.conv.weight",
      "layer2.5.sblock_dw.conv.weight",
      "layer2.5.sblock_proj.conv.weight",
      "layer2.5.mblock.0.conv.weight",
      "layer2.5.mblock.1.branch_1.1.conv.weight",
      "layer2.5.mblock.1.branch_2.1.conv.weight",
      "layer2.5.mblock.1.branch_3.1.conv.weight",
      "layer2.5.mblock.2.conv.weight",
      "layer2.6.sblock_in.conv.weight",
      "layer2.6.sblock_dw.conv.weight",
      "layer2.6.sblock_proj.conv.weight",
      "layer2.6.mblock.0.conv.weight",
      "layer2.6.mblock.1.branch_1.1.conv.weight",
      "layer2.6.mblock.1.branch_2.1.conv.weight",
      "layer2.6.mblock.1.branch_3.1.conv.weight",
      "layer2.6.mblock.2.conv.weight",
      "layer2.7.sblock_in.conv.weight",
      "layer2.7.sblock_dw.conv.weight",
      "layer2.7.sblock_proj.conv.weight",
      "layer2.7.mblock.0.conv.weight",
      "layer2.7.mblock.1.branch_1.1.conv.weight",
      "layer2.7.mblock.1.branch_2.1.conv.weight",
      "layer2.7.mblock.1.branch_3.1.conv.weight",
      "layer2.7.mblock.2.conv.weight",
      "layer2.8.sblock_in.conv.weight",
      "layer2.8.sblock_dw.conv.weight",
      "layer2.8.sblock_proj.conv.weight",
      "layer2.8.mblock.0.conv.weight",
      "layer2.8.mblock.1.branch_1.1.conv.weight",
      "layer2.8.mblock.1.branch_2.1.conv.weight",
      "layer2.8.mblock.1.branch_3.1.conv.weight",
      "layer2.8.mblock.2.conv.weight",
      "layer3.0.mlp.0.conv.weight",
      "layer3.0.mlp.1.conv.weight",
      "layer3.0.mlp.2.conv.weight",
      "layer3.0.skip.0.conv.weight",
      "layer3.0.skip.1.conv.weight",
      "layer3.1.sblock_in.conv.weight",
      "layer3.1.sblock_dw.conv.weight",
      "layer3.1.sblock_proj.conv.weight",
      "layer3.1.mblock.0.conv.weight",
      "layer3.1.mblock.1.branch_1.1.conv.weight",
      "layer3.1.mblock.1.branch_2.1.conv.weight",
      "layer3.1.mblock.1.branch_3.1.conv.weight",
      "layer3.1.mblock.2.conv.weight",
      "layer3.2.sblock_in.conv.weight",
      "layer3.2.sblock_dw.conv.weight",
      "layer3.2.sblock_proj.conv.weight",
      "layer3.2.mblock.0.conv.weight",
      "layer3.2.mblock.1.branch_1.1.conv.weight",
      "layer3.2.mblock.1.branch_2.1.conv.weight",
      "layer3.2.mblock.1.branch_3.1.conv.weight",
      "layer3.2.mblock.2.conv.weight",
      "layer3.3.sblock_in.conv.weight",
      "layer3.3.sblock_dw.conv.weight",
      "layer3.3.sblock_proj.conv.weight",
      "layer3.3.mblock.0.conv.weight",
      "layer3.3.mblock.1.branch_1.1.conv.weight",
      "layer3.3.mblock.1.branch_2.1.conv.weight",
      "layer3.3.mblock.1.branch_3.1.conv.weight",
      "layer3.3.mblock.2.conv.weight",
      "layer3.4.sblock_in.conv.weight",
      "layer3.4.sblock_dw.conv.weight",
      "layer3.4.sblock_proj.conv.weight",
      "layer3.4.mblock.0.conv.weight",
      "layer3.4.mblock.1.branch_1.1.conv.weight",
      "layer3.4.mblock.1.branch_2.1.conv.weight",
      "layer3.4.mblock.1.branch_3.1.conv.weight",
      "layer3.4.mblock.2.conv.weight",
      "layer3.5.sblock_in.conv.weight",
      "layer3.5.sblock_dw.conv.weight",
      "layer3.5.sblock_proj.conv.weight",
      "layer3.5.mblock.0.conv.weight",
      "layer3.5.mblock.1.branch_1.1.conv.weight",
      "layer3.5.mblock.1.branch_2.1.conv.weight",
      "layer3.5.mblock.1.branch_3.1.conv.weight",
      "layer3.5.mblock.2.conv.weight",
      "layer3.6.sblock_in.conv.weight",
      "layer3.6.sblock_dw.conv.weight",
      "layer3.6.sblock_proj.conv.weight",
      "layer3.6.mblock.0.conv.weight",
      "layer3.6.mblock.1.branch_1.1.conv.weight",
      "layer3.6.mblock.1.branch_2.1.conv.weight",
      "layer3.6.mblock.1.branch_3.1.conv.weight",
      "layer3.6.mblock.2.conv.weight",
      "layer3.7.sblock_in.conv.weight",
      "layer3.7.sblock_dw.conv.weight",
      "layer3.7.sblock_proj.conv.weight",
      "layer3.7.mblock.0.conv.weight",
      "layer3.7.mblock.1.branch_1.1.conv.weight",
      "layer3.7.mblock.1.branch_2.1.conv.weight",
      "layer3.7.mblock.1.branch_3.1.conv.weight",
      "layer3.7.mblock.2.conv.weight",
      "layer3.8.sblock_in.conv.weight",
      "layer3.8.sblock_dw.conv.weight",
      "layer3.8.sblock_proj.conv.weight",
      "layer3.8.mblock.0.conv.weight",
      "layer3.8.mblock.1.branch_1.1.conv.weight",
      "layer3.8.mblock.1.branch_2.1.conv.weight",
      "layer3.8.mblock.1.branch_3.1.conv.weight",
      "layer3.8.mblock.2.conv.weight",
      "layer3.9.sblock_in.conv.weight",
      "layer3.9.sblock_dw.conv.weight",
      "layer3.9.sblock_proj.conv.weight",
      "layer3.9.mblock.0.conv.weight",
      "layer3.9.mblock.1.branch_1.1.conv.weight",
      "layer3.9.mblock.1.branch_2.1.conv.weight",
      "layer3.9.mblock.1.branch_3.1.conv.weight",
      "layer3.9.mblock.2.conv.weight",
      "layer3.10.sblock_in.conv.weight",
      "layer3.10.sblock_dw.conv.weight",
      "layer3.10.sblock_proj.conv.weight",
      "layer3.10.mblock.0.conv.weight",
      "layer3.10.mblock.1.branch_1.1.conv.weight",
      "layer3.10.mblock.1.branch_2.1.conv.weight",
      "layer3.10.mblock.1.branch_3.1.conv.weight",
      "layer3.10.mblock.2.conv.weight",
      "layer3.11.sblock_in.conv.weight",
      "layer3.11.sblock_dw.conv.weight",
      "layer3.11.sblock_proj.conv.weight",
      "layer3.11.mblock.0.conv.weight",
      "layer3.11.mblock.1.branch_1.1.conv.weight",
      "layer3.11.mblock.1.branch_2.1.conv.weight",
      "layer3.11.mblock.1.branch_3.1.conv.weight",
      "layer3.11.mblock.2.conv.weight",
      "layer3.12.sblock_in.conv.weight",
      "layer3.12.sblock_dw.conv.weight",
      "layer3.12.sblock_proj.conv.weight",
      "layer3.12.mblock.0.conv.weight",
      "layer3.12.mblock.1.branch_1.1.conv.weight",
      "layer3.12.mblock.1.branch_2.1.conv.weight",
      "layer3.12.mblock.1.branch_3.1.conv.weight",
      "layer3.12.mblock.2.conv.weight",
      "layer3.13.sblock_in.conv.weight",
      "layer3.13.sblock_dw.conv.weight",
      "layer3.13.sblock_proj.conv.weight",
      "layer3.13.mblock.0.conv.weight",
      "layer3.13.mblock.1.branch_1.1.conv.weight",
      "layer3.13.mblock.1.branch_2.1.conv.weight",
      "layer3.13.mblock.1.branch_3.1.conv.weight",
      "layer3.13.mblock.2.conv.weight",
      "layer3.14.sblock_in.conv.weight",
      "layer3.14.sblock_dw.conv.weight",
      "layer3.14.sblock_proj.conv.weight",
      "layer3.14.mblock.0.conv.weight",
      "layer3.14.mblock.1.branch_1.1.conv.weight",
      "layer3.14.mblock.1.branch_2.1.conv.weight",
      "layer3.14.mblock.1.branch_3.1.conv.weight",
      "layer3.14.mblock.2.conv.weight",
      "layer3.15.sblock_in.conv.weight",
      "layer3.15.sblock_dw.conv.weight",
      "layer3.15.sblock_proj.conv.weight",
      "layer3.15.mblock.0.conv.weight",
      "layer3.15.mblock.1.branch_1.1.conv.weight",
      "layer3.15.mblock.1.branch_2.1.conv.weight",
      "layer3.15.mblock.1.branch_3.1.conv.weight",
      "layer3.15.mblock.2.conv.weight",
      "layer3.16.sblock_in.conv.weight",
      "layer3.16.sblock_dw.conv.weight",
      "layer3.16.sblock_proj.conv.weight",
      "layer3.16.mblock.0.conv.weight",
      "layer3.16.mblock.1.branch_1.1.conv.weight",
      "layer3.16.mblock.1.branch_2.1.conv.weight",
      "layer3.16.mblock.1.branch_3.1.conv.weight",
      "layer3.16.mblock.2.conv.weight",
      "layer4.0.mlp.0.conv.weight",
      "layer4.0.mlp.1.conv.weight",
      "layer4.0.mlp.2.conv.weight",
      "layer4.0.skip.0.conv.weight",
      "layer4.0.skip.1.conv.weight",
      "layer4.1.sblock_in.conv.weight",
      "layer4.1.sblock_dw.conv.weight",
      "layer4.1.sblock_proj.conv.weight",
      "layer4.1.mblock.0.conv.weight",
      "layer4.1.mblock.1.branch_1.1.conv.weight",
      "layer4.1.mblock.1.branch_2.1.conv.weight",
      "layer4.1.mblock.1.branch_3.1.conv.weight",
      "layer4.1.mblock.2.conv.weight",
      "layer4.2.sblock_in.conv.weight",
      "layer4.2.sblock_dw.conv.weight",
      "layer4.2.sblock_proj.conv.weight",
      "layer4.2.mblock.0.conv.weight",
      "layer4.2.mblock.1.branch_1.1.conv.weight",
      "layer4.2.mblock.1.branch_2.1.conv.weight",
      "layer4.2.mblock.1.branch_3.1.conv.weight",
      "layer4.2.mblock.2.conv.weight",
      "layer4.3.sblock_in.conv.weight",
      "layer4.3.sblock_dw.conv.weight",
      "layer4.3.sblock_proj.conv.weight",
      "layer4.3.mblock.0.conv.weight",
      "layer4.3.mblock.1.branch_1.1.conv.weight",
      "layer4.3.mblock.1.branch_2.1.conv.weight",
      "layer4.3.mblock.1.branch_3.1.conv.weight",
      "layer4.3.mblock.2.conv.weight",
      "layer4.4.sblock_in.conv.weight",
      "layer4.4.sblock_dw.conv.weight",
      "layer4.4.sblock_proj.conv.weight",
      "layer4.4.mblock.0.conv.weight",
      "layer4.4.mblock.1.branch_1.1.conv.weight",
      "layer4.4.mblock.1.branch_2.1.conv.weight",
      "layer4.4.mblock.1.branch_3.1.conv.weight",
      "layer4.4.mblock.2.conv.weight",
      "head.conv.weight",
      "classifier.fc1.weight",
      "classifier.fc2.weight"
    ],
    "lr_scale": 1.0
  },
  "no_decay": {
    "weight_decay": 0.0,
    "params": [
      "first_conv.norm.weight",
      "first_conv.norm.bias",
      "layer1.0.mlp.0.norm.weight",
      "layer1.0.mlp.0.norm.bias",
      "layer1.0.mlp.1.norm.weight",
      "layer1.0.mlp.1.norm.bias",
      "layer1.0.mlp.2.norm.weight",
      "layer1.0.mlp.2.norm.bias",
      "layer1.0.skip.0.norm.weight",
      "layer1.0.skip.0.norm.bias",
      "layer1.0.skip.1.norm.weight",
      "layer1.0.skip.1.norm.bias",
      "layer1.1.sblock_in.norm.weight",
      "layer1.1.sblock_in.norm.bias",
      "layer1.1.sblock_dw.norm.weight",
      "layer1.1.sblock_dw.norm.bias",
      "layer1.1.sblock_proj.norm.weight",
      "layer1.1.sblock_proj.norm.bias",
      "layer1.1.mblock.0.norm.weight",
      "layer1.1.mblock.0.norm.bias",
      "layer1.1.mblock.1.branch_1.1.norm.weight",
      "layer1.1.mblock.1.branch_1.1.norm.bias",
      "layer1.1.mblock.1.branch_2.1.norm.weight",
      "layer1.1.mblock.1.branch_2.1.norm.bias",
      "layer1.1.mblock.1.branch_3.1.norm.weight",
      "layer1.1.mblock.1.branch_3.1.norm.bias",
      "layer1.1.mblock.2.norm.weight",
      "layer1.1.mblock.2.norm.bias",
      "layer1.2.sblock_in.norm.weight",
      "layer1.2.sblock_in.norm.bias",
      "layer1.2.sblock_dw.norm.weight",
      "layer1.2.sblock_dw.norm.bias",
      "layer1.2.sblock_proj.norm.weight",
      "layer1.2.sblock_proj.norm.bias",
      "layer1.2.mblock.0.norm.weight",
      "layer1.2.mblock.0.norm.bias",
      "layer1.2.mblock.1.branch_1.1.norm.weight",
      "layer1.2.mblock.1.branch_1.1.norm.bias",
      "layer1.2.mblock.1.branch_2.1.norm.weight",
      "layer1.2.mblock.1.branch_2.1.norm.bias",
      "layer1.2.mblock.1.branch_3.1.norm.weight",
      "layer1.2.mblock.1.branch_3.1.norm.bias",
      "layer1.2.mblock.2.norm.weight",
      "layer1.2.mblock.2.norm.bias",
      "layer1.3.sblock_in.norm.weight",
      "layer1.3.sblock_in.norm.bias",
      "layer1.3.sblock_dw.norm.weight",
      "layer1.3.sblock_dw.norm.bias",
      "layer1.3.sblock_proj.norm.weight",
      "layer1.3.sblock_proj.norm.bias",
      "layer1.3.mblock.0.norm.weight",
      "layer1.3.mblock.0.norm.bias",
      "layer1.3.mblock.1.branch_1.1.norm.weight",
      "layer1.3.mblock.1.branch_1.1.norm.bias",
      "layer1.3.mblock.1.branch_2.1.norm.weight",
      "layer1.3.mblock.1.branch_2.1.norm.bias",
      "layer1.3.mblock.1.branch_3.1.norm.weight",
      "layer1.3.mblock.1.branch_3.1.norm.bias",
      "layer1.3.mblock.2.norm.weight",
      "layer1.3.mblock.2.norm.bias",
      "layer1.4.sblock_in.norm.weight",
      "layer1.4.sblock_in.norm.bias",
      "layer1.4.sblock_dw.norm.weight",
      "layer1.4.sblock_dw.norm.bias",
      "layer1.4.sblock_proj.norm.weight",
      "layer1.4.sblock_proj.norm.bias",
      "layer1.4.mblock.0.norm.weight",
      "layer1.4.mblock.0.norm.bias",
      "layer1.4.mblock.1.branch_1.1.norm.weight",
      "layer1.4.mblock.1.branch_1.1.norm.bias",
      "layer1.4.mblock.1.branch_2.1.norm.weight",
      "layer1.4.mblock.1.branch_2.1.norm.bias",
      "layer1.4.mblock.1.branch_3.1.norm.weight",
      "layer1.4.mblock.1.branch_3.1.norm.bias",
      "layer1.4.mblock.2.norm.weight",
      "layer1.4.mblock.2.norm.bias",
      "layer2.0.mlp.0.norm.weight",
      "layer2.0.mlp.0.norm.bias",
      "layer2.0.mlp.1.norm.weight",
      "layer2.0.mlp.1.norm.bias",
      "layer2.0.mlp.2.norm.weight",
      "layer2.0.mlp.2.norm.bias",
      "layer2.0.skip.0.norm.weight",
      "layer2.0.skip.0.norm.bias",
      "layer2.0.skip.1.norm.weight",
      "layer2.0.skip.1.norm.bias",
      "layer2.1.sblock_in.norm.weight",
      "layer2.1.sblock_in.norm.bias",
      "layer2.1.sblock_dw.norm.weight",
      "layer2.1.sblock_dw.norm.bias",
      "layer2.1.sblock_proj.norm.weight",
      "layer2.1.sblock_proj.norm.bias",
      "layer2.1.mblock.0.norm.weight",
      "layer2.1.mblock.0.norm.bias",
      "layer2.1.mblock.1.branch_1.1.norm.weight",
      "layer2.1.mblock.1.branch_1.1.norm.bias",
      "layer2.1.mblock.1.branch_2.1.norm.weight",
      "layer2.1.mblock.1.branch_2.1.norm.bias",
      "layer2.1.mblock.1.branch_3.1.norm.weight",
      "layer2.1.mblock.1.branch_3.1.norm.bias",
      "layer2.1.mblock.2.norm.weight",
      "layer2.1.mblock.2.norm.bias",
      "layer2.2.sblock_in.norm.weight",
      "layer2.2.sblock_in.norm.bias",
      "layer2.2.sblock_dw.norm.weight",
      "layer2.2.sblock_dw.norm.bias",
      "layer2.2.sblock_proj.norm.weight",
      "layer2.2.sblock_proj.norm.bias",
      "layer2.2.mblock.0.norm.weight",
      "layer2.2.mblock.0.norm.bias",
      "layer2.2.mblock.1.branch_1.1.norm.weight",
      "layer2.2.mblock.1.branch_1.1.norm.bias",
      "layer2.2.mblock.1.branch_2.1.norm.weight",
      "layer2.2.mblock.1.branch_2.1.norm.bias",
      "layer2.2.mblock.1.branch_3.1.norm.weight",
      "layer2.2.mblock.1.branch_3.1.norm.bias",
      "layer2.2.mblock.2.norm.weight",
      "layer2.2.mblock.2.norm.bias",
      "layer2.3.sblock_in.norm.weight",
      "layer2.3.sblock_in.norm.bias",
      "layer2.3.sblock_dw.norm.weight",
      "layer2.3.sblock_dw.norm.bias",
      "layer2.3.sblock_proj.norm.weight",
      "layer2.3.sblock_proj.norm.bias",
      "layer2.3.mblock.0.norm.weight",
      "layer2.3.mblock.0.norm.bias",
      "layer2.3.mblock.1.branch_1.1.norm.weight",
      "layer2.3.mblock.1.branch_1.1.norm.bias",
      "layer2.3.mblock.1.branch_2.1.norm.weight",
      "layer2.3.mblock.1.branch_2.1.norm.bias",
      "layer2.3.mblock.1.branch_3.1.norm.weight",
      "layer2.3.mblock.1.branch_3.1.norm.bias",
      "layer2.3.mblock.2.norm.weight",
      "layer2.3.mblock.2.norm.bias",
      "layer2.4.sblock_in.norm.weight",
      "layer2.4.sblock_in.norm.bias",
      "layer2.4.sblock_dw.norm.weight",
      "layer2.4.sblock_dw.norm.bias",
      "layer2.4.sblock_proj.norm.weight",
      "layer2.4.sblock_proj.norm.bias",
      "layer2.4.mblock.0.norm.weight",
      "layer2.4.mblock.0.norm.bias",
      "layer2.4.mblock.1.branch_1.1.norm.weight",
      "layer2.4.mblock.1.branch_1.1.norm.bias",
      "layer2.4.mblock.1.branch_2.1.norm.weight",
      "layer2.4.mblock.1.branch_2.1.norm.bias",
      "layer2.4.mblock.1.branch_3.1.norm.weight",
      "layer2.4.mblock.1.branch_3.1.norm.bias",
      "layer2.4.mblock.2.norm.weight",
      "layer2.4.mblock.2.norm.bias",
      "layer2.5.sblock_in.norm.weight",
      "layer2.5.sblock_in.norm.bias",
      "layer2.5.sblock_dw.norm.weight",
      "layer2.5.sblock_dw.norm.bias",
      "layer2.5.sblock_proj.norm.weight",
      "layer2.5.sblock_proj.norm.bias",
      "layer2.5.mblock.0.norm.weight",
      "layer2.5.mblock.0.norm.bias",
      "layer2.5.mblock.1.branch_1.1.norm.weight",
      "layer2.5.mblock.1.branch_1.1.norm.bias",
      "layer2.5.mblock.1.branch_2.1.norm.weight",
      "layer2.5.mblock.1.branch_2.1.norm.bias",
      "layer2.5.mblock.1.branch_3.1.norm.weight",
      "layer2.5.mblock.1.branch_3.1.norm.bias",
      "layer2.5.mblock.2.norm.weight",
      "layer2.5.mblock.2.norm.bias",
      "layer2.6.sblock_in.norm.weight",
      "layer2.6.sblock_in.norm.bias",
      "layer2.6.sblock_dw.norm.weight",
      "layer2.6.sblock_dw.norm.bias",
      "layer2.6.sblock_proj.norm.weight",
      "layer2.6.sblock_proj.norm.bias",
      "layer2.6.mblock.0.norm.weight",
      "layer2.6.mblock.0.norm.bias",
      "layer2.6.mblock.1.branch_1.1.norm.weight",
      "layer2.6.mblock.1.branch_1.1.norm.bias",
      "layer2.6.mblock.1.branch_2.1.norm.weight",
      "layer2.6.mblock.1.branch_2.1.norm.bias",
      "layer2.6.mblock.1.branch_3.1.norm.weight",
      "layer2.6.mblock.1.branch_3.1.norm.bias",
      "layer2.6.mblock.2.norm.weight",
      "layer2.6.mblock.2.norm.bias",
      "layer2.7.sblock_in.norm.weight",
      "layer2.7.sblock_in.norm.bias",
      "layer2.7.sblock_dw.norm.weight",
      "layer2.7.sblock_dw.norm.bias",
      "layer2.7.sblock_proj.norm.weight",
      "layer2.7.sblock_proj.norm.bias",
      "layer2.7.mblock.0.norm.weight",
      "layer2.7.mblock.0.norm.bias",
      "layer2.7.mblock.1.branch_1.1.norm.weight",
      "layer2.7.mblock.1.branch_1.1.norm.bias",
      "layer2.7.mblock.1.branch_2.1.norm.weight",
      "layer2.7.mblock.1.branch_2.1.norm.bias",
      "layer2.7.mblock.1.branch_3.1.norm.weight",
      "layer2.7.mblock.1.branch_3.1.norm.bias",
      "layer2.7.mblock.2.norm.weight",
      "layer2.7.mblock.2.norm.bias",
      "layer2.8.sblock_in.norm.weight",
      "layer2.8.sblock_in.norm.bias",
      "layer2.8.sblock_dw.norm.weight",
      "layer2.8.sblock_dw.norm.bias",
      "layer2.8.sblock_proj.norm.weight",
      "layer2.8.sblock_proj.norm.bias",
      "layer2.8.mblock.0.norm.weight",
      "layer2.8.mblock.0.norm.bias",
      "layer2.8.mblock.1.branch_1.1.norm.weight",
      "layer2.8.mblock.1.branch_1.1.norm.bias",
      "layer2.8.mblock.1.branch_2.1.norm.weight",
      "layer2.8.mblock.1.branch_2.1.norm.bias",
      "layer2.8.mblock.1.branch_3.1.norm.weight",
      "layer2.8.mblock.1.branch_3.1.norm.bias",
      "layer2.8.mblock.2.norm.weight",
      "layer2.8.mblock.2.norm.bias",
      "layer3.0.mlp.0.norm.weight",
      "layer3.0.mlp.0.norm.bias",
      "layer3.0.mlp.1.norm.weight",
      "layer3.0.mlp.1.norm.bias",
      "layer3.0.mlp.2.norm.weight",
      "layer3.0.mlp.2.norm.bias",
      "layer3.0.skip.0.norm.weight",
      "layer3.0.skip.0.norm.bias",
      "layer3.0.skip.1.norm.weight",
      "layer3.0.skip.1.norm.bias",
      "layer3.1.sblock_in.norm.weight",
      "layer3.1.sblock_in.norm.bias",
      "layer3.1.sblock_dw.norm.weight",
      "layer3.1.sblock_dw.norm.bias",
      "layer3.1.sblock_proj.norm.weight",
      "layer3.1.sblock_proj.norm.bias",
      "layer3.1.mblock.0.norm.weight",
      "layer3.1.mblock.0.norm.bias",
      "layer3.1.mblock.1.branch_1.1.norm.weight",
      "layer3.1.mblock.1.branch_1.1.norm.bias",
      "layer3.1.mblock.1.branch_2.1.norm.weight",
      "layer3.1.mblock.1.branch_2.1.norm.bias",
      "layer3.1.mblock.1.branch_3.1.norm.weight",
      "layer3.1.mblock.1.branch_3.1.norm.bias",
      "layer3.1.mblock.2.norm.weight",
      "layer3.1.mblock.2.norm.bias",
      "layer3.2.sblock_in.norm.weight",
      "layer3.2.sblock_in.norm.bias",
      "layer3.2.sblock_dw.norm.weight",
      "layer3.2.sblock_dw.norm.bias",
      "layer3.2.sblock_proj.norm.weight",
      "layer3.2.sblock_proj.norm.bias",
      "layer3.2.mblock.0.norm.weight",
      "layer3.2.mblock.0.norm.bias",
      "layer3.2.mblock.1.branch_1.1.norm.weight",
      "layer3.2.mblock.1.branch_1.1.norm.bias",
      "layer3.2.mblock.1.branch_2.1.norm.weight",
      "layer3.2.mblock.1.branch_2.1.norm.bias",
      "layer3.2.mblock.1.branch_3.1.norm.weight",
      "layer3.2.mblock.1.branch_3.1.norm.bias",
      "layer3.2.mblock.2.norm.weight",
      "layer3.2.mblock.2.norm.bias",
      "layer3.3.sblock_in.norm.weight",
      "layer3.3.sblock_in.norm.bias",
      "layer3.3.sblock_dw.norm.weight",
      "layer3.3.sblock_dw.norm.bias",
      "layer3.3.sblock_proj.norm.weight",
      "layer3.3.sblock_proj.norm.bias",
      "layer3.3.mblock.0.norm.weight",
      "layer3.3.mblock.0.norm.bias",
      "layer3.3.mblock.1.branch_1.1.norm.weight",
      "layer3.3.mblock.1.branch_1.1.norm.bias",
      "layer3.3.mblock.1.branch_2.1.norm.weight",
      "layer3.3.mblock.1.branch_2.1.norm.bias",
      "layer3.3.mblock.1.branch_3.1.norm.weight",
      "layer3.3.mblock.1.branch_3.1.norm.bias",
      "layer3.3.mblock.2.norm.weight",
      "layer3.3.mblock.2.norm.bias",
      "layer3.4.sblock_in.norm.weight",
      "layer3.4.sblock_in.norm.bias",
      "layer3.4.sblock_dw.norm.weight",
      "layer3.4.sblock_dw.norm.bias",
      "layer3.4.sblock_proj.norm.weight",
      "layer3.4.sblock_proj.norm.bias",
      "layer3.4.mblock.0.norm.weight",
      "layer3.4.mblock.0.norm.bias",
      "layer3.4.mblock.1.branch_1.1.norm.weight",
      "layer3.4.mblock.1.branch_1.1.norm.bias",
      "layer3.4.mblock.1.branch_2.1.norm.weight",
      "layer3.4.mblock.1.branch_2.1.norm.bias",
      "layer3.4.mblock.1.branch_3.1.norm.weight",
      "layer3.4.mblock.1.branch_3.1.norm.bias",
      "layer3.4.mblock.2.norm.weight",
      "layer3.4.mblock.2.norm.bias",
      "layer3.5.sblock_in.norm.weight",
      "layer3.5.sblock_in.norm.bias",
      "layer3.5.sblock_dw.norm.weight",
      "layer3.5.sblock_dw.norm.bias",
      "layer3.5.sblock_proj.norm.weight",
      "layer3.5.sblock_proj.norm.bias",
      "layer3.5.mblock.0.norm.weight",
      "layer3.5.mblock.0.norm.bias",
      "layer3.5.mblock.1.branch_1.1.norm.weight",
      "layer3.5.mblock.1.branch_1.1.norm.bias",
      "layer3.5.mblock.1.branch_2.1.norm.weight",
      "layer3.5.mblock.1.branch_2.1.norm.bias",
      "layer3.5.mblock.1.branch_3.1.norm.weight",
      "layer3.5.mblock.1.branch_3.1.norm.bias",
      "layer3.5.mblock.2.norm.weight",
      "layer3.5.mblock.2.norm.bias",
      "layer3.6.sblock_in.norm.weight",
      "layer3.6.sblock_in.norm.bias",
      "layer3.6.sblock_dw.norm.weight",
      "layer3.6.sblock_dw.norm.bias",
      "layer3.6.sblock_proj.norm.weight",
      "layer3.6.sblock_proj.norm.bias",
      "layer3.6.mblock.0.norm.weight",
      "layer3.6.mblock.0.norm.bias",
      "layer3.6.mblock.1.branch_1.1.norm.weight",
      "layer3.6.mblock.1.branch_1.1.norm.bias",
      "layer3.6.mblock.1.branch_2.1.norm.weight",
      "layer3.6.mblock.1.branch_2.1.norm.bias",
      "layer3.6.mblock.1.branch_3.1.norm.weight",
      "layer3.6.mblock.1.branch_3.1.norm.bias",
      "layer3.6.mblock.2.norm.weight",
      "layer3.6.mblock.2.norm.bias",
      "layer3.7.sblock_in.norm.weight",
      "layer3.7.sblock_in.norm.bias",
      "layer3.7.sblock_dw.norm.weight",
      "layer3.7.sblock_dw.norm.bias",
      "layer3.7.sblock_proj.norm.weight",
      "layer3.7.sblock_proj.norm.bias",
      "layer3.7.mblock.0.norm.weight",
      "layer3.7.mblock.0.norm.bias",
      "layer3.7.mblock.1.branch_1.1.norm.weight",
      "layer3.7.mblock.1.branch_1.1.norm.bias",
      "layer3.7.mblock.1.branch_2.1.norm.weight",
      "layer3.7.mblock.1.branch_2.1.norm.bias",
      "layer3.7.mblock.1.branch_3.1.norm.weight",
      "layer3.7.mblock.1.branch_3.1.norm.bias",
      "layer3.7.mblock.2.norm.weight",
      "layer3.7.mblock.2.norm.bias",
      "layer3.8.sblock_in.norm.weight",
      "layer3.8.sblock_in.norm.bias",
      "layer3.8.sblock_dw.norm.weight",
      "layer3.8.sblock_dw.norm.bias",
      "layer3.8.sblock_proj.norm.weight",
      "layer3.8.sblock_proj.norm.bias",
      "layer3.8.mblock.0.norm.weight",
      "layer3.8.mblock.0.norm.bias",
      "layer3.8.mblock.1.branch_1.1.norm.weight",
      "layer3.8.mblock.1.branch_1.1.norm.bias",
      "layer3.8.mblock.1.branch_2.1.norm.weight",
      "layer3.8.mblock.1.branch_2.1.norm.bias",
      "layer3.8.mblock.1.branch_3.1.norm.weight",
      "layer3.8.mblock.1.branch_3.1.norm.bias",
      "layer3.8.mblock.2.norm.weight",
      "layer3.8.mblock.2.norm.bias",
      "layer3.9.sblock_in.norm.weight",
      "layer3.9.sblock_in.norm.bias",
      "layer3.9.sblock_dw.norm.weight",
      "layer3.9.sblock_dw.norm.bias",
      "layer3.9.sblock_proj.norm.weight",
      "layer3.9.sblock_proj.norm.bias",
      "layer3.9.mblock.0.norm.weight",
      "layer3.9.mblock.0.norm.bias",
      "layer3.9.mblock.1.branch_1.1.norm.weight",
      "layer3.9.mblock.1.branch_1.1.norm.bias",
      "layer3.9.mblock.1.branch_2.1.norm.weight",
      "layer3.9.mblock.1.branch_2.1.norm.bias",
      "layer3.9.mblock.1.branch_3.1.norm.weight",
      "layer3.9.mblock.1.branch_3.1.norm.bias",
      "layer3.9.mblock.2.norm.weight",
      "layer3.9.mblock.2.norm.bias",
      "layer3.10.sblock_in.norm.weight",
      "layer3.10.sblock_in.norm.bias",
      "layer3.10.sblock_dw.norm.weight",
      "layer3.10.sblock_dw.norm.bias",
      "layer3.10.sblock_proj.norm.weight",
      "layer3.10.sblock_proj.norm.bias",
      "layer3.10.mblock.0.norm.weight",
      "layer3.10.mblock.0.norm.bias",
      "layer3.10.mblock.1.branch_1.1.norm.weight",
      "layer3.10.mblock.1.branch_1.1.norm.bias",
      "layer3.10.mblock.1.branch_2.1.norm.weight",
      "layer3.10.mblock.1.branch_2.1.norm.bias",
      "layer3.10.mblock.1.branch_3.1.norm.weight",
      "layer3.10.mblock.1.branch_3.1.norm.bias",
      "layer3.10.mblock.2.norm.weight",
      "layer3.10.mblock.2.norm.bias",
      "layer3.11.sblock_in.norm.weight",
      "layer3.11.sblock_in.norm.bias",
      "layer3.11.sblock_dw.norm.weight",
      "layer3.11.sblock_dw.norm.bias",
      "layer3.11.sblock_proj.norm.weight",
      "layer3.11.sblock_proj.norm.bias",
      "layer3.11.mblock.0.norm.weight",
      "layer3.11.mblock.0.norm.bias",
      "layer3.11.mblock.1.branch_1.1.norm.weight",
      "layer3.11.mblock.1.branch_1.1.norm.bias",
      "layer3.11.mblock.1.branch_2.1.norm.weight",
      "layer3.11.mblock.1.branch_2.1.norm.bias",
      "layer3.11.mblock.1.branch_3.1.norm.weight",
      "layer3.11.mblock.1.branch_3.1.norm.bias",
      "layer3.11.mblock.2.norm.weight",
      "layer3.11.mblock.2.norm.bias",
      "layer3.12.sblock_in.norm.weight",
      "layer3.12.sblock_in.norm.bias",
      "layer3.12.sblock_dw.norm.weight",
      "layer3.12.sblock_dw.norm.bias",
      "layer3.12.sblock_proj.norm.weight",
      "layer3.12.sblock_proj.norm.bias",
      "layer3.12.mblock.0.norm.weight",
      "layer3.12.mblock.0.norm.bias",
      "layer3.12.mblock.1.branch_1.1.norm.weight",
      "layer3.12.mblock.1.branch_1.1.norm.bias",
      "layer3.12.mblock.1.branch_2.1.norm.weight",
      "layer3.12.mblock.1.branch_2.1.norm.bias",
      "layer3.12.mblock.1.branch_3.1.norm.weight",
      "layer3.12.mblock.1.branch_3.1.norm.bias",
      "layer3.12.mblock.2.norm.weight",
      "layer3.12.mblock.2.norm.bias",
      "layer3.13.sblock_in.norm.weight",
      "layer3.13.sblock_in.norm.bias",
      "layer3.13.sblock_dw.norm.weight",
      "layer3.13.sblock_dw.norm.bias",
      "layer3.13.sblock_proj.norm.weight",
      "layer3.13.sblock_proj.norm.bias",
      "layer3.13.mblock.0.norm.weight",
      "layer3.13.mblock.0.norm.bias",
      "layer3.13.mblock.1.branch_1.1.norm.weight",
      "layer3.13.mblock.1.branch_1.1.norm.bias",
      "layer3.13.mblock.1.branch_2.1.norm.weight",
      "layer3.13.mblock.1.branch_2.1.norm.bias",
      "layer3.13.mblock.1.branch_3.1.norm.weight",
      "layer3.13.mblock.1.branch_3.1.norm.bias",
      "layer3.13.mblock.2.norm.weight",
      "layer3.13.mblock.2.norm.bias",
      "layer3.14.sblock_in.norm.weight",
      "layer3.14.sblock_in.norm.bias",
      "layer3.14.sblock_dw.norm.weight",
      "layer3.14.sblock_dw.norm.bias",
      "layer3.14.sblock_proj.norm.weight",
      "layer3.14.sblock_proj.norm.bias",
      "layer3.14.mblock.0.norm.weight",
      "layer3.14.mblock.0.norm.bias",
      "layer3.14.mblock.1.branch_1.1.norm.weight",
      "layer3.14.mblock.1.branch_1.1.norm.bias",
      "layer3.14.mblock.1.branch_2.1.norm.weight",
      "layer3.14.mblock.1.branch_2.1.norm.bias",
      "layer3.14.mblock.1.branch_3.1.norm.weight",
      "layer3.14.mblock.1.branch_3.1.norm.bias",
      "layer3.14.mblock.2.norm.weight",
      "layer3.14.mblock.2.norm.bias",
      "layer3.15.sblock_in.norm.weight",
      "layer3.15.sblock_in.norm.bias",
      "layer3.15.sblock_dw.norm.weight",
      "layer3.15.sblock_dw.norm.bias",
      "layer3.15.sblock_proj.norm.weight",
      "layer3.15.sblock_proj.norm.bias",
      "layer3.15.mblock.0.norm.weight",
      "layer3.15.mblock.0.norm.bias",
      "layer3.15.mblock.1.branch_1.1.norm.weight",
      "layer3.15.mblock.1.branch_1.1.norm.bias",
      "layer3.15.mblock.1.branch_2.1.norm.weight",
      "layer3.15.mblock.1.branch_2.1.norm.bias",
      "layer3.15.mblock.1.branch_3.1.norm.weight",
      "layer3.15.mblock.1.branch_3.1.norm.bias",
      "layer3.15.mblock.2.norm.weight",
      "layer3.15.mblock.2.norm.bias",
      "layer3.16.sblock_in.norm.weight",
      "layer3.16.sblock_in.norm.bias",
      "layer3.16.sblock_dw.norm.weight",
      "layer3.16.sblock_dw.norm.bias",
      "layer3.16.sblock_proj.norm.weight",
      "layer3.16.sblock_proj.norm.bias",
      "layer3.16.mblock.0.norm.weight",
      "layer3.16.mblock.0.norm.bias",
      "layer3.16.mblock.1.branch_1.1.norm.weight",
      "layer3.16.mblock.1.branch_1.1.norm.bias",
      "layer3.16.mblock.1.branch_2.1.norm.weight",
      "layer3.16.mblock.1.branch_2.1.norm.bias",
      "layer3.16.mblock.1.branch_3.1.norm.weight",
      "layer3.16.mblock.1.branch_3.1.norm.bias",
      "layer3.16.mblock.2.norm.weight",
      "layer3.16.mblock.2.norm.bias",
      "layer4.0.mlp.0.norm.weight",
      "layer4.0.mlp.0.norm.bias",
      "layer4.0.mlp.1.norm.weight",
      "layer4.0.mlp.1.norm.bias",
      "layer4.0.mlp.2.norm.weight",
      "layer4.0.mlp.2.norm.bias",
      "layer4.0.skip.0.norm.weight",
      "layer4.0.skip.0.norm.bias",
      "layer4.0.skip.1.norm.weight",
      "layer4.0.skip.1.norm.bias",
      "layer4.1.sblock_in.norm.weight",
      "layer4.1.sblock_in.norm.bias",
      "layer4.1.sblock_dw.norm.weight",
      "layer4.1.sblock_dw.norm.bias",
      "layer4.1.sblock_proj.norm.weight",
      "layer4.1.sblock_proj.norm.bias",
      "layer4.1.mblock.0.norm.weight",
      "layer4.1.mblock.0.norm.bias",
      "layer4.1.mblock.1.branch_1.1.norm.weight",
      "layer4.1.mblock.1.branch_1.1.norm.bias",
      "layer4.1.mblock.1.branch_2.1.norm.weight",
      "layer4.1.mblock.1.branch_2.1.norm.bias",
      "layer4.1.mblock.1.branch_3.1.norm.weight",
      "layer4.1.mblock.1.branch_3.1.norm.bias",
      "layer4.1.mblock.2.norm.weight",
      "layer4.1.mblock.2.norm.bias",
      "layer4.2.sblock_in.norm.weight",
      "layer4.2.sblock_in.norm.bias",
      "layer4.2.sblock_dw.norm.weight",
      "layer4.2.sblock_dw.norm.bias",
      "layer4.2.sblock_proj.norm.weight",
      "layer4.2.sblock_proj.norm.bias",
      "layer4.2.mblock.0.norm.weight",
      "layer4.2.mblock.0.norm.bias",
      "layer4.2.mblock.1.branch_1.1.norm.weight",
      "layer4.2.mblock.1.branch_1.1.norm.bias",
      "layer4.2.mblock.1.branch_2.1.norm.weight",
      "layer4.2.mblock.1.branch_2.1.norm.bias",
      "layer4.2.mblock.1.branch_3.1.norm.weight",
      "layer4.2.mblock.1.branch_3.1.norm.bias",
      "layer4.2.mblock.2.norm.weight",
      "layer4.2.mblock.2.norm.bias",
      "layer4.3.sblock_in.norm.weight",
      "layer4.3.sblock_in.norm.bias",
      "layer4.3.sblock_dw.norm.weight",
      "layer4.3.sblock_dw.norm.bias",
      "layer4.3.sblock_proj.norm.weight",
      "layer4.3.sblock_proj.norm.bias",
      "layer4.3.mblock.0.norm.weight",
      "layer4.3.mblock.0.norm.bias",
      "layer4.3.mblock.1.branch_1.1.norm.weight",
      "layer4.3.mblock.1.branch_1.1.norm.bias",
      "layer4.3.mblock.1.branch_2.1.norm.weight",
      "layer4.3.mblock.1.branch_2.1.norm.bias",
      "layer4.3.mblock.1.branch_3.1.norm.weight",
      "layer4.3.mblock.1.branch_3.1.norm.bias",
      "layer4.3.mblock.2.norm.weight",
      "layer4.3.mblock.2.norm.bias",
      "layer4.4.sblock_in.norm.weight",
      "layer4.4.sblock_in.norm.bias",
      "layer4.4.sblock_dw.norm.weight",
      "layer4.4.sblock_dw.norm.bias",
      "layer4.4.sblock_proj.norm.weight",
      "layer4.4.sblock_proj.norm.bias",
      "layer4.4.mblock.0.norm.weight",
      "layer4.4.mblock.0.norm.bias",
      "layer4.4.mblock.1.branch_1.1.norm.weight",
      "layer4.4.mblock.1.branch_1.1.norm.bias",
      "layer4.4.mblock.1.branch_2.1.norm.weight",
      "layer4.4.mblock.1.branch_2.1.norm.bias",
      "layer4.4.mblock.1.branch_3.1.norm.weight",
      "layer4.4.mblock.1.branch_3.1.norm.bias",
      "layer4.4.mblock.2.norm.weight",
      "layer4.4.mblock.2.norm.bias",
      "head.norm.weight",
      "head.norm.bias",
      "classifier.norm.weight",
      "classifier.norm.bias"
    ],
    "lr_scale": 1.0
  }
}
Use Cosine LR scheduler
Set warmup steps = 6240
Set warmup steps = 0
Max WD = 0.0500000, Min WD = 0.0500000
criterion = SoftTargetCrossEntropy()
Auto resume checkpoint: checkpoint_base_8.5G/checkpoint-246.pth
Resume checkpoint checkpoint_base_8.5G/checkpoint-246.pth
With optim & sched!
Start training for 300 epochs
Epoch: [247]  [   0/1251]  eta: 4:28:04  lr: 0.000344  min_lr: 0.000344  loss: 3.9519 (3.9519)  weight_decay: 0.0500 (0.0500)  time: 12.8575  data: 2.3421  max mem: 40463
Epoch: [247]  [ 200/1251]  eta: 0:09:57  lr: 0.000342  min_lr: 0.000342  loss: 2.6564 (2.8117)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6401 (1.7906)  time: 0.5041  data: 0.0004  max mem: 40463
Epoch: [247]  [ 400/1251]  eta: 0:07:37  lr: 0.000340  min_lr: 0.000340  loss: 2.8381 (2.7615)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7145 (1.8574)  time: 0.5054  data: 0.0004  max mem: 40463
Epoch: [247]  [ 600/1251]  eta: 0:05:42  lr: 0.000338  min_lr: 0.000338  loss: 2.9491 (2.7639)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4636 (1.8065)  time: 0.5069  data: 0.0004  max mem: 40463
Epoch: [247]  [ 800/1251]  eta: 0:03:54  lr: 0.000336  min_lr: 0.000336  loss: 2.9279 (2.7624)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5155 (1.8222)  time: 0.5035  data: 0.0006  max mem: 40463
Epoch: [247]  [1000/1251]  eta: 0:02:09  lr: 0.000334  min_lr: 0.000334  loss: 2.8645 (2.7503)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6766 (1.8486)  time: 0.5043  data: 0.0006  max mem: 40463
Epoch: [247]  [1200/1251]  eta: 0:00:26  lr: 0.000332  min_lr: 0.000332  loss: 3.0270 (2.7599)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4110 (1.9266)  time: 0.5046  data: 0.0006  max mem: 40463
Epoch: [247]  [1250/1251]  eta: 0:00:00  lr: 0.000332  min_lr: 0.000332  loss: 2.8283 (2.7590)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1552 (1.9345)  time: 0.4274  data: 0.0006  max mem: 40463
Epoch: [247] Total time: 0:10:43 (0.5145 s / it)
Averaged stats: lr: 0.000332  min_lr: 0.000332  loss: 2.8283 (2.7580)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1552 (1.9345)
Test:  [ 0/25]  eta: 0:03:54  loss: 0.6410 (0.6410)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 9.3618  data: 4.0991  max mem: 40463
Test:  [10/25]  eta: 0:00:16  loss: 0.7448 (0.7568)  acc1: 86.4000 (86.2182)  acc5: 97.6000 (97.8546)  time: 1.0883  data: 0.3729  max mem: 40463
Test:  [20/25]  eta: 0:00:03  loss: 0.9260 (0.8658)  acc1: 82.0000 (83.7143)  acc5: 96.4000 (96.5524)  time: 0.2608  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9264 (0.8793)  acc1: 82.0000 (83.1360)  acc5: 95.6000 (96.4640)  time: 0.2607  data: 0.0001  max mem: 40463
Test: Total time: 0:00:15 (0.6272 s / it)
* Acc@1 83.882 Acc@5 96.644 loss 0.865
Accuracy of the model on the 50000 test images: 83.9%
Max accuracy: 83.88%
Epoch: [248]  [   0/1251]  eta: 0:58:15  lr: 0.000332  min_lr: 0.000332  loss: 1.8484 (1.8484)  weight_decay: 0.0500 (0.0500)  time: 2.7942  data: 2.2514  max mem: 40463
Epoch: [248]  [ 200/1251]  eta: 0:08:55  lr: 0.000330  min_lr: 0.000330  loss: 2.9704 (2.8029)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8499 (1.7624)  time: 0.4961  data: 0.0004  max mem: 40463
Epoch: [248]  [ 400/1251]  eta: 0:07:08  lr: 0.000328  min_lr: 0.000328  loss: 2.7172 (2.7596)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3117 (1.7696)  time: 0.4958  data: 0.0004  max mem: 40463
Epoch: [248]  [ 600/1251]  eta: 0:05:26  lr: 0.000326  min_lr: 0.000326  loss: 2.8435 (2.7574)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5472 (1.6848)  time: 0.4957  data: 0.0004  max mem: 40463
Epoch: [248]  [ 800/1251]  eta: 0:03:45  lr: 0.000324  min_lr: 0.000324  loss: 2.8564 (2.7436)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3224 (1.7338)  time: 0.4973  data: 0.0004  max mem: 40463
Epoch: [248]  [1000/1251]  eta: 0:02:05  lr: 0.000322  min_lr: 0.000322  loss: 2.5631 (2.7436)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6281 (1.7015)  time: 0.4982  data: 0.0004  max mem: 40463
Epoch: [248]  [1200/1251]  eta: 0:00:25  lr: 0.000320  min_lr: 0.000320  loss: 2.7283 (2.7456)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3504 (1.7400)  time: 0.4980  data: 0.0004  max mem: 40463
Epoch: [248]  [1250/1251]  eta: 0:00:00  lr: 0.000320  min_lr: 0.000320  loss: 2.7008 (2.7446)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1216 (1.7215)  time: 0.4213  data: 0.0005  max mem: 40463
Epoch: [248] Total time: 0:10:23 (0.4988 s / it)
Averaged stats: lr: 0.000320  min_lr: 0.000320  loss: 2.7008 (2.7457)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1216 (1.7215)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.6664 (0.6664)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 5.2314  data: 4.9377  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7675 (0.7702)  acc1: 86.4000 (86.7273)  acc5: 97.2000 (97.6727)  time: 0.7131  data: 0.4492  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9246 (0.8768)  acc1: 82.8000 (83.9048)  acc5: 96.0000 (96.5714)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9398 (0.8896)  acc1: 81.6000 (83.2800)  acc5: 96.0000 (96.5120)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4628 s / it)
* Acc@1 83.962 Acc@5 96.636 loss 0.877
Accuracy of the model on the 50000 test images: 84.0%
Max accuracy: 83.96%
Epoch: [249]  [   0/1251]  eta: 0:52:19  lr: 0.000320  min_lr: 0.000320  loss: 2.4583 (2.4583)  weight_decay: 0.0500 (0.0500)  time: 2.5095  data: 1.9951  max mem: 40463
Epoch: [249]  [ 200/1251]  eta: 0:08:54  lr: 0.000318  min_lr: 0.000318  loss: 2.9881 (2.7952)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4351 (1.5880)  time: 0.5065  data: 0.0004  max mem: 40463
Epoch: [249]  [ 400/1251]  eta: 0:07:08  lr: 0.000316  min_lr: 0.000316  loss: 2.6643 (2.7509)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8346 (1.6105)  time: 0.4976  data: 0.0004  max mem: 40463
Epoch: [249]  [ 600/1251]  eta: 0:05:26  lr: 0.000314  min_lr: 0.000314  loss: 2.8984 (2.7503)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0657 (1.7444)  time: 0.4981  data: 0.0004  max mem: 40463
Epoch: [249]  [ 800/1251]  eta: 0:03:45  lr: 0.000312  min_lr: 0.000312  loss: 2.8143 (2.7548)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9811 (1.7917)  time: 0.4976  data: 0.0004  max mem: 40463
Epoch: [249]  [1000/1251]  eta: 0:02:05  lr: 0.000310  min_lr: 0.000310  loss: 2.7464 (2.7484)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5700 (1.7506)  time: 0.4970  data: 0.0004  max mem: 40463
Epoch: [249]  [1200/1251]  eta: 0:00:25  lr: 0.000308  min_lr: 0.000308  loss: 2.7692 (2.7537)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7419 (1.7793)  time: 0.4967  data: 0.0004  max mem: 40463
Epoch: [249]  [1250/1251]  eta: 0:00:00  lr: 0.000308  min_lr: 0.000308  loss: 2.9719 (2.7573)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5245 (1.7801)  time: 0.4217  data: 0.0005  max mem: 40463
Epoch: [249] Total time: 0:10:24 (0.4991 s / it)
Averaged stats: lr: 0.000308  min_lr: 0.000308  loss: 2.9719 (2.7409)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5245 (1.7801)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.6796 (0.6796)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 5.4338  data: 5.1320  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.8051 (0.8107)  acc1: 86.4000 (86.4000)  acc5: 98.0000 (97.7455)  time: 0.7314  data: 0.4668  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9884 (0.9237)  acc1: 82.8000 (83.6952)  acc5: 96.4000 (96.7429)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9884 (0.9377)  acc1: 82.0000 (83.2160)  acc5: 96.4000 (96.6880)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4708 s / it)
* Acc@1 83.794 Acc@5 96.656 loss 0.925
Accuracy of the model on the 50000 test images: 83.8%
Max accuracy: 83.96%
Epoch: [250]  [   0/1251]  eta: 1:13:30  lr: 0.000307  min_lr: 0.000307  loss: 2.7467 (2.7467)  weight_decay: 0.0500 (0.0500)  time: 3.5259  data: 1.7870  max mem: 40463
Epoch: [250]  [ 200/1251]  eta: 0:09:00  lr: 0.000306  min_lr: 0.000306  loss: 2.7668 (2.7072)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4058 (1.4934)  time: 0.4994  data: 0.0004  max mem: 40463
Epoch: [250]  [ 400/1251]  eta: 0:07:10  lr: 0.000304  min_lr: 0.000304  loss: 2.7105 (2.7121)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3955 (1.5769)  time: 0.4988  data: 0.0005  max mem: 40463
Epoch: [250]  [ 600/1251]  eta: 0:05:28  lr: 0.000302  min_lr: 0.000302  loss: 2.5657 (2.7126)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1538 (1.5765)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [250]  [ 800/1251]  eta: 0:03:46  lr: 0.000300  min_lr: 0.000300  loss: 2.9012 (2.7203)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6300 (1.6608)  time: 0.4982  data: 0.0004  max mem: 40463
Epoch: [250]  [1000/1251]  eta: 0:02:06  lr: 0.000298  min_lr: 0.000298  loss: 2.8792 (2.7355)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8455 (1.7086)  time: 0.4990  data: 0.0004  max mem: 40463
Epoch: [250]  [1200/1251]  eta: 0:00:25  lr: 0.000296  min_lr: 0.000296  loss: 2.9319 (2.7322)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0095 (1.8217)  time: 0.4986  data: 0.0004  max mem: 40463
Epoch: [250]  [1250/1251]  eta: 0:00:00  lr: 0.000296  min_lr: 0.000296  loss: 2.9992 (2.7340)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6373 (1.8159)  time: 0.4216  data: 0.0006  max mem: 40463
Epoch: [250] Total time: 0:10:26 (0.5011 s / it)
Averaged stats: lr: 0.000296  min_lr: 0.000296  loss: 2.9992 (2.7462)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6373 (1.8159)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6656 (0.6656)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 5.4929  data: 5.1759  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7791 (0.7852)  acc1: 86.4000 (86.3273)  acc5: 97.6000 (97.8545)  time: 0.7363  data: 0.4709  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9547 (0.8989)  acc1: 81.6000 (83.5048)  acc5: 96.8000 (96.8191)  time: 0.2605  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9602 (0.9132)  acc1: 81.2000 (83.0080)  acc5: 96.0000 (96.6400)  time: 0.2603  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4736 s / it)
* Acc@1 83.942 Acc@5 96.700 loss 0.897
Accuracy of the model on the 50000 test images: 83.9%
Max accuracy: 83.96%
Epoch: [251]  [   0/1251]  eta: 1:10:27  lr: 0.000296  min_lr: 0.000296  loss: 2.9592 (2.9592)  weight_decay: 0.0500 (0.0500)  time: 3.3791  data: 2.7774  max mem: 40463
Epoch: [251]  [ 200/1251]  eta: 0:09:00  lr: 0.000294  min_lr: 0.000294  loss: 2.7582 (2.7103)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0065 (1.7926)  time: 0.4978  data: 0.0004  max mem: 40463
Epoch: [251]  [ 400/1251]  eta: 0:07:11  lr: 0.000292  min_lr: 0.000292  loss: 2.6873 (2.7347)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2614 (1.7504)  time: 0.4993  data: 0.0004  max mem: 40463
Epoch: [251]  [ 600/1251]  eta: 0:05:28  lr: 0.000290  min_lr: 0.000290  loss: 2.8980 (2.7339)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7609 (1.7746)  time: 0.4975  data: 0.0004  max mem: 40463
Epoch: [251]  [ 800/1251]  eta: 0:03:46  lr: 0.000288  min_lr: 0.000288  loss: 2.7306 (2.7338)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4252 (1.7607)  time: 0.4974  data: 0.0004  max mem: 40463
Epoch: [251]  [1000/1251]  eta: 0:02:06  lr: 0.000286  min_lr: 0.000286  loss: 2.8501 (2.7493)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8208 (1.8306)  time: 0.4976  data: 0.0004  max mem: 40463
Epoch: [251]  [1200/1251]  eta: 0:00:25  lr: 0.000284  min_lr: 0.000284  loss: 2.9637 (2.7484)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0850 (1.8924)  time: 0.5009  data: 0.0004  max mem: 40463
Epoch: [251]  [1250/1251]  eta: 0:00:00  lr: 0.000284  min_lr: 0.000284  loss: 2.8759 (2.7473)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1940 (1.8990)  time: 0.4216  data: 0.0007  max mem: 40463
Epoch: [251] Total time: 0:10:26 (0.5008 s / it)
Averaged stats: lr: 0.000284  min_lr: 0.000284  loss: 2.8759 (2.7436)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1940 (1.8990)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.6490 (0.6490)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 5.3155  data: 5.0153  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7433 (0.7626)  acc1: 86.4000 (86.3273)  acc5: 97.6000 (97.6727)  time: 0.7208  data: 0.4563  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9274 (0.8753)  acc1: 81.6000 (83.3714)  acc5: 96.4000 (96.7048)  time: 0.2612  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9274 (0.8871)  acc1: 81.6000 (82.9920)  acc5: 96.0000 (96.6080)  time: 0.2611  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4662 s / it)
* Acc@1 83.774 Acc@5 96.686 loss 0.869
Accuracy of the model on the 50000 test images: 83.8%
Max accuracy: 83.96%
Epoch: [252]  [   0/1251]  eta: 1:08:50  lr: 0.000284  min_lr: 0.000284  loss: 3.1505 (3.1505)  weight_decay: 0.0500 (0.0500)  time: 3.3020  data: 2.4822  max mem: 40463
Epoch: [252]  [ 200/1251]  eta: 0:09:00  lr: 0.000282  min_lr: 0.000282  loss: 2.7137 (2.8107)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8084 (2.0623)  time: 0.4970  data: 0.0005  max mem: 40463
Epoch: [252]  [ 400/1251]  eta: 0:07:10  lr: 0.000280  min_lr: 0.000280  loss: 2.9836 (2.7641)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4693 (1.8552)  time: 0.4963  data: 0.0004  max mem: 40463
Epoch: [252]  [ 600/1251]  eta: 0:05:27  lr: 0.000279  min_lr: 0.000279  loss: 2.7623 (2.7509)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3549 (1.7718)  time: 0.4967  data: 0.0004  max mem: 40463
Epoch: [252]  [ 800/1251]  eta: 0:03:46  lr: 0.000277  min_lr: 0.000277  loss: 2.8628 (2.7312)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2499 (1.6724)  time: 0.4967  data: 0.0004  max mem: 40463
Epoch: [252]  [1000/1251]  eta: 0:02:05  lr: 0.000275  min_lr: 0.000275  loss: 2.6225 (2.7346)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8971 (1.6723)  time: 0.4989  data: 0.0004  max mem: 40463
Epoch: [252]  [1200/1251]  eta: 0:00:25  lr: 0.000273  min_lr: 0.000273  loss: 2.6087 (2.7338)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6723 (1.6707)  time: 0.4976  data: 0.0004  max mem: 40463
Epoch: [252]  [1250/1251]  eta: 0:00:00  lr: 0.000273  min_lr: 0.000273  loss: 2.6880 (2.7329)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5291 (1.6679)  time: 0.4217  data: 0.0006  max mem: 40463
Epoch: [252] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.000273  min_lr: 0.000273  loss: 2.6880 (2.7366)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5291 (1.6679)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.5928 (0.5928)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 5.5729  data: 5.2829  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7080 (0.7140)  acc1: 86.4000 (86.4727)  acc5: 97.6000 (97.8909)  time: 0.7439  data: 0.4805  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8773 (0.8287)  acc1: 82.4000 (83.6191)  acc5: 96.4000 (96.8000)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.8958 (0.8428)  acc1: 82.0000 (83.1680)  acc5: 96.4000 (96.6720)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4774 s / it)
* Acc@1 83.746 Acc@5 96.686 loss 0.833
Accuracy of the model on the 50000 test images: 83.7%
Max accuracy: 83.96%
Epoch: [253]  [   0/1251]  eta: 1:12:02  lr: 0.000273  min_lr: 0.000273  loss: 3.0568 (3.0568)  weight_decay: 0.0500 (0.0500)  time: 3.4551  data: 2.7681  max mem: 40463
Epoch: [253]  [ 200/1251]  eta: 0:09:00  lr: 0.000271  min_lr: 0.000271  loss: 2.6550 (2.7051)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4086 (1.6294)  time: 0.4982  data: 0.0004  max mem: 40463
Epoch: [253]  [ 400/1251]  eta: 0:07:10  lr: 0.000269  min_lr: 0.000269  loss: 2.6689 (2.7085)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3887 (1.6875)  time: 0.4981  data: 0.0004  max mem: 40463
Epoch: [253]  [ 600/1251]  eta: 0:05:28  lr: 0.000267  min_lr: 0.000267  loss: 2.8962 (2.7102)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4859 (1.6905)  time: 0.4962  data: 0.0004  max mem: 40463
Epoch: [253]  [ 800/1251]  eta: 0:03:46  lr: 0.000265  min_lr: 0.000265  loss: 2.7366 (2.7153)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8098 (1.7157)  time: 0.4967  data: 0.0004  max mem: 40463
Epoch: [253]  [1000/1251]  eta: 0:02:05  lr: 0.000264  min_lr: 0.000264  loss: 2.6493 (2.7215)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.6100 (1.8668)  time: 0.5005  data: 0.0005  max mem: 40463
Epoch: [253]  [1200/1251]  eta: 0:00:25  lr: 0.000262  min_lr: 0.000262  loss: 2.7406 (2.7282)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4716 (nan)  time: 0.4981  data: 0.0004  max mem: 40463
Epoch: [253]  [1250/1251]  eta: 0:00:00  lr: 0.000261  min_lr: 0.000261  loss: 2.8628 (2.7290)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4420 (nan)  time: 0.4215  data: 0.0007  max mem: 40463
Epoch: [253] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.000261  min_lr: 0.000261  loss: 2.8628 (2.7374)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4420 (nan)
Test:  [ 0/25]  eta: 0:02:07  loss: 0.6490 (0.6490)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 5.1016  data: 4.8085  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7707 (0.7709)  acc1: 87.2000 (86.5818)  acc5: 97.6000 (97.7091)  time: 0.7011  data: 0.4374  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9335 (0.8763)  acc1: 82.4000 (83.7143)  acc5: 96.8000 (96.7429)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9374 (0.8901)  acc1: 82.4000 (83.2960)  acc5: 96.4000 (96.6400)  time: 0.2607  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4578 s / it)
* Acc@1 83.856 Acc@5 96.614 loss 0.878
Accuracy of the model on the 50000 test images: 83.9%
Max accuracy: 83.96%
Epoch: [254]  [   0/1251]  eta: 1:12:01  lr: 0.000261  min_lr: 0.000261  loss: 3.1397 (3.1397)  weight_decay: 0.0500 (0.0500)  time: 3.4545  data: 2.9167  max mem: 40463
Epoch: [254]  [ 200/1251]  eta: 0:09:00  lr: 0.000260  min_lr: 0.000260  loss: 2.7753 (2.7549)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5233 (1.7254)  time: 0.4993  data: 0.0004  max mem: 40463
Epoch: [254]  [ 400/1251]  eta: 0:07:11  lr: 0.000258  min_lr: 0.000258  loss: 2.7318 (2.7159)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7650 (1.7435)  time: 0.4982  data: 0.0004  max mem: 40463
Epoch: [254]  [ 600/1251]  eta: 0:05:28  lr: 0.000256  min_lr: 0.000256  loss: 2.6325 (2.7117)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7055 (1.7823)  time: 0.4979  data: 0.0004  max mem: 40463
Epoch: [254]  [ 800/1251]  eta: 0:03:46  lr: 0.000254  min_lr: 0.000254  loss: 2.9076 (2.7271)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4743 (1.7422)  time: 0.4971  data: 0.0004  max mem: 40463
Epoch: [254]  [1000/1251]  eta: 0:02:05  lr: 0.000253  min_lr: 0.000253  loss: 2.6681 (2.7329)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9425 (1.7966)  time: 0.5061  data: 0.0004  max mem: 40463
Epoch: [254]  [1200/1251]  eta: 0:00:25  lr: 0.000251  min_lr: 0.000251  loss: 2.8254 (2.7291)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1184 (1.8253)  time: 0.4963  data: 0.0005  max mem: 40463
Epoch: [254]  [1250/1251]  eta: 0:00:00  lr: 0.000251  min_lr: 0.000251  loss: 2.9527 (2.7281)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4657 (1.8276)  time: 0.4211  data: 0.0007  max mem: 40463
Epoch: [254] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.000251  min_lr: 0.000251  loss: 2.9527 (2.7198)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4657 (1.8276)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.6153 (0.6153)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 5.6002  data: 5.2923  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7201 (0.7319)  acc1: 87.2000 (87.0909)  acc5: 97.6000 (97.7818)  time: 0.7466  data: 0.4814  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9032 (0.8490)  acc1: 82.4000 (84.0762)  acc5: 96.4000 (96.7619)  time: 0.2611  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9244 (0.8627)  acc1: 82.4000 (83.7120)  acc5: 96.4000 (96.6240)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4775 s / it)
* Acc@1 84.068 Acc@5 96.656 loss 0.851
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.07%
Epoch: [255]  [   0/1251]  eta: 0:50:32  lr: 0.000250  min_lr: 0.000250  loss: 2.3821 (2.3821)  weight_decay: 0.0500 (0.0500)  time: 2.4244  data: 1.9257  max mem: 40463
Epoch: [255]  [ 200/1251]  eta: 0:08:53  lr: 0.000249  min_lr: 0.000249  loss: 2.8558 (2.7621)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7166 (1.6469)  time: 0.4963  data: 0.0004  max mem: 40463
Epoch: [255]  [ 400/1251]  eta: 0:07:07  lr: 0.000247  min_lr: 0.000247  loss: 2.7606 (2.7525)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2976 (1.6012)  time: 0.4963  data: 0.0004  max mem: 40463
Epoch: [255]  [ 600/1251]  eta: 0:05:25  lr: 0.000245  min_lr: 0.000245  loss: 2.9843 (2.7353)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6567 (1.6690)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [255]  [ 800/1251]  eta: 0:03:45  lr: 0.000244  min_lr: 0.000244  loss: 2.7798 (2.7326)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4987 (1.7487)  time: 0.4963  data: 0.0004  max mem: 40463
Epoch: [255]  [1000/1251]  eta: 0:02:05  lr: 0.000242  min_lr: 0.000242  loss: 2.8104 (2.7285)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7397 (1.7611)  time: 0.4966  data: 0.0004  max mem: 40463
Epoch: [255]  [1200/1251]  eta: 0:00:25  lr: 0.000240  min_lr: 0.000240  loss: 2.6251 (2.7309)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3117 (1.7372)  time: 0.4965  data: 0.0004  max mem: 40463
Epoch: [255]  [1250/1251]  eta: 0:00:00  lr: 0.000240  min_lr: 0.000240  loss: 2.9043 (2.7306)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4988 (1.7448)  time: 0.4212  data: 0.0005  max mem: 40463
Epoch: [255] Total time: 0:10:23 (0.4981 s / it)
Averaged stats: lr: 0.000240  min_lr: 0.000240  loss: 2.9043 (2.7220)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4988 (1.7448)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.6421 (0.6421)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 5.2986  data: 4.9979  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7500 (0.7639)  acc1: 86.4000 (86.4727)  acc5: 97.6000 (97.8182)  time: 0.7191  data: 0.4547  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9211 (0.8793)  acc1: 81.6000 (83.4667)  acc5: 96.4000 (96.7429)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9552 (0.8915)  acc1: 81.6000 (83.1360)  acc5: 96.0000 (96.5920)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4653 s / it)
* Acc@1 83.854 Acc@5 96.564 loss 0.878
Accuracy of the model on the 50000 test images: 83.9%
Max accuracy: 84.07%
Epoch: [256]  [   0/1251]  eta: 1:11:43  lr: 0.000240  min_lr: 0.000240  loss: 3.2356 (3.2356)  weight_decay: 0.0500 (0.0500)  time: 3.4398  data: 2.6231  max mem: 40463
Epoch: [256]  [ 200/1251]  eta: 0:08:58  lr: 0.000238  min_lr: 0.000238  loss: 2.9681 (2.7139)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5050 (1.7945)  time: 0.4963  data: 0.0004  max mem: 40463
Epoch: [256]  [ 400/1251]  eta: 0:07:09  lr: 0.000236  min_lr: 0.000236  loss: 2.5624 (2.7168)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5065 (1.7610)  time: 0.4963  data: 0.0004  max mem: 40463
Epoch: [256]  [ 600/1251]  eta: 0:05:27  lr: 0.000235  min_lr: 0.000235  loss: 2.7645 (2.7141)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5344 (1.7373)  time: 0.4968  data: 0.0004  max mem: 40463
Epoch: [256]  [ 800/1251]  eta: 0:03:45  lr: 0.000233  min_lr: 0.000233  loss: 2.7514 (2.7130)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7120 (1.7220)  time: 0.4958  data: 0.0004  max mem: 40463
Epoch: [256]  [1000/1251]  eta: 0:02:05  lr: 0.000231  min_lr: 0.000231  loss: 2.6912 (2.7050)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6592 (1.7275)  time: 0.4959  data: 0.0004  max mem: 40463
Epoch: [256]  [1200/1251]  eta: 0:00:25  lr: 0.000230  min_lr: 0.000230  loss: 2.6423 (2.7040)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7394 (1.7373)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [256]  [1250/1251]  eta: 0:00:00  lr: 0.000229  min_lr: 0.000229  loss: 2.8138 (2.7030)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7452 (1.7370)  time: 0.4213  data: 0.0005  max mem: 40463
Epoch: [256] Total time: 0:10:24 (0.4988 s / it)
Averaged stats: lr: 0.000229  min_lr: 0.000229  loss: 2.8138 (2.7253)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7452 (1.7370)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6466 (0.6466)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 5.4970  data: 5.1823  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7376 (0.7547)  acc1: 86.8000 (87.2364)  acc5: 97.6000 (97.8182)  time: 0.7372  data: 0.4715  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9090 (0.8650)  acc1: 82.4000 (84.1714)  acc5: 96.8000 (96.7619)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9376 (0.8788)  acc1: 81.6000 (83.8080)  acc5: 96.0000 (96.6560)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4730 s / it)
* Acc@1 84.002 Acc@5 96.686 loss 0.868
Accuracy of the model on the 50000 test images: 84.0%
Max accuracy: 84.07%
Epoch: [257]  [   0/1251]  eta: 1:09:08  lr: 0.000229  min_lr: 0.000229  loss: 2.4776 (2.4776)  weight_decay: 0.0500 (0.0500)  time: 3.3159  data: 1.5145  max mem: 40463
Epoch: [257]  [ 200/1251]  eta: 0:08:59  lr: 0.000228  min_lr: 0.000228  loss: 2.8707 (2.7394)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5181 (1.7203)  time: 0.5051  data: 0.0004  max mem: 40463
Epoch: [257]  [ 400/1251]  eta: 0:07:10  lr: 0.000226  min_lr: 0.000226  loss: 2.7764 (2.7331)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2121 (1.7175)  time: 0.4974  data: 0.0004  max mem: 40463
Epoch: [257]  [ 600/1251]  eta: 0:05:27  lr: 0.000224  min_lr: 0.000224  loss: 2.7261 (2.7351)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1627 (1.9298)  time: 0.5071  data: 0.0004  max mem: 40463
Epoch: [257]  [ 800/1251]  eta: 0:03:46  lr: 0.000223  min_lr: 0.000223  loss: 2.5952 (2.7377)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3816 (1.8935)  time: 0.4989  data: 0.0004  max mem: 40463
Epoch: [257]  [1000/1251]  eta: 0:02:05  lr: 0.000221  min_lr: 0.000221  loss: 2.8509 (2.7283)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6359 (1.8819)  time: 0.4981  data: 0.0004  max mem: 40463
Epoch: [257]  [1200/1251]  eta: 0:00:25  lr: 0.000219  min_lr: 0.000219  loss: 2.9351 (2.7149)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5401 (1.8589)  time: 0.4975  data: 0.0004  max mem: 40463
Epoch: [257]  [1250/1251]  eta: 0:00:00  lr: 0.000219  min_lr: 0.000219  loss: 2.7976 (2.7146)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7544 (1.8549)  time: 0.4213  data: 0.0007  max mem: 40463
Epoch: [257] Total time: 0:10:26 (0.5005 s / it)
Averaged stats: lr: 0.000219  min_lr: 0.000219  loss: 2.7976 (2.7179)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7544 (1.8549)
Test:  [ 0/25]  eta: 0:02:07  loss: 0.6197 (0.6197)  acc1: 90.8000 (90.8000)  acc5: 99.2000 (99.2000)  time: 5.1093  data: 4.8140  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7110 (0.7170)  acc1: 87.6000 (87.0546)  acc5: 98.0000 (97.8182)  time: 0.7018  data: 0.4379  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9049 (0.8371)  acc1: 82.4000 (84.0191)  acc5: 96.4000 (96.8381)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9049 (0.8488)  acc1: 82.0000 (83.6160)  acc5: 96.0000 (96.7360)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4577 s / it)
* Acc@1 84.014 Acc@5 96.728 loss 0.838
Accuracy of the model on the 50000 test images: 84.0%
Max accuracy: 84.07%
Epoch: [258]  [   0/1251]  eta: 1:12:47  lr: 0.000219  min_lr: 0.000219  loss: 2.6997 (2.6997)  weight_decay: 0.0500 (0.0500)  time: 3.4915  data: 2.5097  max mem: 40463
Epoch: [258]  [ 200/1251]  eta: 0:08:59  lr: 0.000217  min_lr: 0.000217  loss: 2.5887 (2.7024)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4289 (2.1146)  time: 0.4976  data: 0.0004  max mem: 40463
Epoch: [258]  [ 400/1251]  eta: 0:07:09  lr: 0.000216  min_lr: 0.000216  loss: 2.9251 (2.7174)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.3970 (2.0783)  time: 0.4964  data: 0.0004  max mem: 40463
Epoch: [258]  [ 600/1251]  eta: 0:05:28  lr: 0.000214  min_lr: 0.000214  loss: 2.6514 (2.7057)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5496 (1.9617)  time: 0.4998  data: 0.0004  max mem: 40463
Epoch: [258]  [ 800/1251]  eta: 0:03:46  lr: 0.000212  min_lr: 0.000212  loss: 2.8724 (2.7261)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1790 (1.8985)  time: 0.4980  data: 0.0004  max mem: 40463
Epoch: [258]  [1000/1251]  eta: 0:02:05  lr: 0.000211  min_lr: 0.000211  loss: 2.6950 (2.7174)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6276 (1.8899)  time: 0.4964  data: 0.0004  max mem: 40463
Epoch: [258]  [1200/1251]  eta: 0:00:25  lr: 0.000209  min_lr: 0.000209  loss: 2.7836 (2.7180)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0605 (1.9130)  time: 0.4967  data: 0.0003  max mem: 40463
Epoch: [258]  [1250/1251]  eta: 0:00:00  lr: 0.000209  min_lr: 0.000209  loss: 2.7336 (2.7185)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7297 (1.9216)  time: 0.4223  data: 0.0006  max mem: 40463
Epoch: [258] Total time: 0:10:25 (0.5003 s / it)
Averaged stats: lr: 0.000209  min_lr: 0.000209  loss: 2.7336 (2.7072)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7297 (1.9216)
Test:  [ 0/25]  eta: 0:02:10  loss: 0.5913 (0.5913)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 5.2100  data: 4.9065  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7210 (0.7143)  acc1: 86.8000 (86.7273)  acc5: 97.6000 (97.7818)  time: 0.7109  data: 0.4463  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8614 (0.8331)  acc1: 82.0000 (83.9238)  acc5: 96.4000 (96.6095)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9061 (0.8463)  acc1: 81.6000 (83.5360)  acc5: 96.4000 (96.5600)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4621 s / it)
* Acc@1 84.064 Acc@5 96.682 loss 0.830
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.07%
Epoch: [259]  [   0/1251]  eta: 1:13:58  lr: 0.000209  min_lr: 0.000209  loss: 2.5443 (2.5443)  weight_decay: 0.0500 (0.0500)  time: 3.5478  data: 2.5558  max mem: 40463
Epoch: [259]  [ 200/1251]  eta: 0:08:59  lr: 0.000207  min_lr: 0.000207  loss: 2.7888 (2.7073)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6832 (1.6500)  time: 0.4969  data: 0.0004  max mem: 40463
Epoch: [259]  [ 400/1251]  eta: 0:07:10  lr: 0.000206  min_lr: 0.000206  loss: 2.8133 (2.7146)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7149 (1.6318)  time: 0.5007  data: 0.0004  max mem: 40463
Epoch: [259]  [ 600/1251]  eta: 0:05:27  lr: 0.000204  min_lr: 0.000204  loss: 2.9293 (2.7098)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4275 (1.6574)  time: 0.4967  data: 0.0004  max mem: 40463
Epoch: [259]  [ 800/1251]  eta: 0:03:46  lr: 0.000203  min_lr: 0.000203  loss: 2.8029 (2.7083)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9714 (1.7055)  time: 0.4978  data: 0.0004  max mem: 40463
Epoch: [259]  [1000/1251]  eta: 0:02:05  lr: 0.000201  min_lr: 0.000201  loss: 2.9233 (2.7083)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5150 (1.6929)  time: 0.4969  data: 0.0004  max mem: 40463
Epoch: [259]  [1200/1251]  eta: 0:00:25  lr: 0.000199  min_lr: 0.000199  loss: 2.7731 (2.7068)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1259 (1.7275)  time: 0.4981  data: 0.0004  max mem: 40463
Epoch: [259]  [1250/1251]  eta: 0:00:00  lr: 0.000199  min_lr: 0.000199  loss: 2.8821 (2.7077)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.5066 (1.7849)  time: 0.4216  data: 0.0005  max mem: 40463
Epoch: [259] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.000199  min_lr: 0.000199  loss: 2.8821 (2.7135)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.5066 (1.7849)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.6406 (0.6406)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 5.5939  data: 5.2928  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7350 (0.7497)  acc1: 87.2000 (87.3091)  acc5: 97.6000 (97.8909)  time: 0.7459  data: 0.4814  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9011 (0.8665)  acc1: 82.0000 (84.1714)  acc5: 96.4000 (96.7048)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9283 (0.8810)  acc1: 81.6000 (83.7280)  acc5: 96.0000 (96.6080)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4774 s / it)
* Acc@1 84.056 Acc@5 96.652 loss 0.868
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.07%
Epoch: [260]  [   0/1251]  eta: 1:14:50  lr: 0.000199  min_lr: 0.000199  loss: 2.8016 (2.8016)  weight_decay: 0.0500 (0.0500)  time: 3.5892  data: 1.4873  max mem: 40463
Epoch: [260]  [ 200/1251]  eta: 0:09:03  lr: 0.000197  min_lr: 0.000197  loss: 2.7373 (2.6338)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2561 (2.0191)  time: 0.4983  data: 0.0004  max mem: 40463
Epoch: [260]  [ 400/1251]  eta: 0:07:11  lr: 0.000196  min_lr: 0.000196  loss: 2.6977 (2.6544)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3426 (1.8521)  time: 0.4981  data: 0.0004  max mem: 40463
Epoch: [260]  [ 600/1251]  eta: 0:05:28  lr: 0.000194  min_lr: 0.000194  loss: 2.6424 (2.6723)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5873 (1.8584)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [260]  [ 800/1251]  eta: 0:03:46  lr: 0.000193  min_lr: 0.000193  loss: 2.5255 (2.6764)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5248 (1.8614)  time: 0.4995  data: 0.0004  max mem: 40463
Epoch: [260]  [1000/1251]  eta: 0:02:06  lr: 0.000191  min_lr: 0.000191  loss: 2.7065 (2.6838)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.3287 (1.9445)  time: 0.4982  data: 0.0004  max mem: 40463
Epoch: [260]  [1200/1251]  eta: 0:00:25  lr: 0.000190  min_lr: 0.000190  loss: 2.7783 (2.6890)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3136 (1.9299)  time: 0.4973  data: 0.0004  max mem: 40463
Epoch: [260]  [1250/1251]  eta: 0:00:00  lr: 0.000189  min_lr: 0.000189  loss: 2.8071 (2.6877)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3468 (1.9248)  time: 0.4212  data: 0.0007  max mem: 40463
Epoch: [260] Total time: 0:10:26 (0.5005 s / it)
Averaged stats: lr: 0.000189  min_lr: 0.000189  loss: 2.8071 (2.6963)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3468 (1.9248)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6131 (0.6131)  acc1: 91.2000 (91.2000)  acc5: 99.2000 (99.2000)  time: 5.5088  data: 5.2022  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7300 (0.7264)  acc1: 86.8000 (86.8364)  acc5: 97.6000 (97.8909)  time: 0.7382  data: 0.4732  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8922 (0.8395)  acc1: 82.4000 (84.0000)  acc5: 96.4000 (96.8000)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9065 (0.8523)  acc1: 82.0000 (83.6000)  acc5: 96.0000 (96.6560)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4743 s / it)
* Acc@1 84.196 Acc@5 96.756 loss 0.835
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.20%
Epoch: [261]  [   0/1251]  eta: 0:50:31  lr: 0.000189  min_lr: 0.000189  loss: 2.4277 (2.4277)  weight_decay: 0.0500 (0.0500)  time: 2.4232  data: 1.9242  max mem: 40463
Epoch: [261]  [ 200/1251]  eta: 0:08:55  lr: 0.000188  min_lr: 0.000188  loss: 2.8684 (2.7068)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6135 (1.6371)  time: 0.5006  data: 0.0005  max mem: 40463
Epoch: [261]  [ 400/1251]  eta: 0:07:09  lr: 0.000186  min_lr: 0.000186  loss: 2.7011 (2.6748)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.5005  data: 0.0004  max mem: 40463
Epoch: [261]  [ 600/1251]  eta: 0:05:27  lr: 0.000185  min_lr: 0.000185  loss: 2.8304 (2.6754)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6408 (nan)  time: 0.5078  data: 0.0004  max mem: 40463
Epoch: [261]  [ 800/1251]  eta: 0:03:46  lr: 0.000183  min_lr: 0.000183  loss: 2.9034 (2.6982)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9478 (nan)  time: 0.5005  data: 0.0004  max mem: 40463
Epoch: [261]  [1000/1251]  eta: 0:02:05  lr: 0.000182  min_lr: 0.000182  loss: 2.8317 (2.7006)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8735 (nan)  time: 0.4991  data: 0.0004  max mem: 40463
Epoch: [261]  [1200/1251]  eta: 0:00:25  lr: 0.000180  min_lr: 0.000180  loss: 2.7342 (2.6971)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2515 (nan)  time: 0.4977  data: 0.0004  max mem: 40463
Epoch: [261]  [1250/1251]  eta: 0:00:00  lr: 0.000180  min_lr: 0.000180  loss: 2.5150 (2.6959)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2515 (nan)  time: 0.4214  data: 0.0007  max mem: 40463
Epoch: [261] Total time: 0:10:26 (0.5005 s / it)
Averaged stats: lr: 0.000180  min_lr: 0.000180  loss: 2.5150 (2.6980)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2515 (nan)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.5845 (0.5845)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 5.6254  data: 5.3014  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7037 (0.7009)  acc1: 86.4000 (87.2727)  acc5: 97.6000 (97.7455)  time: 0.7487  data: 0.4822  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8825 (0.8175)  acc1: 82.4000 (84.2286)  acc5: 96.8000 (96.5905)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.8999 (0.8331)  acc1: 82.0000 (83.6960)  acc5: 96.0000 (96.5120)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4787 s / it)
* Acc@1 84.120 Acc@5 96.624 loss 0.817
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.20%
Epoch: [262]  [   0/1251]  eta: 1:08:42  lr: 0.000180  min_lr: 0.000180  loss: 2.9163 (2.9163)  weight_decay: 0.0500 (0.0500)  time: 3.2953  data: 2.1493  max mem: 40463
Epoch: [262]  [ 200/1251]  eta: 0:08:58  lr: 0.000179  min_lr: 0.000179  loss: 2.6525 (2.6735)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4781 (1.6837)  time: 0.4996  data: 0.0005  max mem: 40463
Epoch: [262]  [ 400/1251]  eta: 0:07:10  lr: 0.000177  min_lr: 0.000177  loss: 2.8571 (2.6783)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2785 (1.8887)  time: 0.4989  data: 0.0005  max mem: 40463
Epoch: [262]  [ 600/1251]  eta: 0:05:27  lr: 0.000176  min_lr: 0.000176  loss: 2.7521 (2.6778)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3040 (1.7847)  time: 0.4968  data: 0.0005  max mem: 40463
Epoch: [262]  [ 800/1251]  eta: 0:03:46  lr: 0.000174  min_lr: 0.000174  loss: 2.7640 (2.6878)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3817 (1.7848)  time: 0.5040  data: 0.0005  max mem: 40463
Epoch: [262]  [1000/1251]  eta: 0:02:05  lr: 0.000173  min_lr: 0.000173  loss: 2.7519 (2.6867)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2902 (1.7907)  time: 0.4981  data: 0.0005  max mem: 40463
Epoch: [262]  [1200/1251]  eta: 0:00:25  lr: 0.000171  min_lr: 0.000171  loss: 2.7181 (2.6877)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4848 (1.8058)  time: 0.4989  data: 0.0005  max mem: 40463
Epoch: [262]  [1250/1251]  eta: 0:00:00  lr: 0.000171  min_lr: 0.000171  loss: 2.8850 (2.6890)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3082 (1.7958)  time: 0.4218  data: 0.0007  max mem: 40463
Epoch: [262] Total time: 0:10:26 (0.5006 s / it)
Averaged stats: lr: 0.000171  min_lr: 0.000171  loss: 2.8850 (2.6955)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3082 (1.7958)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.6269 (0.6269)  acc1: 91.2000 (91.2000)  acc5: 99.2000 (99.2000)  time: 5.3451  data: 5.0416  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7506 (0.7396)  acc1: 86.4000 (87.2727)  acc5: 97.6000 (97.8545)  time: 0.7232  data: 0.4586  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9051 (0.8500)  acc1: 82.8000 (84.3048)  acc5: 96.4000 (96.8191)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9177 (0.8647)  acc1: 82.0000 (83.6960)  acc5: 96.4000 (96.6880)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4676 s / it)
* Acc@1 84.064 Acc@5 96.712 loss 0.851
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.20%
Epoch: [263]  [   0/1251]  eta: 1:04:48  lr: 0.000171  min_lr: 0.000171  loss: 2.5627 (2.5627)  weight_decay: 0.0500 (0.0500)  time: 3.1081  data: 2.5052  max mem: 40463
Epoch: [263]  [ 200/1251]  eta: 0:08:58  lr: 0.000169  min_lr: 0.000169  loss: 2.6178 (2.6898)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5108 (1.5573)  time: 0.4982  data: 0.0004  max mem: 40463
Epoch: [263]  [ 400/1251]  eta: 0:07:11  lr: 0.000168  min_lr: 0.000168  loss: 2.5517 (2.6834)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8755 (1.6794)  time: 0.4983  data: 0.0004  max mem: 40463
Epoch: [263]  [ 600/1251]  eta: 0:05:28  lr: 0.000167  min_lr: 0.000167  loss: 2.7197 (2.6951)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6515 (1.6957)  time: 0.5066  data: 0.0004  max mem: 40463
Epoch: [263]  [ 800/1251]  eta: 0:03:46  lr: 0.000165  min_lr: 0.000165  loss: 2.6928 (2.7039)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6949 (1.7367)  time: 0.4985  data: 0.0004  max mem: 40463
Epoch: [263]  [1000/1251]  eta: 0:02:06  lr: 0.000164  min_lr: 0.000164  loss: 2.7664 (2.7015)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7021 (1.7486)  time: 0.4980  data: 0.0004  max mem: 40463
Epoch: [263]  [1200/1251]  eta: 0:00:25  lr: 0.000162  min_lr: 0.000162  loss: 2.7389 (2.6923)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6843 (1.8174)  time: 0.4965  data: 0.0004  max mem: 40463
Epoch: [263]  [1250/1251]  eta: 0:00:00  lr: 0.000162  min_lr: 0.000162  loss: 2.8955 (2.6955)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3225 (1.8119)  time: 0.4216  data: 0.0005  max mem: 40463
Epoch: [263] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.000162  min_lr: 0.000162  loss: 2.8955 (2.6915)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3225 (1.8119)
Test:  [ 0/25]  eta: 0:01:51  loss: 0.6319 (0.6319)  acc1: 91.2000 (91.2000)  acc5: 99.2000 (99.2000)  time: 4.4706  data: 4.1631  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7579 (0.7553)  acc1: 87.2000 (87.1636)  acc5: 97.2000 (97.6727)  time: 0.6772  data: 0.4112  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9356 (0.8692)  acc1: 81.6000 (83.8857)  acc5: 96.4000 (96.6667)  time: 0.2793  data: 0.0181  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9422 (0.8840)  acc1: 81.2000 (83.4560)  acc5: 96.4000 (96.5920)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4478 s / it)
* Acc@1 84.090 Acc@5 96.676 loss 0.871
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.20%
Epoch: [264]  [   0/1251]  eta: 1:11:14  lr: 0.000162  min_lr: 0.000162  loss: 2.7478 (2.7478)  weight_decay: 0.0500 (0.0500)  time: 3.4172  data: 2.5140  max mem: 40463
Epoch: [264]  [ 200/1251]  eta: 0:09:00  lr: 0.000160  min_lr: 0.000160  loss: 2.6227 (2.6690)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3604 (1.7839)  time: 0.5089  data: 0.0004  max mem: 40463
Epoch: [264]  [ 400/1251]  eta: 0:07:12  lr: 0.000159  min_lr: 0.000159  loss: 2.3334 (2.6286)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5778 (1.7226)  time: 0.4990  data: 0.0004  max mem: 40463
Epoch: [264]  [ 600/1251]  eta: 0:05:28  lr: 0.000158  min_lr: 0.000158  loss: 2.8609 (2.6616)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5005 (1.6928)  time: 0.4995  data: 0.0004  max mem: 40463
Epoch: [264]  [ 800/1251]  eta: 0:03:47  lr: 0.000156  min_lr: 0.000156  loss: 2.9278 (2.6719)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4938 (1.6769)  time: 0.4977  data: 0.0004  max mem: 40463
Epoch: [264]  [1000/1251]  eta: 0:02:06  lr: 0.000155  min_lr: 0.000155  loss: 2.6223 (2.6654)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0689 (1.7582)  time: 0.4986  data: 0.0003  max mem: 40463
Epoch: [264]  [1200/1251]  eta: 0:00:25  lr: 0.000154  min_lr: 0.000154  loss: 2.8521 (2.6810)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4705 (1.7917)  time: 0.4967  data: 0.0004  max mem: 40463
Epoch: [264]  [1250/1251]  eta: 0:00:00  lr: 0.000153  min_lr: 0.000153  loss: 2.7932 (2.6847)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4705 (1.8080)  time: 0.4212  data: 0.0005  max mem: 40463
Epoch: [264] Total time: 0:10:27 (0.5017 s / it)
Averaged stats: lr: 0.000153  min_lr: 0.000153  loss: 2.7932 (2.6914)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4705 (1.8080)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.7245 (0.7245)  acc1: 90.8000 (90.8000)  acc5: 99.2000 (99.2000)  time: 5.3256  data: 5.0206  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.8215 (0.8329)  acc1: 87.6000 (87.2000)  acc5: 98.0000 (98.0000)  time: 0.7215  data: 0.4567  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9932 (0.9448)  acc1: 82.0000 (84.0762)  acc5: 96.4000 (96.7238)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 1.0158 (0.9590)  acc1: 82.0000 (83.5200)  acc5: 96.0000 (96.6400)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4671 s / it)
* Acc@1 84.028 Acc@5 96.686 loss 0.946
Accuracy of the model on the 50000 test images: 84.0%
Max accuracy: 84.20%
Epoch: [265]  [   0/1251]  eta: 1:08:18  lr: 0.000153  min_lr: 0.000153  loss: 2.1956 (2.1956)  weight_decay: 0.0500 (0.0500)  time: 3.2761  data: 2.4144  max mem: 40463
Epoch: [265]  [ 200/1251]  eta: 0:09:02  lr: 0.000152  min_lr: 0.000152  loss: 2.8310 (2.6787)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5457 (1.8608)  time: 0.4980  data: 0.0004  max mem: 40463
Epoch: [265]  [ 400/1251]  eta: 0:07:10  lr: 0.000150  min_lr: 0.000150  loss: 2.7230 (2.6688)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6198 (1.7962)  time: 0.4965  data: 0.0004  max mem: 40463
Epoch: [265]  [ 600/1251]  eta: 0:05:27  lr: 0.000149  min_lr: 0.000149  loss: 2.3282 (2.6602)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5231 (1.7214)  time: 0.4993  data: 0.0004  max mem: 40463
Epoch: [265]  [ 800/1251]  eta: 0:03:46  lr: 0.000148  min_lr: 0.000148  loss: 2.7748 (2.6714)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4509 (1.7440)  time: 0.5004  data: 0.0004  max mem: 40463
Epoch: [265]  [1000/1251]  eta: 0:02:05  lr: 0.000146  min_lr: 0.000146  loss: 2.8587 (2.6706)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6534 (1.7668)  time: 0.4974  data: 0.0004  max mem: 40463
Epoch: [265]  [1200/1251]  eta: 0:00:25  lr: 0.000145  min_lr: 0.000145  loss: 2.7914 (2.6781)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5076 (1.8019)  time: 0.5065  data: 0.0004  max mem: 40463
Epoch: [265]  [1250/1251]  eta: 0:00:00  lr: 0.000145  min_lr: 0.000145  loss: 2.7266 (2.6796)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5627 (1.8094)  time: 0.4220  data: 0.0005  max mem: 40463
Epoch: [265] Total time: 0:10:26 (0.5009 s / it)
Averaged stats: lr: 0.000145  min_lr: 0.000145  loss: 2.7266 (2.6863)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5627 (1.8094)
Test:  [ 0/25]  eta: 0:02:08  loss: 0.6021 (0.6021)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 5.1244  data: 4.8173  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7181 (0.7285)  acc1: 87.2000 (87.1273)  acc5: 98.0000 (97.8909)  time: 0.7033  data: 0.4383  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9064 (0.8465)  acc1: 82.4000 (84.3238)  acc5: 96.4000 (96.7048)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9070 (0.8617)  acc1: 82.4000 (83.8240)  acc5: 96.0000 (96.6400)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4586 s / it)
* Acc@1 84.112 Acc@5 96.742 loss 0.850
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.20%
Epoch: [266]  [   0/1251]  eta: 1:10:55  lr: 0.000145  min_lr: 0.000145  loss: 2.8223 (2.8223)  weight_decay: 0.0500 (0.0500)  time: 3.4019  data: 2.7589  max mem: 40463
Epoch: [266]  [ 200/1251]  eta: 0:08:58  lr: 0.000143  min_lr: 0.000143  loss: 2.7326 (2.6657)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5775 (1.7917)  time: 0.4981  data: 0.0004  max mem: 40463
Epoch: [266]  [ 400/1251]  eta: 0:07:09  lr: 0.000142  min_lr: 0.000142  loss: 2.7735 (2.6893)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8457 (1.8159)  time: 0.4968  data: 0.0004  max mem: 40463
Epoch: [266]  [ 600/1251]  eta: 0:05:28  lr: 0.000141  min_lr: 0.000141  loss: 2.8652 (2.6980)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3951 (1.7953)  time: 0.4970  data: 0.0004  max mem: 40463
Epoch: [266]  [ 800/1251]  eta: 0:03:46  lr: 0.000139  min_lr: 0.000139  loss: 2.7938 (2.6860)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4291 (1.7337)  time: 0.4985  data: 0.0004  max mem: 40463
Epoch: [266]  [1000/1251]  eta: 0:02:05  lr: 0.000138  min_lr: 0.000138  loss: 2.7382 (2.6935)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3900 (1.7392)  time: 0.4970  data: 0.0005  max mem: 40463
Epoch: [266]  [1200/1251]  eta: 0:00:25  lr: 0.000137  min_lr: 0.000137  loss: 2.4995 (2.6935)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3348 (1.7181)  time: 0.4968  data: 0.0004  max mem: 40463
Epoch: [266]  [1250/1251]  eta: 0:00:00  lr: 0.000137  min_lr: 0.000137  loss: 2.8441 (2.6950)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3348 (1.7164)  time: 0.4214  data: 0.0005  max mem: 40463
Epoch: [266] Total time: 0:10:26 (0.5008 s / it)
Averaged stats: lr: 0.000137  min_lr: 0.000137  loss: 2.8441 (2.6859)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3348 (1.7164)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.7299 (0.7299)  acc1: 90.4000 (90.4000)  acc5: 98.4000 (98.4000)  time: 5.5495  data: 5.2456  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.8177 (0.8288)  acc1: 87.2000 (87.2727)  acc5: 98.0000 (97.8182)  time: 0.7418  data: 0.4771  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9684 (0.9377)  acc1: 82.0000 (84.2476)  acc5: 96.4000 (96.7429)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9998 (0.9517)  acc1: 82.0000 (83.7760)  acc5: 96.0000 (96.6080)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4756 s / it)
* Acc@1 84.138 Acc@5 96.668 loss 0.939
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.20%
Epoch: [267]  [   0/1251]  eta: 1:14:23  lr: 0.000136  min_lr: 0.000136  loss: 2.7189 (2.7189)  weight_decay: 0.0500 (0.0500)  time: 3.5675  data: 2.3998  max mem: 40463
Epoch: [267]  [ 200/1251]  eta: 0:08:59  lr: 0.000135  min_lr: 0.000135  loss: 2.5988 (2.6515)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3558 (1.7231)  time: 0.5004  data: 0.0004  max mem: 40463
Epoch: [267]  [ 400/1251]  eta: 0:07:12  lr: 0.000134  min_lr: 0.000134  loss: 2.7736 (2.6850)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3171 (1.7131)  time: 0.5071  data: 0.0004  max mem: 40463
Epoch: [267]  [ 600/1251]  eta: 0:05:28  lr: 0.000133  min_lr: 0.000133  loss: 2.7436 (2.6597)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7839 (1.8205)  time: 0.4978  data: 0.0004  max mem: 40463
Epoch: [267]  [ 800/1251]  eta: 0:03:47  lr: 0.000131  min_lr: 0.000131  loss: 2.9202 (2.6685)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6326 (2.0288)  time: 0.4974  data: 0.0004  max mem: 40463
Epoch: [267]  [1000/1251]  eta: 0:02:06  lr: 0.000130  min_lr: 0.000130  loss: 2.5610 (2.6607)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5118 (1.9416)  time: 0.4963  data: 0.0004  max mem: 40463
Epoch: [267]  [1200/1251]  eta: 0:00:25  lr: 0.000129  min_lr: 0.000129  loss: 2.3949 (2.6531)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7204 (2.0359)  time: 0.4987  data: 0.0004  max mem: 40463
Epoch: [267]  [1250/1251]  eta: 0:00:00  lr: 0.000129  min_lr: 0.000129  loss: 2.7568 (2.6545)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9936 (2.0445)  time: 0.4217  data: 0.0005  max mem: 40463
Epoch: [267] Total time: 0:10:27 (0.5014 s / it)
Averaged stats: lr: 0.000129  min_lr: 0.000129  loss: 2.7568 (2.6814)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9936 (2.0445)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.6330 (0.6330)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 5.4056  data: 5.0919  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7362 (0.7314)  acc1: 86.8000 (87.1273)  acc5: 97.6000 (97.7091)  time: 0.7289  data: 0.4632  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8750 (0.8470)  acc1: 82.4000 (83.8476)  acc5: 96.0000 (96.6857)  time: 0.2611  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9139 (0.8596)  acc1: 81.6000 (83.4240)  acc5: 96.0000 (96.5760)  time: 0.2610  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4704 s / it)
* Acc@1 84.124 Acc@5 96.746 loss 0.846
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.20%
Epoch: [268]  [   0/1251]  eta: 1:10:16  lr: 0.000128  min_lr: 0.000128  loss: 2.4749 (2.4749)  weight_decay: 0.0500 (0.0500)  time: 3.3708  data: 1.6100  max mem: 40463
Epoch: [268]  [ 200/1251]  eta: 0:08:59  lr: 0.000127  min_lr: 0.000127  loss: 2.6707 (2.7034)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4288 (1.6234)  time: 0.5021  data: 0.0004  max mem: 40463
Epoch: [268]  [ 400/1251]  eta: 0:07:11  lr: 0.000126  min_lr: 0.000126  loss: 2.8489 (2.7044)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6764 (1.6838)  time: 0.5001  data: 0.0004  max mem: 40463
Epoch: [268]  [ 600/1251]  eta: 0:05:28  lr: 0.000125  min_lr: 0.000125  loss: 2.8418 (2.7033)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8572 (1.7895)  time: 0.4970  data: 0.0004  max mem: 40463
Epoch: [268]  [ 800/1251]  eta: 0:03:47  lr: 0.000123  min_lr: 0.000123  loss: 2.5446 (2.7024)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8124 (1.7924)  time: 0.5126  data: 0.0004  max mem: 40463
Epoch: [268]  [1000/1251]  eta: 0:02:06  lr: 0.000122  min_lr: 0.000122  loss: 2.7844 (2.7040)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8106 (1.7730)  time: 0.4978  data: 0.0004  max mem: 40463
Epoch: [268]  [1200/1251]  eta: 0:00:25  lr: 0.000121  min_lr: 0.000121  loss: 2.6755 (2.6930)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1429 (1.7299)  time: 0.4964  data: 0.0004  max mem: 40463
Epoch: [268]  [1250/1251]  eta: 0:00:00  lr: 0.000121  min_lr: 0.000121  loss: 2.8087 (2.6915)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4004 (1.7223)  time: 0.4216  data: 0.0007  max mem: 40463
Epoch: [268] Total time: 0:10:26 (0.5012 s / it)
Averaged stats: lr: 0.000121  min_lr: 0.000121  loss: 2.8087 (2.6771)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4004 (1.7223)
Test:  [ 0/25]  eta: 0:02:04  loss: 0.6774 (0.6774)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 4.9891  data: 4.6925  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7655 (0.7668)  acc1: 85.6000 (86.8000)  acc5: 97.6000 (97.7091)  time: 0.6910  data: 0.4270  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9238 (0.8772)  acc1: 82.4000 (83.8286)  acc5: 96.0000 (96.6476)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9248 (0.8916)  acc1: 82.0000 (83.3760)  acc5: 96.0000 (96.5600)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4530 s / it)
* Acc@1 84.212 Acc@5 96.738 loss 0.877
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.21%
Epoch: [269]  [   0/1251]  eta: 0:50:43  lr: 0.000121  min_lr: 0.000121  loss: 1.9559 (1.9559)  weight_decay: 0.0500 (0.0500)  time: 2.4325  data: 1.9268  max mem: 40463
Epoch: [269]  [ 200/1251]  eta: 0:08:59  lr: 0.000120  min_lr: 0.000120  loss: 2.7035 (2.6546)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6701 (1.9381)  time: 0.4979  data: 0.0004  max mem: 40463
Epoch: [269]  [ 400/1251]  eta: 0:07:10  lr: 0.000118  min_lr: 0.000118  loss: 2.8992 (2.6679)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9003 (1.9640)  time: 0.4976  data: 0.0004  max mem: 40463
Epoch: [269]  [ 600/1251]  eta: 0:05:27  lr: 0.000117  min_lr: 0.000117  loss: 2.7310 (2.6651)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7806 (2.0190)  time: 0.4961  data: 0.0004  max mem: 40463
Epoch: [269]  [ 800/1251]  eta: 0:03:46  lr: 0.000116  min_lr: 0.000116  loss: 2.8307 (2.6683)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4639 (1.9536)  time: 0.4990  data: 0.0005  max mem: 40463
Epoch: [269]  [1000/1251]  eta: 0:02:05  lr: 0.000115  min_lr: 0.000115  loss: 2.8180 (2.6651)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4162 (1.9061)  time: 0.4976  data: 0.0004  max mem: 40463
Epoch: [269]  [1200/1251]  eta: 0:00:25  lr: 0.000113  min_lr: 0.000113  loss: 2.8228 (2.6727)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3952 (1.8415)  time: 0.5090  data: 0.0004  max mem: 40463
Epoch: [269]  [1250/1251]  eta: 0:00:00  lr: 0.000113  min_lr: 0.000113  loss: 2.9785 (2.6758)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3952 (1.8225)  time: 0.4255  data: 0.0006  max mem: 40463
Epoch: [269] Total time: 0:10:26 (0.5006 s / it)
Averaged stats: lr: 0.000113  min_lr: 0.000113  loss: 2.9785 (2.6730)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3952 (1.8225)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.6549 (0.6549)  acc1: 90.8000 (90.8000)  acc5: 99.2000 (99.2000)  time: 5.4728  data: 5.1701  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7739 (0.7729)  acc1: 86.4000 (86.9455)  acc5: 97.2000 (97.7091)  time: 0.7347  data: 0.4703  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9430 (0.8861)  acc1: 81.6000 (83.8095)  acc5: 96.4000 (96.6667)  time: 0.2606  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9521 (0.8997)  acc1: 81.6000 (83.3760)  acc5: 96.0000 (96.5920)  time: 0.2605  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4728 s / it)
* Acc@1 84.066 Acc@5 96.754 loss 0.884
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.21%
Epoch: [270]  [   0/1251]  eta: 1:10:21  lr: 0.000113  min_lr: 0.000113  loss: 3.0729 (3.0729)  weight_decay: 0.0500 (0.0500)  time: 3.3745  data: 2.8083  max mem: 40463
Epoch: [270]  [ 200/1251]  eta: 0:08:58  lr: 0.000112  min_lr: 0.000112  loss: 2.5831 (2.6479)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8117 (1.8937)  time: 0.4956  data: 0.0004  max mem: 40463
Epoch: [270]  [ 400/1251]  eta: 0:07:09  lr: 0.000111  min_lr: 0.000111  loss: 2.8160 (2.6539)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3760 (nan)  time: 0.4959  data: 0.0004  max mem: 40463
Epoch: [270]  [ 600/1251]  eta: 0:05:27  lr: 0.000110  min_lr: 0.000110  loss: 2.7800 (2.6562)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6712 (nan)  time: 0.4987  data: 0.0004  max mem: 40463
Epoch: [270]  [ 800/1251]  eta: 0:03:46  lr: 0.000109  min_lr: 0.000109  loss: 2.9486 (2.6643)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6705 (nan)  time: 0.4966  data: 0.0004  max mem: 40463
Epoch: [270]  [1000/1251]  eta: 0:02:05  lr: 0.000107  min_lr: 0.000107  loss: 2.8017 (2.6662)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5048 (nan)  time: 0.4965  data: 0.0004  max mem: 40463
Epoch: [270]  [1200/1251]  eta: 0:00:25  lr: 0.000106  min_lr: 0.000106  loss: 2.7096 (2.6648)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5638 (nan)  time: 0.4980  data: 0.0004  max mem: 40463
Epoch: [270]  [1250/1251]  eta: 0:00:00  lr: 0.000106  min_lr: 0.000106  loss: 2.9309 (2.6649)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5925 (nan)  time: 0.4220  data: 0.0005  max mem: 40463
Epoch: [270] Total time: 0:10:25 (0.5002 s / it)
Averaged stats: lr: 0.000106  min_lr: 0.000106  loss: 2.9309 (2.6692)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5925 (nan)
Test:  [ 0/25]  eta: 0:02:05  loss: 0.6914 (0.6914)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.0166  data: 4.7144  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.8001 (0.7947)  acc1: 87.2000 (87.2364)  acc5: 97.2000 (97.7091)  time: 0.6933  data: 0.4288  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9689 (0.9087)  acc1: 82.0000 (83.9238)  acc5: 96.4000 (96.5333)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9689 (0.9224)  acc1: 82.0000 (83.4400)  acc5: 96.0000 (96.4640)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4541 s / it)
* Acc@1 84.130 Acc@5 96.656 loss 0.904
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.21%
Epoch: [271]  [   0/1251]  eta: 1:07:17  lr: 0.000106  min_lr: 0.000106  loss: 3.3026 (3.3026)  weight_decay: 0.0500 (0.0500)  time: 3.2278  data: 2.2338  max mem: 40463
Epoch: [271]  [ 200/1251]  eta: 0:08:59  lr: 0.000105  min_lr: 0.000105  loss: 2.7390 (2.7026)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6107 (1.9286)  time: 0.4985  data: 0.0004  max mem: 40463
Epoch: [271]  [ 400/1251]  eta: 0:07:10  lr: 0.000104  min_lr: 0.000104  loss: 2.6642 (2.6802)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7800 (1.8462)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [271]  [ 600/1251]  eta: 0:05:28  lr: 0.000102  min_lr: 0.000102  loss: 2.6754 (2.6678)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2620 (1.7424)  time: 0.4988  data: 0.0004  max mem: 40463
Epoch: [271]  [ 800/1251]  eta: 0:03:46  lr: 0.000101  min_lr: 0.000101  loss: 2.7707 (2.6642)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4217 (1.7847)  time: 0.4983  data: 0.0004  max mem: 40463
Epoch: [271]  [1000/1251]  eta: 0:02:06  lr: 0.000100  min_lr: 0.000100  loss: 2.6463 (2.6805)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7686 (1.7523)  time: 0.5080  data: 0.0004  max mem: 40463
Epoch: [271]  [1200/1251]  eta: 0:00:25  lr: 0.000099  min_lr: 0.000099  loss: 2.8054 (2.6887)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9730 (1.8041)  time: 0.4990  data: 0.0004  max mem: 40463
Epoch: [271]  [1250/1251]  eta: 0:00:00  lr: 0.000099  min_lr: 0.000099  loss: 2.5849 (2.6855)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8020 (1.8183)  time: 0.4213  data: 0.0005  max mem: 40463
Epoch: [271] Total time: 0:10:27 (0.5013 s / it)
Averaged stats: lr: 0.000099  min_lr: 0.000099  loss: 2.5849 (2.6764)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8020 (1.8183)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6170 (0.6170)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 5.5510  data: 5.2428  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7311 (0.7279)  acc1: 87.2000 (87.3455)  acc5: 97.6000 (97.8545)  time: 0.7420  data: 0.4769  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8984 (0.8444)  acc1: 82.4000 (84.1524)  acc5: 96.8000 (96.8571)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9032 (0.8594)  acc1: 82.4000 (83.7760)  acc5: 96.4000 (96.7200)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4753 s / it)
* Acc@1 84.296 Acc@5 96.740 loss 0.846
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.30%
Epoch: [272]  [   0/1251]  eta: 1:03:31  lr: 0.000099  min_lr: 0.000099  loss: 2.2802 (2.2802)  weight_decay: 0.0500 (0.0500)  time: 3.0466  data: 2.5440  max mem: 40463
Epoch: [272]  [ 200/1251]  eta: 0:08:58  lr: 0.000098  min_lr: 0.000098  loss: 2.7473 (2.6510)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7340 (1.7936)  time: 0.5080  data: 0.0004  max mem: 40463
Epoch: [272]  [ 400/1251]  eta: 0:07:11  lr: 0.000097  min_lr: 0.000097  loss: 2.8388 (2.6700)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6643 (1.8450)  time: 0.4961  data: 0.0004  max mem: 40463
Epoch: [272]  [ 600/1251]  eta: 0:05:28  lr: 0.000096  min_lr: 0.000096  loss: 2.8238 (2.6788)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0937 (1.8314)  time: 0.4980  data: 0.0005  max mem: 40463
Epoch: [272]  [ 800/1251]  eta: 0:03:46  lr: 0.000094  min_lr: 0.000094  loss: 2.5576 (2.6697)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4976 (1.7923)  time: 0.5079  data: 0.0004  max mem: 40463
Epoch: [272]  [1000/1251]  eta: 0:02:06  lr: 0.000093  min_lr: 0.000093  loss: 2.7669 (2.6746)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3706 (1.7554)  time: 0.4964  data: 0.0004  max mem: 40463
Epoch: [272]  [1200/1251]  eta: 0:00:25  lr: 0.000092  min_lr: 0.000092  loss: 2.8579 (2.6802)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4527 (1.7463)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [272]  [1250/1251]  eta: 0:00:00  lr: 0.000092  min_lr: 0.000092  loss: 2.8456 (2.6799)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5663 (1.7464)  time: 0.4215  data: 0.0006  max mem: 40463
Epoch: [272] Total time: 0:10:26 (0.5004 s / it)
Averaged stats: lr: 0.000092  min_lr: 0.000092  loss: 2.8456 (2.6675)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5663 (1.7464)
Test:  [ 0/25]  eta: 0:02:06  loss: 0.5943 (0.5943)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 5.0601  data: 4.7514  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7168 (0.7137)  acc1: 87.6000 (87.2000)  acc5: 97.6000 (97.7818)  time: 0.6973  data: 0.4322  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9074 (0.8352)  acc1: 82.4000 (83.9810)  acc5: 96.4000 (96.6667)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9132 (0.8504)  acc1: 81.2000 (83.5040)  acc5: 96.0000 (96.5440)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4555 s / it)
* Acc@1 84.176 Acc@5 96.666 loss 0.836
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.30%
Epoch: [273]  [   0/1251]  eta: 1:08:54  lr: 0.000092  min_lr: 0.000092  loss: 2.0094 (2.0094)  weight_decay: 0.0500 (0.0500)  time: 3.3049  data: 2.5249  max mem: 40463
Epoch: [273]  [ 200/1251]  eta: 0:09:03  lr: 0.000091  min_lr: 0.000091  loss: 2.9436 (2.6343)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5062 (nan)  time: 0.4967  data: 0.0004  max mem: 40463
Epoch: [273]  [ 400/1251]  eta: 0:07:11  lr: 0.000090  min_lr: 0.000090  loss: 2.7469 (2.6536)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2303 (nan)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [273]  [ 600/1251]  eta: 0:05:28  lr: 0.000089  min_lr: 0.000089  loss: 2.7935 (2.6621)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1856 (nan)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [273]  [ 800/1251]  eta: 0:03:47  lr: 0.000088  min_lr: 0.000088  loss: 2.9007 (2.6643)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4175 (nan)  time: 0.4973  data: 0.0004  max mem: 40463
Epoch: [273]  [1000/1251]  eta: 0:02:06  lr: 0.000087  min_lr: 0.000087  loss: 2.5515 (2.6607)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6047 (nan)  time: 0.4974  data: 0.0004  max mem: 40463
Epoch: [273]  [1200/1251]  eta: 0:00:25  lr: 0.000086  min_lr: 0.000086  loss: 2.4284 (2.6687)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3207 (nan)  time: 0.5052  data: 0.0004  max mem: 40463
Epoch: [273]  [1250/1251]  eta: 0:00:00  lr: 0.000085  min_lr: 0.000085  loss: 2.5834 (2.6667)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3864 (nan)  time: 0.4217  data: 0.0005  max mem: 40463
Epoch: [273] Total time: 0:10:27 (0.5013 s / it)
Averaged stats: lr: 0.000085  min_lr: 0.000085  loss: 2.5834 (2.6692)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3864 (nan)
Test:  [ 0/25]  eta: 0:02:23  loss: 0.6227 (0.6227)  acc1: 90.8000 (90.8000)  acc5: 98.8000 (98.8000)  time: 5.7371  data: 5.4307  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7412 (0.7353)  acc1: 86.8000 (87.1273)  acc5: 97.6000 (97.7455)  time: 0.7588  data: 0.4939  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9062 (0.8468)  acc1: 82.8000 (84.1333)  acc5: 96.8000 (96.8381)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9087 (0.8620)  acc1: 82.0000 (83.6320)  acc5: 96.4000 (96.7200)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:12 (0.4827 s / it)
* Acc@1 84.222 Acc@5 96.748 loss 0.847
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.30%
Epoch: [274]  [   0/1251]  eta: 1:09:46  lr: 0.000085  min_lr: 0.000085  loss: 2.9440 (2.9440)  weight_decay: 0.0500 (0.0500)  time: 3.3462  data: 2.3407  max mem: 40463
Epoch: [274]  [ 200/1251]  eta: 0:09:00  lr: 0.000084  min_lr: 0.000084  loss: 2.6898 (2.6736)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5699 (1.6647)  time: 0.4987  data: 0.0004  max mem: 40463
Epoch: [274]  [ 400/1251]  eta: 0:07:11  lr: 0.000083  min_lr: 0.000083  loss: 2.5990 (2.6540)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9014 (1.8090)  time: 0.4973  data: 0.0004  max mem: 40463
Epoch: [274]  [ 600/1251]  eta: 0:05:29  lr: 0.000082  min_lr: 0.000082  loss: 2.7167 (2.6422)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3544 (1.7760)  time: 0.5005  data: 0.0004  max mem: 40463
Epoch: [274]  [ 800/1251]  eta: 0:03:47  lr: 0.000081  min_lr: 0.000081  loss: 2.8899 (2.6562)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6962 (1.7379)  time: 0.4990  data: 0.0004  max mem: 40463
Epoch: [274]  [1000/1251]  eta: 0:02:06  lr: 0.000080  min_lr: 0.000080  loss: 2.8920 (2.6504)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3851 (1.6795)  time: 0.4984  data: 0.0004  max mem: 40463
Epoch: [274]  [1200/1251]  eta: 0:00:25  lr: 0.000079  min_lr: 0.000079  loss: 2.5630 (2.6583)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2539 (1.7003)  time: 0.4969  data: 0.0004  max mem: 40463
Epoch: [274]  [1250/1251]  eta: 0:00:00  lr: 0.000079  min_lr: 0.000079  loss: 2.8066 (2.6609)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1150 (1.7029)  time: 0.4214  data: 0.0005  max mem: 40463
Epoch: [274] Total time: 0:10:27 (0.5014 s / it)
Averaged stats: lr: 0.000079  min_lr: 0.000079  loss: 2.8066 (2.6590)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1150 (1.7029)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6317 (0.6317)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 5.5596  data: 5.2612  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7528 (0.7457)  acc1: 87.6000 (87.3818)  acc5: 97.6000 (97.7455)  time: 0.7428  data: 0.4786  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9161 (0.8634)  acc1: 82.8000 (84.2476)  acc5: 96.4000 (96.7619)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9279 (0.8784)  acc1: 82.4000 (83.7440)  acc5: 96.4000 (96.6240)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4765 s / it)
* Acc@1 84.154 Acc@5 96.716 loss 0.864
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.30%
Epoch: [275]  [   0/1251]  eta: 1:10:25  lr: 0.000079  min_lr: 0.000079  loss: 2.7460 (2.7460)  weight_decay: 0.0500 (0.0500)  time: 3.3777  data: 2.2873  max mem: 40463
Epoch: [275]  [ 200/1251]  eta: 0:09:00  lr: 0.000078  min_lr: 0.000078  loss: 2.8441 (2.6540)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7744 (1.9514)  time: 0.5095  data: 0.0004  max mem: 40463
Epoch: [275]  [ 400/1251]  eta: 0:07:12  lr: 0.000077  min_lr: 0.000077  loss: 2.7143 (2.6744)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5720 (1.9228)  time: 0.5058  data: 0.0004  max mem: 40463
Epoch: [275]  [ 600/1251]  eta: 0:05:28  lr: 0.000076  min_lr: 0.000076  loss: 2.6333 (2.6572)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7341 (1.9073)  time: 0.4998  data: 0.0004  max mem: 40463
Epoch: [275]  [ 800/1251]  eta: 0:03:46  lr: 0.000075  min_lr: 0.000075  loss: 2.7544 (2.6550)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5622 (1.8271)  time: 0.4963  data: 0.0004  max mem: 40463
Epoch: [275]  [1000/1251]  eta: 0:02:06  lr: 0.000074  min_lr: 0.000074  loss: 2.6577 (2.6511)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4083 (1.7922)  time: 0.5038  data: 0.0004  max mem: 40463
Epoch: [275]  [1200/1251]  eta: 0:00:25  lr: 0.000073  min_lr: 0.000073  loss: 2.6854 (2.6439)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4424 (1.7899)  time: 0.4980  data: 0.0004  max mem: 40463
Epoch: [275]  [1250/1251]  eta: 0:00:00  lr: 0.000073  min_lr: 0.000073  loss: 2.6771 (2.6477)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6414 (1.7984)  time: 0.4220  data: 0.0005  max mem: 40463
Epoch: [275] Total time: 0:10:27 (0.5014 s / it)
Averaged stats: lr: 0.000073  min_lr: 0.000073  loss: 2.6771 (2.6611)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6414 (1.7984)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.6286 (0.6286)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 5.4267  data: 5.1201  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7411 (0.7487)  acc1: 87.6000 (87.1273)  acc5: 97.2000 (97.6364)  time: 0.7307  data: 0.4657  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9330 (0.8675)  acc1: 82.4000 (84.0000)  acc5: 96.0000 (96.5905)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9408 (0.8826)  acc1: 82.0000 (83.5680)  acc5: 96.0000 (96.4800)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4706 s / it)
* Acc@1 84.118 Acc@5 96.638 loss 0.870
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.30%
Epoch: [276]  [   0/1251]  eta: 1:11:48  lr: 0.000073  min_lr: 0.000073  loss: 2.7170 (2.7170)  weight_decay: 0.0500 (0.0500)  time: 3.4439  data: 1.5729  max mem: 40463
Epoch: [276]  [ 200/1251]  eta: 0:08:59  lr: 0.000072  min_lr: 0.000072  loss: 2.5994 (2.6261)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2648 (1.6302)  time: 0.4990  data: 0.0004  max mem: 40463
Epoch: [276]  [ 400/1251]  eta: 0:07:11  lr: 0.000071  min_lr: 0.000071  loss: 2.7700 (2.6470)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5098 (1.6545)  time: 0.4969  data: 0.0004  max mem: 40463
Epoch: [276]  [ 600/1251]  eta: 0:05:28  lr: 0.000070  min_lr: 0.000070  loss: 2.6776 (2.6525)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5679 (1.6406)  time: 0.4964  data: 0.0004  max mem: 40463
Epoch: [276]  [ 800/1251]  eta: 0:03:46  lr: 0.000069  min_lr: 0.000069  loss: 2.8499 (2.6581)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5332 (1.6507)  time: 0.5107  data: 0.0004  max mem: 40463
Epoch: [276]  [1000/1251]  eta: 0:02:06  lr: 0.000068  min_lr: 0.000068  loss: 2.5121 (2.6507)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4082 (1.6466)  time: 0.4967  data: 0.0004  max mem: 40463
Epoch: [276]  [1200/1251]  eta: 0:00:25  lr: 0.000067  min_lr: 0.000067  loss: 2.7137 (2.6567)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6196 (1.6793)  time: 0.4970  data: 0.0004  max mem: 40463
Epoch: [276]  [1250/1251]  eta: 0:00:00  lr: 0.000067  min_lr: 0.000067  loss: 2.7525 (2.6572)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3500 (1.6762)  time: 0.4217  data: 0.0005  max mem: 40463
Epoch: [276] Total time: 0:10:26 (0.5006 s / it)
Averaged stats: lr: 0.000067  min_lr: 0.000067  loss: 2.7525 (2.6563)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3500 (1.6762)
Test:  [ 0/25]  eta: 0:01:54  loss: 0.6040 (0.6040)  acc1: 90.8000 (90.8000)  acc5: 99.2000 (99.2000)  time: 4.5766  data: 4.2553  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7314 (0.7202)  acc1: 86.8000 (87.2727)  acc5: 97.2000 (97.7091)  time: 0.6853  data: 0.4190  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8984 (0.8373)  acc1: 83.2000 (84.1905)  acc5: 96.4000 (96.7619)  time: 0.2785  data: 0.0177  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9096 (0.8527)  acc1: 81.2000 (83.7440)  acc5: 96.0000 (96.6880)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4514 s / it)
* Acc@1 84.224 Acc@5 96.708 loss 0.840
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.30%
Epoch: [277]  [   0/1251]  eta: 1:09:20  lr: 0.000067  min_lr: 0.000067  loss: 2.7986 (2.7986)  weight_decay: 0.0500 (0.0500)  time: 3.3260  data: 2.6820  max mem: 40463
Epoch: [277]  [ 200/1251]  eta: 0:09:03  lr: 0.000066  min_lr: 0.000066  loss: 2.8754 (2.6316)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2503 (1.3362)  time: 0.4991  data: 0.0004  max mem: 40463
Epoch: [277]  [ 400/1251]  eta: 0:07:12  lr: 0.000065  min_lr: 0.000065  loss: 2.5779 (2.6318)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0495 (1.5662)  time: 0.4965  data: 0.0004  max mem: 40463
Epoch: [277]  [ 600/1251]  eta: 0:05:28  lr: 0.000064  min_lr: 0.000064  loss: 2.6314 (2.6254)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9810 (1.6515)  time: 0.4964  data: 0.0004  max mem: 40463
Epoch: [277]  [ 800/1251]  eta: 0:03:46  lr: 0.000064  min_lr: 0.000064  loss: 2.8270 (2.6424)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8222 (1.6907)  time: 0.4993  data: 0.0004  max mem: 40463
Epoch: [277]  [1000/1251]  eta: 0:02:06  lr: 0.000063  min_lr: 0.000063  loss: 2.8871 (2.6416)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5664 (1.7189)  time: 0.4982  data: 0.0004  max mem: 40463
Epoch: [277]  [1200/1251]  eta: 0:00:25  lr: 0.000062  min_lr: 0.000062  loss: 2.7551 (2.6366)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5045 (1.7087)  time: 0.4992  data: 0.0004  max mem: 40463
Epoch: [277]  [1250/1251]  eta: 0:00:00  lr: 0.000062  min_lr: 0.000062  loss: 2.7454 (2.6355)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4305 (1.7284)  time: 0.4252  data: 0.0005  max mem: 40463
Epoch: [277] Total time: 0:10:26 (0.5011 s / it)
Averaged stats: lr: 0.000062  min_lr: 0.000062  loss: 2.7454 (2.6506)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4305 (1.7284)
Test:  [ 0/25]  eta: 0:02:06  loss: 0.6282 (0.6282)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 5.0461  data: 4.7477  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7572 (0.7508)  acc1: 86.8000 (87.1636)  acc5: 97.6000 (97.7091)  time: 0.6961  data: 0.4320  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9248 (0.8639)  acc1: 83.2000 (84.0191)  acc5: 96.4000 (96.7429)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9254 (0.8786)  acc1: 81.2000 (83.6000)  acc5: 96.0000 (96.6240)  time: 0.2607  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4559 s / it)
* Acc@1 84.250 Acc@5 96.734 loss 0.865
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.30%
Epoch: [278]  [   0/1251]  eta: 1:14:13  lr: 0.000062  min_lr: 0.000062  loss: 1.8040 (1.8040)  weight_decay: 0.0500 (0.0500)  time: 3.5603  data: 1.8460  max mem: 40463
Epoch: [278]  [ 200/1251]  eta: 0:09:02  lr: 0.000061  min_lr: 0.000061  loss: 2.9193 (2.6178)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5620 (1.7515)  time: 0.4990  data: 0.0004  max mem: 40463
Epoch: [278]  [ 400/1251]  eta: 0:07:11  lr: 0.000060  min_lr: 0.000060  loss: 2.8246 (2.6533)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3313 (1.6559)  time: 0.4988  data: 0.0004  max mem: 40463
Epoch: [278]  [ 600/1251]  eta: 0:05:29  lr: 0.000059  min_lr: 0.000059  loss: 2.6512 (2.6517)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5180 (1.6362)  time: 0.5140  data: 0.0005  max mem: 40463
Epoch: [278]  [ 800/1251]  eta: 0:03:47  lr: 0.000058  min_lr: 0.000058  loss: 2.8140 (2.6580)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6708 (1.6453)  time: 0.4999  data: 0.0004  max mem: 40463
Epoch: [278]  [1000/1251]  eta: 0:02:06  lr: 0.000057  min_lr: 0.000057  loss: 2.8211 (2.6662)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3839 (1.6346)  time: 0.4985  data: 0.0003  max mem: 40463
Epoch: [278]  [1200/1251]  eta: 0:00:25  lr: 0.000056  min_lr: 0.000056  loss: 2.5270 (2.6635)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2226 (1.6777)  time: 0.4963  data: 0.0003  max mem: 40463
Epoch: [278]  [1250/1251]  eta: 0:00:00  lr: 0.000056  min_lr: 0.000056  loss: 2.6985 (2.6605)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4332 (1.7240)  time: 0.4282  data: 0.0006  max mem: 40463
Epoch: [278] Total time: 0:10:28 (0.5023 s / it)
Averaged stats: lr: 0.000056  min_lr: 0.000056  loss: 2.6985 (2.6584)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4332 (1.7240)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.5938 (0.5938)  acc1: 91.2000 (91.2000)  acc5: 99.2000 (99.2000)  time: 5.5531  data: 5.2469  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7315 (0.7162)  acc1: 87.2000 (87.3818)  acc5: 97.6000 (97.8182)  time: 0.7420  data: 0.4773  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8896 (0.8274)  acc1: 82.4000 (84.0000)  acc5: 96.4000 (96.8952)  time: 0.2608  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.8936 (0.8432)  acc1: 82.0000 (83.5680)  acc5: 96.0000 (96.7040)  time: 0.2607  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4751 s / it)
* Acc@1 84.216 Acc@5 96.788 loss 0.828
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.30%
Epoch: [279]  [   0/1251]  eta: 1:11:15  lr: 0.000056  min_lr: 0.000056  loss: 2.9017 (2.9017)  weight_decay: 0.0500 (0.0500)  time: 3.4173  data: 2.6327  max mem: 40463
Epoch: [279]  [ 200/1251]  eta: 0:09:00  lr: 0.000055  min_lr: 0.000055  loss: 2.4874 (2.6389)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8204 (1.8990)  time: 0.4987  data: 0.0004  max mem: 40463
Epoch: [279]  [ 400/1251]  eta: 0:07:11  lr: 0.000055  min_lr: 0.000055  loss: 2.6233 (2.6569)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6189 (1.9579)  time: 0.5075  data: 0.0005  max mem: 40463
Epoch: [279]  [ 600/1251]  eta: 0:05:28  lr: 0.000054  min_lr: 0.000054  loss: 2.7084 (2.6641)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6141 (1.9037)  time: 0.4971  data: 0.0004  max mem: 40463
Epoch: [279]  [ 800/1251]  eta: 0:03:46  lr: 0.000053  min_lr: 0.000053  loss: 2.7378 (2.6556)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4202 (1.8803)  time: 0.4966  data: 0.0003  max mem: 40463
Epoch: [279]  [1000/1251]  eta: 0:02:06  lr: 0.000052  min_lr: 0.000052  loss: 2.4119 (2.6413)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5204 (1.8608)  time: 0.4974  data: 0.0005  max mem: 40463
Epoch: [279]  [1200/1251]  eta: 0:00:25  lr: 0.000051  min_lr: 0.000051  loss: 2.8380 (2.6505)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5460 (1.8863)  time: 0.4961  data: 0.0003  max mem: 40463
Epoch: [279]  [1250/1251]  eta: 0:00:00  lr: 0.000051  min_lr: 0.000051  loss: 2.6154 (2.6537)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3614 (1.8774)  time: 0.4222  data: 0.0006  max mem: 40463
Epoch: [279] Total time: 0:10:26 (0.5010 s / it)
Averaged stats: lr: 0.000051  min_lr: 0.000051  loss: 2.6154 (2.6499)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3614 (1.8774)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6309 (0.6309)  acc1: 90.8000 (90.8000)  acc5: 98.8000 (98.8000)  time: 5.4881  data: 5.1803  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7563 (0.7489)  acc1: 87.2000 (87.4182)  acc5: 97.6000 (97.7091)  time: 0.7362  data: 0.4712  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9259 (0.8635)  acc1: 82.4000 (84.1333)  acc5: 96.0000 (96.7048)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9326 (0.8786)  acc1: 81.6000 (83.6960)  acc5: 96.0000 (96.5600)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4725 s / it)
* Acc@1 84.216 Acc@5 96.728 loss 0.863
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.30%
Epoch: [280]  [   0/1251]  eta: 1:04:54  lr: 0.000051  min_lr: 0.000051  loss: 2.0706 (2.0706)  weight_decay: 0.0500 (0.0500)  time: 3.1127  data: 1.5660  max mem: 40463
Epoch: [280]  [ 200/1251]  eta: 0:08:58  lr: 0.000050  min_lr: 0.000050  loss: 2.8570 (2.6209)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4053 (1.6858)  time: 0.4970  data: 0.0004  max mem: 40463
Epoch: [280]  [ 400/1251]  eta: 0:07:12  lr: 0.000050  min_lr: 0.000050  loss: 2.6836 (2.6189)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3131 (nan)  time: 0.5003  data: 0.0004  max mem: 40463
Epoch: [280]  [ 600/1251]  eta: 0:05:29  lr: 0.000049  min_lr: 0.000049  loss: 2.7099 (2.6106)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6399 (nan)  time: 0.5009  data: 0.0004  max mem: 40463
Epoch: [280]  [ 800/1251]  eta: 0:03:47  lr: 0.000048  min_lr: 0.000048  loss: 2.8895 (2.6188)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3345 (nan)  time: 0.5065  data: 0.0004  max mem: 40463
Epoch: [280]  [1000/1251]  eta: 0:02:06  lr: 0.000047  min_lr: 0.000047  loss: 2.8044 (2.6296)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7796 (nan)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [280]  [1200/1251]  eta: 0:00:25  lr: 0.000046  min_lr: 0.000046  loss: 2.5547 (2.6304)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5910 (nan)  time: 0.4979  data: 0.0005  max mem: 40463
Epoch: [280]  [1250/1251]  eta: 0:00:00  lr: 0.000046  min_lr: 0.000046  loss: 2.6437 (2.6333)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6667 (nan)  time: 0.4218  data: 0.0007  max mem: 40463
Epoch: [280] Total time: 0:10:28 (0.5026 s / it)
Averaged stats: lr: 0.000046  min_lr: 0.000046  loss: 2.6437 (2.6471)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6667 (nan)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.6343 (0.6343)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.5794  data: 5.2650  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7544 (0.7445)  acc1: 87.6000 (87.4182)  acc5: 97.6000 (97.8182)  time: 0.7446  data: 0.4789  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9205 (0.8609)  acc1: 82.4000 (84.1905)  acc5: 96.4000 (96.8381)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9253 (0.8759)  acc1: 82.0000 (83.7600)  acc5: 96.0000 (96.6560)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4766 s / it)
* Acc@1 84.224 Acc@5 96.756 loss 0.860
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.30%
Epoch: [281]  [   0/1251]  eta: 1:10:46  lr: 0.000046  min_lr: 0.000046  loss: 2.7074 (2.7074)  weight_decay: 0.0500 (0.0500)  time: 3.3943  data: 2.7739  max mem: 40463
Epoch: [281]  [ 200/1251]  eta: 0:09:04  lr: 0.000046  min_lr: 0.000046  loss: 2.7761 (2.6190)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6437 (1.8464)  time: 0.5050  data: 0.0004  max mem: 40463
Epoch: [281]  [ 400/1251]  eta: 0:07:12  lr: 0.000045  min_lr: 0.000045  loss: 2.8244 (2.6274)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4785 (1.7023)  time: 0.4984  data: 0.0003  max mem: 40463
Epoch: [281]  [ 600/1251]  eta: 0:05:28  lr: 0.000044  min_lr: 0.000044  loss: 2.6444 (2.6220)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2971 (1.6318)  time: 0.4975  data: 0.0004  max mem: 40463
Epoch: [281]  [ 800/1251]  eta: 0:03:47  lr: 0.000043  min_lr: 0.000043  loss: 2.7764 (2.6389)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0964 (1.6152)  time: 0.4972  data: 0.0003  max mem: 40463
Epoch: [281]  [1000/1251]  eta: 0:02:06  lr: 0.000043  min_lr: 0.000043  loss: 2.8593 (2.6485)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3956 (1.5895)  time: 0.5000  data: 0.0004  max mem: 40463
Epoch: [281]  [1200/1251]  eta: 0:00:25  lr: 0.000042  min_lr: 0.000042  loss: 2.5200 (2.6437)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4824 (1.6237)  time: 0.4984  data: 0.0004  max mem: 40463
Epoch: [281]  [1250/1251]  eta: 0:00:00  lr: 0.000042  min_lr: 0.000042  loss: 2.6467 (2.6446)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5747 (1.6247)  time: 0.4298  data: 0.0007  max mem: 40463
Epoch: [281] Total time: 0:10:27 (0.5015 s / it)
Averaged stats: lr: 0.000042  min_lr: 0.000042  loss: 2.6467 (2.6471)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5747 (1.6247)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.6368 (0.6368)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 5.5868  data: 5.2802  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7585 (0.7455)  acc1: 87.6000 (87.3818)  acc5: 97.6000 (97.8182)  time: 0.7452  data: 0.4802  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9202 (0.8613)  acc1: 82.4000 (84.2667)  acc5: 96.4000 (96.8381)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9335 (0.8775)  acc1: 82.0000 (83.7440)  acc5: 96.0000 (96.6560)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4766 s / it)
* Acc@1 84.220 Acc@5 96.756 loss 0.861
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.30%
Epoch: [282]  [   0/1251]  eta: 1:10:19  lr: 0.000042  min_lr: 0.000042  loss: 2.3622 (2.3622)  weight_decay: 0.0500 (0.0500)  time: 3.3725  data: 2.1968  max mem: 40463
Epoch: [282]  [ 200/1251]  eta: 0:09:02  lr: 0.000041  min_lr: 0.000041  loss: 2.5563 (2.6402)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3711 (1.5024)  time: 0.5016  data: 0.0004  max mem: 40463
Epoch: [282]  [ 400/1251]  eta: 0:07:11  lr: 0.000040  min_lr: 0.000040  loss: 2.7244 (2.6481)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5572 (1.6286)  time: 0.4985  data: 0.0004  max mem: 40463
Epoch: [282]  [ 600/1251]  eta: 0:05:29  lr: 0.000040  min_lr: 0.000040  loss: 2.8048 (2.6726)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1601 (1.5932)  time: 0.5012  data: 0.0004  max mem: 40463
Epoch: [282]  [ 800/1251]  eta: 0:03:47  lr: 0.000039  min_lr: 0.000039  loss: 2.7432 (2.6627)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7228 (1.6150)  time: 0.4992  data: 0.0004  max mem: 40463
Epoch: [282]  [1000/1251]  eta: 0:02:06  lr: 0.000038  min_lr: 0.000038  loss: 2.5672 (2.6541)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2394 (1.6911)  time: 0.4997  data: 0.0004  max mem: 40463
Epoch: [282]  [1200/1251]  eta: 0:00:25  lr: 0.000037  min_lr: 0.000037  loss: 2.5892 (2.6501)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1514 (1.6412)  time: 0.4993  data: 0.0005  max mem: 40463
Epoch: [282]  [1250/1251]  eta: 0:00:00  lr: 0.000037  min_lr: 0.000037  loss: 2.7523 (2.6480)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3601 (1.6358)  time: 0.4217  data: 0.0007  max mem: 40463
Epoch: [282] Total time: 0:10:29 (0.5030 s / it)
Averaged stats: lr: 0.000037  min_lr: 0.000037  loss: 2.7523 (2.6518)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3601 (1.6358)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.5936 (0.5936)  acc1: 90.8000 (90.8000)  acc5: 98.8000 (98.8000)  time: 5.3414  data: 5.0209  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7193 (0.7107)  acc1: 87.2000 (87.2727)  acc5: 97.6000 (97.7818)  time: 0.7227  data: 0.4567  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8838 (0.8266)  acc1: 82.0000 (84.2667)  acc5: 96.4000 (96.7429)  time: 0.2607  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9087 (0.8415)  acc1: 82.0000 (83.8400)  acc5: 96.0000 (96.6080)  time: 0.2605  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4673 s / it)
* Acc@1 84.324 Acc@5 96.738 loss 0.825
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.32%
Epoch: [283]  [   0/1251]  eta: 1:04:36  lr: 0.000037  min_lr: 0.000037  loss: 2.7171 (2.7171)  weight_decay: 0.0500 (0.0500)  time: 3.0986  data: 2.6001  max mem: 40463
Epoch: [283]  [ 200/1251]  eta: 0:08:59  lr: 0.000037  min_lr: 0.000037  loss: 2.7021 (2.6750)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2745 (1.5976)  time: 0.4985  data: 0.0004  max mem: 40463
Epoch: [283]  [ 400/1251]  eta: 0:07:11  lr: 0.000036  min_lr: 0.000036  loss: 2.5718 (2.6668)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2877 (1.5708)  time: 0.5074  data: 0.0004  max mem: 40463
Epoch: [283]  [ 600/1251]  eta: 0:05:28  lr: 0.000035  min_lr: 0.000035  loss: 2.3145 (2.6468)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0919 (1.6007)  time: 0.4997  data: 0.0004  max mem: 40463
Epoch: [283]  [ 800/1251]  eta: 0:03:47  lr: 0.000035  min_lr: 0.000035  loss: 2.7890 (2.6444)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7293 (1.6361)  time: 0.5004  data: 0.0005  max mem: 40463
Epoch: [283]  [1000/1251]  eta: 0:02:06  lr: 0.000034  min_lr: 0.000034  loss: 2.5996 (2.6325)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5926 (1.6646)  time: 0.5026  data: 0.0004  max mem: 40463
Epoch: [283]  [1200/1251]  eta: 0:00:25  lr: 0.000033  min_lr: 0.000033  loss: 2.8386 (2.6408)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3309 (1.6536)  time: 0.4985  data: 0.0004  max mem: 40463
Epoch: [283]  [1250/1251]  eta: 0:00:00  lr: 0.000033  min_lr: 0.000033  loss: 2.8953 (2.6431)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3971 (1.6587)  time: 0.4220  data: 0.0006  max mem: 40463
Epoch: [283] Total time: 0:10:28 (0.5022 s / it)
Averaged stats: lr: 0.000033  min_lr: 0.000033  loss: 2.8953 (2.6466)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3971 (1.6587)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6314 (0.6314)  acc1: 90.8000 (90.8000)  acc5: 98.8000 (98.8000)  time: 5.4920  data: 5.1959  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7610 (0.7564)  acc1: 87.2000 (87.3455)  acc5: 97.6000 (97.7455)  time: 0.7367  data: 0.4726  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9246 (0.8724)  acc1: 82.4000 (84.0571)  acc5: 96.4000 (96.6286)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9458 (0.8870)  acc1: 82.0000 (83.6160)  acc5: 95.6000 (96.4480)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4731 s / it)
* Acc@1 84.220 Acc@5 96.678 loss 0.873
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.32%
Epoch: [284]  [   0/1251]  eta: 1:09:49  lr: 0.000033  min_lr: 0.000033  loss: 2.5758 (2.5758)  weight_decay: 0.0500 (0.0500)  time: 3.3490  data: 2.5050  max mem: 40463
Epoch: [284]  [ 200/1251]  eta: 0:08:59  lr: 0.000032  min_lr: 0.000032  loss: 2.8903 (2.6751)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6322 (1.8307)  time: 0.5001  data: 0.0004  max mem: 40463
Epoch: [284]  [ 400/1251]  eta: 0:07:11  lr: 0.000032  min_lr: 0.000032  loss: 2.8634 (2.6560)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3292 (1.6978)  time: 0.4976  data: 0.0004  max mem: 40463
Epoch: [284]  [ 600/1251]  eta: 0:05:28  lr: 0.000031  min_lr: 0.000031  loss: 2.8327 (2.6412)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2155 (1.6215)  time: 0.4987  data: 0.0004  max mem: 40463
Epoch: [284]  [ 800/1251]  eta: 0:03:46  lr: 0.000031  min_lr: 0.000031  loss: 2.6952 (2.6510)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5718 (1.6568)  time: 0.4975  data: 0.0004  max mem: 40463
Epoch: [284]  [1000/1251]  eta: 0:02:06  lr: 0.000030  min_lr: 0.000030  loss: 2.6464 (2.6490)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5062 (1.6347)  time: 0.5000  data: 0.0004  max mem: 40463
Epoch: [284]  [1200/1251]  eta: 0:00:25  lr: 0.000029  min_lr: 0.000029  loss: 2.6839 (2.6504)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3716 (1.6451)  time: 0.4964  data: 0.0004  max mem: 40463
Epoch: [284]  [1250/1251]  eta: 0:00:00  lr: 0.000029  min_lr: 0.000029  loss: 2.8101 (2.6537)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5852 (1.6579)  time: 0.4213  data: 0.0005  max mem: 40463
Epoch: [284] Total time: 0:10:26 (0.5010 s / it)
Averaged stats: lr: 0.000029  min_lr: 0.000029  loss: 2.8101 (2.6481)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5852 (1.6579)
Test:  [ 0/25]  eta: 0:01:55  loss: 0.6414 (0.6414)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 4.6004  data: 4.2917  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7620 (0.7516)  acc1: 87.6000 (87.4182)  acc5: 97.6000 (97.7818)  time: 0.7127  data: 0.4476  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9332 (0.8690)  acc1: 82.0000 (84.1143)  acc5: 96.4000 (96.7619)  time: 0.2923  data: 0.0316  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9423 (0.8843)  acc1: 81.6000 (83.6000)  acc5: 96.0000 (96.6240)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4626 s / it)
* Acc@1 84.192 Acc@5 96.722 loss 0.868
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.32%
Epoch: [285]  [   0/1251]  eta: 1:13:31  lr: 0.000029  min_lr: 0.000029  loss: 2.8596 (2.8596)  weight_decay: 0.0500 (0.0500)  time: 3.5267  data: 2.6239  max mem: 40463
Epoch: [285]  [ 200/1251]  eta: 0:09:05  lr: 0.000029  min_lr: 0.000029  loss: 2.8402 (2.6686)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5474 (1.6739)  time: 0.5077  data: 0.0004  max mem: 40463
Epoch: [285]  [ 400/1251]  eta: 0:07:12  lr: 0.000028  min_lr: 0.000028  loss: 2.6241 (2.6860)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4510 (1.6287)  time: 0.4969  data: 0.0004  max mem: 40463
Epoch: [285]  [ 600/1251]  eta: 0:05:28  lr: 0.000027  min_lr: 0.000027  loss: 2.8480 (2.6767)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1807 (1.6439)  time: 0.4973  data: 0.0005  max mem: 40463
Epoch: [285]  [ 800/1251]  eta: 0:03:47  lr: 0.000027  min_lr: 0.000027  loss: 2.7869 (2.6665)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6104 (1.6090)  time: 0.4978  data: 0.0004  max mem: 40463
Epoch: [285]  [1000/1251]  eta: 0:02:06  lr: 0.000026  min_lr: 0.000026  loss: 2.7171 (2.6681)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5502 (1.6200)  time: 0.4971  data: 0.0004  max mem: 40463
Epoch: [285]  [1200/1251]  eta: 0:00:25  lr: 0.000026  min_lr: 0.000026  loss: 2.7667 (2.6696)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4557 (1.6179)  time: 0.4971  data: 0.0004  max mem: 40463
Epoch: [285]  [1250/1251]  eta: 0:00:00  lr: 0.000026  min_lr: 0.000026  loss: 2.2533 (2.6656)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2784 (1.6209)  time: 0.4334  data: 0.0005  max mem: 40463
Epoch: [285] Total time: 0:10:26 (0.5011 s / it)
Averaged stats: lr: 0.000026  min_lr: 0.000026  loss: 2.2533 (2.6468)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2784 (1.6209)
Test:  [ 0/25]  eta: 0:02:14  loss: 0.5790 (0.5790)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 5.3838  data: 5.0791  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7054 (0.6948)  acc1: 86.8000 (87.1636)  acc5: 97.6000 (97.8545)  time: 0.7267  data: 0.4620  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8783 (0.8114)  acc1: 82.8000 (84.1143)  acc5: 96.4000 (96.8191)  time: 0.2608  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.8797 (0.8267)  acc1: 81.6000 (83.6480)  acc5: 96.0000 (96.6400)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4700 s / it)
* Acc@1 84.196 Acc@5 96.760 loss 0.811
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.32%
Epoch: [286]  [   0/1251]  eta: 1:18:41  lr: 0.000026  min_lr: 0.000026  loss: 2.7887 (2.7887)  weight_decay: 0.0500 (0.0500)  time: 3.7740  data: 2.6896  max mem: 40463
Epoch: [286]  [ 200/1251]  eta: 0:09:03  lr: 0.000025  min_lr: 0.000025  loss: 2.7341 (2.6346)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7763 (1.8142)  time: 0.4971  data: 0.0004  max mem: 40463
Epoch: [286]  [ 400/1251]  eta: 0:07:11  lr: 0.000025  min_lr: 0.000025  loss: 2.6847 (2.6660)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4215 (1.7233)  time: 0.4967  data: 0.0004  max mem: 40463
Epoch: [286]  [ 600/1251]  eta: 0:05:28  lr: 0.000024  min_lr: 0.000024  loss: 2.7788 (2.6665)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5636 (1.6916)  time: 0.4962  data: 0.0004  max mem: 40463
Epoch: [286]  [ 800/1251]  eta: 0:03:47  lr: 0.000023  min_lr: 0.000023  loss: 2.6951 (2.6709)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5195 (1.6323)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [286]  [1000/1251]  eta: 0:02:06  lr: 0.000023  min_lr: 0.000023  loss: 2.7337 (2.6575)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3401 (1.6276)  time: 0.4977  data: 0.0004  max mem: 40463
Epoch: [286]  [1200/1251]  eta: 0:00:25  lr: 0.000022  min_lr: 0.000022  loss: 2.7492 (2.6568)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4869 (1.6221)  time: 0.4970  data: 0.0004  max mem: 40463
Epoch: [286]  [1250/1251]  eta: 0:00:00  lr: 0.000022  min_lr: 0.000022  loss: 2.7333 (2.6593)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3489 (1.6182)  time: 0.4213  data: 0.0005  max mem: 40463
Epoch: [286] Total time: 0:10:27 (0.5015 s / it)
Averaged stats: lr: 0.000022  min_lr: 0.000022  loss: 2.7333 (2.6411)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3489 (1.6182)
Test:  [ 0/25]  eta: 0:01:57  loss: 0.6358 (0.6358)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 4.7052  data: 4.3901  max mem: 40463
Test:  [10/25]  eta: 0:00:09  loss: 0.7641 (0.7524)  acc1: 87.6000 (87.3455)  acc5: 97.6000 (97.7455)  time: 0.6651  data: 0.3994  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9306 (0.8687)  acc1: 83.6000 (84.3619)  acc5: 96.4000 (96.7429)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9317 (0.8838)  acc1: 82.0000 (83.8560)  acc5: 96.0000 (96.5760)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4416 s / it)
* Acc@1 84.216 Acc@5 96.728 loss 0.869
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.32%
Epoch: [287]  [   0/1251]  eta: 1:13:38  lr: 0.000022  min_lr: 0.000022  loss: 2.2803 (2.2803)  weight_decay: 0.0500 (0.0500)  time: 3.5316  data: 2.1440  max mem: 40463
Epoch: [287]  [ 200/1251]  eta: 0:09:00  lr: 0.000022  min_lr: 0.000022  loss: 2.6681 (2.6467)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5758 (1.7797)  time: 0.5004  data: 0.0004  max mem: 40463
Epoch: [287]  [ 400/1251]  eta: 0:07:11  lr: 0.000021  min_lr: 0.000021  loss: 2.2694 (2.6374)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4583 (1.6930)  time: 0.4986  data: 0.0004  max mem: 40463
Epoch: [287]  [ 600/1251]  eta: 0:05:29  lr: 0.000021  min_lr: 0.000021  loss: 2.7507 (2.6673)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2485 (1.6613)  time: 0.4985  data: 0.0004  max mem: 40463
Epoch: [287]  [ 800/1251]  eta: 0:03:47  lr: 0.000020  min_lr: 0.000020  loss: 2.8311 (2.6644)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7518 (1.6987)  time: 0.4982  data: 0.0004  max mem: 40463
Epoch: [287]  [1000/1251]  eta: 0:02:06  lr: 0.000020  min_lr: 0.000020  loss: 2.8440 (2.6676)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4109 (1.6892)  time: 0.5046  data: 0.0004  max mem: 40463
Epoch: [287]  [1200/1251]  eta: 0:00:25  lr: 0.000019  min_lr: 0.000019  loss: 2.7561 (2.6627)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3495 (1.6490)  time: 0.4985  data: 0.0004  max mem: 40463
Epoch: [287]  [1250/1251]  eta: 0:00:00  lr: 0.000019  min_lr: 0.000019  loss: 2.8300 (2.6599)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0865 (1.6343)  time: 0.4214  data: 0.0006  max mem: 40463
Epoch: [287] Total time: 0:10:27 (0.5017 s / it)
Averaged stats: lr: 0.000019  min_lr: 0.000019  loss: 2.8300 (2.6425)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0865 (1.6343)
Test:  [ 0/25]  eta: 0:02:28  loss: 0.6527 (0.6527)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 5.9308  data: 5.6104  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7659 (0.7622)  acc1: 87.2000 (87.0909)  acc5: 97.2000 (97.7455)  time: 0.7765  data: 0.5103  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9446 (0.8776)  acc1: 82.0000 (84.0000)  acc5: 96.4000 (96.7810)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9476 (0.8924)  acc1: 81.2000 (83.5360)  acc5: 96.0000 (96.6240)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:12 (0.4912 s / it)
* Acc@1 84.228 Acc@5 96.740 loss 0.877
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.32%
Epoch: [288]  [   0/1251]  eta: 1:12:34  lr: 0.000019  min_lr: 0.000019  loss: 2.9108 (2.9108)  weight_decay: 0.0500 (0.0500)  time: 3.4809  data: 2.2315  max mem: 40463
Epoch: [288]  [ 200/1251]  eta: 0:08:59  lr: 0.000019  min_lr: 0.000019  loss: 2.7723 (2.5941)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6853 (1.5860)  time: 0.5042  data: 0.0004  max mem: 40463
Epoch: [288]  [ 400/1251]  eta: 0:07:12  lr: 0.000018  min_lr: 0.000018  loss: 2.7706 (2.6288)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5911 (1.6225)  time: 0.4976  data: 0.0004  max mem: 40463
Epoch: [288]  [ 600/1251]  eta: 0:05:28  lr: 0.000018  min_lr: 0.000018  loss: 2.5151 (2.6357)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3709 (1.6262)  time: 0.4992  data: 0.0004  max mem: 40463
Epoch: [288]  [ 800/1251]  eta: 0:03:47  lr: 0.000017  min_lr: 0.000017  loss: 2.6598 (2.6433)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3742 (1.5896)  time: 0.5004  data: 0.0004  max mem: 40463
Epoch: [288]  [1000/1251]  eta: 0:02:06  lr: 0.000017  min_lr: 0.000017  loss: 2.7829 (2.6486)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1165 (1.5628)  time: 0.4999  data: 0.0004  max mem: 40463
Epoch: [288]  [1200/1251]  eta: 0:00:25  lr: 0.000016  min_lr: 0.000016  loss: 2.8440 (2.6524)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7782 (1.5763)  time: 0.4980  data: 0.0004  max mem: 40463
Epoch: [288]  [1250/1251]  eta: 0:00:00  lr: 0.000016  min_lr: 0.000016  loss: 2.9244 (2.6582)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5568 (1.5748)  time: 0.4215  data: 0.0006  max mem: 40463
Epoch: [288] Total time: 0:10:27 (0.5016 s / it)
Averaged stats: lr: 0.000016  min_lr: 0.000016  loss: 2.9244 (2.6514)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5568 (1.5748)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.6975 (0.6975)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.5781  data: 5.2916  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.8123 (0.8092)  acc1: 87.6000 (87.5273)  acc5: 97.2000 (97.7818)  time: 0.7445  data: 0.4813  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9799 (0.9250)  acc1: 82.4000 (84.2095)  acc5: 96.8000 (96.7810)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9947 (0.9396)  acc1: 81.6000 (83.7280)  acc5: 96.0000 (96.6240)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4765 s / it)
* Acc@1 84.190 Acc@5 96.730 loss 0.924
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.32%
Epoch: [289]  [   0/1251]  eta: 1:06:29  lr: 0.000016  min_lr: 0.000016  loss: 2.7953 (2.7953)  weight_decay: 0.0500 (0.0500)  time: 3.1892  data: 2.3309  max mem: 40463
Epoch: [289]  [ 200/1251]  eta: 0:09:01  lr: 0.000016  min_lr: 0.000016  loss: 2.8945 (2.6789)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4490 (1.5452)  time: 0.4980  data: 0.0004  max mem: 40463
Epoch: [289]  [ 400/1251]  eta: 0:07:11  lr: 0.000015  min_lr: 0.000015  loss: 2.4893 (2.6361)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4109 (1.5589)  time: 0.4973  data: 0.0004  max mem: 40463
Epoch: [289]  [ 600/1251]  eta: 0:05:27  lr: 0.000015  min_lr: 0.000015  loss: 2.6524 (2.6341)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2437 (1.5570)  time: 0.4957  data: 0.0004  max mem: 40463
Epoch: [289]  [ 800/1251]  eta: 0:03:46  lr: 0.000014  min_lr: 0.000014  loss: 2.3399 (2.6315)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4256 (1.5836)  time: 0.4960  data: 0.0004  max mem: 40463
Epoch: [289]  [1000/1251]  eta: 0:02:05  lr: 0.000014  min_lr: 0.000014  loss: 2.8153 (2.6290)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2513 (1.5842)  time: 0.4962  data: 0.0004  max mem: 40463
Epoch: [289]  [1200/1251]  eta: 0:00:25  lr: 0.000014  min_lr: 0.000014  loss: 2.7379 (2.6329)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2580 (1.5886)  time: 0.4961  data: 0.0004  max mem: 40463
Epoch: [289]  [1250/1251]  eta: 0:00:00  lr: 0.000014  min_lr: 0.000014  loss: 2.5589 (2.6281)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2075 (1.5777)  time: 0.4211  data: 0.0006  max mem: 40463
Epoch: [289] Total time: 0:10:25 (0.5000 s / it)
Averaged stats: lr: 0.000014  min_lr: 0.000014  loss: 2.5589 (2.6383)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2075 (1.5777)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.5554 (0.5554)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 5.4535  data: 5.1443  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.6740 (0.6700)  acc1: 87.2000 (87.3091)  acc5: 97.6000 (97.8545)  time: 0.7332  data: 0.4680  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8438 (0.7876)  acc1: 82.4000 (84.1524)  acc5: 96.4000 (96.8381)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.8539 (0.8032)  acc1: 82.0000 (83.7120)  acc5: 96.0000 (96.6880)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4723 s / it)
* Acc@1 84.332 Acc@5 96.784 loss 0.787
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.33%
Epoch: [290]  [   0/1251]  eta: 1:01:27  lr: 0.000014  min_lr: 0.000014  loss: 2.9487 (2.9487)  weight_decay: 0.0500 (0.0500)  time: 2.9480  data: 2.4367  max mem: 40463
Epoch: [290]  [ 200/1251]  eta: 0:08:59  lr: 0.000013  min_lr: 0.000013  loss: 2.6893 (2.6569)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1692 (1.4787)  time: 0.4979  data: 0.0004  max mem: 40463
Epoch: [290]  [ 400/1251]  eta: 0:07:10  lr: 0.000013  min_lr: 0.000013  loss: 2.7847 (2.6533)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5108 (1.5730)  time: 0.4970  data: 0.0004  max mem: 40463
Epoch: [290]  [ 600/1251]  eta: 0:05:28  lr: 0.000012  min_lr: 0.000012  loss: 2.7835 (2.6553)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4217 (1.5478)  time: 0.5035  data: 0.0004  max mem: 40463
Epoch: [290]  [ 800/1251]  eta: 0:03:46  lr: 0.000012  min_lr: 0.000012  loss: 2.5171 (2.6401)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8079 (1.6209)  time: 0.4983  data: 0.0004  max mem: 40463
Epoch: [290]  [1000/1251]  eta: 0:02:05  lr: 0.000012  min_lr: 0.000012  loss: 2.6167 (2.6458)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1431 (1.5642)  time: 0.4960  data: 0.0004  max mem: 40463
Epoch: [290]  [1200/1251]  eta: 0:00:25  lr: 0.000011  min_lr: 0.000011  loss: 2.7421 (2.6326)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2237 (1.5541)  time: 0.5034  data: 0.0005  max mem: 40463
Epoch: [290]  [1250/1251]  eta: 0:00:00  lr: 0.000011  min_lr: 0.000011  loss: 2.8119 (2.6373)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.4216  data: 0.0006  max mem: 40463
Epoch: [290] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.000011  min_lr: 0.000011  loss: 2.8119 (2.6404)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.6428 (0.6428)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.4682  data: 5.1646  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7745 (0.7600)  acc1: 87.2000 (87.4545)  acc5: 97.6000 (97.8182)  time: 0.7346  data: 0.4698  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9360 (0.8758)  acc1: 82.4000 (84.3429)  acc5: 96.4000 (96.8191)  time: 0.2611  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9388 (0.8908)  acc1: 82.0000 (83.8240)  acc5: 96.0000 (96.6880)  time: 0.2610  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4723 s / it)
* Acc@1 84.308 Acc@5 96.748 loss 0.875
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.33%
Epoch: [291]  [   0/1251]  eta: 1:11:34  lr: 0.000011  min_lr: 0.000011  loss: 3.2338 (3.2338)  weight_decay: 0.0500 (0.0500)  time: 3.4329  data: 1.6204  max mem: 40463
Epoch: [291]  [ 200/1251]  eta: 0:08:59  lr: 0.000011  min_lr: 0.000011  loss: 2.6266 (2.6139)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2529 (1.4592)  time: 0.4980  data: 0.0004  max mem: 40463
Epoch: [291]  [ 400/1251]  eta: 0:07:10  lr: 0.000010  min_lr: 0.000010  loss: 2.8476 (2.6334)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3663 (1.4845)  time: 0.4971  data: 0.0004  max mem: 40463
Epoch: [291]  [ 600/1251]  eta: 0:05:28  lr: 0.000010  min_lr: 0.000010  loss: 2.7469 (2.6489)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4149 (1.5289)  time: 0.4979  data: 0.0004  max mem: 40463
Epoch: [291]  [ 800/1251]  eta: 0:03:46  lr: 0.000010  min_lr: 0.000010  loss: 2.7758 (2.6532)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3667 (1.5522)  time: 0.5024  data: 0.0004  max mem: 40463
Epoch: [291]  [1000/1251]  eta: 0:02:06  lr: 0.000009  min_lr: 0.000009  loss: 2.6453 (2.6377)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4954 (1.5401)  time: 0.5131  data: 0.0004  max mem: 40463
Epoch: [291]  [1200/1251]  eta: 0:00:25  lr: 0.000009  min_lr: 0.000009  loss: 2.6223 (2.6407)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4027 (1.5301)  time: 0.4997  data: 0.0004  max mem: 40463
Epoch: [291]  [1250/1251]  eta: 0:00:00  lr: 0.000009  min_lr: 0.000009  loss: 2.4873 (2.6370)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3273 (1.5234)  time: 0.4222  data: 0.0007  max mem: 40463
Epoch: [291] Total time: 0:10:27 (0.5020 s / it)
Averaged stats: lr: 0.000009  min_lr: 0.000009  loss: 2.4873 (2.6373)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3273 (1.5234)
Test:  [ 0/25]  eta: 0:02:14  loss: 0.5753 (0.5753)  acc1: 90.8000 (90.8000)  acc5: 98.8000 (98.8000)  time: 5.3644  data: 5.0650  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7021 (0.6945)  acc1: 87.2000 (87.3818)  acc5: 97.6000 (97.7818)  time: 0.7251  data: 0.4607  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.8696 (0.8117)  acc1: 82.8000 (84.3429)  acc5: 96.4000 (96.7429)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.8833 (0.8273)  acc1: 82.0000 (83.8080)  acc5: 96.0000 (96.6080)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4683 s / it)
* Acc@1 84.330 Acc@5 96.786 loss 0.812
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.33%
Epoch: [292]  [   0/1251]  eta: 1:11:25  lr: 0.000009  min_lr: 0.000009  loss: 2.8125 (2.8125)  weight_decay: 0.0500 (0.0500)  time: 3.4258  data: 1.5146  max mem: 40463
Epoch: [292]  [ 200/1251]  eta: 0:08:59  lr: 0.000009  min_lr: 0.000009  loss: 2.7161 (2.6875)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3959 (1.4233)  time: 0.4970  data: 0.0004  max mem: 40463
Epoch: [292]  [ 400/1251]  eta: 0:07:11  lr: 0.000008  min_lr: 0.000008  loss: 2.7198 (2.6771)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2815 (1.4568)  time: 0.4970  data: 0.0004  max mem: 40463
Epoch: [292]  [ 600/1251]  eta: 0:05:28  lr: 0.000008  min_lr: 0.000008  loss: 2.7212 (2.6605)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4267 (1.4829)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [292]  [ 800/1251]  eta: 0:03:46  lr: 0.000008  min_lr: 0.000008  loss: 2.7279 (2.6583)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1817 (1.5018)  time: 0.4981  data: 0.0004  max mem: 40463
Epoch: [292]  [1000/1251]  eta: 0:02:06  lr: 0.000008  min_lr: 0.000008  loss: 2.7252 (2.6532)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2775 (1.5323)  time: 0.5072  data: 0.0004  max mem: 40463
Epoch: [292]  [1200/1251]  eta: 0:00:25  lr: 0.000007  min_lr: 0.000007  loss: 2.5733 (2.6449)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3615 (1.5312)  time: 0.4973  data: 0.0004  max mem: 40463
Epoch: [292]  [1250/1251]  eta: 0:00:00  lr: 0.000007  min_lr: 0.000007  loss: 2.5452 (2.6430)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4082 (1.5310)  time: 0.4216  data: 0.0005  max mem: 40463
Epoch: [292] Total time: 0:10:26 (0.5007 s / it)
Averaged stats: lr: 0.000007  min_lr: 0.000007  loss: 2.5452 (2.6387)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4082 (1.5310)
Test:  [ 0/25]  eta: 0:02:23  loss: 0.6059 (0.6059)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.7260  data: 5.4153  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7330 (0.7241)  acc1: 86.8000 (87.2727)  acc5: 97.6000 (97.8182)  time: 0.7579  data: 0.4926  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9020 (0.8400)  acc1: 83.2000 (84.1905)  acc5: 96.4000 (96.7810)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9040 (0.8552)  acc1: 81.6000 (83.7280)  acc5: 96.0000 (96.6400)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:12 (0.4825 s / it)
* Acc@1 84.266 Acc@5 96.796 loss 0.839
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.33%
Epoch: [293]  [   0/1251]  eta: 1:11:09  lr: 0.000007  min_lr: 0.000007  loss: 2.9662 (2.9662)  weight_decay: 0.0500 (0.0500)  time: 3.4131  data: 2.2966  max mem: 40463
Epoch: [293]  [ 200/1251]  eta: 0:09:04  lr: 0.000007  min_lr: 0.000007  loss: 2.8072 (2.6531)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4424 (1.4482)  time: 0.4982  data: 0.0005  max mem: 40463
Epoch: [293]  [ 400/1251]  eta: 0:07:12  lr: 0.000007  min_lr: 0.000007  loss: 2.7798 (2.6582)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6507 (1.5291)  time: 0.4978  data: 0.0004  max mem: 40463
Epoch: [293]  [ 600/1251]  eta: 0:05:28  lr: 0.000006  min_lr: 0.000006  loss: 2.7523 (2.6323)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3911 (1.5280)  time: 0.4976  data: 0.0004  max mem: 40463
Epoch: [293]  [ 800/1251]  eta: 0:03:47  lr: 0.000006  min_lr: 0.000006  loss: 2.8080 (2.6394)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4143 (1.5441)  time: 0.5049  data: 0.0004  max mem: 40463
Epoch: [293]  [1000/1251]  eta: 0:02:06  lr: 0.000006  min_lr: 0.000006  loss: 2.2776 (2.6359)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2660 (1.5138)  time: 0.4982  data: 0.0004  max mem: 40463
Epoch: [293]  [1200/1251]  eta: 0:00:25  lr: 0.000006  min_lr: 0.000006  loss: 2.6173 (2.6336)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6386 (1.5273)  time: 0.5001  data: 0.0005  max mem: 40463
Epoch: [293]  [1250/1251]  eta: 0:00:00  lr: 0.000006  min_lr: 0.000006  loss: 2.6267 (2.6303)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2322 (1.5165)  time: 0.4220  data: 0.0007  max mem: 40463
Epoch: [293] Total time: 0:10:27 (0.5017 s / it)
Averaged stats: lr: 0.000006  min_lr: 0.000006  loss: 2.6267 (2.6377)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2322 (1.5165)
Test:  [ 0/25]  eta: 0:02:03  loss: 0.6070 (0.6070)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 4.9416  data: 4.6138  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7314 (0.7250)  acc1: 86.8000 (87.2364)  acc5: 97.2000 (97.7091)  time: 0.6898  data: 0.4230  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9059 (0.8429)  acc1: 83.2000 (84.2476)  acc5: 96.4000 (96.7429)  time: 0.2627  data: 0.0020  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9085 (0.8581)  acc1: 81.6000 (83.7760)  acc5: 96.0000 (96.6240)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4522 s / it)
* Acc@1 84.226 Acc@5 96.746 loss 0.843
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.33%
Epoch: [294]  [   0/1251]  eta: 1:10:28  lr: 0.000006  min_lr: 0.000006  loss: 2.8010 (2.8010)  weight_decay: 0.0500 (0.0500)  time: 3.3805  data: 2.7951  max mem: 40463
Epoch: [294]  [ 200/1251]  eta: 0:09:02  lr: 0.000005  min_lr: 0.000005  loss: 2.6428 (2.6532)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4297 (1.4980)  time: 0.4980  data: 0.0004  max mem: 40463
Epoch: [294]  [ 400/1251]  eta: 0:07:11  lr: 0.000005  min_lr: 0.000005  loss: 2.6665 (2.6487)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5437 (1.5226)  time: 0.4972  data: 0.0004  max mem: 40463
Epoch: [294]  [ 600/1251]  eta: 0:05:28  lr: 0.000005  min_lr: 0.000005  loss: 2.6332 (2.6509)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3832 (1.5273)  time: 0.5039  data: 0.0004  max mem: 40463
Epoch: [294]  [ 800/1251]  eta: 0:03:47  lr: 0.000005  min_lr: 0.000005  loss: 2.7136 (2.6540)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2741 (1.5219)  time: 0.4973  data: 0.0004  max mem: 40463
Epoch: [294]  [1000/1251]  eta: 0:02:06  lr: 0.000004  min_lr: 0.000004  loss: 2.5720 (2.6520)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3906 (1.5078)  time: 0.4987  data: 0.0005  max mem: 40463
Epoch: [294]  [1200/1251]  eta: 0:00:25  lr: 0.000004  min_lr: 0.000004  loss: 2.5358 (2.6396)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3969 (1.5214)  time: 0.5029  data: 0.0004  max mem: 40463
Epoch: [294]  [1250/1251]  eta: 0:00:00  lr: 0.000004  min_lr: 0.000004  loss: 2.7094 (2.6402)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3566 (1.5191)  time: 0.4217  data: 0.0005  max mem: 40463
Epoch: [294] Total time: 0:10:27 (0.5018 s / it)
Averaged stats: lr: 0.000004  min_lr: 0.000004  loss: 2.7094 (2.6441)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3566 (1.5191)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.6730 (0.6730)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 5.2849  data: 4.9951  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7889 (0.7851)  acc1: 87.6000 (87.4909)  acc5: 97.2000 (97.7455)  time: 0.7178  data: 0.4544  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9608 (0.9020)  acc1: 82.4000 (84.2857)  acc5: 96.4000 (96.7238)  time: 0.2610  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9647 (0.9165)  acc1: 81.6000 (83.8080)  acc5: 96.0000 (96.5760)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4650 s / it)
* Acc@1 84.240 Acc@5 96.712 loss 0.901
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.33%
Epoch: [295]  [   0/1251]  eta: 1:11:53  lr: 0.000004  min_lr: 0.000004  loss: 1.8844 (1.8844)  weight_decay: 0.0500 (0.0500)  time: 3.4477  data: 2.6432  max mem: 40463
Epoch: [295]  [ 200/1251]  eta: 0:09:00  lr: 0.000004  min_lr: 0.000004  loss: 2.7699 (2.6553)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3159 (1.4650)  time: 0.4969  data: 0.0004  max mem: 40463
Epoch: [295]  [ 400/1251]  eta: 0:07:11  lr: 0.000004  min_lr: 0.000004  loss: 2.7674 (2.6479)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2579 (1.4791)  time: 0.4980  data: 0.0004  max mem: 40463
Epoch: [295]  [ 600/1251]  eta: 0:05:29  lr: 0.000004  min_lr: 0.000004  loss: 2.6079 (2.6366)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3037 (1.4936)  time: 0.4968  data: 0.0004  max mem: 40463
Epoch: [295]  [ 800/1251]  eta: 0:03:46  lr: 0.000003  min_lr: 0.000003  loss: 2.7911 (2.6469)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2806 (1.4906)  time: 0.4970  data: 0.0004  max mem: 40463
Epoch: [295]  [1000/1251]  eta: 0:02:06  lr: 0.000003  min_lr: 0.000003  loss: 2.6755 (2.6490)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2702 (1.4826)  time: 0.5037  data: 0.0004  max mem: 40463
Epoch: [295]  [1200/1251]  eta: 0:00:25  lr: 0.000003  min_lr: 0.000003  loss: 2.6149 (2.6432)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3643 (1.5093)  time: 0.4970  data: 0.0005  max mem: 40463
Epoch: [295]  [1250/1251]  eta: 0:00:00  lr: 0.000003  min_lr: 0.000003  loss: 2.7428 (2.6442)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3534 (1.5098)  time: 0.4221  data: 0.0007  max mem: 40463
Epoch: [295] Total time: 0:10:26 (0.5012 s / it)
Averaged stats: lr: 0.000003  min_lr: 0.000003  loss: 2.7428 (2.6413)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3534 (1.5098)
Test:  [ 0/25]  eta: 0:02:16  loss: 0.6349 (0.6349)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.4510  data: 5.1403  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7566 (0.7500)  acc1: 87.2000 (87.3091)  acc5: 97.2000 (97.7091)  time: 0.7326  data: 0.4676  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9277 (0.8659)  acc1: 82.8000 (84.1905)  acc5: 96.4000 (96.7810)  time: 0.2606  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9299 (0.8808)  acc1: 81.6000 (83.7440)  acc5: 96.0000 (96.6560)  time: 0.2605  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4711 s / it)
* Acc@1 84.288 Acc@5 96.774 loss 0.865
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.33%
Epoch: [296]  [   0/1251]  eta: 1:10:57  lr: 0.000003  min_lr: 0.000003  loss: 2.0733 (2.0733)  weight_decay: 0.0500 (0.0500)  time: 3.4030  data: 1.6144  max mem: 40463
Epoch: [296]  [ 200/1251]  eta: 0:09:00  lr: 0.000003  min_lr: 0.000003  loss: 2.7010 (2.6185)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3352 (1.4543)  time: 0.4993  data: 0.0004  max mem: 40463
Epoch: [296]  [ 400/1251]  eta: 0:07:13  lr: 0.000003  min_lr: 0.000003  loss: 2.7433 (2.6020)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4066 (1.4338)  time: 0.4997  data: 0.0004  max mem: 40463
Epoch: [296]  [ 600/1251]  eta: 0:05:29  lr: 0.000003  min_lr: 0.000003  loss: 2.7898 (2.6230)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3506 (1.4855)  time: 0.4984  data: 0.0004  max mem: 40463
Epoch: [296]  [ 800/1251]  eta: 0:03:47  lr: 0.000002  min_lr: 0.000002  loss: 2.6999 (2.6268)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4803 (1.4952)  time: 0.4969  data: 0.0004  max mem: 40463
Epoch: [296]  [1000/1251]  eta: 0:02:06  lr: 0.000002  min_lr: 0.000002  loss: 2.5309 (2.6231)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1687 (1.5014)  time: 0.4965  data: 0.0004  max mem: 40463
Epoch: [296]  [1200/1251]  eta: 0:00:25  lr: 0.000002  min_lr: 0.000002  loss: 2.7694 (2.6220)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1460 (1.4839)  time: 0.4973  data: 0.0004  max mem: 40463
Epoch: [296]  [1250/1251]  eta: 0:00:00  lr: 0.000002  min_lr: 0.000002  loss: 2.6358 (2.6230)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3665 (1.4829)  time: 0.4292  data: 0.0007  max mem: 40463
Epoch: [296] Total time: 0:10:27 (0.5014 s / it)
Averaged stats: lr: 0.000002  min_lr: 0.000002  loss: 2.6358 (2.6366)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3665 (1.4829)
Test:  [ 0/25]  eta: 0:02:12  loss: 0.6328 (0.6328)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.2927  data: 4.9773  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7543 (0.7418)  acc1: 87.2000 (87.3818)  acc5: 97.2000 (97.7455)  time: 0.7185  data: 0.4528  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9146 (0.8581)  acc1: 82.4000 (84.2095)  acc5: 96.4000 (96.8000)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9202 (0.8728)  acc1: 81.2000 (83.7280)  acc5: 96.0000 (96.6560)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4649 s / it)
* Acc@1 84.258 Acc@5 96.780 loss 0.857
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.33%
Epoch: [297]  [   0/1251]  eta: 1:09:37  lr: 0.000002  min_lr: 0.000002  loss: 3.3133 (3.3133)  weight_decay: 0.0500 (0.0500)  time: 3.3392  data: 2.3175  max mem: 40463
Epoch: [297]  [ 200/1251]  eta: 0:09:02  lr: 0.000002  min_lr: 0.000002  loss: 2.4643 (2.6067)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5058 (1.5895)  time: 0.5073  data: 0.0004  max mem: 40463
Epoch: [297]  [ 400/1251]  eta: 0:07:12  lr: 0.000002  min_lr: 0.000002  loss: 2.7456 (2.6332)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2484 (1.5606)  time: 0.4963  data: 0.0004  max mem: 40463
Epoch: [297]  [ 600/1251]  eta: 0:05:28  lr: 0.000002  min_lr: 0.000002  loss: 2.6496 (2.6444)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3142 (1.5358)  time: 0.4981  data: 0.0004  max mem: 40463
Epoch: [297]  [ 800/1251]  eta: 0:03:47  lr: 0.000002  min_lr: 0.000002  loss: 2.6331 (2.6454)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5719 (1.5658)  time: 0.5034  data: 0.0004  max mem: 40463
Epoch: [297]  [1000/1251]  eta: 0:02:06  lr: 0.000002  min_lr: 0.000002  loss: 2.7518 (2.6502)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3213 (1.5414)  time: 0.4971  data: 0.0004  max mem: 40463
Epoch: [297]  [1200/1251]  eta: 0:00:25  lr: 0.000002  min_lr: 0.000002  loss: 2.6684 (2.6466)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1800 (1.5140)  time: 0.4965  data: 0.0004  max mem: 40463
Epoch: [297]  [1250/1251]  eta: 0:00:00  lr: 0.000002  min_lr: 0.000002  loss: 2.7898 (2.6440)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2329 (1.5130)  time: 0.4215  data: 0.0006  max mem: 40463
Epoch: [297] Total time: 0:10:27 (0.5015 s / it)
Averaged stats: lr: 0.000002  min_lr: 0.000002  loss: 2.7898 (2.6409)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2329 (1.5130)
Test:  [ 0/25]  eta: 0:02:03  loss: 0.6278 (0.6278)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 4.9331  data: 4.6117  max mem: 40463
Test:  [10/25]  eta: 0:00:10  loss: 0.7488 (0.7391)  acc1: 86.8000 (87.4182)  acc5: 97.6000 (97.8182)  time: 0.7134  data: 0.4388  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9149 (0.8530)  acc1: 82.8000 (84.2286)  acc5: 96.4000 (96.8952)  time: 0.2778  data: 0.0108  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9181 (0.8677)  acc1: 82.0000 (83.7760)  acc5: 96.4000 (96.7360)  time: 0.2649  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4644 s / it)
* Acc@1 84.286 Acc@5 96.788 loss 0.852
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.33%
Epoch: [298]  [   0/1251]  eta: 1:12:51  lr: 0.000002  min_lr: 0.000002  loss: 2.2110 (2.2110)  weight_decay: 0.0500 (0.0500)  time: 3.4946  data: 2.3533  max mem: 40463
Epoch: [298]  [ 200/1251]  eta: 0:09:04  lr: 0.000001  min_lr: 0.000001  loss: 2.7430 (2.6632)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3204 (1.4500)  time: 0.4986  data: 0.0004  max mem: 40463
Epoch: [298]  [ 400/1251]  eta: 0:07:12  lr: 0.000001  min_lr: 0.000001  loss: 2.5051 (2.6567)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3558 (1.4719)  time: 0.4984  data: 0.0004  max mem: 40463
Epoch: [298]  [ 600/1251]  eta: 0:05:28  lr: 0.000001  min_lr: 0.000001  loss: 2.7807 (2.6410)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4204 (1.4595)  time: 0.5042  data: 0.0005  max mem: 40463
Epoch: [298]  [ 800/1251]  eta: 0:03:47  lr: 0.000001  min_lr: 0.000001  loss: 2.7458 (2.6375)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2165 (1.4487)  time: 0.4983  data: 0.0004  max mem: 40463
Epoch: [298]  [1000/1251]  eta: 0:02:06  lr: 0.000001  min_lr: 0.000001  loss: 2.5901 (2.6399)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2459 (1.4323)  time: 0.4968  data: 0.0005  max mem: 40463
Epoch: [298]  [1200/1251]  eta: 0:00:25  lr: 0.000001  min_lr: 0.000001  loss: 2.5790 (2.6292)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2343 (1.4482)  time: 0.5069  data: 0.0004  max mem: 40463
Epoch: [298]  [1250/1251]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 2.8394 (2.6324)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2709 (1.4479)  time: 0.4249  data: 0.0007  max mem: 40463
Epoch: [298] Total time: 0:10:27 (0.5017 s / it)
Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 2.8394 (2.6365)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2709 (1.4479)
Test:  [ 0/25]  eta: 0:02:18  loss: 0.6667 (0.6667)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.5302  data: 5.2299  max mem: 40463
Test:  [10/25]  eta: 0:00:11  loss: 0.7847 (0.7838)  acc1: 86.8000 (87.3091)  acc5: 97.2000 (97.6727)  time: 0.7401  data: 0.4757  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9620 (0.8994)  acc1: 82.4000 (84.1143)  acc5: 96.8000 (96.7238)  time: 0.2609  data: 0.0002  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9658 (0.9142)  acc1: 81.2000 (83.6160)  acc5: 96.0000 (96.5600)  time: 0.2609  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4743 s / it)
* Acc@1 84.220 Acc@5 96.694 loss 0.899
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.33%
Epoch: [299]  [   0/1251]  eta: 1:09:13  lr: 0.000001  min_lr: 0.000001  loss: 2.6018 (2.6018)  weight_decay: 0.0500 (0.0500)  time: 3.3200  data: 1.6865  max mem: 40463
Epoch: [299]  [ 200/1251]  eta: 0:09:00  lr: 0.000001  min_lr: 0.000001  loss: 2.7661 (2.6397)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4669 (1.4812)  time: 0.4967  data: 0.0004  max mem: 40463
Epoch: [299]  [ 400/1251]  eta: 0:07:10  lr: 0.000001  min_lr: 0.000001  loss: 2.8441 (2.6705)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2717 (1.4261)  time: 0.4986  data: 0.0005  max mem: 40463
Epoch: [299]  [ 600/1251]  eta: 0:05:29  lr: 0.000001  min_lr: 0.000001  loss: 2.7515 (2.6652)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4583 (1.4449)  time: 0.5070  data: 0.0004  max mem: 40463
Epoch: [299]  [ 800/1251]  eta: 0:03:47  lr: 0.000001  min_lr: 0.000001  loss: 2.5755 (2.6597)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1451 (1.4360)  time: 0.4977  data: 0.0004  max mem: 40463
Epoch: [299]  [1000/1251]  eta: 0:02:06  lr: 0.000001  min_lr: 0.000001  loss: 2.6857 (2.6513)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3676 (1.4688)  time: 0.4987  data: 0.0005  max mem: 40463
Epoch: [299]  [1200/1251]  eta: 0:00:25  lr: 0.000001  min_lr: 0.000001  loss: 2.7523 (2.6548)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5314 (1.4774)  time: 0.4979  data: 0.0005  max mem: 40463
Epoch: [299]  [1250/1251]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 2.6972 (2.6555)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3623 (1.4802)  time: 0.4213  data: 0.0007  max mem: 40463
Epoch: [299] Total time: 0:10:27 (0.5018 s / it)
Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 2.6972 (2.6357)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3623 (1.4802)
Test:  [ 0/25]  eta: 0:01:45  loss: 0.6581 (0.6581)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 4.2101  data: 3.8866  max mem: 40463
Test:  [10/25]  eta: 0:00:09  loss: 0.7824 (0.7721)  acc1: 87.2000 (87.4182)  acc5: 97.2000 (97.7455)  time: 0.6661  data: 0.3996  max mem: 40463
Test:  [20/25]  eta: 0:00:02  loss: 0.9454 (0.8869)  acc1: 83.2000 (84.2286)  acc5: 96.4000 (96.8762)  time: 0.2862  data: 0.0255  max mem: 40463
Test:  [24/25]  eta: 0:00:00  loss: 0.9485 (0.9032)  acc1: 81.2000 (83.7120)  acc5: 96.0000 (96.7040)  time: 0.2608  data: 0.0001  max mem: 40463
Test: Total time: 0:00:11 (0.4426 s / it)
* Acc@1 84.226 Acc@5 96.778 loss 0.887
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.33%
Training time 9:26:22
