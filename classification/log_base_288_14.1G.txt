| distributed init (rank 0): env://, gpu 0
| distributed init (rank 6): env://, gpu 6
| distributed init (rank 3): env://, gpu 3
| distributed init (rank 1): env://, gpu 1
| distributed init (rank 5): env://, gpu 5
| distributed init (rank 7): env://, gpu 7
| distributed init (rank 4): env://, gpu 4
| distributed init (rank 2): env://, gpu 2
Namespace(batch_size=128, epochs=300, update_freq=4, model='base', drop_path=0, input_size=288, layer_scale_init_value=1e-06, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, model_ema_eval=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=5.0, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=0.004, layer_decay=1.0, min_lr=1e-06, warmup_epochs=20, warmup_steps=-1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', crop_pct=None, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', head_init_scale=1.0, model_key='model|module', model_prefix='', data_path='/dev/shm/imagenet', eval_data_path=None, nb_classes=1000, imagenet_default_mean_and_std=True, data_set='IMNET', output_dir='./checkpoint_base_288_14.1G', log_dir=None, device='cuda', seed=0, resume='', auto_resume=True, save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, start_epoch=0, eval=False, dist_eval=True, disable_eval=False, num_workers=10, pin_mem=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', use_amp=True, enable_wandb=False, project='convnext', wandb_ckpt=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
Transform = 
RandomResizedCropAndInterpolation(size=(288, 288), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic)
RandomHorizontalFlip(p=0.5)
RandAugment(n=2, ops=
	AugmentOp(name=AutoContrast, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Equalize, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Invert, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Rotate, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=PosterizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeAdd, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ColorIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ContrastIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=BrightnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SharpnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearX, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearY, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateXRel, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateYRel, p=0.5, m=9, mstd=0.5))
ToTensor()
Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))
RandomErasing(p=0.25, mode=pixel, count=(1, 1))
---------------------------
reading from datapath /dev/shm/imagenet
Number of the class = 1000
Transform = 
Resize(size=329, interpolation=bicubic, max_size=None, antialias=True)
CenterCrop(size=(288, 288))
ToTensor()
Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
---------------------------
reading from datapath /dev/shm/imagenet
Number of the class = 1000
Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7fd735954310>
Mixup is activated!
Model = SPCNN(
  (first_conv): ConvX(
    (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
  )
  (layer1): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): Identity()
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.010)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.020)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.030)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.040)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer2): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.050)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.060)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.070)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.080)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.090)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (5): BottleNeck(
      (drop_path): DropPath(drop_prob=0.100)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (6): BottleNeck(
      (drop_path): DropPath(drop_prob=0.110)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (7): BottleNeck(
      (drop_path): DropPath(drop_prob=0.120)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (8): BottleNeck(
      (drop_path): DropPath(drop_prob=0.130)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer3): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=768, bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.140)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.150)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.160)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.170)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.180)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (5): BottleNeck(
      (drop_path): DropPath(drop_prob=0.190)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (6): BottleNeck(
      (drop_path): DropPath(drop_prob=0.200)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (7): BottleNeck(
      (drop_path): DropPath(drop_prob=0.210)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (8): BottleNeck(
      (drop_path): DropPath(drop_prob=0.220)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (9): BottleNeck(
      (drop_path): DropPath(drop_prob=0.230)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (10): BottleNeck(
      (drop_path): DropPath(drop_prob=0.240)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (11): BottleNeck(
      (drop_path): DropPath(drop_prob=0.250)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (12): BottleNeck(
      (drop_path): DropPath(drop_prob=0.260)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (13): BottleNeck(
      (drop_path): DropPath(drop_prob=0.270)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (14): BottleNeck(
      (drop_path): DropPath(drop_prob=0.280)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (15): BottleNeck(
      (drop_path): DropPath(drop_prob=0.290)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (16): BottleNeck(
      (drop_path): DropPath(drop_prob=0.300)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer4): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1536, bias=False)
          (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.310)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.320)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.330)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.340)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.350)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (head): ConvX(
    (conv): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (classifier): MlpHead(
    (fc1): Linear(in_features=1024, out_features=2048, bias=False)
    (norm): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
    (drop): Dropout(p=0.2, inplace=False)
    (fc2): Linear(in_features=2048, out_features=1000, bias=False)
  )
)
number of params: 48903328
LR = 0.00400000
Batch size = 4096
Update frequent = 4
Number of training examples = 1281167
Number of training training per epoch = 312
Param groups = {
  "decay": {
    "weight_decay": 0.05,
    "params": [
      "first_conv.conv.weight",
      "layer1.0.mlp.0.conv.weight",
      "layer1.0.mlp.1.conv.weight",
      "layer1.0.mlp.2.conv.weight",
      "layer1.0.skip.0.conv.weight",
      "layer1.0.skip.1.conv.weight",
      "layer1.1.sblock_in.conv.weight",
      "layer1.1.sblock_dw.conv.weight",
      "layer1.1.sblock_proj.conv.weight",
      "layer1.1.mblock.0.conv.weight",
      "layer1.1.mblock.1.branch_1.1.conv.weight",
      "layer1.1.mblock.1.branch_2.1.conv.weight",
      "layer1.1.mblock.1.branch_3.1.conv.weight",
      "layer1.1.mblock.2.conv.weight",
      "layer1.2.sblock_in.conv.weight",
      "layer1.2.sblock_dw.conv.weight",
      "layer1.2.sblock_proj.conv.weight",
      "layer1.2.mblock.0.conv.weight",
      "layer1.2.mblock.1.branch_1.1.conv.weight",
      "layer1.2.mblock.1.branch_2.1.conv.weight",
      "layer1.2.mblock.1.branch_3.1.conv.weight",
      "layer1.2.mblock.2.conv.weight",
      "layer1.3.sblock_in.conv.weight",
      "layer1.3.sblock_dw.conv.weight",
      "layer1.3.sblock_proj.conv.weight",
      "layer1.3.mblock.0.conv.weight",
      "layer1.3.mblock.1.branch_1.1.conv.weight",
      "layer1.3.mblock.1.branch_2.1.conv.weight",
      "layer1.3.mblock.1.branch_3.1.conv.weight",
      "layer1.3.mblock.2.conv.weight",
      "layer1.4.sblock_in.conv.weight",
      "layer1.4.sblock_dw.conv.weight",
      "layer1.4.sblock_proj.conv.weight",
      "layer1.4.mblock.0.conv.weight",
      "layer1.4.mblock.1.branch_1.1.conv.weight",
      "layer1.4.mblock.1.branch_2.1.conv.weight",
      "layer1.4.mblock.1.branch_3.1.conv.weight",
      "layer1.4.mblock.2.conv.weight",
      "layer2.0.mlp.0.conv.weight",
      "layer2.0.mlp.1.conv.weight",
      "layer2.0.mlp.2.conv.weight",
      "layer2.0.skip.0.conv.weight",
      "layer2.0.skip.1.conv.weight",
      "layer2.1.sblock_in.conv.weight",
      "layer2.1.sblock_dw.conv.weight",
      "layer2.1.sblock_proj.conv.weight",
      "layer2.1.mblock.0.conv.weight",
      "layer2.1.mblock.1.branch_1.1.conv.weight",
      "layer2.1.mblock.1.branch_2.1.conv.weight",
      "layer2.1.mblock.1.branch_3.1.conv.weight",
      "layer2.1.mblock.2.conv.weight",
      "layer2.2.sblock_in.conv.weight",
      "layer2.2.sblock_dw.conv.weight",
      "layer2.2.sblock_proj.conv.weight",
      "layer2.2.mblock.0.conv.weight",
      "layer2.2.mblock.1.branch_1.1.conv.weight",
      "layer2.2.mblock.1.branch_2.1.conv.weight",
      "layer2.2.mblock.1.branch_3.1.conv.weight",
      "layer2.2.mblock.2.conv.weight",
      "layer2.3.sblock_in.conv.weight",
      "layer2.3.sblock_dw.conv.weight",
      "layer2.3.sblock_proj.conv.weight",
      "layer2.3.mblock.0.conv.weight",
      "layer2.3.mblock.1.branch_1.1.conv.weight",
      "layer2.3.mblock.1.branch_2.1.conv.weight",
      "layer2.3.mblock.1.branch_3.1.conv.weight",
      "layer2.3.mblock.2.conv.weight",
      "layer2.4.sblock_in.conv.weight",
      "layer2.4.sblock_dw.conv.weight",
      "layer2.4.sblock_proj.conv.weight",
      "layer2.4.mblock.0.conv.weight",
      "layer2.4.mblock.1.branch_1.1.conv.weight",
      "layer2.4.mblock.1.branch_2.1.conv.weight",
      "layer2.4.mblock.1.branch_3.1.conv.weight",
      "layer2.4.mblock.2.conv.weight",
      "layer2.5.sblock_in.conv.weight",
      "layer2.5.sblock_dw.conv.weight",
      "layer2.5.sblock_proj.conv.weight",
      "layer2.5.mblock.0.conv.weight",
      "layer2.5.mblock.1.branch_1.1.conv.weight",
      "layer2.5.mblock.1.branch_2.1.conv.weight",
      "layer2.5.mblock.1.branch_3.1.conv.weight",
      "layer2.5.mblock.2.conv.weight",
      "layer2.6.sblock_in.conv.weight",
      "layer2.6.sblock_dw.conv.weight",
      "layer2.6.sblock_proj.conv.weight",
      "layer2.6.mblock.0.conv.weight",
      "layer2.6.mblock.1.branch_1.1.conv.weight",
      "layer2.6.mblock.1.branch_2.1.conv.weight",
      "layer2.6.mblock.1.branch_3.1.conv.weight",
      "layer2.6.mblock.2.conv.weight",
      "layer2.7.sblock_in.conv.weight",
      "layer2.7.sblock_dw.conv.weight",
      "layer2.7.sblock_proj.conv.weight",
      "layer2.7.mblock.0.conv.weight",
      "layer2.7.mblock.1.branch_1.1.conv.weight",
      "layer2.7.mblock.1.branch_2.1.conv.weight",
      "layer2.7.mblock.1.branch_3.1.conv.weight",
      "layer2.7.mblock.2.conv.weight",
      "layer2.8.sblock_in.conv.weight",
      "layer2.8.sblock_dw.conv.weight",
      "layer2.8.sblock_proj.conv.weight",
      "layer2.8.mblock.0.conv.weight",
      "layer2.8.mblock.1.branch_1.1.conv.weight",
      "layer2.8.mblock.1.branch_2.1.conv.weight",
      "layer2.8.mblock.1.branch_3.1.conv.weight",
      "layer2.8.mblock.2.conv.weight",
      "layer3.0.mlp.0.conv.weight",
      "layer3.0.mlp.1.conv.weight",
      "layer3.0.mlp.2.conv.weight",
      "layer3.0.skip.0.conv.weight",
      "layer3.0.skip.1.conv.weight",
      "layer3.1.sblock_in.conv.weight",
      "layer3.1.sblock_dw.conv.weight",
      "layer3.1.sblock_proj.conv.weight",
      "layer3.1.mblock.0.conv.weight",
      "layer3.1.mblock.1.branch_1.1.conv.weight",
      "layer3.1.mblock.1.branch_2.1.conv.weight",
      "layer3.1.mblock.1.branch_3.1.conv.weight",
      "layer3.1.mblock.2.conv.weight",
      "layer3.2.sblock_in.conv.weight",
      "layer3.2.sblock_dw.conv.weight",
      "layer3.2.sblock_proj.conv.weight",
      "layer3.2.mblock.0.conv.weight",
      "layer3.2.mblock.1.branch_1.1.conv.weight",
      "layer3.2.mblock.1.branch_2.1.conv.weight",
      "layer3.2.mblock.1.branch_3.1.conv.weight",
      "layer3.2.mblock.2.conv.weight",
      "layer3.3.sblock_in.conv.weight",
      "layer3.3.sblock_dw.conv.weight",
      "layer3.3.sblock_proj.conv.weight",
      "layer3.3.mblock.0.conv.weight",
      "layer3.3.mblock.1.branch_1.1.conv.weight",
      "layer3.3.mblock.1.branch_2.1.conv.weight",
      "layer3.3.mblock.1.branch_3.1.conv.weight",
      "layer3.3.mblock.2.conv.weight",
      "layer3.4.sblock_in.conv.weight",
      "layer3.4.sblock_dw.conv.weight",
      "layer3.4.sblock_proj.conv.weight",
      "layer3.4.mblock.0.conv.weight",
      "layer3.4.mblock.1.branch_1.1.conv.weight",
      "layer3.4.mblock.1.branch_2.1.conv.weight",
      "layer3.4.mblock.1.branch_3.1.conv.weight",
      "layer3.4.mblock.2.conv.weight",
      "layer3.5.sblock_in.conv.weight",
      "layer3.5.sblock_dw.conv.weight",
      "layer3.5.sblock_proj.conv.weight",
      "layer3.5.mblock.0.conv.weight",
      "layer3.5.mblock.1.branch_1.1.conv.weight",
      "layer3.5.mblock.1.branch_2.1.conv.weight",
      "layer3.5.mblock.1.branch_3.1.conv.weight",
      "layer3.5.mblock.2.conv.weight",
      "layer3.6.sblock_in.conv.weight",
      "layer3.6.sblock_dw.conv.weight",
      "layer3.6.sblock_proj.conv.weight",
      "layer3.6.mblock.0.conv.weight",
      "layer3.6.mblock.1.branch_1.1.conv.weight",
      "layer3.6.mblock.1.branch_2.1.conv.weight",
      "layer3.6.mblock.1.branch_3.1.conv.weight",
      "layer3.6.mblock.2.conv.weight",
      "layer3.7.sblock_in.conv.weight",
      "layer3.7.sblock_dw.conv.weight",
      "layer3.7.sblock_proj.conv.weight",
      "layer3.7.mblock.0.conv.weight",
      "layer3.7.mblock.1.branch_1.1.conv.weight",
      "layer3.7.mblock.1.branch_2.1.conv.weight",
      "layer3.7.mblock.1.branch_3.1.conv.weight",
      "layer3.7.mblock.2.conv.weight",
      "layer3.8.sblock_in.conv.weight",
      "layer3.8.sblock_dw.conv.weight",
      "layer3.8.sblock_proj.conv.weight",
      "layer3.8.mblock.0.conv.weight",
      "layer3.8.mblock.1.branch_1.1.conv.weight",
      "layer3.8.mblock.1.branch_2.1.conv.weight",
      "layer3.8.mblock.1.branch_3.1.conv.weight",
      "layer3.8.mblock.2.conv.weight",
      "layer3.9.sblock_in.conv.weight",
      "layer3.9.sblock_dw.conv.weight",
      "layer3.9.sblock_proj.conv.weight",
      "layer3.9.mblock.0.conv.weight",
      "layer3.9.mblock.1.branch_1.1.conv.weight",
      "layer3.9.mblock.1.branch_2.1.conv.weight",
      "layer3.9.mblock.1.branch_3.1.conv.weight",
      "layer3.9.mblock.2.conv.weight",
      "layer3.10.sblock_in.conv.weight",
      "layer3.10.sblock_dw.conv.weight",
      "layer3.10.sblock_proj.conv.weight",
      "layer3.10.mblock.0.conv.weight",
      "layer3.10.mblock.1.branch_1.1.conv.weight",
      "layer3.10.mblock.1.branch_2.1.conv.weight",
      "layer3.10.mblock.1.branch_3.1.conv.weight",
      "layer3.10.mblock.2.conv.weight",
      "layer3.11.sblock_in.conv.weight",
      "layer3.11.sblock_dw.conv.weight",
      "layer3.11.sblock_proj.conv.weight",
      "layer3.11.mblock.0.conv.weight",
      "layer3.11.mblock.1.branch_1.1.conv.weight",
      "layer3.11.mblock.1.branch_2.1.conv.weight",
      "layer3.11.mblock.1.branch_3.1.conv.weight",
      "layer3.11.mblock.2.conv.weight",
      "layer3.12.sblock_in.conv.weight",
      "layer3.12.sblock_dw.conv.weight",
      "layer3.12.sblock_proj.conv.weight",
      "layer3.12.mblock.0.conv.weight",
      "layer3.12.mblock.1.branch_1.1.conv.weight",
      "layer3.12.mblock.1.branch_2.1.conv.weight",
      "layer3.12.mblock.1.branch_3.1.conv.weight",
      "layer3.12.mblock.2.conv.weight",
      "layer3.13.sblock_in.conv.weight",
      "layer3.13.sblock_dw.conv.weight",
      "layer3.13.sblock_proj.conv.weight",
      "layer3.13.mblock.0.conv.weight",
      "layer3.13.mblock.1.branch_1.1.conv.weight",
      "layer3.13.mblock.1.branch_2.1.conv.weight",
      "layer3.13.mblock.1.branch_3.1.conv.weight",
      "layer3.13.mblock.2.conv.weight",
      "layer3.14.sblock_in.conv.weight",
      "layer3.14.sblock_dw.conv.weight",
      "layer3.14.sblock_proj.conv.weight",
      "layer3.14.mblock.0.conv.weight",
      "layer3.14.mblock.1.branch_1.1.conv.weight",
      "layer3.14.mblock.1.branch_2.1.conv.weight",
      "layer3.14.mblock.1.branch_3.1.conv.weight",
      "layer3.14.mblock.2.conv.weight",
      "layer3.15.sblock_in.conv.weight",
      "layer3.15.sblock_dw.conv.weight",
      "layer3.15.sblock_proj.conv.weight",
      "layer3.15.mblock.0.conv.weight",
      "layer3.15.mblock.1.branch_1.1.conv.weight",
      "layer3.15.mblock.1.branch_2.1.conv.weight",
      "layer3.15.mblock.1.branch_3.1.conv.weight",
      "layer3.15.mblock.2.conv.weight",
      "layer3.16.sblock_in.conv.weight",
      "layer3.16.sblock_dw.conv.weight",
      "layer3.16.sblock_proj.conv.weight",
      "layer3.16.mblock.0.conv.weight",
      "layer3.16.mblock.1.branch_1.1.conv.weight",
      "layer3.16.mblock.1.branch_2.1.conv.weight",
      "layer3.16.mblock.1.branch_3.1.conv.weight",
      "layer3.16.mblock.2.conv.weight",
      "layer4.0.mlp.0.conv.weight",
      "layer4.0.mlp.1.conv.weight",
      "layer4.0.mlp.2.conv.weight",
      "layer4.0.skip.0.conv.weight",
      "layer4.0.skip.1.conv.weight",
      "layer4.1.sblock_in.conv.weight",
      "layer4.1.sblock_dw.conv.weight",
      "layer4.1.sblock_proj.conv.weight",
      "layer4.1.mblock.0.conv.weight",
      "layer4.1.mblock.1.branch_1.1.conv.weight",
      "layer4.1.mblock.1.branch_2.1.conv.weight",
      "layer4.1.mblock.1.branch_3.1.conv.weight",
      "layer4.1.mblock.2.conv.weight",
      "layer4.2.sblock_in.conv.weight",
      "layer4.2.sblock_dw.conv.weight",
      "layer4.2.sblock_proj.conv.weight",
      "layer4.2.mblock.0.conv.weight",
      "layer4.2.mblock.1.branch_1.1.conv.weight",
      "layer4.2.mblock.1.branch_2.1.conv.weight",
      "layer4.2.mblock.1.branch_3.1.conv.weight",
      "layer4.2.mblock.2.conv.weight",
      "layer4.3.sblock_in.conv.weight",
      "layer4.3.sblock_dw.conv.weight",
      "layer4.3.sblock_proj.conv.weight",
      "layer4.3.mblock.0.conv.weight",
      "layer4.3.mblock.1.branch_1.1.conv.weight",
      "layer4.3.mblock.1.branch_2.1.conv.weight",
      "layer4.3.mblock.1.branch_3.1.conv.weight",
      "layer4.3.mblock.2.conv.weight",
      "layer4.4.sblock_in.conv.weight",
      "layer4.4.sblock_dw.conv.weight",
      "layer4.4.sblock_proj.conv.weight",
      "layer4.4.mblock.0.conv.weight",
      "layer4.4.mblock.1.branch_1.1.conv.weight",
      "layer4.4.mblock.1.branch_2.1.conv.weight",
      "layer4.4.mblock.1.branch_3.1.conv.weight",
      "layer4.4.mblock.2.conv.weight",
      "head.conv.weight",
      "classifier.fc1.weight",
      "classifier.fc2.weight"
    ],
    "lr_scale": 1.0
  },
  "no_decay": {
    "weight_decay": 0.0,
    "params": [
      "first_conv.norm.weight",
      "first_conv.norm.bias",
      "layer1.0.mlp.0.norm.weight",
      "layer1.0.mlp.0.norm.bias",
      "layer1.0.mlp.1.norm.weight",
      "layer1.0.mlp.1.norm.bias",
      "layer1.0.mlp.2.norm.weight",
      "layer1.0.mlp.2.norm.bias",
      "layer1.0.skip.0.norm.weight",
      "layer1.0.skip.0.norm.bias",
      "layer1.0.skip.1.norm.weight",
      "layer1.0.skip.1.norm.bias",
      "layer1.1.sblock_in.norm.weight",
      "layer1.1.sblock_in.norm.bias",
      "layer1.1.sblock_dw.norm.weight",
      "layer1.1.sblock_dw.norm.bias",
      "layer1.1.sblock_proj.norm.weight",
      "layer1.1.sblock_proj.norm.bias",
      "layer1.1.mblock.0.norm.weight",
      "layer1.1.mblock.0.norm.bias",
      "layer1.1.mblock.1.branch_1.1.norm.weight",
      "layer1.1.mblock.1.branch_1.1.norm.bias",
      "layer1.1.mblock.1.branch_2.1.norm.weight",
      "layer1.1.mblock.1.branch_2.1.norm.bias",
      "layer1.1.mblock.1.branch_3.1.norm.weight",
      "layer1.1.mblock.1.branch_3.1.norm.bias",
      "layer1.1.mblock.2.norm.weight",
      "layer1.1.mblock.2.norm.bias",
      "layer1.2.sblock_in.norm.weight",
      "layer1.2.sblock_in.norm.bias",
      "layer1.2.sblock_dw.norm.weight",
      "layer1.2.sblock_dw.norm.bias",
      "layer1.2.sblock_proj.norm.weight",
      "layer1.2.sblock_proj.norm.bias",
      "layer1.2.mblock.0.norm.weight",
      "layer1.2.mblock.0.norm.bias",
      "layer1.2.mblock.1.branch_1.1.norm.weight",
      "layer1.2.mblock.1.branch_1.1.norm.bias",
      "layer1.2.mblock.1.branch_2.1.norm.weight",
      "layer1.2.mblock.1.branch_2.1.norm.bias",
      "layer1.2.mblock.1.branch_3.1.norm.weight",
      "layer1.2.mblock.1.branch_3.1.norm.bias",
      "layer1.2.mblock.2.norm.weight",
      "layer1.2.mblock.2.norm.bias",
      "layer1.3.sblock_in.norm.weight",
      "layer1.3.sblock_in.norm.bias",
      "layer1.3.sblock_dw.norm.weight",
      "layer1.3.sblock_dw.norm.bias",
      "layer1.3.sblock_proj.norm.weight",
      "layer1.3.sblock_proj.norm.bias",
      "layer1.3.mblock.0.norm.weight",
      "layer1.3.mblock.0.norm.bias",
      "layer1.3.mblock.1.branch_1.1.norm.weight",
      "layer1.3.mblock.1.branch_1.1.norm.bias",
      "layer1.3.mblock.1.branch_2.1.norm.weight",
      "layer1.3.mblock.1.branch_2.1.norm.bias",
      "layer1.3.mblock.1.branch_3.1.norm.weight",
      "layer1.3.mblock.1.branch_3.1.norm.bias",
      "layer1.3.mblock.2.norm.weight",
      "layer1.3.mblock.2.norm.bias",
      "layer1.4.sblock_in.norm.weight",
      "layer1.4.sblock_in.norm.bias",
      "layer1.4.sblock_dw.norm.weight",
      "layer1.4.sblock_dw.norm.bias",
      "layer1.4.sblock_proj.norm.weight",
      "layer1.4.sblock_proj.norm.bias",
      "layer1.4.mblock.0.norm.weight",
      "layer1.4.mblock.0.norm.bias",
      "layer1.4.mblock.1.branch_1.1.norm.weight",
      "layer1.4.mblock.1.branch_1.1.norm.bias",
      "layer1.4.mblock.1.branch_2.1.norm.weight",
      "layer1.4.mblock.1.branch_2.1.norm.bias",
      "layer1.4.mblock.1.branch_3.1.norm.weight",
      "layer1.4.mblock.1.branch_3.1.norm.bias",
      "layer1.4.mblock.2.norm.weight",
      "layer1.4.mblock.2.norm.bias",
      "layer2.0.mlp.0.norm.weight",
      "layer2.0.mlp.0.norm.bias",
      "layer2.0.mlp.1.norm.weight",
      "layer2.0.mlp.1.norm.bias",
      "layer2.0.mlp.2.norm.weight",
      "layer2.0.mlp.2.norm.bias",
      "layer2.0.skip.0.norm.weight",
      "layer2.0.skip.0.norm.bias",
      "layer2.0.skip.1.norm.weight",
      "layer2.0.skip.1.norm.bias",
      "layer2.1.sblock_in.norm.weight",
      "layer2.1.sblock_in.norm.bias",
      "layer2.1.sblock_dw.norm.weight",
      "layer2.1.sblock_dw.norm.bias",
      "layer2.1.sblock_proj.norm.weight",
      "layer2.1.sblock_proj.norm.bias",
      "layer2.1.mblock.0.norm.weight",
      "layer2.1.mblock.0.norm.bias",
      "layer2.1.mblock.1.branch_1.1.norm.weight",
      "layer2.1.mblock.1.branch_1.1.norm.bias",
      "layer2.1.mblock.1.branch_2.1.norm.weight",
      "layer2.1.mblock.1.branch_2.1.norm.bias",
      "layer2.1.mblock.1.branch_3.1.norm.weight",
      "layer2.1.mblock.1.branch_3.1.norm.bias",
      "layer2.1.mblock.2.norm.weight",
      "layer2.1.mblock.2.norm.bias",
      "layer2.2.sblock_in.norm.weight",
      "layer2.2.sblock_in.norm.bias",
      "layer2.2.sblock_dw.norm.weight",
      "layer2.2.sblock_dw.norm.bias",
      "layer2.2.sblock_proj.norm.weight",
      "layer2.2.sblock_proj.norm.bias",
      "layer2.2.mblock.0.norm.weight",
      "layer2.2.mblock.0.norm.bias",
      "layer2.2.mblock.1.branch_1.1.norm.weight",
      "layer2.2.mblock.1.branch_1.1.norm.bias",
      "layer2.2.mblock.1.branch_2.1.norm.weight",
      "layer2.2.mblock.1.branch_2.1.norm.bias",
      "layer2.2.mblock.1.branch_3.1.norm.weight",
      "layer2.2.mblock.1.branch_3.1.norm.bias",
      "layer2.2.mblock.2.norm.weight",
      "layer2.2.mblock.2.norm.bias",
      "layer2.3.sblock_in.norm.weight",
      "layer2.3.sblock_in.norm.bias",
      "layer2.3.sblock_dw.norm.weight",
      "layer2.3.sblock_dw.norm.bias",
      "layer2.3.sblock_proj.norm.weight",
      "layer2.3.sblock_proj.norm.bias",
      "layer2.3.mblock.0.norm.weight",
      "layer2.3.mblock.0.norm.bias",
      "layer2.3.mblock.1.branch_1.1.norm.weight",
      "layer2.3.mblock.1.branch_1.1.norm.bias",
      "layer2.3.mblock.1.branch_2.1.norm.weight",
      "layer2.3.mblock.1.branch_2.1.norm.bias",
      "layer2.3.mblock.1.branch_3.1.norm.weight",
      "layer2.3.mblock.1.branch_3.1.norm.bias",
      "layer2.3.mblock.2.norm.weight",
      "layer2.3.mblock.2.norm.bias",
      "layer2.4.sblock_in.norm.weight",
      "layer2.4.sblock_in.norm.bias",
      "layer2.4.sblock_dw.norm.weight",
      "layer2.4.sblock_dw.norm.bias",
      "layer2.4.sblock_proj.norm.weight",
      "layer2.4.sblock_proj.norm.bias",
      "layer2.4.mblock.0.norm.weight",
      "layer2.4.mblock.0.norm.bias",
      "layer2.4.mblock.1.branch_1.1.norm.weight",
      "layer2.4.mblock.1.branch_1.1.norm.bias",
      "layer2.4.mblock.1.branch_2.1.norm.weight",
      "layer2.4.mblock.1.branch_2.1.norm.bias",
      "layer2.4.mblock.1.branch_3.1.norm.weight",
      "layer2.4.mblock.1.branch_3.1.norm.bias",
      "layer2.4.mblock.2.norm.weight",
      "layer2.4.mblock.2.norm.bias",
      "layer2.5.sblock_in.norm.weight",
      "layer2.5.sblock_in.norm.bias",
      "layer2.5.sblock_dw.norm.weight",
      "layer2.5.sblock_dw.norm.bias",
      "layer2.5.sblock_proj.norm.weight",
      "layer2.5.sblock_proj.norm.bias",
      "layer2.5.mblock.0.norm.weight",
      "layer2.5.mblock.0.norm.bias",
      "layer2.5.mblock.1.branch_1.1.norm.weight",
      "layer2.5.mblock.1.branch_1.1.norm.bias",
      "layer2.5.mblock.1.branch_2.1.norm.weight",
      "layer2.5.mblock.1.branch_2.1.norm.bias",
      "layer2.5.mblock.1.branch_3.1.norm.weight",
      "layer2.5.mblock.1.branch_3.1.norm.bias",
      "layer2.5.mblock.2.norm.weight",
      "layer2.5.mblock.2.norm.bias",
      "layer2.6.sblock_in.norm.weight",
      "layer2.6.sblock_in.norm.bias",
      "layer2.6.sblock_dw.norm.weight",
      "layer2.6.sblock_dw.norm.bias",
      "layer2.6.sblock_proj.norm.weight",
      "layer2.6.sblock_proj.norm.bias",
      "layer2.6.mblock.0.norm.weight",
      "layer2.6.mblock.0.norm.bias",
      "layer2.6.mblock.1.branch_1.1.norm.weight",
      "layer2.6.mblock.1.branch_1.1.norm.bias",
      "layer2.6.mblock.1.branch_2.1.norm.weight",
      "layer2.6.mblock.1.branch_2.1.norm.bias",
      "layer2.6.mblock.1.branch_3.1.norm.weight",
      "layer2.6.mblock.1.branch_3.1.norm.bias",
      "layer2.6.mblock.2.norm.weight",
      "layer2.6.mblock.2.norm.bias",
      "layer2.7.sblock_in.norm.weight",
      "layer2.7.sblock_in.norm.bias",
      "layer2.7.sblock_dw.norm.weight",
      "layer2.7.sblock_dw.norm.bias",
      "layer2.7.sblock_proj.norm.weight",
      "layer2.7.sblock_proj.norm.bias",
      "layer2.7.mblock.0.norm.weight",
      "layer2.7.mblock.0.norm.bias",
      "layer2.7.mblock.1.branch_1.1.norm.weight",
      "layer2.7.mblock.1.branch_1.1.norm.bias",
      "layer2.7.mblock.1.branch_2.1.norm.weight",
      "layer2.7.mblock.1.branch_2.1.norm.bias",
      "layer2.7.mblock.1.branch_3.1.norm.weight",
      "layer2.7.mblock.1.branch_3.1.norm.bias",
      "layer2.7.mblock.2.norm.weight",
      "layer2.7.mblock.2.norm.bias",
      "layer2.8.sblock_in.norm.weight",
      "layer2.8.sblock_in.norm.bias",
      "layer2.8.sblock_dw.norm.weight",
      "layer2.8.sblock_dw.norm.bias",
      "layer2.8.sblock_proj.norm.weight",
      "layer2.8.sblock_proj.norm.bias",
      "layer2.8.mblock.0.norm.weight",
      "layer2.8.mblock.0.norm.bias",
      "layer2.8.mblock.1.branch_1.1.norm.weight",
      "layer2.8.mblock.1.branch_1.1.norm.bias",
      "layer2.8.mblock.1.branch_2.1.norm.weight",
      "layer2.8.mblock.1.branch_2.1.norm.bias",
      "layer2.8.mblock.1.branch_3.1.norm.weight",
      "layer2.8.mblock.1.branch_3.1.norm.bias",
      "layer2.8.mblock.2.norm.weight",
      "layer2.8.mblock.2.norm.bias",
      "layer3.0.mlp.0.norm.weight",
      "layer3.0.mlp.0.norm.bias",
      "layer3.0.mlp.1.norm.weight",
      "layer3.0.mlp.1.norm.bias",
      "layer3.0.mlp.2.norm.weight",
      "layer3.0.mlp.2.norm.bias",
      "layer3.0.skip.0.norm.weight",
      "layer3.0.skip.0.norm.bias",
      "layer3.0.skip.1.norm.weight",
      "layer3.0.skip.1.norm.bias",
      "layer3.1.sblock_in.norm.weight",
      "layer3.1.sblock_in.norm.bias",
      "layer3.1.sblock_dw.norm.weight",
      "layer3.1.sblock_dw.norm.bias",
      "layer3.1.sblock_proj.norm.weight",
      "layer3.1.sblock_proj.norm.bias",
      "layer3.1.mblock.0.norm.weight",
      "layer3.1.mblock.0.norm.bias",
      "layer3.1.mblock.1.branch_1.1.norm.weight",
      "layer3.1.mblock.1.branch_1.1.norm.bias",
      "layer3.1.mblock.1.branch_2.1.norm.weight",
      "layer3.1.mblock.1.branch_2.1.norm.bias",
      "layer3.1.mblock.1.branch_3.1.norm.weight",
      "layer3.1.mblock.1.branch_3.1.norm.bias",
      "layer3.1.mblock.2.norm.weight",
      "layer3.1.mblock.2.norm.bias",
      "layer3.2.sblock_in.norm.weight",
      "layer3.2.sblock_in.norm.bias",
      "layer3.2.sblock_dw.norm.weight",
      "layer3.2.sblock_dw.norm.bias",
      "layer3.2.sblock_proj.norm.weight",
      "layer3.2.sblock_proj.norm.bias",
      "layer3.2.mblock.0.norm.weight",
      "layer3.2.mblock.0.norm.bias",
      "layer3.2.mblock.1.branch_1.1.norm.weight",
      "layer3.2.mblock.1.branch_1.1.norm.bias",
      "layer3.2.mblock.1.branch_2.1.norm.weight",
      "layer3.2.mblock.1.branch_2.1.norm.bias",
      "layer3.2.mblock.1.branch_3.1.norm.weight",
      "layer3.2.mblock.1.branch_3.1.norm.bias",
      "layer3.2.mblock.2.norm.weight",
      "layer3.2.mblock.2.norm.bias",
      "layer3.3.sblock_in.norm.weight",
      "layer3.3.sblock_in.norm.bias",
      "layer3.3.sblock_dw.norm.weight",
      "layer3.3.sblock_dw.norm.bias",
      "layer3.3.sblock_proj.norm.weight",
      "layer3.3.sblock_proj.norm.bias",
      "layer3.3.mblock.0.norm.weight",
      "layer3.3.mblock.0.norm.bias",
      "layer3.3.mblock.1.branch_1.1.norm.weight",
      "layer3.3.mblock.1.branch_1.1.norm.bias",
      "layer3.3.mblock.1.branch_2.1.norm.weight",
      "layer3.3.mblock.1.branch_2.1.norm.bias",
      "layer3.3.mblock.1.branch_3.1.norm.weight",
      "layer3.3.mblock.1.branch_3.1.norm.bias",
      "layer3.3.mblock.2.norm.weight",
      "layer3.3.mblock.2.norm.bias",
      "layer3.4.sblock_in.norm.weight",
      "layer3.4.sblock_in.norm.bias",
      "layer3.4.sblock_dw.norm.weight",
      "layer3.4.sblock_dw.norm.bias",
      "layer3.4.sblock_proj.norm.weight",
      "layer3.4.sblock_proj.norm.bias",
      "layer3.4.mblock.0.norm.weight",
      "layer3.4.mblock.0.norm.bias",
      "layer3.4.mblock.1.branch_1.1.norm.weight",
      "layer3.4.mblock.1.branch_1.1.norm.bias",
      "layer3.4.mblock.1.branch_2.1.norm.weight",
      "layer3.4.mblock.1.branch_2.1.norm.bias",
      "layer3.4.mblock.1.branch_3.1.norm.weight",
      "layer3.4.mblock.1.branch_3.1.norm.bias",
      "layer3.4.mblock.2.norm.weight",
      "layer3.4.mblock.2.norm.bias",
      "layer3.5.sblock_in.norm.weight",
      "layer3.5.sblock_in.norm.bias",
      "layer3.5.sblock_dw.norm.weight",
      "layer3.5.sblock_dw.norm.bias",
      "layer3.5.sblock_proj.norm.weight",
      "layer3.5.sblock_proj.norm.bias",
      "layer3.5.mblock.0.norm.weight",
      "layer3.5.mblock.0.norm.bias",
      "layer3.5.mblock.1.branch_1.1.norm.weight",
      "layer3.5.mblock.1.branch_1.1.norm.bias",
      "layer3.5.mblock.1.branch_2.1.norm.weight",
      "layer3.5.mblock.1.branch_2.1.norm.bias",
      "layer3.5.mblock.1.branch_3.1.norm.weight",
      "layer3.5.mblock.1.branch_3.1.norm.bias",
      "layer3.5.mblock.2.norm.weight",
      "layer3.5.mblock.2.norm.bias",
      "layer3.6.sblock_in.norm.weight",
      "layer3.6.sblock_in.norm.bias",
      "layer3.6.sblock_dw.norm.weight",
      "layer3.6.sblock_dw.norm.bias",
      "layer3.6.sblock_proj.norm.weight",
      "layer3.6.sblock_proj.norm.bias",
      "layer3.6.mblock.0.norm.weight",
      "layer3.6.mblock.0.norm.bias",
      "layer3.6.mblock.1.branch_1.1.norm.weight",
      "layer3.6.mblock.1.branch_1.1.norm.bias",
      "layer3.6.mblock.1.branch_2.1.norm.weight",
      "layer3.6.mblock.1.branch_2.1.norm.bias",
      "layer3.6.mblock.1.branch_3.1.norm.weight",
      "layer3.6.mblock.1.branch_3.1.norm.bias",
      "layer3.6.mblock.2.norm.weight",
      "layer3.6.mblock.2.norm.bias",
      "layer3.7.sblock_in.norm.weight",
      "layer3.7.sblock_in.norm.bias",
      "layer3.7.sblock_dw.norm.weight",
      "layer3.7.sblock_dw.norm.bias",
      "layer3.7.sblock_proj.norm.weight",
      "layer3.7.sblock_proj.norm.bias",
      "layer3.7.mblock.0.norm.weight",
      "layer3.7.mblock.0.norm.bias",
      "layer3.7.mblock.1.branch_1.1.norm.weight",
      "layer3.7.mblock.1.branch_1.1.norm.bias",
      "layer3.7.mblock.1.branch_2.1.norm.weight",
      "layer3.7.mblock.1.branch_2.1.norm.bias",
      "layer3.7.mblock.1.branch_3.1.norm.weight",
      "layer3.7.mblock.1.branch_3.1.norm.bias",
      "layer3.7.mblock.2.norm.weight",
      "layer3.7.mblock.2.norm.bias",
      "layer3.8.sblock_in.norm.weight",
      "layer3.8.sblock_in.norm.bias",
      "layer3.8.sblock_dw.norm.weight",
      "layer3.8.sblock_dw.norm.bias",
      "layer3.8.sblock_proj.norm.weight",
      "layer3.8.sblock_proj.norm.bias",
      "layer3.8.mblock.0.norm.weight",
      "layer3.8.mblock.0.norm.bias",
      "layer3.8.mblock.1.branch_1.1.norm.weight",
      "layer3.8.mblock.1.branch_1.1.norm.bias",
      "layer3.8.mblock.1.branch_2.1.norm.weight",
      "layer3.8.mblock.1.branch_2.1.norm.bias",
      "layer3.8.mblock.1.branch_3.1.norm.weight",
      "layer3.8.mblock.1.branch_3.1.norm.bias",
      "layer3.8.mblock.2.norm.weight",
      "layer3.8.mblock.2.norm.bias",
      "layer3.9.sblock_in.norm.weight",
      "layer3.9.sblock_in.norm.bias",
      "layer3.9.sblock_dw.norm.weight",
      "layer3.9.sblock_dw.norm.bias",
      "layer3.9.sblock_proj.norm.weight",
      "layer3.9.sblock_proj.norm.bias",
      "layer3.9.mblock.0.norm.weight",
      "layer3.9.mblock.0.norm.bias",
      "layer3.9.mblock.1.branch_1.1.norm.weight",
      "layer3.9.mblock.1.branch_1.1.norm.bias",
      "layer3.9.mblock.1.branch_2.1.norm.weight",
      "layer3.9.mblock.1.branch_2.1.norm.bias",
      "layer3.9.mblock.1.branch_3.1.norm.weight",
      "layer3.9.mblock.1.branch_3.1.norm.bias",
      "layer3.9.mblock.2.norm.weight",
      "layer3.9.mblock.2.norm.bias",
      "layer3.10.sblock_in.norm.weight",
      "layer3.10.sblock_in.norm.bias",
      "layer3.10.sblock_dw.norm.weight",
      "layer3.10.sblock_dw.norm.bias",
      "layer3.10.sblock_proj.norm.weight",
      "layer3.10.sblock_proj.norm.bias",
      "layer3.10.mblock.0.norm.weight",
      "layer3.10.mblock.0.norm.bias",
      "layer3.10.mblock.1.branch_1.1.norm.weight",
      "layer3.10.mblock.1.branch_1.1.norm.bias",
      "layer3.10.mblock.1.branch_2.1.norm.weight",
      "layer3.10.mblock.1.branch_2.1.norm.bias",
      "layer3.10.mblock.1.branch_3.1.norm.weight",
      "layer3.10.mblock.1.branch_3.1.norm.bias",
      "layer3.10.mblock.2.norm.weight",
      "layer3.10.mblock.2.norm.bias",
      "layer3.11.sblock_in.norm.weight",
      "layer3.11.sblock_in.norm.bias",
      "layer3.11.sblock_dw.norm.weight",
      "layer3.11.sblock_dw.norm.bias",
      "layer3.11.sblock_proj.norm.weight",
      "layer3.11.sblock_proj.norm.bias",
      "layer3.11.mblock.0.norm.weight",
      "layer3.11.mblock.0.norm.bias",
      "layer3.11.mblock.1.branch_1.1.norm.weight",
      "layer3.11.mblock.1.branch_1.1.norm.bias",
      "layer3.11.mblock.1.branch_2.1.norm.weight",
      "layer3.11.mblock.1.branch_2.1.norm.bias",
      "layer3.11.mblock.1.branch_3.1.norm.weight",
      "layer3.11.mblock.1.branch_3.1.norm.bias",
      "layer3.11.mblock.2.norm.weight",
      "layer3.11.mblock.2.norm.bias",
      "layer3.12.sblock_in.norm.weight",
      "layer3.12.sblock_in.norm.bias",
      "layer3.12.sblock_dw.norm.weight",
      "layer3.12.sblock_dw.norm.bias",
      "layer3.12.sblock_proj.norm.weight",
      "layer3.12.sblock_proj.norm.bias",
      "layer3.12.mblock.0.norm.weight",
      "layer3.12.mblock.0.norm.bias",
      "layer3.12.mblock.1.branch_1.1.norm.weight",
      "layer3.12.mblock.1.branch_1.1.norm.bias",
      "layer3.12.mblock.1.branch_2.1.norm.weight",
      "layer3.12.mblock.1.branch_2.1.norm.bias",
      "layer3.12.mblock.1.branch_3.1.norm.weight",
      "layer3.12.mblock.1.branch_3.1.norm.bias",
      "layer3.12.mblock.2.norm.weight",
      "layer3.12.mblock.2.norm.bias",
      "layer3.13.sblock_in.norm.weight",
      "layer3.13.sblock_in.norm.bias",
      "layer3.13.sblock_dw.norm.weight",
      "layer3.13.sblock_dw.norm.bias",
      "layer3.13.sblock_proj.norm.weight",
      "layer3.13.sblock_proj.norm.bias",
      "layer3.13.mblock.0.norm.weight",
      "layer3.13.mblock.0.norm.bias",
      "layer3.13.mblock.1.branch_1.1.norm.weight",
      "layer3.13.mblock.1.branch_1.1.norm.bias",
      "layer3.13.mblock.1.branch_2.1.norm.weight",
      "layer3.13.mblock.1.branch_2.1.norm.bias",
      "layer3.13.mblock.1.branch_3.1.norm.weight",
      "layer3.13.mblock.1.branch_3.1.norm.bias",
      "layer3.13.mblock.2.norm.weight",
      "layer3.13.mblock.2.norm.bias",
      "layer3.14.sblock_in.norm.weight",
      "layer3.14.sblock_in.norm.bias",
      "layer3.14.sblock_dw.norm.weight",
      "layer3.14.sblock_dw.norm.bias",
      "layer3.14.sblock_proj.norm.weight",
      "layer3.14.sblock_proj.norm.bias",
      "layer3.14.mblock.0.norm.weight",
      "layer3.14.mblock.0.norm.bias",
      "layer3.14.mblock.1.branch_1.1.norm.weight",
      "layer3.14.mblock.1.branch_1.1.norm.bias",
      "layer3.14.mblock.1.branch_2.1.norm.weight",
      "layer3.14.mblock.1.branch_2.1.norm.bias",
      "layer3.14.mblock.1.branch_3.1.norm.weight",
      "layer3.14.mblock.1.branch_3.1.norm.bias",
      "layer3.14.mblock.2.norm.weight",
      "layer3.14.mblock.2.norm.bias",
      "layer3.15.sblock_in.norm.weight",
      "layer3.15.sblock_in.norm.bias",
      "layer3.15.sblock_dw.norm.weight",
      "layer3.15.sblock_dw.norm.bias",
      "layer3.15.sblock_proj.norm.weight",
      "layer3.15.sblock_proj.norm.bias",
      "layer3.15.mblock.0.norm.weight",
      "layer3.15.mblock.0.norm.bias",
      "layer3.15.mblock.1.branch_1.1.norm.weight",
      "layer3.15.mblock.1.branch_1.1.norm.bias",
      "layer3.15.mblock.1.branch_2.1.norm.weight",
      "layer3.15.mblock.1.branch_2.1.norm.bias",
      "layer3.15.mblock.1.branch_3.1.norm.weight",
      "layer3.15.mblock.1.branch_3.1.norm.bias",
      "layer3.15.mblock.2.norm.weight",
      "layer3.15.mblock.2.norm.bias",
      "layer3.16.sblock_in.norm.weight",
      "layer3.16.sblock_in.norm.bias",
      "layer3.16.sblock_dw.norm.weight",
      "layer3.16.sblock_dw.norm.bias",
      "layer3.16.sblock_proj.norm.weight",
      "layer3.16.sblock_proj.norm.bias",
      "layer3.16.mblock.0.norm.weight",
      "layer3.16.mblock.0.norm.bias",
      "layer3.16.mblock.1.branch_1.1.norm.weight",
      "layer3.16.mblock.1.branch_1.1.norm.bias",
      "layer3.16.mblock.1.branch_2.1.norm.weight",
      "layer3.16.mblock.1.branch_2.1.norm.bias",
      "layer3.16.mblock.1.branch_3.1.norm.weight",
      "layer3.16.mblock.1.branch_3.1.norm.bias",
      "layer3.16.mblock.2.norm.weight",
      "layer3.16.mblock.2.norm.bias",
      "layer4.0.mlp.0.norm.weight",
      "layer4.0.mlp.0.norm.bias",
      "layer4.0.mlp.1.norm.weight",
      "layer4.0.mlp.1.norm.bias",
      "layer4.0.mlp.2.norm.weight",
      "layer4.0.mlp.2.norm.bias",
      "layer4.0.skip.0.norm.weight",
      "layer4.0.skip.0.norm.bias",
      "layer4.0.skip.1.norm.weight",
      "layer4.0.skip.1.norm.bias",
      "layer4.1.sblock_in.norm.weight",
      "layer4.1.sblock_in.norm.bias",
      "layer4.1.sblock_dw.norm.weight",
      "layer4.1.sblock_dw.norm.bias",
      "layer4.1.sblock_proj.norm.weight",
      "layer4.1.sblock_proj.norm.bias",
      "layer4.1.mblock.0.norm.weight",
      "layer4.1.mblock.0.norm.bias",
      "layer4.1.mblock.1.branch_1.1.norm.weight",
      "layer4.1.mblock.1.branch_1.1.norm.bias",
      "layer4.1.mblock.1.branch_2.1.norm.weight",
      "layer4.1.mblock.1.branch_2.1.norm.bias",
      "layer4.1.mblock.1.branch_3.1.norm.weight",
      "layer4.1.mblock.1.branch_3.1.norm.bias",
      "layer4.1.mblock.2.norm.weight",
      "layer4.1.mblock.2.norm.bias",
      "layer4.2.sblock_in.norm.weight",
      "layer4.2.sblock_in.norm.bias",
      "layer4.2.sblock_dw.norm.weight",
      "layer4.2.sblock_dw.norm.bias",
      "layer4.2.sblock_proj.norm.weight",
      "layer4.2.sblock_proj.norm.bias",
      "layer4.2.mblock.0.norm.weight",
      "layer4.2.mblock.0.norm.bias",
      "layer4.2.mblock.1.branch_1.1.norm.weight",
      "layer4.2.mblock.1.branch_1.1.norm.bias",
      "layer4.2.mblock.1.branch_2.1.norm.weight",
      "layer4.2.mblock.1.branch_2.1.norm.bias",
      "layer4.2.mblock.1.branch_3.1.norm.weight",
      "layer4.2.mblock.1.branch_3.1.norm.bias",
      "layer4.2.mblock.2.norm.weight",
      "layer4.2.mblock.2.norm.bias",
      "layer4.3.sblock_in.norm.weight",
      "layer4.3.sblock_in.norm.bias",
      "layer4.3.sblock_dw.norm.weight",
      "layer4.3.sblock_dw.norm.bias",
      "layer4.3.sblock_proj.norm.weight",
      "layer4.3.sblock_proj.norm.bias",
      "layer4.3.mblock.0.norm.weight",
      "layer4.3.mblock.0.norm.bias",
      "layer4.3.mblock.1.branch_1.1.norm.weight",
      "layer4.3.mblock.1.branch_1.1.norm.bias",
      "layer4.3.mblock.1.branch_2.1.norm.weight",
      "layer4.3.mblock.1.branch_2.1.norm.bias",
      "layer4.3.mblock.1.branch_3.1.norm.weight",
      "layer4.3.mblock.1.branch_3.1.norm.bias",
      "layer4.3.mblock.2.norm.weight",
      "layer4.3.mblock.2.norm.bias",
      "layer4.4.sblock_in.norm.weight",
      "layer4.4.sblock_in.norm.bias",
      "layer4.4.sblock_dw.norm.weight",
      "layer4.4.sblock_dw.norm.bias",
      "layer4.4.sblock_proj.norm.weight",
      "layer4.4.sblock_proj.norm.bias",
      "layer4.4.mblock.0.norm.weight",
      "layer4.4.mblock.0.norm.bias",
      "layer4.4.mblock.1.branch_1.1.norm.weight",
      "layer4.4.mblock.1.branch_1.1.norm.bias",
      "layer4.4.mblock.1.branch_2.1.norm.weight",
      "layer4.4.mblock.1.branch_2.1.norm.bias",
      "layer4.4.mblock.1.branch_3.1.norm.weight",
      "layer4.4.mblock.1.branch_3.1.norm.bias",
      "layer4.4.mblock.2.norm.weight",
      "layer4.4.mblock.2.norm.bias",
      "head.norm.weight",
      "head.norm.bias",
      "classifier.norm.weight",
      "classifier.norm.bias"
    ],
    "lr_scale": 1.0
  }
}
Use Cosine LR scheduler
Set warmup steps = 6240
Set warmup steps = 0
Max WD = 0.0500000, Min WD = 0.0500000
criterion = SoftTargetCrossEntropy()
Auto resume checkpoint: 
Start training for 300 epochs
Epoch: [0]  [   0/1251]  eta: 6:59:36  lr: 0.000000  min_lr: 0.000000  loss: 6.9863 (6.9863)  weight_decay: 0.0500 (0.0500)  time: 20.1254  data: 3.5054  max mem: 62457
Epoch: [0]  [ 200/1251]  eta: 0:16:06  lr: 0.000032  min_lr: 0.000032  loss: 6.9199 (6.9426)  weight_decay: 0.0500 (0.0500)  grad_norm: 11.8515 (nan)  time: 0.8222  data: 0.0004  max mem: 62457
Epoch: [0]  [ 400/1251]  eta: 0:12:22  lr: 0.000064  min_lr: 0.000064  loss: 6.8521 (6.9094)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.3130 (nan)  time: 0.8232  data: 0.0004  max mem: 62457
Epoch: [0]  [ 600/1251]  eta: 0:09:17  lr: 0.000096  min_lr: 0.000096  loss: 6.7589 (6.8657)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.1768 (nan)  time: 0.8240  data: 0.0006  max mem: 62457
Epoch: [0]  [ 800/1251]  eta: 0:06:22  lr: 0.000128  min_lr: 0.000128  loss: 6.6731 (6.8218)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.7071 (nan)  time: 0.8239  data: 0.0006  max mem: 62457
Epoch: [0]  [1000/1251]  eta: 0:03:31  lr: 0.000160  min_lr: 0.000160  loss: 6.6366 (6.7790)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.7145 (nan)  time: 0.8235  data: 0.0006  max mem: 62457
Epoch: [0]  [1200/1251]  eta: 0:00:42  lr: 0.000192  min_lr: 0.000192  loss: 6.5496 (6.7367)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.9430 (nan)  time: 0.8235  data: 0.0006  max mem: 62457
Epoch: [0]  [1250/1251]  eta: 0:00:00  lr: 0.000199  min_lr: 0.000199  loss: 6.3927 (6.7274)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.9430 (nan)  time: 0.6996  data: 0.0006  max mem: 62457
Epoch: [0] Total time: 0:17:28 (0.8382 s / it)
Averaged stats: lr: 0.000199  min_lr: 0.000199  loss: 6.3927 (6.7255)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.9430 (nan)
Test:  [ 0/25]  eta: 0:05:57  loss: 5.7085 (5.7085)  acc1: 2.8000 (2.8000)  acc5: 10.0000 (10.0000)  time: 14.3056  data: 8.8501  max mem: 62457
Test:  [10/25]  eta: 0:00:25  loss: 5.6049 (5.6201)  acc1: 2.8000 (2.9818)  acc5: 10.0000 (11.7818)  time: 1.7049  data: 0.8048  max mem: 62457
Test:  [20/25]  eta: 0:00:05  loss: 5.6936 (5.7002)  acc1: 3.6000 (3.4857)  acc5: 12.0000 (12.2286)  time: 0.4448  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 5.7527 (5.6530)  acc1: 4.0000 (4.2080)  acc5: 12.8000 (13.4720)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:25 (1.0028 s / it)
* Acc@1 3.722 Acc@5 13.046 loss 5.667
Accuracy of the model on the 50000 test images: 3.7%
Max accuracy: 3.72%
Epoch: [1]  [   0/1251]  eta: 1:34:22  lr: 0.000200  min_lr: 0.000200  loss: 6.5157 (6.5157)  weight_decay: 0.0500 (0.0500)  time: 4.5267  data: 3.7088  max mem: 62457
Epoch: [1]  [ 200/1251]  eta: 0:14:38  lr: 0.000232  min_lr: 0.000232  loss: 6.4534 (6.4507)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.7963 (3.9209)  time: 0.8164  data: 0.0004  max mem: 62457
Epoch: [1]  [ 400/1251]  eta: 0:11:43  lr: 0.000264  min_lr: 0.000264  loss: 6.4448 (6.4128)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.7698 (3.9015)  time: 0.8169  data: 0.0004  max mem: 62457
Epoch: [1]  [ 600/1251]  eta: 0:08:56  lr: 0.000296  min_lr: 0.000296  loss: 6.4139 (6.3875)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.2735 (3.7992)  time: 0.8169  data: 0.0005  max mem: 62457
Epoch: [1]  [ 800/1251]  eta: 0:06:10  lr: 0.000328  min_lr: 0.000328  loss: 6.2585 (6.3525)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.5207 (3.7680)  time: 0.8213  data: 0.0005  max mem: 62457
Epoch: [1]  [1000/1251]  eta: 0:03:26  lr: 0.000360  min_lr: 0.000360  loss: 5.9882 (6.3167)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.3308 (3.7253)  time: 0.8165  data: 0.0005  max mem: 62457
Epoch: [1]  [1200/1251]  eta: 0:00:41  lr: 0.000392  min_lr: 0.000392  loss: 5.9621 (6.2873)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0239 (3.6471)  time: 0.8164  data: 0.0005  max mem: 62457
Epoch: [1]  [1250/1251]  eta: 0:00:00  lr: 0.000399  min_lr: 0.000399  loss: 6.0105 (6.2765)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.1080 (3.6379)  time: 0.6923  data: 0.0006  max mem: 62457
Epoch: [1] Total time: 0:17:04 (0.8192 s / it)
Averaged stats: lr: 0.000399  min_lr: 0.000399  loss: 6.0105 (6.2709)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.1080 (3.6379)
Test:  [ 0/25]  eta: 0:03:30  loss: 4.5660 (4.5660)  acc1: 12.4000 (12.4000)  acc5: 35.2000 (35.2000)  time: 8.4084  data: 7.9447  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 4.3583 (4.4948)  acc1: 12.4000 (12.1818)  acc5: 30.4000 (31.0909)  time: 1.1690  data: 0.7225  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 4.7457 (4.6702)  acc1: 10.8000 (11.5238)  acc5: 29.2000 (29.7905)  time: 0.4446  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 4.7503 (4.6362)  acc1: 10.8000 (12.1440)  acc5: 30.4000 (31.0400)  time: 0.4441  data: 0.0001  max mem: 62457
Test: Total time: 0:00:19 (0.7686 s / it)
* Acc@1 12.590 Acc@5 31.452 loss 4.631
Accuracy of the model on the 50000 test images: 12.6%
Max accuracy: 12.59%
Epoch: [2]  [   0/1251]  eta: 1:17:44  lr: 0.000400  min_lr: 0.000400  loss: 6.2657 (6.2657)  weight_decay: 0.0500 (0.0500)  time: 3.7285  data: 2.9019  max mem: 62457
Epoch: [2]  [ 200/1251]  eta: 0:14:34  lr: 0.000432  min_lr: 0.000432  loss: 5.7921 (6.0506)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.2286 (3.4120)  time: 0.8157  data: 0.0005  max mem: 62457
Epoch: [2]  [ 400/1251]  eta: 0:11:41  lr: 0.000464  min_lr: 0.000464  loss: 5.7524 (6.0011)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0798 (3.4126)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [2]  [ 600/1251]  eta: 0:08:54  lr: 0.000496  min_lr: 0.000496  loss: 6.0152 (5.9472)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.4488 (3.4849)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [2]  [ 800/1251]  eta: 0:06:09  lr: 0.000528  min_lr: 0.000528  loss: 5.7995 (5.9231)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0287 (3.4455)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [2]  [1000/1251]  eta: 0:03:25  lr: 0.000560  min_lr: 0.000560  loss: 5.9717 (5.8945)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.2123 (3.4221)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [2]  [1200/1251]  eta: 0:00:41  lr: 0.000592  min_lr: 0.000592  loss: 5.8683 (5.8673)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0019 (3.3860)  time: 0.8203  data: 0.0004  max mem: 62457
Epoch: [2]  [1250/1251]  eta: 0:00:00  lr: 0.000599  min_lr: 0.000599  loss: 5.5235 (5.8555)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0389 (3.3711)  time: 0.6922  data: 0.0006  max mem: 62457
Epoch: [2] Total time: 0:17:02 (0.8174 s / it)
Averaged stats: lr: 0.000599  min_lr: 0.000599  loss: 5.5235 (5.8574)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0389 (3.3711)
Test:  [ 0/25]  eta: 0:03:16  loss: 3.4245 (3.4245)  acc1: 30.0000 (30.0000)  acc5: 56.0000 (56.0000)  time: 7.8589  data: 7.3704  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 3.4656 (3.6195)  acc1: 25.2000 (24.4364)  acc5: 54.8000 (51.3091)  time: 1.1195  data: 0.6704  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 3.9167 (3.8299)  acc1: 21.6000 (23.1048)  acc5: 46.0000 (47.8286)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 3.9167 (3.7993)  acc1: 22.4000 (24.0000)  acc5: 46.0000 (49.0400)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7472 s / it)
* Acc@1 23.768 Acc@5 49.060 loss 3.793
Accuracy of the model on the 50000 test images: 23.8%
Max accuracy: 23.77%
Epoch: [3]  [   0/1251]  eta: 1:18:19  lr: 0.000600  min_lr: 0.000600  loss: 6.1825 (6.1825)  weight_decay: 0.0500 (0.0500)  time: 3.7568  data: 2.9362  max mem: 62457
Epoch: [3]  [ 200/1251]  eta: 0:14:31  lr: 0.000632  min_lr: 0.000632  loss: 5.8031 (5.7070)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.1860 (3.2613)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [3]  [ 400/1251]  eta: 0:11:39  lr: 0.000664  min_lr: 0.000664  loss: 5.6084 (5.6173)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.7653 (3.0954)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [3]  [ 600/1251]  eta: 0:08:54  lr: 0.000696  min_lr: 0.000696  loss: 5.4939 (5.5959)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.8321 (3.1143)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [3]  [ 800/1251]  eta: 0:06:09  lr: 0.000728  min_lr: 0.000728  loss: 5.6370 (5.5862)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.7716 (3.0553)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [3]  [1000/1251]  eta: 0:03:25  lr: 0.000760  min_lr: 0.000760  loss: 5.5607 (5.5574)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.8299 (3.0075)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [3]  [1200/1251]  eta: 0:00:41  lr: 0.000792  min_lr: 0.000792  loss: 5.0898 (5.5199)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.6503 (3.0045)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [3]  [1250/1251]  eta: 0:00:00  lr: 0.000799  min_lr: 0.000799  loss: 5.7385 (5.5182)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.6952 (2.9950)  time: 0.6923  data: 0.0004  max mem: 62457
Epoch: [3] Total time: 0:17:02 (0.8171 s / it)
Averaged stats: lr: 0.000799  min_lr: 0.000799  loss: 5.7385 (5.5260)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.6952 (2.9950)
Test:  [ 0/25]  eta: 0:03:03  loss: 2.6722 (2.6722)  acc1: 50.0000 (50.0000)  acc5: 69.2000 (69.2000)  time: 7.3484  data: 6.8749  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 2.6722 (2.8197)  acc1: 42.4000 (38.0364)  acc5: 69.2000 (68.0364)  time: 1.0732  data: 0.6253  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 3.2713 (3.1383)  acc1: 30.4000 (33.7714)  acc5: 61.2000 (61.8286)  time: 0.4456  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 3.3804 (3.1256)  acc1: 30.8000 (34.5440)  acc5: 56.4000 (61.8720)  time: 0.4455  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7261 s / it)
* Acc@1 34.520 Acc@5 61.960 loss 3.130
Accuracy of the model on the 50000 test images: 34.5%
Max accuracy: 34.52%
Epoch: [4]  [   0/1251]  eta: 1:19:42  lr: 0.000800  min_lr: 0.000800  loss: 6.0120 (6.0120)  weight_decay: 0.0500 (0.0500)  time: 3.8233  data: 3.0028  max mem: 62457
Epoch: [4]  [ 200/1251]  eta: 0:14:31  lr: 0.000832  min_lr: 0.000832  loss: 5.2926 (5.3291)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2900 (2.4711)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [4]  [ 400/1251]  eta: 0:11:41  lr: 0.000864  min_lr: 0.000864  loss: 5.1372 (5.3289)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.6753 (2.6391)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [4]  [ 600/1251]  eta: 0:08:54  lr: 0.000896  min_lr: 0.000896  loss: 5.2925 (5.3197)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.3926 (2.6228)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [4]  [ 800/1251]  eta: 0:06:09  lr: 0.000928  min_lr: 0.000928  loss: 5.0928 (5.2767)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1036 (2.5415)  time: 0.8136  data: 0.0004  max mem: 62457
Epoch: [4]  [1000/1251]  eta: 0:03:25  lr: 0.000960  min_lr: 0.000960  loss: 5.1298 (5.2659)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2891 (2.5032)  time: 0.8145  data: 0.0005  max mem: 62457
Epoch: [4]  [1200/1251]  eta: 0:00:41  lr: 0.000992  min_lr: 0.000992  loss: 5.2880 (5.2546)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2574 (2.4789)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [4]  [1250/1251]  eta: 0:00:00  lr: 0.001000  min_lr: 0.001000  loss: 5.4897 (5.2532)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.6092 (2.4870)  time: 0.6916  data: 0.0005  max mem: 62457
Epoch: [4] Total time: 0:17:01 (0.8165 s / it)
Averaged stats: lr: 0.001000  min_lr: 0.001000  loss: 5.4897 (5.2635)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.6092 (2.4870)
Test:  [ 0/25]  eta: 0:03:22  loss: 2.3658 (2.3658)  acc1: 50.8000 (50.8000)  acc5: 78.4000 (78.4000)  time: 8.1134  data: 7.6400  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 2.3658 (2.4246)  acc1: 49.6000 (48.2909)  acc5: 79.2000 (77.6364)  time: 1.1418  data: 0.6948  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 2.8161 (2.7610)  acc1: 40.4000 (42.8000)  acc5: 68.0000 (70.6667)  time: 0.4446  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 2.9464 (2.7605)  acc1: 40.4000 (42.6880)  acc5: 65.2000 (70.3680)  time: 0.4446  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7562 s / it)
* Acc@1 42.786 Acc@5 69.920 loss 2.762
Accuracy of the model on the 50000 test images: 42.8%
Max accuracy: 42.79%
Epoch: [5]  [   0/1251]  eta: 1:19:48  lr: 0.001000  min_lr: 0.001000  loss: 5.3827 (5.3827)  weight_decay: 0.0500 (0.0500)  time: 3.8275  data: 3.0177  max mem: 62457
Epoch: [5]  [ 200/1251]  eta: 0:14:32  lr: 0.001032  min_lr: 0.001032  loss: 4.6620 (5.0934)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9765 (2.2447)  time: 0.8230  data: 0.0004  max mem: 62457
Epoch: [5]  [ 400/1251]  eta: 0:11:40  lr: 0.001064  min_lr: 0.001064  loss: 5.1714 (5.1004)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0595 (2.1766)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [5]  [ 600/1251]  eta: 0:08:54  lr: 0.001096  min_lr: 0.001096  loss: 5.4184 (5.0817)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9671 (2.1166)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [5]  [ 800/1251]  eta: 0:06:09  lr: 0.001128  min_lr: 0.001128  loss: 5.2725 (5.0684)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8063 (2.1044)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [5]  [1000/1251]  eta: 0:03:25  lr: 0.001160  min_lr: 0.001160  loss: 5.1620 (5.0605)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8759 (2.0984)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [5]  [1200/1251]  eta: 0:00:41  lr: 0.001192  min_lr: 0.001192  loss: 5.1873 (5.0424)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7792 (2.0742)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [5]  [1250/1251]  eta: 0:00:00  lr: 0.001200  min_lr: 0.001200  loss: 5.1985 (5.0398)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6712 (2.0629)  time: 0.6917  data: 0.0005  max mem: 62457
Epoch: [5] Total time: 0:17:01 (0.8164 s / it)
Averaged stats: lr: 0.001200  min_lr: 0.001200  loss: 5.1985 (5.0632)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6712 (2.0629)
Test:  [ 0/25]  eta: 0:03:09  loss: 2.0354 (2.0354)  acc1: 62.4000 (62.4000)  acc5: 82.4000 (82.4000)  time: 7.5824  data: 7.1038  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 2.0972 (2.1476)  acc1: 55.6000 (54.7273)  acc5: 82.8000 (81.7455)  time: 1.0938  data: 0.6461  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 2.5024 (2.4768)  acc1: 46.8000 (48.7238)  acc5: 73.6000 (75.2571)  time: 0.4448  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 2.6190 (2.4766)  acc1: 42.8000 (48.6240)  acc5: 69.2000 (74.8640)  time: 0.4447  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7345 s / it)
* Acc@1 48.422 Acc@5 74.906 loss 2.477
Accuracy of the model on the 50000 test images: 48.4%
Max accuracy: 48.42%
Epoch: [6]  [   0/1251]  eta: 1:35:09  lr: 0.001200  min_lr: 0.001200  loss: 5.3449 (5.3449)  weight_decay: 0.0500 (0.0500)  time: 4.5643  data: 3.7406  max mem: 62457
Epoch: [6]  [ 200/1251]  eta: 0:14:36  lr: 0.001232  min_lr: 0.001232  loss: 4.8938 (4.9089)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6275 (1.8367)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [6]  [ 400/1251]  eta: 0:11:42  lr: 0.001264  min_lr: 0.001264  loss: 4.7929 (4.8952)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9277 (1.8105)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [6]  [ 600/1251]  eta: 0:08:55  lr: 0.001296  min_lr: 0.001296  loss: 4.7982 (4.8777)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5418 (1.8147)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [6]  [ 800/1251]  eta: 0:06:10  lr: 0.001328  min_lr: 0.001328  loss: 4.7006 (4.8921)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6247 (1.7963)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [6]  [1000/1251]  eta: 0:03:25  lr: 0.001360  min_lr: 0.001360  loss: 4.8859 (4.8813)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5421 (1.7533)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [6]  [1200/1251]  eta: 0:00:41  lr: 0.001393  min_lr: 0.001393  loss: 4.6047 (4.8708)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5400 (1.7336)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [6]  [1250/1251]  eta: 0:00:00  lr: 0.001400  min_lr: 0.001400  loss: 5.0116 (4.8706)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5400 (1.7258)  time: 0.6923  data: 0.0006  max mem: 62457
Epoch: [6] Total time: 0:17:02 (0.8176 s / it)
Averaged stats: lr: 0.001400  min_lr: 0.001400  loss: 5.0116 (4.8773)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5400 (1.7258)
Test:  [ 0/25]  eta: 0:03:03  loss: 1.9616 (1.9616)  acc1: 60.4000 (60.4000)  acc5: 84.0000 (84.0000)  time: 7.3350  data: 6.8294  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.9201 (2.0288)  acc1: 60.4000 (57.8182)  acc5: 86.0000 (84.3273)  time: 1.0724  data: 0.6211  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 2.4419 (2.3129)  acc1: 49.6000 (52.4000)  acc5: 75.2000 (78.4571)  time: 0.4461  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 2.4540 (2.3197)  acc1: 48.4000 (52.1760)  acc5: 74.4000 (78.2240)  time: 0.4460  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7254 s / it)
* Acc@1 51.992 Acc@5 78.088 loss 2.318
Accuracy of the model on the 50000 test images: 52.0%
Max accuracy: 51.99%
Epoch: [7]  [   0/1251]  eta: 1:35:40  lr: 0.001400  min_lr: 0.001400  loss: 5.0286 (5.0286)  weight_decay: 0.0500 (0.0500)  time: 4.5889  data: 3.7676  max mem: 62457
Epoch: [7]  [ 200/1251]  eta: 0:14:36  lr: 0.001432  min_lr: 0.001432  loss: 4.5410 (4.7331)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6009 (1.5264)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [7]  [ 400/1251]  eta: 0:11:41  lr: 0.001464  min_lr: 0.001464  loss: 4.9445 (4.7874)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4589 (1.5151)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [7]  [ 600/1251]  eta: 0:08:54  lr: 0.001496  min_lr: 0.001496  loss: 4.8800 (4.7717)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3185 (1.5166)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [7]  [ 800/1251]  eta: 0:06:09  lr: 0.001528  min_lr: 0.001528  loss: 5.0064 (4.7674)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2555 (1.4788)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [7]  [1000/1251]  eta: 0:03:25  lr: 0.001561  min_lr: 0.001561  loss: 4.7178 (4.7723)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3406 (1.4751)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [7]  [1200/1251]  eta: 0:00:41  lr: 0.001593  min_lr: 0.001593  loss: 4.6628 (4.7631)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3216 (1.4822)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [7]  [1250/1251]  eta: 0:00:00  lr: 0.001600  min_lr: 0.001600  loss: 4.4203 (4.7548)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3388 (1.4746)  time: 0.6927  data: 0.0006  max mem: 62457
Epoch: [7] Total time: 0:17:02 (0.8171 s / it)
Averaged stats: lr: 0.001600  min_lr: 0.001600  loss: 4.4203 (4.7562)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3388 (1.4746)
Test:  [ 0/25]  eta: 0:03:17  loss: 1.6188 (1.6188)  acc1: 66.0000 (66.0000)  acc5: 88.8000 (88.8000)  time: 7.9029  data: 7.4159  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.6892 (1.7396)  acc1: 64.4000 (63.4182)  acc5: 88.8000 (87.2364)  time: 1.1237  data: 0.6745  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 2.1788 (2.0646)  acc1: 52.8000 (56.7238)  acc5: 77.6000 (81.2952)  time: 0.4456  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 2.2590 (2.0785)  acc1: 51.6000 (56.6240)  acc5: 76.4000 (80.7360)  time: 0.4455  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7483 s / it)
* Acc@1 56.014 Acc@5 80.746 loss 2.083
Accuracy of the model on the 50000 test images: 56.0%
Max accuracy: 56.01%
Epoch: [8]  [   0/1251]  eta: 1:26:22  lr: 0.001600  min_lr: 0.001600  loss: 5.0811 (5.0811)  weight_decay: 0.0500 (0.0500)  time: 4.1424  data: 3.3276  max mem: 62457
Epoch: [8]  [ 200/1251]  eta: 0:14:32  lr: 0.001632  min_lr: 0.001632  loss: 4.7706 (4.7246)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1946 (1.2864)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [8]  [ 400/1251]  eta: 0:11:40  lr: 0.001664  min_lr: 0.001664  loss: 4.9059 (4.6865)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2780 (1.3120)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [8]  [ 600/1251]  eta: 0:08:54  lr: 0.001696  min_lr: 0.001696  loss: 4.6549 (4.6595)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5378 (1.3367)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [8]  [ 800/1251]  eta: 0:06:09  lr: 0.001728  min_lr: 0.001728  loss: 4.6793 (4.6524)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2106 (1.3385)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [8]  [1000/1251]  eta: 0:03:25  lr: 0.001761  min_lr: 0.001761  loss: 4.7933 (4.6556)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2284 (1.3351)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [8]  [1200/1251]  eta: 0:00:41  lr: 0.001793  min_lr: 0.001793  loss: 4.5191 (4.6492)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2090 (1.3285)  time: 0.8139  data: 0.0005  max mem: 62457
Epoch: [8]  [1250/1251]  eta: 0:00:00  lr: 0.001800  min_lr: 0.001800  loss: 4.7240 (4.6472)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1555 (1.3206)  time: 0.6915  data: 0.0006  max mem: 62457
Epoch: [8] Total time: 0:17:01 (0.8161 s / it)
Averaged stats: lr: 0.001800  min_lr: 0.001800  loss: 4.7240 (4.6463)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1555 (1.3206)
Test:  [ 0/25]  eta: 0:03:05  loss: 1.7496 (1.7496)  acc1: 65.2000 (65.2000)  acc5: 87.6000 (87.6000)  time: 7.4117  data: 6.9334  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.7380 (1.8401)  acc1: 66.4000 (64.4364)  acc5: 89.6000 (87.8909)  time: 1.0779  data: 0.6306  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 2.1295 (2.0944)  acc1: 54.4000 (58.5714)  acc5: 80.8000 (82.6667)  time: 0.4445  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 2.1337 (2.0928)  acc1: 52.8000 (58.4480)  acc5: 78.8000 (82.3520)  time: 0.4444  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7272 s / it)
* Acc@1 58.474 Acc@5 82.706 loss 2.081
Accuracy of the model on the 50000 test images: 58.5%
Max accuracy: 58.47%
Epoch: [9]  [   0/1251]  eta: 1:33:36  lr: 0.001800  min_lr: 0.001800  loss: 4.1306 (4.1306)  weight_decay: 0.0500 (0.0500)  time: 4.4900  data: 3.6617  max mem: 62457
Epoch: [9]  [ 200/1251]  eta: 0:14:35  lr: 0.001832  min_lr: 0.001832  loss: 4.3565 (4.5393)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0617 (1.2416)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [9]  [ 400/1251]  eta: 0:11:41  lr: 0.001864  min_lr: 0.001864  loss: 4.7740 (4.5607)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1189 (1.2155)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [9]  [ 600/1251]  eta: 0:08:54  lr: 0.001896  min_lr: 0.001896  loss: 4.9200 (4.5729)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2886 (1.2353)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [9]  [ 800/1251]  eta: 0:06:09  lr: 0.001929  min_lr: 0.001929  loss: 4.2121 (4.5648)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2034 (1.2354)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [9]  [1000/1251]  eta: 0:03:25  lr: 0.001961  min_lr: 0.001961  loss: 4.3687 (4.5555)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1518 (1.2146)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [9]  [1200/1251]  eta: 0:00:41  lr: 0.001993  min_lr: 0.001993  loss: 4.7451 (4.5432)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1017 (1.2039)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [9]  [1250/1251]  eta: 0:00:00  lr: 0.002000  min_lr: 0.002000  loss: 4.6704 (4.5443)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0512 (1.1983)  time: 0.6920  data: 0.0005  max mem: 62457
Epoch: [9] Total time: 0:17:01 (0.8166 s / it)
Averaged stats: lr: 0.002000  min_lr: 0.002000  loss: 4.6704 (4.5456)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0512 (1.1983)
Test:  [ 0/25]  eta: 0:02:58  loss: 1.4425 (1.4425)  acc1: 70.4000 (70.4000)  acc5: 89.2000 (89.2000)  time: 7.1257  data: 6.6365  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 1.4913 (1.5762)  acc1: 70.4000 (67.4909)  acc5: 90.8000 (89.3818)  time: 1.0528  data: 0.6036  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.9591 (1.8822)  acc1: 59.2000 (61.2762)  acc5: 82.4000 (84.0000)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 2.0325 (1.8935)  acc1: 55.6000 (60.7200)  acc5: 79.2000 (83.7600)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7168 s / it)
* Acc@1 60.560 Acc@5 84.278 loss 1.889
Accuracy of the model on the 50000 test images: 60.6%
Max accuracy: 60.56%
Epoch: [10]  [   0/1251]  eta: 1:29:23  lr: 0.002000  min_lr: 0.002000  loss: 4.7128 (4.7128)  weight_decay: 0.0500 (0.0500)  time: 4.2877  data: 3.4755  max mem: 62457
Epoch: [10]  [ 200/1251]  eta: 0:14:36  lr: 0.002032  min_lr: 0.002032  loss: 4.5849 (4.5178)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1268 (1.1641)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [10]  [ 400/1251]  eta: 0:11:41  lr: 0.002064  min_lr: 0.002064  loss: 4.5134 (4.5086)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0113 (1.0910)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [10]  [ 600/1251]  eta: 0:08:54  lr: 0.002096  min_lr: 0.002096  loss: 4.5148 (4.5099)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0130 (1.0813)  time: 0.8241  data: 0.0004  max mem: 62457
Epoch: [10]  [ 800/1251]  eta: 0:06:09  lr: 0.002129  min_lr: 0.002129  loss: 4.1308 (4.4759)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0522 (1.0815)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [10]  [1000/1251]  eta: 0:03:25  lr: 0.002161  min_lr: 0.002161  loss: 4.4475 (4.4684)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0384 (1.0849)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [10]  [1200/1251]  eta: 0:00:41  lr: 0.002193  min_lr: 0.002193  loss: 3.8123 (4.4482)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1040 (1.0838)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [10]  [1250/1251]  eta: 0:00:00  lr: 0.002200  min_lr: 0.002200  loss: 4.3935 (4.4446)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9893 (1.0775)  time: 0.6919  data: 0.0004  max mem: 62457
Epoch: [10] Total time: 0:17:02 (0.8172 s / it)
Averaged stats: lr: 0.002200  min_lr: 0.002200  loss: 4.3935 (4.4696)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9893 (1.0775)
Test:  [ 0/25]  eta: 0:03:00  loss: 1.4387 (1.4387)  acc1: 74.8000 (74.8000)  acc5: 91.2000 (91.2000)  time: 7.2167  data: 6.7233  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 1.4805 (1.5721)  acc1: 69.6000 (68.8727)  acc5: 91.2000 (90.5818)  time: 1.0602  data: 0.6115  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.8912 (1.8388)  acc1: 58.8000 (62.6857)  acc5: 84.0000 (86.1714)  time: 0.4444  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.9106 (1.8550)  acc1: 58.0000 (62.3040)  acc5: 82.4000 (85.7760)  time: 0.4444  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7198 s / it)
* Acc@1 62.356 Acc@5 85.402 loss 1.852
Accuracy of the model on the 50000 test images: 62.4%
Max accuracy: 62.36%
Epoch: [11]  [   0/1251]  eta: 1:24:29  lr: 0.002200  min_lr: 0.002200  loss: 5.0030 (5.0030)  weight_decay: 0.0500 (0.0500)  time: 4.0525  data: 3.2256  max mem: 62457
Epoch: [11]  [ 200/1251]  eta: 0:14:32  lr: 0.002232  min_lr: 0.002232  loss: 4.7167 (4.4072)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8816 (1.0130)  time: 0.8137  data: 0.0004  max mem: 62457
Epoch: [11]  [ 400/1251]  eta: 0:11:39  lr: 0.002264  min_lr: 0.002264  loss: 4.3822 (4.4200)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8904 (0.9838)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [11]  [ 600/1251]  eta: 0:08:54  lr: 0.002297  min_lr: 0.002297  loss: 4.5370 (4.3961)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8840 (0.9921)  time: 0.8149  data: 0.0005  max mem: 62457
Epoch: [11]  [ 800/1251]  eta: 0:06:09  lr: 0.002329  min_lr: 0.002329  loss: 4.6934 (4.3990)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9210 (0.9727)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [11]  [1000/1251]  eta: 0:03:25  lr: 0.002361  min_lr: 0.002361  loss: 4.5226 (4.4065)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7744 (0.9510)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [11]  [1200/1251]  eta: 0:00:41  lr: 0.002393  min_lr: 0.002393  loss: 4.7501 (4.4028)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9273 (0.9496)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [11]  [1250/1251]  eta: 0:00:00  lr: 0.002400  min_lr: 0.002400  loss: 4.5030 (4.4017)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9322 (0.9506)  time: 0.6917  data: 0.0005  max mem: 62457
Epoch: [11] Total time: 0:17:01 (0.8163 s / it)
Averaged stats: lr: 0.002400  min_lr: 0.002400  loss: 4.5030 (4.3825)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9322 (0.9506)
Test:  [ 0/25]  eta: 0:03:23  loss: 1.4282 (1.4282)  acc1: 75.6000 (75.6000)  acc5: 91.6000 (91.6000)  time: 8.1340  data: 7.6512  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 1.4968 (1.5495)  acc1: 72.0000 (69.8909)  acc5: 92.0000 (91.0909)  time: 1.1444  data: 0.6958  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.8469 (1.8124)  acc1: 61.2000 (64.3429)  acc5: 84.8000 (86.3619)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.9981 (1.8177)  acc1: 60.0000 (64.0960)  acc5: 82.4000 (86.2720)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7566 s / it)
* Acc@1 63.720 Acc@5 86.310 loss 1.815
Accuracy of the model on the 50000 test images: 63.7%
Max accuracy: 63.72%
Epoch: [12]  [   0/1251]  eta: 1:20:18  lr: 0.002400  min_lr: 0.002400  loss: 3.8315 (3.8315)  weight_decay: 0.0500 (0.0500)  time: 3.8514  data: 3.0379  max mem: 62457
Epoch: [12]  [ 200/1251]  eta: 0:14:32  lr: 0.002432  min_lr: 0.002432  loss: 4.2429 (4.3586)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7853 (0.8885)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [12]  [ 400/1251]  eta: 0:11:40  lr: 0.002464  min_lr: 0.002464  loss: 4.0983 (4.3238)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8909 (0.8899)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [12]  [ 600/1251]  eta: 0:08:53  lr: 0.002497  min_lr: 0.002497  loss: 4.3020 (4.3284)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8806 (0.8963)  time: 0.8189  data: 0.0004  max mem: 62457
Epoch: [12]  [ 800/1251]  eta: 0:06:09  lr: 0.002529  min_lr: 0.002529  loss: 4.3830 (4.3363)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8367 (0.9047)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [12]  [1000/1251]  eta: 0:03:25  lr: 0.002561  min_lr: 0.002561  loss: 4.3672 (4.3344)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7827 (0.9010)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [12]  [1200/1251]  eta: 0:00:41  lr: 0.002593  min_lr: 0.002593  loss: 4.8670 (4.3310)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7659 (0.8831)  time: 0.8137  data: 0.0004  max mem: 62457
Epoch: [12]  [1250/1251]  eta: 0:00:00  lr: 0.002600  min_lr: 0.002600  loss: 4.5553 (4.3338)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7931 (0.8829)  time: 0.6912  data: 0.0005  max mem: 62457
Epoch: [12] Total time: 0:17:01 (0.8162 s / it)
Averaged stats: lr: 0.002600  min_lr: 0.002600  loss: 4.5553 (4.3256)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7931 (0.8829)
Test:  [ 0/25]  eta: 0:03:08  loss: 1.2891 (1.2891)  acc1: 75.6000 (75.6000)  acc5: 94.4000 (94.4000)  time: 7.5436  data: 7.0720  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.4772 (1.5055)  acc1: 72.8000 (71.3455)  acc5: 92.4000 (91.7091)  time: 1.0906  data: 0.6432  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.8034 (1.8087)  acc1: 62.8000 (66.2095)  acc5: 87.2000 (87.4095)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 2.0130 (1.8256)  acc1: 63.6000 (65.8400)  acc5: 84.0000 (87.1040)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7345 s / it)
* Acc@1 65.108 Acc@5 86.970 loss 1.833
Accuracy of the model on the 50000 test images: 65.1%
Max accuracy: 65.11%
Epoch: [13]  [   0/1251]  eta: 1:28:54  lr: 0.002600  min_lr: 0.002600  loss: 4.8288 (4.8288)  weight_decay: 0.0500 (0.0500)  time: 4.2642  data: 3.4517  max mem: 62457
Epoch: [13]  [ 200/1251]  eta: 0:14:35  lr: 0.002632  min_lr: 0.002632  loss: 4.4445 (4.3348)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7290 (0.8315)  time: 0.8222  data: 0.0004  max mem: 62457
Epoch: [13]  [ 400/1251]  eta: 0:11:41  lr: 0.002665  min_lr: 0.002665  loss: 4.4565 (4.3005)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7721 (0.8345)  time: 0.8137  data: 0.0004  max mem: 62457
Epoch: [13]  [ 600/1251]  eta: 0:08:54  lr: 0.002697  min_lr: 0.002697  loss: 4.6477 (4.2822)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8082 (0.8068)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [13]  [ 800/1251]  eta: 0:06:09  lr: 0.002729  min_lr: 0.002729  loss: 4.3920 (4.2747)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7102 (0.7878)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [13]  [1000/1251]  eta: 0:03:25  lr: 0.002761  min_lr: 0.002761  loss: 4.4154 (4.2605)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8381 (0.7883)  time: 0.8136  data: 0.0004  max mem: 62457
Epoch: [13]  [1200/1251]  eta: 0:00:41  lr: 0.002793  min_lr: 0.002793  loss: 3.8829 (4.2550)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7765 (0.7865)  time: 0.8132  data: 0.0004  max mem: 62457
Epoch: [13]  [1250/1251]  eta: 0:00:00  lr: 0.002800  min_lr: 0.002800  loss: 4.3370 (4.2585)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7713 (0.7855)  time: 0.6909  data: 0.0006  max mem: 62457
Epoch: [13] Total time: 0:17:00 (0.8160 s / it)
Averaged stats: lr: 0.002800  min_lr: 0.002800  loss: 4.3370 (4.2643)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7713 (0.7855)
Test:  [ 0/25]  eta: 0:03:09  loss: 1.4170 (1.4170)  acc1: 74.8000 (74.8000)  acc5: 92.4000 (92.4000)  time: 7.5664  data: 7.0852  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.4170 (1.5165)  acc1: 72.0000 (71.8545)  acc5: 92.8000 (92.3636)  time: 1.0923  data: 0.6444  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.7967 (1.8105)  acc1: 62.0000 (65.9048)  acc5: 87.2000 (88.0191)  time: 0.4448  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 2.0539 (1.8258)  acc1: 63.6000 (65.9200)  acc5: 85.2000 (87.8560)  time: 0.4447  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7354 s / it)
* Acc@1 65.256 Acc@5 87.622 loss 1.830
Accuracy of the model on the 50000 test images: 65.3%
Max accuracy: 65.26%
Epoch: [14]  [   0/1251]  eta: 1:20:40  lr: 0.002800  min_lr: 0.002800  loss: 4.8972 (4.8972)  weight_decay: 0.0500 (0.0500)  time: 3.8690  data: 3.0441  max mem: 62457
Epoch: [14]  [ 200/1251]  eta: 0:14:33  lr: 0.002833  min_lr: 0.002833  loss: 4.5333 (4.2105)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8158 (0.7815)  time: 0.8136  data: 0.0004  max mem: 62457
Epoch: [14]  [ 400/1251]  eta: 0:11:40  lr: 0.002865  min_lr: 0.002865  loss: 4.0101 (4.1932)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7290 (0.7910)  time: 0.8138  data: 0.0005  max mem: 62457
Epoch: [14]  [ 600/1251]  eta: 0:08:54  lr: 0.002897  min_lr: 0.002897  loss: 4.5908 (4.1777)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6842 (0.7715)  time: 0.8270  data: 0.0004  max mem: 62457
Epoch: [14]  [ 800/1251]  eta: 0:06:09  lr: 0.002929  min_lr: 0.002929  loss: 4.3724 (4.1761)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6877 (0.7580)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [14]  [1000/1251]  eta: 0:03:25  lr: 0.002961  min_lr: 0.002961  loss: 4.2315 (4.1950)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6513 (0.7455)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [14]  [1200/1251]  eta: 0:00:41  lr: 0.002993  min_lr: 0.002993  loss: 4.4329 (4.1947)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6894 (0.7411)  time: 0.8148  data: 0.0005  max mem: 62457
Epoch: [14]  [1250/1251]  eta: 0:00:00  lr: 0.003000  min_lr: 0.003000  loss: 3.9572 (4.1932)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6894 (0.7409)  time: 0.6919  data: 0.0006  max mem: 62457
Epoch: [14] Total time: 0:17:01 (0.8163 s / it)
Averaged stats: lr: 0.003000  min_lr: 0.003000  loss: 3.9572 (4.2295)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6894 (0.7409)
Test:  [ 0/25]  eta: 0:03:09  loss: 1.1087 (1.1087)  acc1: 78.8000 (78.8000)  acc5: 94.0000 (94.0000)  time: 7.5678  data: 7.0764  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.2451 (1.3180)  acc1: 75.2000 (73.0909)  acc5: 93.2000 (92.3636)  time: 1.0931  data: 0.6436  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.7217 (1.5689)  acc1: 63.2000 (67.8095)  acc5: 87.6000 (88.4191)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.7561 (1.5858)  acc1: 63.2000 (67.2960)  acc5: 85.2000 (88.0320)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7348 s / it)
* Acc@1 67.156 Acc@5 88.364 loss 1.589
Accuracy of the model on the 50000 test images: 67.2%
Max accuracy: 67.16%
Epoch: [15]  [   0/1251]  eta: 1:32:11  lr: 0.003000  min_lr: 0.003000  loss: 4.1614 (4.1614)  weight_decay: 0.0500 (0.0500)  time: 4.4220  data: 3.5958  max mem: 62457
Epoch: [15]  [ 200/1251]  eta: 0:14:34  lr: 0.003033  min_lr: 0.003033  loss: 4.5283 (4.2251)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7198 (0.7543)  time: 0.8143  data: 0.0005  max mem: 62457
Epoch: [15]  [ 400/1251]  eta: 0:11:40  lr: 0.003065  min_lr: 0.003065  loss: 4.2383 (4.1911)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6842 (0.7154)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [15]  [ 600/1251]  eta: 0:08:54  lr: 0.003097  min_lr: 0.003097  loss: 4.0110 (4.1896)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6966 (0.7141)  time: 0.8133  data: 0.0004  max mem: 62457
Epoch: [15]  [ 800/1251]  eta: 0:06:09  lr: 0.003129  min_lr: 0.003129  loss: 4.3192 (4.1931)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7193 (0.7104)  time: 0.8137  data: 0.0005  max mem: 62457
Epoch: [15]  [1000/1251]  eta: 0:03:25  lr: 0.003161  min_lr: 0.003161  loss: 4.3862 (4.1878)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6071 (0.7026)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [15]  [1200/1251]  eta: 0:00:41  lr: 0.003193  min_lr: 0.003193  loss: 4.0976 (4.1836)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7407 (0.7046)  time: 0.8135  data: 0.0004  max mem: 62457
Epoch: [15]  [1250/1251]  eta: 0:00:00  lr: 0.003200  min_lr: 0.003200  loss: 4.3463 (4.1792)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6654 (0.7028)  time: 0.6911  data: 0.0005  max mem: 62457
Epoch: [15] Total time: 0:17:01 (0.8163 s / it)
Averaged stats: lr: 0.003200  min_lr: 0.003200  loss: 4.3463 (4.1828)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6654 (0.7028)
Test:  [ 0/25]  eta: 0:03:06  loss: 1.2110 (1.2110)  acc1: 78.8000 (78.8000)  acc5: 94.0000 (94.0000)  time: 7.4673  data: 6.9909  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.2366 (1.3298)  acc1: 76.8000 (73.4182)  acc5: 93.2000 (92.5455)  time: 1.0835  data: 0.6358  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.6731 (1.5820)  acc1: 64.4000 (68.1714)  acc5: 86.8000 (88.7429)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.7653 (1.5957)  acc1: 64.4000 (68.0320)  acc5: 86.4000 (88.6400)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7301 s / it)
* Acc@1 67.990 Acc@5 88.738 loss 1.594
Accuracy of the model on the 50000 test images: 68.0%
Max accuracy: 67.99%
Epoch: [16]  [   0/1251]  eta: 1:21:51  lr: 0.003201  min_lr: 0.003201  loss: 4.3187 (4.3187)  weight_decay: 0.0500 (0.0500)  time: 3.9264  data: 3.1117  max mem: 62457
Epoch: [16]  [ 200/1251]  eta: 0:14:31  lr: 0.003233  min_lr: 0.003233  loss: 4.0030 (4.1794)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7315 (0.6744)  time: 0.8135  data: 0.0004  max mem: 62457
Epoch: [16]  [ 400/1251]  eta: 0:11:40  lr: 0.003265  min_lr: 0.003265  loss: 4.0911 (4.1767)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6643 (0.6705)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [16]  [ 600/1251]  eta: 0:08:53  lr: 0.003297  min_lr: 0.003297  loss: 4.3149 (4.1833)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6845 (0.6852)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [16]  [ 800/1251]  eta: 0:06:09  lr: 0.003329  min_lr: 0.003329  loss: 4.1230 (4.1707)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5987 (0.6804)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [16]  [1000/1251]  eta: 0:03:25  lr: 0.003361  min_lr: 0.003361  loss: 4.2675 (4.1626)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6001 (0.6726)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [16]  [1200/1251]  eta: 0:00:41  lr: 0.003393  min_lr: 0.003393  loss: 4.3830 (4.1540)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7085 (0.6689)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [16]  [1250/1251]  eta: 0:00:00  lr: 0.003400  min_lr: 0.003400  loss: 4.2125 (4.1536)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6117 (0.6666)  time: 0.6910  data: 0.0005  max mem: 62457
Epoch: [16] Total time: 0:17:01 (0.8164 s / it)
Averaged stats: lr: 0.003400  min_lr: 0.003400  loss: 4.2125 (4.1502)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6117 (0.6666)
Test:  [ 0/25]  eta: 0:03:08  loss: 1.1045 (1.1045)  acc1: 79.6000 (79.6000)  acc5: 95.6000 (95.6000)  time: 7.5599  data: 7.0789  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.1974 (1.2704)  acc1: 74.8000 (73.4545)  acc5: 94.0000 (93.2000)  time: 1.0916  data: 0.6438  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.5849 (1.5276)  acc1: 64.8000 (68.5524)  acc5: 89.6000 (89.4476)  time: 0.4447  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.7033 (1.5381)  acc1: 65.6000 (68.4960)  acc5: 86.4000 (89.1360)  time: 0.4447  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7335 s / it)
* Acc@1 68.222 Acc@5 89.134 loss 1.537
Accuracy of the model on the 50000 test images: 68.2%
Max accuracy: 68.22%
Epoch: [17]  [   0/1251]  eta: 1:28:43  lr: 0.003401  min_lr: 0.003401  loss: 4.3566 (4.3566)  weight_decay: 0.0500 (0.0500)  time: 4.2553  data: 3.4420  max mem: 62457
Epoch: [17]  [ 200/1251]  eta: 0:14:37  lr: 0.003433  min_lr: 0.003433  loss: 4.2876 (4.1131)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6411 (0.6901)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [17]  [ 400/1251]  eta: 0:11:41  lr: 0.003465  min_lr: 0.003465  loss: 4.4324 (4.1181)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6675 (0.6694)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [17]  [ 600/1251]  eta: 0:08:54  lr: 0.003497  min_lr: 0.003497  loss: 4.0875 (4.1016)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5888 (0.6452)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [17]  [ 800/1251]  eta: 0:06:09  lr: 0.003529  min_lr: 0.003529  loss: 3.6515 (4.0980)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5995 (0.6566)  time: 0.8190  data: 0.0004  max mem: 62457
Epoch: [17]  [1000/1251]  eta: 0:03:25  lr: 0.003561  min_lr: 0.003561  loss: 4.1374 (4.0804)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6064 (0.6492)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [17]  [1200/1251]  eta: 0:00:41  lr: 0.003593  min_lr: 0.003593  loss: 4.2118 (4.0887)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6035 (0.6429)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [17]  [1250/1251]  eta: 0:00:00  lr: 0.003600  min_lr: 0.003600  loss: 4.0114 (4.0846)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5589 (0.6404)  time: 0.6944  data: 0.0005  max mem: 62457
Epoch: [17] Total time: 0:17:01 (0.8167 s / it)
Averaged stats: lr: 0.003600  min_lr: 0.003600  loss: 4.0114 (4.1083)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5589 (0.6404)
Test:  [ 0/25]  eta: 0:03:13  loss: 1.0817 (1.0817)  acc1: 79.2000 (79.2000)  acc5: 93.6000 (93.6000)  time: 7.7451  data: 7.2677  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.2381 (1.3059)  acc1: 75.6000 (74.2545)  acc5: 93.6000 (93.0546)  time: 1.1089  data: 0.6610  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.6740 (1.5504)  acc1: 66.4000 (69.6381)  acc5: 87.6000 (89.3143)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.6853 (1.5587)  acc1: 66.4000 (69.0400)  acc5: 87.6000 (89.3280)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7417 s / it)
* Acc@1 69.000 Acc@5 89.466 loss 1.565
Accuracy of the model on the 50000 test images: 69.0%
Max accuracy: 69.00%
Epoch: [18]  [   0/1251]  eta: 1:24:06  lr: 0.003601  min_lr: 0.003601  loss: 4.3841 (4.3841)  weight_decay: 0.0500 (0.0500)  time: 4.0343  data: 3.2063  max mem: 62457
Epoch: [18]  [ 200/1251]  eta: 0:14:33  lr: 0.003633  min_lr: 0.003633  loss: 4.3541 (4.0734)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5618 (0.6156)  time: 0.8133  data: 0.0004  max mem: 62457
Epoch: [18]  [ 400/1251]  eta: 0:11:39  lr: 0.003665  min_lr: 0.003665  loss: 4.2541 (4.0411)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5988 (0.6173)  time: 0.8134  data: 0.0004  max mem: 62457
Epoch: [18]  [ 600/1251]  eta: 0:08:53  lr: 0.003697  min_lr: 0.003697  loss: 4.0748 (4.0546)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5680 (0.6090)  time: 0.8185  data: 0.0005  max mem: 62457
Epoch: [18]  [ 800/1251]  eta: 0:06:09  lr: 0.003729  min_lr: 0.003729  loss: 4.3134 (4.0791)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5086 (0.5989)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [18]  [1000/1251]  eta: 0:03:25  lr: 0.003761  min_lr: 0.003761  loss: 4.4983 (4.0805)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5599 (0.6087)  time: 0.8132  data: 0.0004  max mem: 62457
Epoch: [18]  [1200/1251]  eta: 0:00:41  lr: 0.003793  min_lr: 0.003793  loss: 4.2504 (4.0979)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5835 (0.6168)  time: 0.8133  data: 0.0005  max mem: 62457
Epoch: [18]  [1250/1251]  eta: 0:00:00  lr: 0.003800  min_lr: 0.003800  loss: 4.0186 (4.0925)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6690 (0.6180)  time: 0.6910  data: 0.0006  max mem: 62457
Epoch: [18] Total time: 0:17:00 (0.8158 s / it)
Averaged stats: lr: 0.003800  min_lr: 0.003800  loss: 4.0186 (4.0873)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6690 (0.6180)
Test:  [ 0/25]  eta: 0:03:18  loss: 1.0570 (1.0570)  acc1: 81.6000 (81.6000)  acc5: 94.8000 (94.8000)  time: 7.9547  data: 7.4940  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.1675 (1.2512)  acc1: 74.4000 (74.9455)  acc5: 94.4000 (93.1636)  time: 1.1300  data: 0.6815  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.6211 (1.5051)  acc1: 67.2000 (69.6381)  acc5: 87.6000 (89.6762)  time: 0.4464  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.6211 (1.5117)  acc1: 67.2000 (69.5040)  acc5: 86.8000 (89.5360)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7513 s / it)
* Acc@1 69.164 Acc@5 89.676 loss 1.516
Accuracy of the model on the 50000 test images: 69.2%
Max accuracy: 69.16%
Epoch: [19]  [   0/1251]  eta: 1:25:51  lr: 0.003801  min_lr: 0.003801  loss: 3.2257 (3.2257)  weight_decay: 0.0500 (0.0500)  time: 4.1182  data: 3.2876  max mem: 62457
Epoch: [19]  [ 200/1251]  eta: 0:14:33  lr: 0.003833  min_lr: 0.003833  loss: 4.3158 (4.0287)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5559 (0.5393)  time: 0.8198  data: 0.0004  max mem: 62457
Epoch: [19]  [ 400/1251]  eta: 0:11:39  lr: 0.003865  min_lr: 0.003865  loss: 4.1470 (4.0413)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6319 (0.5599)  time: 0.8199  data: 0.0004  max mem: 62457
Epoch: [19]  [ 600/1251]  eta: 0:08:53  lr: 0.003897  min_lr: 0.003897  loss: 4.4146 (4.0687)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5806 (0.5690)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [19]  [ 800/1251]  eta: 0:06:09  lr: 0.003929  min_lr: 0.003929  loss: 4.0084 (4.0647)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5320 (0.5793)  time: 0.8130  data: 0.0004  max mem: 62457
Epoch: [19]  [1000/1251]  eta: 0:03:25  lr: 0.003961  min_lr: 0.003961  loss: 3.9789 (4.0572)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5510 (0.5820)  time: 0.8131  data: 0.0004  max mem: 62457
Epoch: [19]  [1200/1251]  eta: 0:00:41  lr: 0.003993  min_lr: 0.003993  loss: 4.1202 (4.0560)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6044 (0.5797)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [19]  [1250/1251]  eta: 0:00:00  lr: 0.004000  min_lr: 0.004000  loss: 4.1895 (4.0562)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5769 (0.5829)  time: 0.6914  data: 0.0005  max mem: 62457
Epoch: [19] Total time: 0:17:00 (0.8157 s / it)
Averaged stats: lr: 0.004000  min_lr: 0.004000  loss: 4.1895 (4.0446)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5769 (0.5829)
Test:  [ 0/25]  eta: 0:02:47  loss: 0.9546 (0.9546)  acc1: 82.0000 (82.0000)  acc5: 96.0000 (96.0000)  time: 6.6975  data: 6.2138  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 1.1721 (1.2217)  acc1: 77.2000 (75.6364)  acc5: 94.8000 (93.6364)  time: 1.0140  data: 0.5652  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.5000 (1.4625)  acc1: 66.8000 (70.1714)  acc5: 88.0000 (90.1143)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.6326 (1.4775)  acc1: 66.4000 (69.7440)  acc5: 86.8000 (89.8400)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7001 s / it)
* Acc@1 69.588 Acc@5 90.054 loss 1.484
Accuracy of the model on the 50000 test images: 69.6%
Max accuracy: 69.59%
Epoch: [20]  [   0/1251]  eta: 1:30:51  lr: 0.004000  min_lr: 0.004000  loss: 3.1375 (3.1375)  weight_decay: 0.0500 (0.0500)  time: 4.3580  data: 3.5469  max mem: 62457
Epoch: [20]  [ 200/1251]  eta: 0:14:33  lr: 0.004000  min_lr: 0.004000  loss: 4.0281 (4.0575)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6150 (0.6017)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [20]  [ 400/1251]  eta: 0:11:40  lr: 0.004000  min_lr: 0.004000  loss: 3.8449 (4.0144)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5643 (0.5846)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [20]  [ 600/1251]  eta: 0:08:54  lr: 0.004000  min_lr: 0.004000  loss: 4.3186 (4.0299)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5744 (0.5922)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [20]  [ 800/1251]  eta: 0:06:09  lr: 0.004000  min_lr: 0.004000  loss: 3.9353 (4.0395)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5018 (0.5784)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [20]  [1000/1251]  eta: 0:03:25  lr: 0.004000  min_lr: 0.004000  loss: 3.8979 (4.0204)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5799 (0.5850)  time: 0.8137  data: 0.0004  max mem: 62457
Epoch: [20]  [1200/1251]  eta: 0:00:41  lr: 0.004000  min_lr: 0.004000  loss: 3.8154 (4.0244)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4955 (0.5732)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [20]  [1250/1251]  eta: 0:00:00  lr: 0.004000  min_lr: 0.004000  loss: 3.4500 (4.0165)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4910 (0.5713)  time: 0.6915  data: 0.0005  max mem: 62457
Epoch: [20] Total time: 0:17:01 (0.8163 s / it)
Averaged stats: lr: 0.004000  min_lr: 0.004000  loss: 3.4500 (4.0211)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4910 (0.5713)
Test:  [ 0/25]  eta: 0:03:09  loss: 1.0163 (1.0163)  acc1: 81.2000 (81.2000)  acc5: 94.4000 (94.4000)  time: 7.5842  data: 7.1188  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.0745 (1.1848)  acc1: 78.0000 (75.0545)  acc5: 94.4000 (94.2182)  time: 1.0946  data: 0.6474  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.4558 (1.4160)  acc1: 66.0000 (69.9810)  acc5: 90.8000 (90.5333)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.5801 (1.4326)  acc1: 66.4000 (69.9040)  acc5: 88.0000 (90.3360)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7357 s / it)
* Acc@1 70.162 Acc@5 90.298 loss 1.425
Accuracy of the model on the 50000 test images: 70.2%
Max accuracy: 70.16%
Epoch: [21]  [   0/1251]  eta: 1:25:56  lr: 0.004000  min_lr: 0.004000  loss: 4.4598 (4.4598)  weight_decay: 0.0500 (0.0500)  time: 4.1220  data: 3.3154  max mem: 62457
Epoch: [21]  [ 200/1251]  eta: 0:14:36  lr: 0.004000  min_lr: 0.004000  loss: 4.0290 (3.9817)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5506 (0.5761)  time: 0.8206  data: 0.0004  max mem: 62457
Epoch: [21]  [ 400/1251]  eta: 0:11:41  lr: 0.004000  min_lr: 0.004000  loss: 3.7003 (4.0048)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5339 (0.5706)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [21]  [ 600/1251]  eta: 0:08:54  lr: 0.004000  min_lr: 0.004000  loss: 4.2238 (4.0081)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5178 (0.5685)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [21]  [ 800/1251]  eta: 0:06:09  lr: 0.004000  min_lr: 0.004000  loss: 4.0839 (4.0018)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4687 (0.5599)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [21]  [1000/1251]  eta: 0:03:25  lr: 0.004000  min_lr: 0.004000  loss: 3.6487 (3.9834)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [21]  [1200/1251]  eta: 0:00:41  lr: 0.004000  min_lr: 0.004000  loss: 3.9780 (3.9872)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5244 (nan)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [21]  [1250/1251]  eta: 0:00:00  lr: 0.003999  min_lr: 0.003999  loss: 4.0201 (3.9905)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5846 (nan)  time: 0.6950  data: 0.0006  max mem: 62457
Epoch: [21] Total time: 0:17:01 (0.8167 s / it)
Averaged stats: lr: 0.003999  min_lr: 0.003999  loss: 4.0201 (3.9911)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5846 (nan)
Test:  [ 0/25]  eta: 0:03:17  loss: 1.0512 (1.0512)  acc1: 82.4000 (82.4000)  acc5: 95.2000 (95.2000)  time: 7.8851  data: 7.4046  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.1657 (1.2130)  acc1: 77.2000 (75.6364)  acc5: 94.8000 (94.4364)  time: 1.1216  data: 0.6734  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.5134 (1.4452)  acc1: 67.2000 (71.0667)  acc5: 90.8000 (90.9333)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.6492 (1.4593)  acc1: 67.6000 (70.8480)  acc5: 88.0000 (90.7680)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7466 s / it)
* Acc@1 70.940 Acc@5 90.654 loss 1.456
Accuracy of the model on the 50000 test images: 70.9%
Max accuracy: 70.94%
Epoch: [22]  [   0/1251]  eta: 1:31:06  lr: 0.003999  min_lr: 0.003999  loss: 4.2046 (4.2046)  weight_decay: 0.0500 (0.0500)  time: 4.3697  data: 3.5592  max mem: 62457
Epoch: [22]  [ 200/1251]  eta: 0:14:35  lr: 0.003999  min_lr: 0.003999  loss: 4.1474 (3.9980)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5700 (0.6693)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [22]  [ 400/1251]  eta: 0:11:40  lr: 0.003999  min_lr: 0.003999  loss: 4.0884 (3.9661)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4967 (0.6317)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [22]  [ 600/1251]  eta: 0:08:54  lr: 0.003999  min_lr: 0.003999  loss: 4.2088 (3.9515)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5243 (0.5990)  time: 0.8136  data: 0.0004  max mem: 62457
Epoch: [22]  [ 800/1251]  eta: 0:06:09  lr: 0.003999  min_lr: 0.003999  loss: 3.9875 (3.9410)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5375 (0.5813)  time: 0.8146  data: 0.0005  max mem: 62457
Epoch: [22]  [1000/1251]  eta: 0:03:25  lr: 0.003999  min_lr: 0.003999  loss: 3.9445 (3.9373)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5605 (0.5850)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [22]  [1200/1251]  eta: 0:00:41  lr: 0.003999  min_lr: 0.003999  loss: 4.0773 (3.9389)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6185 (0.5867)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [22]  [1250/1251]  eta: 0:00:00  lr: 0.003999  min_lr: 0.003999  loss: 3.8630 (3.9353)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6185 (0.5882)  time: 0.6915  data: 0.0006  max mem: 62457
Epoch: [22] Total time: 0:17:01 (0.8169 s / it)
Averaged stats: lr: 0.003999  min_lr: 0.003999  loss: 3.8630 (3.9479)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6185 (0.5882)
Test:  [ 0/25]  eta: 0:03:21  loss: 0.9742 (0.9742)  acc1: 82.8000 (82.8000)  acc5: 94.8000 (94.8000)  time: 8.0598  data: 7.5808  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 1.1195 (1.1526)  acc1: 77.6000 (76.5455)  acc5: 94.8000 (94.0000)  time: 1.1376  data: 0.6894  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.3960 (1.3675)  acc1: 69.2000 (72.0191)  acc5: 90.0000 (90.8381)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.5408 (1.3878)  acc1: 69.2000 (71.7600)  acc5: 89.2000 (90.7040)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7539 s / it)
* Acc@1 71.378 Acc@5 90.858 loss 1.387
Accuracy of the model on the 50000 test images: 71.4%
Max accuracy: 71.38%
Epoch: [23]  [   0/1251]  eta: 1:29:32  lr: 0.003999  min_lr: 0.003999  loss: 4.2923 (4.2923)  weight_decay: 0.0500 (0.0500)  time: 4.2944  data: 3.4692  max mem: 62457
Epoch: [23]  [ 200/1251]  eta: 0:14:34  lr: 0.003999  min_lr: 0.003999  loss: 3.5687 (3.9024)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5163 (0.5488)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [23]  [ 400/1251]  eta: 0:11:41  lr: 0.003999  min_lr: 0.003999  loss: 4.0618 (3.9361)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4513 (0.5476)  time: 0.8224  data: 0.0004  max mem: 62457
Epoch: [23]  [ 600/1251]  eta: 0:08:54  lr: 0.003998  min_lr: 0.003998  loss: 4.2196 (3.9505)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5145 (0.5639)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [23]  [ 800/1251]  eta: 0:06:09  lr: 0.003998  min_lr: 0.003998  loss: 4.1994 (3.9452)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5665 (0.5752)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [23]  [1000/1251]  eta: 0:03:25  lr: 0.003998  min_lr: 0.003998  loss: 4.2076 (3.9405)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4911 (0.5767)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [23]  [1200/1251]  eta: 0:00:41  lr: 0.003998  min_lr: 0.003998  loss: 3.6084 (3.9366)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5304 (0.5781)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [23]  [1250/1251]  eta: 0:00:00  lr: 0.003998  min_lr: 0.003998  loss: 3.7842 (3.9360)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5749 (0.5825)  time: 0.6916  data: 0.0006  max mem: 62457
Epoch: [23] Total time: 0:17:01 (0.8167 s / it)
Averaged stats: lr: 0.003998  min_lr: 0.003998  loss: 3.7842 (3.9169)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5749 (0.5825)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.9669 (0.9669)  acc1: 82.0000 (82.0000)  acc5: 96.4000 (96.4000)  time: 7.5631  data: 7.0832  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.1302 (1.1947)  acc1: 76.0000 (76.2545)  acc5: 95.6000 (94.6182)  time: 1.0926  data: 0.6442  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.4434 (1.4223)  acc1: 68.0000 (71.5238)  acc5: 92.0000 (91.3524)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.5920 (1.4434)  acc1: 68.0000 (71.0240)  acc5: 88.8000 (91.1040)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7344 s / it)
* Acc@1 71.428 Acc@5 91.160 loss 1.436
Accuracy of the model on the 50000 test images: 71.4%
Max accuracy: 71.43%
Epoch: [24]  [   0/1251]  eta: 1:25:25  lr: 0.003998  min_lr: 0.003998  loss: 4.2439 (4.2439)  weight_decay: 0.0500 (0.0500)  time: 4.0973  data: 3.2883  max mem: 62457
Epoch: [24]  [ 200/1251]  eta: 0:14:32  lr: 0.003998  min_lr: 0.003998  loss: 3.7666 (3.8689)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5007 (0.6243)  time: 0.8139  data: 0.0005  max mem: 62457
Epoch: [24]  [ 400/1251]  eta: 0:11:40  lr: 0.003998  min_lr: 0.003998  loss: 4.0834 (3.9002)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4799 (0.5945)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [24]  [ 600/1251]  eta: 0:08:54  lr: 0.003997  min_lr: 0.003997  loss: 3.9721 (3.9045)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5033 (0.5819)  time: 0.8142  data: 0.0005  max mem: 62457
Epoch: [24]  [ 800/1251]  eta: 0:06:09  lr: 0.003997  min_lr: 0.003997  loss: 4.0750 (3.9046)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5051 (0.5727)  time: 0.8200  data: 0.0004  max mem: 62457
Epoch: [24]  [1000/1251]  eta: 0:03:25  lr: 0.003997  min_lr: 0.003997  loss: 4.1489 (3.8833)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5367 (0.5731)  time: 0.8177  data: 0.0004  max mem: 62457
Epoch: [24]  [1200/1251]  eta: 0:00:41  lr: 0.003997  min_lr: 0.003997  loss: 3.9805 (3.8797)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4873 (0.5627)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [24]  [1250/1251]  eta: 0:00:00  lr: 0.003997  min_lr: 0.003997  loss: 3.9813 (3.8779)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5190 (0.5663)  time: 0.6921  data: 0.0006  max mem: 62457
Epoch: [24] Total time: 0:17:01 (0.8164 s / it)
Averaged stats: lr: 0.003997  min_lr: 0.003997  loss: 3.9813 (3.8892)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5190 (0.5663)
Test:  [ 0/25]  eta: 0:03:04  loss: 1.0082 (1.0082)  acc1: 82.8000 (82.8000)  acc5: 96.4000 (96.4000)  time: 7.3979  data: 6.9170  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.1693 (1.2333)  acc1: 76.4000 (76.3273)  acc5: 94.8000 (94.2182)  time: 1.0776  data: 0.6291  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.5302 (1.4492)  acc1: 68.8000 (71.5048)  acc5: 91.2000 (90.9333)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.5709 (1.4644)  acc1: 68.4000 (71.2640)  acc5: 89.6000 (90.9440)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7285 s / it)
* Acc@1 71.710 Acc@5 91.338 loss 1.456
Accuracy of the model on the 50000 test images: 71.7%
Max accuracy: 71.71%
Epoch: [25]  [   0/1251]  eta: 1:36:32  lr: 0.003997  min_lr: 0.003997  loss: 4.1949 (4.1949)  weight_decay: 0.0500 (0.0500)  time: 4.6305  data: 3.8122  max mem: 62457
Epoch: [25]  [ 200/1251]  eta: 0:14:38  lr: 0.003997  min_lr: 0.003997  loss: 3.7834 (3.9205)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4273 (0.5908)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [25]  [ 400/1251]  eta: 0:11:42  lr: 0.003996  min_lr: 0.003996  loss: 4.1181 (3.9299)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4910 (0.5944)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [25]  [ 600/1251]  eta: 0:08:54  lr: 0.003996  min_lr: 0.003996  loss: 3.7078 (3.8968)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6743 (0.5981)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [25]  [ 800/1251]  eta: 0:06:10  lr: 0.003996  min_lr: 0.003996  loss: 3.9860 (3.8978)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6581 (0.6027)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [25]  [1000/1251]  eta: 0:03:25  lr: 0.003996  min_lr: 0.003996  loss: 3.8990 (3.8942)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4748 (0.6077)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [25]  [1200/1251]  eta: 0:00:41  lr: 0.003996  min_lr: 0.003996  loss: 3.4953 (3.8811)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4919 (0.5945)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [25]  [1250/1251]  eta: 0:00:00  lr: 0.003995  min_lr: 0.003995  loss: 3.7814 (3.8802)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5065 (0.5945)  time: 0.6948  data: 0.0006  max mem: 62457
Epoch: [25] Total time: 0:17:02 (0.8176 s / it)
Averaged stats: lr: 0.003995  min_lr: 0.003995  loss: 3.7814 (3.8667)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5065 (0.5945)
Test:  [ 0/25]  eta: 0:03:16  loss: 0.9980 (0.9980)  acc1: 84.0000 (84.0000)  acc5: 97.2000 (97.2000)  time: 7.8581  data: 7.3853  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.1616 (1.1923)  acc1: 77.6000 (76.8000)  acc5: 95.6000 (95.2000)  time: 1.1195  data: 0.6717  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.4517 (1.4093)  acc1: 69.6000 (71.8286)  acc5: 91.2000 (91.6191)  time: 0.4456  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.5465 (1.4240)  acc1: 69.6000 (71.5360)  acc5: 89.6000 (91.5520)  time: 0.4455  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7461 s / it)
* Acc@1 72.198 Acc@5 91.528 loss 1.415
Accuracy of the model on the 50000 test images: 72.2%
Max accuracy: 72.20%
Epoch: [26]  [   0/1251]  eta: 1:28:53  lr: 0.003995  min_lr: 0.003995  loss: 2.9443 (2.9443)  weight_decay: 0.0500 (0.0500)  time: 4.2632  data: 3.4525  max mem: 62457
Epoch: [26]  [ 200/1251]  eta: 0:14:34  lr: 0.003995  min_lr: 0.003995  loss: 4.0584 (3.8222)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6315 (0.5814)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [26]  [ 400/1251]  eta: 0:11:40  lr: 0.003995  min_lr: 0.003995  loss: 3.7586 (3.7952)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5887 (0.6171)  time: 0.8135  data: 0.0004  max mem: 62457
Epoch: [26]  [ 600/1251]  eta: 0:08:54  lr: 0.003995  min_lr: 0.003995  loss: 4.0095 (3.8143)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5319 (0.6064)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [26]  [ 800/1251]  eta: 0:06:09  lr: 0.003994  min_lr: 0.003994  loss: 3.6901 (3.8224)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5535 (0.6043)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [26]  [1000/1251]  eta: 0:03:25  lr: 0.003994  min_lr: 0.003994  loss: 4.0025 (3.8375)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4901 (0.6133)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [26]  [1200/1251]  eta: 0:00:41  lr: 0.003994  min_lr: 0.003994  loss: 3.9621 (3.8412)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5412 (0.6123)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [26]  [1250/1251]  eta: 0:00:00  lr: 0.003994  min_lr: 0.003994  loss: 3.9334 (3.8440)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5432 (0.6106)  time: 0.6915  data: 0.0006  max mem: 62457
Epoch: [26] Total time: 0:17:01 (0.8164 s / it)
Averaged stats: lr: 0.003994  min_lr: 0.003994  loss: 3.9334 (3.8451)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5432 (0.6106)
Test:  [ 0/25]  eta: 0:03:02  loss: 1.0154 (1.0154)  acc1: 84.4000 (84.4000)  acc5: 95.2000 (95.2000)  time: 7.3089  data: 6.8276  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.1876 (1.2007)  acc1: 77.6000 (76.7273)  acc5: 95.2000 (94.6182)  time: 1.0686  data: 0.6210  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.5044 (1.4261)  acc1: 68.8000 (72.0381)  acc5: 91.6000 (91.4667)  time: 0.4444  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.5687 (1.4391)  acc1: 69.6000 (71.8240)  acc5: 90.4000 (91.4080)  time: 0.4443  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7250 s / it)
* Acc@1 72.452 Acc@5 91.728 loss 1.420
Accuracy of the model on the 50000 test images: 72.5%
Max accuracy: 72.45%
Epoch: [27]  [   0/1251]  eta: 1:22:57  lr: 0.003994  min_lr: 0.003994  loss: 2.7795 (2.7795)  weight_decay: 0.0500 (0.0500)  time: 3.9785  data: 3.1490  max mem: 62457
Epoch: [27]  [ 200/1251]  eta: 0:14:32  lr: 0.003994  min_lr: 0.003994  loss: 3.7572 (3.8280)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5281 (0.6424)  time: 0.8135  data: 0.0004  max mem: 62457
Epoch: [27]  [ 400/1251]  eta: 0:11:40  lr: 0.003993  min_lr: 0.003993  loss: 3.9408 (3.8073)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5331 (0.6012)  time: 0.8207  data: 0.0004  max mem: 62457
Epoch: [27]  [ 600/1251]  eta: 0:08:54  lr: 0.003993  min_lr: 0.003993  loss: 4.0762 (3.8377)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6179 (0.6151)  time: 0.8182  data: 0.0004  max mem: 62457
Epoch: [27]  [ 800/1251]  eta: 0:06:09  lr: 0.003993  min_lr: 0.003993  loss: 3.9715 (3.8512)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4871 (0.6163)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [27]  [1000/1251]  eta: 0:03:25  lr: 0.003992  min_lr: 0.003992  loss: 3.8252 (3.8434)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6435 (0.6174)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [27]  [1200/1251]  eta: 0:00:41  lr: 0.003992  min_lr: 0.003992  loss: 4.0368 (3.8420)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6978 (0.6211)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [27]  [1250/1251]  eta: 0:00:00  lr: 0.003992  min_lr: 0.003992  loss: 4.0609 (3.8423)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4434 (0.6185)  time: 0.6908  data: 0.0005  max mem: 62457
Epoch: [27] Total time: 0:17:00 (0.8161 s / it)
Averaged stats: lr: 0.003992  min_lr: 0.003992  loss: 4.0609 (3.8269)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4434 (0.6185)
Test:  [ 0/25]  eta: 0:03:14  loss: 1.0299 (1.0299)  acc1: 82.8000 (82.8000)  acc5: 96.0000 (96.0000)  time: 7.7963  data: 7.3078  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.2448 (1.2276)  acc1: 78.0000 (77.0182)  acc5: 94.8000 (94.7636)  time: 1.1130  data: 0.6646  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.4396 (1.4519)  acc1: 70.0000 (72.6476)  acc5: 90.4000 (91.7905)  time: 0.4446  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.6020 (1.4689)  acc1: 70.0000 (72.3200)  acc5: 90.0000 (91.6160)  time: 0.4445  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7442 s / it)
* Acc@1 72.438 Acc@5 91.734 loss 1.457
Accuracy of the model on the 50000 test images: 72.4%
Max accuracy: 72.45%
Epoch: [28]  [   0/1251]  eta: 1:30:34  lr: 0.003992  min_lr: 0.003992  loss: 3.4837 (3.4837)  weight_decay: 0.0500 (0.0500)  time: 4.3439  data: 1.8876  max mem: 62457
Epoch: [28]  [ 200/1251]  eta: 0:14:33  lr: 0.003992  min_lr: 0.003992  loss: 3.4519 (3.8299)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5075 (0.5507)  time: 0.8131  data: 0.0004  max mem: 62457
Epoch: [28]  [ 400/1251]  eta: 0:11:40  lr: 0.003991  min_lr: 0.003991  loss: 3.5945 (3.8214)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6160 (0.6067)  time: 0.8137  data: 0.0004  max mem: 62457
Epoch: [28]  [ 600/1251]  eta: 0:08:54  lr: 0.003991  min_lr: 0.003991  loss: 3.7595 (3.8056)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5676 (0.6164)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [28]  [ 800/1251]  eta: 0:06:09  lr: 0.003991  min_lr: 0.003991  loss: 3.9920 (3.8057)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5197 (0.6099)  time: 0.8198  data: 0.0004  max mem: 62457
Epoch: [28]  [1000/1251]  eta: 0:03:25  lr: 0.003990  min_lr: 0.003990  loss: 3.8441 (3.8080)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5294 (nan)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [28]  [1200/1251]  eta: 0:00:41  lr: 0.003990  min_lr: 0.003990  loss: 3.6269 (3.8083)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5959 (nan)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [28]  [1250/1251]  eta: 0:00:00  lr: 0.003990  min_lr: 0.003990  loss: 3.6668 (3.8069)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4885 (nan)  time: 0.6917  data: 0.0005  max mem: 62457
Epoch: [28] Total time: 0:17:01 (0.8166 s / it)
Averaged stats: lr: 0.003990  min_lr: 0.003990  loss: 3.6668 (3.8012)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4885 (nan)
Test:  [ 0/25]  eta: 0:03:10  loss: 0.9019 (0.9019)  acc1: 83.2000 (83.2000)  acc5: 96.8000 (96.8000)  time: 7.6280  data: 7.1503  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.0944 (1.0885)  acc1: 78.0000 (77.3818)  acc5: 95.6000 (94.9091)  time: 1.0984  data: 0.6503  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.3497 (1.3026)  acc1: 71.6000 (73.2762)  acc5: 92.0000 (92.0000)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.4580 (1.3135)  acc1: 70.0000 (72.9280)  acc5: 89.6000 (91.8080)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7369 s / it)
* Acc@1 72.846 Acc@5 91.976 loss 1.304
Accuracy of the model on the 50000 test images: 72.8%
Max accuracy: 72.85%
Epoch: [29]  [   0/1251]  eta: 1:29:07  lr: 0.003990  min_lr: 0.003990  loss: 4.3177 (4.3177)  weight_decay: 0.0500 (0.0500)  time: 4.2742  data: 3.4694  max mem: 62457
Epoch: [29]  [ 200/1251]  eta: 0:14:37  lr: 0.003989  min_lr: 0.003989  loss: 3.9386 (3.7991)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6761 (0.6847)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [29]  [ 400/1251]  eta: 0:11:41  lr: 0.003989  min_lr: 0.003989  loss: 3.8134 (3.7947)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4744 (0.6847)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [29]  [ 600/1251]  eta: 0:08:54  lr: 0.003989  min_lr: 0.003989  loss: 3.9266 (3.8062)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5890 (0.6888)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [29]  [ 800/1251]  eta: 0:06:09  lr: 0.003988  min_lr: 0.003988  loss: 4.0296 (3.7961)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5279 (0.6724)  time: 0.8136  data: 0.0004  max mem: 62457
Epoch: [29]  [1000/1251]  eta: 0:03:25  lr: 0.003988  min_lr: 0.003988  loss: 3.8956 (3.7914)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5482 (0.6569)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [29]  [1200/1251]  eta: 0:00:41  lr: 0.003988  min_lr: 0.003988  loss: 3.7876 (3.7860)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4914 (0.6523)  time: 0.8246  data: 0.0004  max mem: 62457
Epoch: [29]  [1250/1251]  eta: 0:00:00  lr: 0.003987  min_lr: 0.003987  loss: 3.6322 (3.7797)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5882 (0.6506)  time: 0.6915  data: 0.0006  max mem: 62457
Epoch: [29] Total time: 0:17:02 (0.8170 s / it)
Averaged stats: lr: 0.003987  min_lr: 0.003987  loss: 3.6322 (3.7887)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5882 (0.6506)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.8540 (0.8540)  acc1: 84.0000 (84.0000)  acc5: 97.2000 (97.2000)  time: 7.8238  data: 7.3478  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.0253 (1.0570)  acc1: 78.8000 (77.1636)  acc5: 95.2000 (94.9091)  time: 1.1161  data: 0.6683  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.3181 (1.2855)  acc1: 68.8000 (72.5714)  acc5: 91.6000 (91.9429)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3874 (1.2981)  acc1: 69.6000 (72.3200)  acc5: 90.8000 (91.9200)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7441 s / it)
* Acc@1 73.052 Acc@5 92.130 loss 1.275
Accuracy of the model on the 50000 test images: 73.1%
Max accuracy: 73.05%
Epoch: [30]  [   0/1251]  eta: 1:30:21  lr: 0.003987  min_lr: 0.003987  loss: 2.7427 (2.7427)  weight_decay: 0.0500 (0.0500)  time: 4.3337  data: 3.5132  max mem: 62457
Epoch: [30]  [ 200/1251]  eta: 0:14:34  lr: 0.003987  min_lr: 0.003987  loss: 3.9978 (3.8036)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5008 (0.5620)  time: 0.8154  data: 0.0005  max mem: 62457
Epoch: [30]  [ 400/1251]  eta: 0:11:41  lr: 0.003987  min_lr: 0.003987  loss: 4.0771 (3.8036)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6776 (0.6617)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [30]  [ 600/1251]  eta: 0:08:54  lr: 0.003986  min_lr: 0.003986  loss: 3.8316 (3.7721)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5716 (0.6287)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [30]  [ 800/1251]  eta: 0:06:09  lr: 0.003986  min_lr: 0.003986  loss: 3.8624 (3.7597)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6544 (0.6460)  time: 0.8149  data: 0.0005  max mem: 62457
Epoch: [30]  [1000/1251]  eta: 0:03:25  lr: 0.003985  min_lr: 0.003985  loss: 3.4889 (3.7575)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6023 (0.6466)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [30]  [1200/1251]  eta: 0:00:41  lr: 0.003985  min_lr: 0.003985  loss: 3.9416 (3.7485)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5779 (0.6363)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [30]  [1250/1251]  eta: 0:00:00  lr: 0.003985  min_lr: 0.003985  loss: 3.6749 (3.7474)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4699 (0.6334)  time: 0.6920  data: 0.0006  max mem: 62457
Epoch: [30] Total time: 0:17:02 (0.8173 s / it)
Averaged stats: lr: 0.003985  min_lr: 0.003985  loss: 3.6749 (3.7632)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4699 (0.6334)
Test:  [ 0/25]  eta: 0:03:16  loss: 0.9178 (0.9178)  acc1: 81.6000 (81.6000)  acc5: 96.4000 (96.4000)  time: 7.8698  data: 7.3968  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9593 (1.0738)  acc1: 80.0000 (77.6000)  acc5: 95.2000 (94.8364)  time: 1.1203  data: 0.6728  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.3180 (1.2721)  acc1: 70.8000 (73.5619)  acc5: 91.2000 (92.3429)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.4499 (1.2875)  acc1: 70.0000 (73.1840)  acc5: 91.2000 (92.2880)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7461 s / it)
* Acc@1 73.508 Acc@5 92.238 loss 1.277
Accuracy of the model on the 50000 test images: 73.5%
Max accuracy: 73.51%
Epoch: [31]  [   0/1251]  eta: 1:12:04  lr: 0.003985  min_lr: 0.003985  loss: 3.8664 (3.8664)  weight_decay: 0.0500 (0.0500)  time: 3.4570  data: 2.6432  max mem: 62457
Epoch: [31]  [ 200/1251]  eta: 0:14:29  lr: 0.003984  min_lr: 0.003984  loss: 3.9385 (3.6813)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5314 (0.6673)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [31]  [ 400/1251]  eta: 0:11:39  lr: 0.003984  min_lr: 0.003984  loss: 3.6079 (3.7216)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6920 (0.6898)  time: 0.8216  data: 0.0004  max mem: 62457
Epoch: [31]  [ 600/1251]  eta: 0:08:53  lr: 0.003983  min_lr: 0.003983  loss: 3.7153 (3.7417)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8411 (0.6993)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [31]  [ 800/1251]  eta: 0:06:09  lr: 0.003983  min_lr: 0.003983  loss: 3.8029 (3.7572)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6001 (0.6995)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [31]  [1000/1251]  eta: 0:03:25  lr: 0.003982  min_lr: 0.003982  loss: 3.8662 (3.7619)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5384 (0.6986)  time: 0.8197  data: 0.0004  max mem: 62457
Epoch: [31]  [1200/1251]  eta: 0:00:41  lr: 0.003982  min_lr: 0.003982  loss: 4.0424 (3.7641)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6368 (0.6956)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [31]  [1250/1251]  eta: 0:00:00  lr: 0.003982  min_lr: 0.003982  loss: 3.8923 (3.7626)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8194 (0.7031)  time: 0.6916  data: 0.0005  max mem: 62457
Epoch: [31] Total time: 0:17:01 (0.8164 s / it)
Averaged stats: lr: 0.003982  min_lr: 0.003982  loss: 3.8923 (3.7442)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8194 (0.7031)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.8894 (0.8894)  acc1: 83.6000 (83.6000)  acc5: 97.2000 (97.2000)  time: 7.6859  data: 7.1998  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.0349 (1.0925)  acc1: 80.8000 (77.8545)  acc5: 96.4000 (95.5636)  time: 1.1037  data: 0.6548  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.3327 (1.2953)  acc1: 71.2000 (74.0381)  acc5: 92.4000 (92.5143)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.4275 (1.3080)  acc1: 71.6000 (73.8720)  acc5: 90.0000 (92.4000)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7390 s / it)
* Acc@1 73.860 Acc@5 92.470 loss 1.300
Accuracy of the model on the 50000 test images: 73.9%
Max accuracy: 73.86%
Epoch: [32]  [   0/1251]  eta: 1:22:26  lr: 0.003982  min_lr: 0.003982  loss: 3.4248 (3.4248)  weight_decay: 0.0500 (0.0500)  time: 3.9540  data: 3.1355  max mem: 62457
Epoch: [32]  [ 200/1251]  eta: 0:14:32  lr: 0.003981  min_lr: 0.003981  loss: 3.7208 (3.6618)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6965 (0.7515)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [32]  [ 400/1251]  eta: 0:11:40  lr: 0.003981  min_lr: 0.003981  loss: 3.8243 (3.6644)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5875 (0.7416)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [32]  [ 600/1251]  eta: 0:08:54  lr: 0.003980  min_lr: 0.003980  loss: 3.8706 (3.6818)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5056 (nan)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [32]  [ 800/1251]  eta: 0:06:09  lr: 0.003980  min_lr: 0.003980  loss: 3.5346 (3.6826)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7679 (nan)  time: 0.8184  data: 0.0004  max mem: 62457
Epoch: [32]  [1000/1251]  eta: 0:03:25  lr: 0.003979  min_lr: 0.003979  loss: 3.7764 (3.7053)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6983 (nan)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [32]  [1200/1251]  eta: 0:00:41  lr: 0.003979  min_lr: 0.003979  loss: 3.9259 (3.7148)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6820 (nan)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [32]  [1250/1251]  eta: 0:00:00  lr: 0.003979  min_lr: 0.003979  loss: 3.8929 (3.7179)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6419 (nan)  time: 0.6918  data: 0.0006  max mem: 62457
Epoch: [32] Total time: 0:17:01 (0.8168 s / it)
Averaged stats: lr: 0.003979  min_lr: 0.003979  loss: 3.8929 (3.7242)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6419 (nan)
Test:  [ 0/25]  eta: 0:03:00  loss: 0.9498 (0.9498)  acc1: 85.6000 (85.6000)  acc5: 98.0000 (98.0000)  time: 7.2177  data: 6.7564  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 1.1048 (1.1742)  acc1: 78.8000 (77.6364)  acc5: 95.2000 (95.4909)  time: 1.0625  data: 0.6145  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.3475 (1.3583)  acc1: 72.0000 (73.7143)  acc5: 92.0000 (92.8571)  time: 0.4462  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.4399 (1.3666)  acc1: 72.4000 (73.4880)  acc5: 90.8000 (92.6880)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7215 s / it)
* Acc@1 74.010 Acc@5 92.558 loss 1.357
Accuracy of the model on the 50000 test images: 74.0%
Max accuracy: 74.01%
Epoch: [33]  [   0/1251]  eta: 1:16:29  lr: 0.003979  min_lr: 0.003979  loss: 3.2940 (3.2940)  weight_decay: 0.0500 (0.0500)  time: 3.6683  data: 2.8484  max mem: 62457
Epoch: [33]  [ 200/1251]  eta: 0:14:34  lr: 0.003978  min_lr: 0.003978  loss: 3.9312 (3.7097)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4787 (0.7297)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [33]  [ 400/1251]  eta: 0:11:40  lr: 0.003978  min_lr: 0.003978  loss: 3.8758 (3.6955)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5550 (0.7004)  time: 0.8141  data: 0.0005  max mem: 62457
Epoch: [33]  [ 600/1251]  eta: 0:08:54  lr: 0.003977  min_lr: 0.003977  loss: 3.7282 (3.7089)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6039 (0.6961)  time: 0.8147  data: 0.0005  max mem: 62457
Epoch: [33]  [ 800/1251]  eta: 0:06:09  lr: 0.003977  min_lr: 0.003977  loss: 3.9008 (3.7113)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7938 (0.7147)  time: 0.8150  data: 0.0005  max mem: 62457
Epoch: [33]  [1000/1251]  eta: 0:03:25  lr: 0.003976  min_lr: 0.003976  loss: 3.6014 (3.7169)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6688 (0.7186)  time: 0.8145  data: 0.0005  max mem: 62457
Epoch: [33]  [1200/1251]  eta: 0:00:41  lr: 0.003976  min_lr: 0.003976  loss: 3.8450 (3.7192)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6254 (0.7382)  time: 0.8183  data: 0.0004  max mem: 62457
Epoch: [33]  [1250/1251]  eta: 0:00:00  lr: 0.003975  min_lr: 0.003975  loss: 3.5428 (3.7179)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4818 (0.7275)  time: 0.6944  data: 0.0006  max mem: 62457
Epoch: [33] Total time: 0:17:01 (0.8169 s / it)
Averaged stats: lr: 0.003975  min_lr: 0.003975  loss: 3.5428 (3.7101)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4818 (0.7275)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.9074 (0.9074)  acc1: 85.2000 (85.2000)  acc5: 97.6000 (97.6000)  time: 7.7038  data: 7.2235  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.0526 (1.0933)  acc1: 80.4000 (78.0364)  acc5: 96.0000 (95.4546)  time: 1.1055  data: 0.6570  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.3353 (1.3069)  acc1: 71.2000 (74.1905)  acc5: 91.6000 (92.5143)  time: 0.4456  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.4751 (1.3221)  acc1: 71.2000 (73.9040)  acc5: 90.4000 (92.4640)  time: 0.4455  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7404 s / it)
* Acc@1 74.246 Acc@5 92.618 loss 1.317
Accuracy of the model on the 50000 test images: 74.2%
Max accuracy: 74.25%
Epoch: [34]  [   0/1251]  eta: 1:38:20  lr: 0.003975  min_lr: 0.003975  loss: 4.3895 (4.3895)  weight_decay: 0.0500 (0.0500)  time: 4.7169  data: 3.9011  max mem: 62457
Epoch: [34]  [ 200/1251]  eta: 0:14:36  lr: 0.003975  min_lr: 0.003975  loss: 3.8337 (3.7024)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9437 (0.7614)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [34]  [ 400/1251]  eta: 0:11:41  lr: 0.003974  min_lr: 0.003974  loss: 3.6689 (3.7046)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6504 (0.7551)  time: 0.8142  data: 0.0005  max mem: 62457
Epoch: [34]  [ 600/1251]  eta: 0:08:55  lr: 0.003974  min_lr: 0.003974  loss: 3.8351 (3.7095)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7332 (0.7633)  time: 0.8147  data: 0.0005  max mem: 62457
Epoch: [34]  [ 800/1251]  eta: 0:06:09  lr: 0.003973  min_lr: 0.003973  loss: 3.3202 (3.6926)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5862 (0.7514)  time: 0.8143  data: 0.0005  max mem: 62457
Epoch: [34]  [1000/1251]  eta: 0:03:25  lr: 0.003972  min_lr: 0.003972  loss: 3.9759 (3.6890)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7675 (0.7550)  time: 0.8140  data: 0.0005  max mem: 62457
Epoch: [34]  [1200/1251]  eta: 0:00:41  lr: 0.003972  min_lr: 0.003972  loss: 3.5353 (3.6821)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7806 (0.7425)  time: 0.8141  data: 0.0005  max mem: 62457
Epoch: [34]  [1250/1251]  eta: 0:00:00  lr: 0.003972  min_lr: 0.003972  loss: 3.5928 (3.6775)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9712 (0.7542)  time: 0.6917  data: 0.0006  max mem: 62457
Epoch: [34] Total time: 0:17:02 (0.8173 s / it)
Averaged stats: lr: 0.003972  min_lr: 0.003972  loss: 3.5928 (3.7039)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9712 (0.7542)
Test:  [ 0/25]  eta: 0:03:02  loss: 0.8910 (0.8910)  acc1: 84.8000 (84.8000)  acc5: 96.0000 (96.0000)  time: 7.3060  data: 6.8189  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9915 (1.0485)  acc1: 80.8000 (79.2727)  acc5: 96.0000 (95.2364)  time: 1.0693  data: 0.6202  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.2831 (1.2710)  acc1: 70.0000 (74.4952)  acc5: 92.0000 (92.7619)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.4035 (1.2831)  acc1: 70.4000 (74.2560)  acc5: 91.2000 (92.6720)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7240 s / it)
* Acc@1 74.768 Acc@5 92.626 loss 1.275
Accuracy of the model on the 50000 test images: 74.8%
Max accuracy: 74.77%
Epoch: [35]  [   0/1251]  eta: 1:32:00  lr: 0.003972  min_lr: 0.003972  loss: 3.8651 (3.8651)  weight_decay: 0.0500 (0.0500)  time: 4.4132  data: 3.5988  max mem: 62457
Epoch: [35]  [ 200/1251]  eta: 0:14:34  lr: 0.003971  min_lr: 0.003971  loss: 3.9157 (3.6986)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6442 (0.7937)  time: 0.8143  data: 0.0005  max mem: 62457
Epoch: [35]  [ 400/1251]  eta: 0:11:42  lr: 0.003971  min_lr: 0.003971  loss: 3.5306 (3.6688)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7134 (0.7565)  time: 0.8213  data: 0.0004  max mem: 62457
Epoch: [35]  [ 600/1251]  eta: 0:08:54  lr: 0.003970  min_lr: 0.003970  loss: 3.6915 (3.6473)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5550 (0.7386)  time: 0.8132  data: 0.0004  max mem: 62457
Epoch: [35]  [ 800/1251]  eta: 0:06:09  lr: 0.003969  min_lr: 0.003969  loss: 3.6677 (3.6526)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5647 (0.7681)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [35]  [1000/1251]  eta: 0:03:25  lr: 0.003969  min_lr: 0.003969  loss: 3.9321 (3.6632)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8319 (0.7630)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [35]  [1200/1251]  eta: 0:00:41  lr: 0.003968  min_lr: 0.003968  loss: 3.6770 (3.6694)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7548 (0.7659)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [35]  [1250/1251]  eta: 0:00:00  lr: 0.003968  min_lr: 0.003968  loss: 3.4008 (3.6691)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7373 (0.7688)  time: 0.6913  data: 0.0006  max mem: 62457
Epoch: [35] Total time: 0:17:01 (0.8169 s / it)
Averaged stats: lr: 0.003968  min_lr: 0.003968  loss: 3.4008 (3.6872)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7373 (0.7688)
Test:  [ 0/25]  eta: 0:03:10  loss: 0.7929 (0.7929)  acc1: 84.4000 (84.4000)  acc5: 96.8000 (96.8000)  time: 7.6278  data: 7.1515  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9375 (0.9940)  acc1: 81.6000 (78.8727)  acc5: 95.6000 (95.5273)  time: 1.0984  data: 0.6504  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1785 (1.1896)  acc1: 72.8000 (75.0286)  acc5: 93.2000 (93.3524)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3121 (1.2018)  acc1: 72.8000 (74.6720)  acc5: 91.6000 (93.2640)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7374 s / it)
* Acc@1 74.790 Acc@5 93.086 loss 1.193
Accuracy of the model on the 50000 test images: 74.8%
Max accuracy: 74.79%
Epoch: [36]  [   0/1251]  eta: 1:11:40  lr: 0.003968  min_lr: 0.003968  loss: 4.5246 (4.5246)  weight_decay: 0.0500 (0.0500)  time: 3.4376  data: 2.6160  max mem: 62457
Epoch: [36]  [ 200/1251]  eta: 0:14:32  lr: 0.003967  min_lr: 0.003967  loss: 3.7910 (3.7099)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8313 (0.8380)  time: 0.8377  data: 0.0004  max mem: 62457
Epoch: [36]  [ 400/1251]  eta: 0:11:40  lr: 0.003967  min_lr: 0.003967  loss: 3.7309 (3.7140)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6985 (0.7947)  time: 0.8135  data: 0.0005  max mem: 62457
Epoch: [36]  [ 600/1251]  eta: 0:08:53  lr: 0.003966  min_lr: 0.003966  loss: 3.8920 (3.7110)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9134 (0.8146)  time: 0.8141  data: 0.0005  max mem: 62457
Epoch: [36]  [ 800/1251]  eta: 0:06:09  lr: 0.003965  min_lr: 0.003965  loss: 3.8228 (3.7111)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5340 (0.7869)  time: 0.8188  data: 0.0004  max mem: 62457
Epoch: [36]  [1000/1251]  eta: 0:03:25  lr: 0.003965  min_lr: 0.003965  loss: 3.5633 (3.6965)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7593 (0.7931)  time: 0.8143  data: 0.0005  max mem: 62457
Epoch: [36]  [1200/1251]  eta: 0:00:41  lr: 0.003964  min_lr: 0.003964  loss: 3.7726 (3.6912)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7321 (0.7988)  time: 0.8144  data: 0.0005  max mem: 62457
Epoch: [36]  [1250/1251]  eta: 0:00:00  lr: 0.003964  min_lr: 0.003964  loss: 3.7851 (3.6884)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7197 (0.7987)  time: 0.6920  data: 0.0006  max mem: 62457
Epoch: [36] Total time: 0:17:01 (0.8163 s / it)
Averaged stats: lr: 0.003964  min_lr: 0.003964  loss: 3.7851 (3.6686)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7197 (0.7987)
Test:  [ 0/25]  eta: 0:03:18  loss: 0.7940 (0.7940)  acc1: 85.2000 (85.2000)  acc5: 97.6000 (97.6000)  time: 7.9278  data: 7.4541  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9436 (0.9958)  acc1: 80.4000 (78.6545)  acc5: 95.6000 (95.3818)  time: 1.1258  data: 0.6779  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.2543 (1.1985)  acc1: 73.2000 (74.9714)  acc5: 92.0000 (92.8191)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3232 (1.2077)  acc1: 73.2000 (74.8640)  acc5: 91.6000 (92.7040)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7488 s / it)
* Acc@1 75.132 Acc@5 92.952 loss 1.201
Accuracy of the model on the 50000 test images: 75.1%
Max accuracy: 75.13%
Epoch: [37]  [   0/1251]  eta: 1:28:13  lr: 0.003964  min_lr: 0.003964  loss: 4.4038 (4.4038)  weight_decay: 0.0500 (0.0500)  time: 4.2316  data: 3.4082  max mem: 62457
Epoch: [37]  [ 200/1251]  eta: 0:14:36  lr: 0.003963  min_lr: 0.003963  loss: 3.7564 (3.6586)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6619 (0.7851)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [37]  [ 400/1251]  eta: 0:11:41  lr: 0.003962  min_lr: 0.003962  loss: 3.8038 (3.7030)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4988 (0.8209)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [37]  [ 600/1251]  eta: 0:08:54  lr: 0.003962  min_lr: 0.003962  loss: 3.5923 (3.6829)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8310 (0.8423)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [37]  [ 800/1251]  eta: 0:06:09  lr: 0.003961  min_lr: 0.003961  loss: 3.9476 (3.6832)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6246 (0.8172)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [37]  [1000/1251]  eta: 0:03:25  lr: 0.003960  min_lr: 0.003960  loss: 3.6207 (3.6749)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8143 (0.8319)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [37]  [1200/1251]  eta: 0:00:41  lr: 0.003960  min_lr: 0.003960  loss: 3.8302 (3.6681)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5412 (0.8166)  time: 0.8189  data: 0.0004  max mem: 62457
Epoch: [37]  [1250/1251]  eta: 0:00:00  lr: 0.003959  min_lr: 0.003959  loss: 3.4942 (3.6701)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6656 (0.8165)  time: 0.6912  data: 0.0005  max mem: 62457
Epoch: [37] Total time: 0:17:01 (0.8169 s / it)
Averaged stats: lr: 0.003959  min_lr: 0.003959  loss: 3.4942 (3.6644)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6656 (0.8165)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.8209 (0.8209)  acc1: 82.8000 (82.8000)  acc5: 98.0000 (98.0000)  time: 7.5224  data: 7.0514  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9389 (1.0151)  acc1: 78.0000 (78.1455)  acc5: 96.4000 (95.6727)  time: 1.0890  data: 0.6413  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1965 (1.1963)  acc1: 72.4000 (74.6667)  acc5: 93.2000 (93.2571)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3061 (1.2054)  acc1: 72.4000 (74.5280)  acc5: 91.6000 (93.0720)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7329 s / it)
* Acc@1 75.280 Acc@5 93.268 loss 1.189
Accuracy of the model on the 50000 test images: 75.3%
Max accuracy: 75.28%
Epoch: [38]  [   0/1251]  eta: 1:27:44  lr: 0.003959  min_lr: 0.003959  loss: 3.2182 (3.2182)  weight_decay: 0.0500 (0.0500)  time: 4.2083  data: 3.3910  max mem: 62457
Epoch: [38]  [ 200/1251]  eta: 0:14:34  lr: 0.003959  min_lr: 0.003959  loss: 3.8790 (3.6624)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6629 (0.7991)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [38]  [ 400/1251]  eta: 0:11:40  lr: 0.003958  min_lr: 0.003958  loss: 3.5961 (3.6579)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0623 (0.8861)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [38]  [ 600/1251]  eta: 0:08:54  lr: 0.003957  min_lr: 0.003957  loss: 3.9972 (3.6917)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6363 (0.8170)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [38]  [ 800/1251]  eta: 0:06:09  lr: 0.003956  min_lr: 0.003956  loss: 3.6280 (3.6864)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6147 (0.8351)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [38]  [1000/1251]  eta: 0:03:25  lr: 0.003956  min_lr: 0.003956  loss: 3.7109 (3.6758)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7334 (0.8280)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [38]  [1200/1251]  eta: 0:00:41  lr: 0.003955  min_lr: 0.003955  loss: 3.7666 (3.6653)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5023 (0.8089)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [38]  [1250/1251]  eta: 0:00:00  lr: 0.003955  min_lr: 0.003955  loss: 3.9283 (3.6611)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7031 (0.8257)  time: 0.6914  data: 0.0005  max mem: 62457
Epoch: [38] Total time: 0:17:01 (0.8169 s / it)
Averaged stats: lr: 0.003955  min_lr: 0.003955  loss: 3.9283 (3.6492)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7031 (0.8257)
Test:  [ 0/25]  eta: 0:03:17  loss: 0.8384 (0.8384)  acc1: 84.8000 (84.8000)  acc5: 97.2000 (97.2000)  time: 7.9188  data: 7.4334  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.0328 (1.0748)  acc1: 80.8000 (79.2727)  acc5: 96.4000 (95.5273)  time: 1.1249  data: 0.6760  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.3104 (1.2658)  acc1: 72.4000 (74.8000)  acc5: 92.8000 (93.2762)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3309 (1.2729)  acc1: 71.2000 (74.5600)  acc5: 91.6000 (93.1200)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7495 s / it)
* Acc@1 75.314 Acc@5 93.264 loss 1.257
Accuracy of the model on the 50000 test images: 75.3%
Max accuracy: 75.31%
Epoch: [39]  [   0/1251]  eta: 1:27:32  lr: 0.003955  min_lr: 0.003955  loss: 3.4947 (3.4947)  weight_decay: 0.0500 (0.0500)  time: 4.1987  data: 3.3784  max mem: 62457
Epoch: [39]  [ 200/1251]  eta: 0:14:33  lr: 0.003954  min_lr: 0.003954  loss: 3.6428 (3.6569)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7448 (0.8921)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [39]  [ 400/1251]  eta: 0:11:41  lr: 0.003953  min_lr: 0.003953  loss: 3.8579 (3.6540)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7748 (0.8859)  time: 0.8137  data: 0.0004  max mem: 62457
Epoch: [39]  [ 600/1251]  eta: 0:08:54  lr: 0.003952  min_lr: 0.003952  loss: 3.4700 (3.6601)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1786 (0.8960)  time: 0.8134  data: 0.0004  max mem: 62457
Epoch: [39]  [ 800/1251]  eta: 0:06:09  lr: 0.003952  min_lr: 0.003952  loss: 3.6155 (3.6502)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7979 (0.8869)  time: 0.8139  data: 0.0005  max mem: 62457
Epoch: [39]  [1000/1251]  eta: 0:03:25  lr: 0.003951  min_lr: 0.003951  loss: 3.5311 (3.6489)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9296 (0.9255)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [39]  [1200/1251]  eta: 0:00:41  lr: 0.003950  min_lr: 0.003950  loss: 3.7359 (3.6444)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8847 (0.9157)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [39]  [1250/1251]  eta: 0:00:00  lr: 0.003950  min_lr: 0.003950  loss: 3.4641 (3.6429)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6222 (0.9053)  time: 0.6911  data: 0.0005  max mem: 62457
Epoch: [39] Total time: 0:17:01 (0.8163 s / it)
Averaged stats: lr: 0.003950  min_lr: 0.003950  loss: 3.4641 (3.6377)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6222 (0.9053)
Test:  [ 0/25]  eta: 0:03:05  loss: 0.8066 (0.8066)  acc1: 84.0000 (84.0000)  acc5: 98.4000 (98.4000)  time: 7.4336  data: 6.9565  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8879 (0.9756)  acc1: 78.4000 (79.3091)  acc5: 96.4000 (95.8909)  time: 1.0808  data: 0.6327  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.2206 (1.1835)  acc1: 72.0000 (75.1048)  acc5: 92.4000 (92.8762)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3254 (1.1933)  acc1: 72.0000 (74.8480)  acc5: 90.8000 (92.8000)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7296 s / it)
* Acc@1 75.642 Acc@5 93.292 loss 1.178
Accuracy of the model on the 50000 test images: 75.6%
Max accuracy: 75.64%
Epoch: [40]  [   0/1251]  eta: 1:27:50  lr: 0.003950  min_lr: 0.003950  loss: 2.9544 (2.9544)  weight_decay: 0.0500 (0.0500)  time: 4.2132  data: 3.3849  max mem: 62457
Epoch: [40]  [ 200/1251]  eta: 0:14:35  lr: 0.003949  min_lr: 0.003949  loss: 3.7996 (3.6353)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2494 (0.9989)  time: 0.8221  data: 0.0004  max mem: 62457
Epoch: [40]  [ 400/1251]  eta: 0:11:41  lr: 0.003948  min_lr: 0.003948  loss: 3.4804 (3.6276)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6103 (0.9304)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [40]  [ 600/1251]  eta: 0:08:54  lr: 0.003947  min_lr: 0.003947  loss: 3.6761 (3.6261)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8177  data: 0.0004  max mem: 62457
Epoch: [40]  [ 800/1251]  eta: 0:06:09  lr: 0.003947  min_lr: 0.003947  loss: 3.8274 (3.6349)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7702 (nan)  time: 0.8191  data: 0.0004  max mem: 62457
Epoch: [40]  [1000/1251]  eta: 0:03:25  lr: 0.003946  min_lr: 0.003946  loss: 3.7773 (3.6292)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5677 (nan)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [40]  [1200/1251]  eta: 0:00:41  lr: 0.003945  min_lr: 0.003945  loss: 3.9005 (3.6397)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7491 (nan)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [40]  [1250/1251]  eta: 0:00:00  lr: 0.003945  min_lr: 0.003945  loss: 3.6531 (3.6375)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6004 (nan)  time: 0.6913  data: 0.0006  max mem: 62457
Epoch: [40] Total time: 0:17:01 (0.8164 s / it)
Averaged stats: lr: 0.003945  min_lr: 0.003945  loss: 3.6531 (3.6332)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6004 (nan)
Test:  [ 0/25]  eta: 0:03:20  loss: 0.8930 (0.8930)  acc1: 84.8000 (84.8000)  acc5: 96.4000 (96.4000)  time: 8.0062  data: 7.5264  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9940 (1.0292)  acc1: 80.4000 (79.7818)  acc5: 95.6000 (95.8182)  time: 1.1327  data: 0.6845  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.2567 (1.2243)  acc1: 72.4000 (75.5238)  acc5: 93.6000 (93.1429)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3903 (1.2351)  acc1: 72.4000 (75.2000)  acc5: 90.8000 (93.0080)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7519 s / it)
* Acc@1 75.702 Acc@5 93.326 loss 1.225
Accuracy of the model on the 50000 test images: 75.7%
Max accuracy: 75.70%
Epoch: [41]  [   0/1251]  eta: 1:32:17  lr: 0.003945  min_lr: 0.003945  loss: 3.7828 (3.7828)  weight_decay: 0.0500 (0.0500)  time: 4.4261  data: 3.6167  max mem: 62457
Epoch: [41]  [ 200/1251]  eta: 0:14:37  lr: 0.003944  min_lr: 0.003944  loss: 3.6538 (3.5584)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7119 (0.9438)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [41]  [ 400/1251]  eta: 0:11:41  lr: 0.003943  min_lr: 0.003943  loss: 3.7882 (3.6029)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8013 (0.9841)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [41]  [ 600/1251]  eta: 0:08:54  lr: 0.003942  min_lr: 0.003942  loss: 3.6731 (3.5903)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7885 (0.9074)  time: 0.8239  data: 0.0004  max mem: 62457
Epoch: [41]  [ 800/1251]  eta: 0:06:09  lr: 0.003941  min_lr: 0.003941  loss: 3.5937 (3.5967)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9034 (0.8960)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [41]  [1000/1251]  eta: 0:03:25  lr: 0.003940  min_lr: 0.003940  loss: 3.3212 (3.5936)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2743 (0.9241)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [41]  [1200/1251]  eta: 0:00:41  lr: 0.003940  min_lr: 0.003940  loss: 3.6752 (3.5957)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6359 (0.8959)  time: 0.8240  data: 0.0004  max mem: 62457
Epoch: [41]  [1250/1251]  eta: 0:00:00  lr: 0.003939  min_lr: 0.003939  loss: 3.8663 (3.5970)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6047 (0.8874)  time: 0.6911  data: 0.0006  max mem: 62457
Epoch: [41] Total time: 0:17:02 (0.8171 s / it)
Averaged stats: lr: 0.003939  min_lr: 0.003939  loss: 3.8663 (3.6116)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6047 (0.8874)
Test:  [ 0/25]  eta: 0:02:40  loss: 0.8520 (0.8520)  acc1: 85.2000 (85.2000)  acc5: 98.8000 (98.8000)  time: 6.4192  data: 5.9226  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9829 (1.0307)  acc1: 80.0000 (80.0364)  acc5: 96.0000 (95.9636)  time: 1.0697  data: 0.6204  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.2439 (1.2394)  acc1: 72.0000 (75.5048)  acc5: 93.2000 (93.2952)  time: 0.4897  data: 0.0451  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.4095 (1.2491)  acc1: 72.0000 (75.1840)  acc5: 91.2000 (93.1520)  time: 0.4447  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7239 s / it)
* Acc@1 75.842 Acc@5 93.292 loss 1.227
Accuracy of the model on the 50000 test images: 75.8%
Max accuracy: 75.84%
Epoch: [42]  [   0/1251]  eta: 1:21:28  lr: 0.003939  min_lr: 0.003939  loss: 3.8866 (3.8866)  weight_decay: 0.0500 (0.0500)  time: 3.9079  data: 3.0903  max mem: 62457
Epoch: [42]  [ 200/1251]  eta: 0:14:31  lr: 0.003939  min_lr: 0.003939  loss: 3.7011 (3.6400)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8057 (0.9356)  time: 0.8139  data: 0.0005  max mem: 62457
Epoch: [42]  [ 400/1251]  eta: 0:11:39  lr: 0.003938  min_lr: 0.003938  loss: 3.6821 (3.6190)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8698 (0.9386)  time: 0.8143  data: 0.0005  max mem: 62457
Epoch: [42]  [ 600/1251]  eta: 0:08:54  lr: 0.003937  min_lr: 0.003937  loss: 3.3824 (3.6130)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7318 (0.9485)  time: 0.8224  data: 0.0005  max mem: 62457
Epoch: [42]  [ 800/1251]  eta: 0:06:09  lr: 0.003936  min_lr: 0.003936  loss: 3.4749 (3.6195)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9720 (0.9628)  time: 0.8136  data: 0.0004  max mem: 62457
Epoch: [42]  [1000/1251]  eta: 0:03:25  lr: 0.003935  min_lr: 0.003935  loss: 3.7406 (3.6191)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7044 (0.9560)  time: 0.8176  data: 0.0005  max mem: 62457
Epoch: [42]  [1200/1251]  eta: 0:00:41  lr: 0.003934  min_lr: 0.003934  loss: 3.5476 (3.6258)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6384 (0.9727)  time: 0.8142  data: 0.0005  max mem: 62457
Epoch: [42]  [1250/1251]  eta: 0:00:00  lr: 0.003934  min_lr: 0.003934  loss: 3.9462 (3.6326)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7073 (0.9651)  time: 0.6917  data: 0.0006  max mem: 62457
Epoch: [42] Total time: 0:17:01 (0.8163 s / it)
Averaged stats: lr: 0.003934  min_lr: 0.003934  loss: 3.9462 (3.6115)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7073 (0.9651)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.8683 (0.8683)  acc1: 85.2000 (85.2000)  acc5: 98.8000 (98.8000)  time: 7.7838  data: 7.3032  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.0152 (1.0720)  acc1: 80.8000 (80.4727)  acc5: 96.0000 (95.7455)  time: 1.1125  data: 0.6642  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.2508 (1.2634)  acc1: 73.2000 (75.7714)  acc5: 93.2000 (93.1810)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3889 (1.2668)  acc1: 73.2000 (75.5360)  acc5: 91.6000 (93.1680)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7432 s / it)
* Acc@1 75.710 Acc@5 93.382 loss 1.251
Accuracy of the model on the 50000 test images: 75.7%
Max accuracy: 75.84%
Epoch: [43]  [   0/1251]  eta: 1:48:59  lr: 0.003934  min_lr: 0.003934  loss: 3.6153 (3.6153)  weight_decay: 0.0500 (0.0500)  time: 5.2277  data: 3.0343  max mem: 62457
Epoch: [43]  [ 200/1251]  eta: 0:14:39  lr: 0.003933  min_lr: 0.003933  loss: 3.4602 (3.5445)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0610 (0.8854)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [43]  [ 400/1251]  eta: 0:11:44  lr: 0.003932  min_lr: 0.003932  loss: 3.7896 (3.5923)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8153 (0.9100)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [43]  [ 600/1251]  eta: 0:08:55  lr: 0.003931  min_lr: 0.003931  loss: 3.7966 (3.5912)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5928 (0.9088)  time: 0.8145  data: 0.0003  max mem: 62457
Epoch: [43]  [ 800/1251]  eta: 0:06:10  lr: 0.003930  min_lr: 0.003930  loss: 3.7362 (3.5898)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7699 (0.9400)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [43]  [1000/1251]  eta: 0:03:25  lr: 0.003929  min_lr: 0.003929  loss: 3.7185 (3.5816)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7861 (0.9580)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [43]  [1200/1251]  eta: 0:00:41  lr: 0.003928  min_lr: 0.003928  loss: 3.9364 (3.5885)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9883 (0.9746)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [43]  [1250/1251]  eta: 0:00:00  lr: 0.003928  min_lr: 0.003928  loss: 3.4526 (3.5861)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0202 (0.9801)  time: 0.6919  data: 0.0005  max mem: 62457
Epoch: [43] Total time: 0:17:03 (0.8179 s / it)
Averaged stats: lr: 0.003928  min_lr: 0.003928  loss: 3.4526 (3.5916)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0202 (0.9801)
Test:  [ 0/25]  eta: 0:03:19  loss: 0.8173 (0.8173)  acc1: 85.2000 (85.2000)  acc5: 98.4000 (98.4000)  time: 7.9610  data: 7.4846  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9930 (1.0231)  acc1: 78.4000 (79.3091)  acc5: 96.8000 (96.0000)  time: 1.1288  data: 0.6807  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.2630 (1.2054)  acc1: 72.4000 (75.1048)  acc5: 92.8000 (93.2762)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3306 (1.2230)  acc1: 72.8000 (74.7360)  acc5: 91.6000 (93.1200)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7500 s / it)
* Acc@1 75.950 Acc@5 93.464 loss 1.195
Accuracy of the model on the 50000 test images: 76.0%
Max accuracy: 75.95%
Epoch: [44]  [   0/1251]  eta: 1:32:17  lr: 0.003928  min_lr: 0.003928  loss: 3.5311 (3.5311)  weight_decay: 0.0500 (0.0500)  time: 4.4267  data: 3.6006  max mem: 62457
Epoch: [44]  [ 200/1251]  eta: 0:14:36  lr: 0.003927  min_lr: 0.003927  loss: 3.8161 (3.5864)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6858 (0.9149)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [44]  [ 400/1251]  eta: 0:11:42  lr: 0.003926  min_lr: 0.003926  loss: 3.6448 (3.6042)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7602 (0.9886)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [44]  [ 600/1251]  eta: 0:08:54  lr: 0.003925  min_lr: 0.003925  loss: 3.8064 (3.6021)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0865 (1.0145)  time: 0.8142  data: 0.0005  max mem: 62457
Epoch: [44]  [ 800/1251]  eta: 0:06:10  lr: 0.003924  min_lr: 0.003924  loss: 3.9011 (3.6024)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8947 (1.0187)  time: 0.8214  data: 0.0005  max mem: 62457
Epoch: [44]  [1000/1251]  eta: 0:03:25  lr: 0.003923  min_lr: 0.003923  loss: 3.7521 (3.5989)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7670 (0.9814)  time: 0.8151  data: 0.0005  max mem: 62457
Epoch: [44]  [1200/1251]  eta: 0:00:41  lr: 0.003922  min_lr: 0.003922  loss: 3.5795 (3.5937)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0179 (nan)  time: 0.8141  data: 0.0005  max mem: 62457
Epoch: [44]  [1250/1251]  eta: 0:00:00  lr: 0.003922  min_lr: 0.003922  loss: 3.4670 (3.5947)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0179 (nan)  time: 0.6919  data: 0.0006  max mem: 62457
Epoch: [44] Total time: 0:17:02 (0.8172 s / it)
Averaged stats: lr: 0.003922  min_lr: 0.003922  loss: 3.4670 (3.5897)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0179 (nan)
Test:  [ 0/25]  eta: 0:03:16  loss: 0.7924 (0.7924)  acc1: 85.2000 (85.2000)  acc5: 96.4000 (96.4000)  time: 7.8651  data: 7.4049  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9345 (0.9636)  acc1: 80.4000 (79.8545)  acc5: 96.4000 (95.9636)  time: 1.1217  data: 0.6735  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1931 (1.1533)  acc1: 73.6000 (75.7905)  acc5: 92.8000 (93.3333)  time: 0.4464  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2817 (1.1690)  acc1: 73.2000 (75.4560)  acc5: 91.2000 (93.1840)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7467 s / it)
* Acc@1 76.324 Acc@5 93.634 loss 1.145
Accuracy of the model on the 50000 test images: 76.3%
Max accuracy: 76.32%
Epoch: [45]  [   0/1251]  eta: 1:29:22  lr: 0.003922  min_lr: 0.003922  loss: 4.2315 (4.2315)  weight_decay: 0.0500 (0.0500)  time: 4.2862  data: 3.4710  max mem: 62457
Epoch: [45]  [ 200/1251]  eta: 0:14:37  lr: 0.003921  min_lr: 0.003921  loss: 3.6939 (3.5867)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6689 (0.9999)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [45]  [ 400/1251]  eta: 0:11:42  lr: 0.003920  min_lr: 0.003920  loss: 3.8816 (3.5757)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9795 (1.0163)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [45]  [ 600/1251]  eta: 0:08:55  lr: 0.003919  min_lr: 0.003919  loss: 3.6544 (3.5730)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9843 (1.0367)  time: 0.8222  data: 0.0005  max mem: 62457
Epoch: [45]  [ 800/1251]  eta: 0:06:10  lr: 0.003918  min_lr: 0.003918  loss: 3.8313 (3.5892)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6377 (1.0417)  time: 0.8150  data: 0.0005  max mem: 62457
Epoch: [45]  [1000/1251]  eta: 0:03:25  lr: 0.003917  min_lr: 0.003917  loss: 3.5147 (3.5958)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6962 (1.0173)  time: 0.8151  data: 0.0005  max mem: 62457
Epoch: [45]  [1200/1251]  eta: 0:00:41  lr: 0.003916  min_lr: 0.003916  loss: 3.8066 (3.5945)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0175 (1.0306)  time: 0.8191  data: 0.0005  max mem: 62457
Epoch: [45]  [1250/1251]  eta: 0:00:00  lr: 0.003916  min_lr: 0.003916  loss: 3.6104 (3.5903)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9701 (1.0265)  time: 0.6921  data: 0.0005  max mem: 62457
Epoch: [45] Total time: 0:17:03 (0.8181 s / it)
Averaged stats: lr: 0.003916  min_lr: 0.003916  loss: 3.6104 (3.5836)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9701 (1.0265)
Test:  [ 0/25]  eta: 0:03:17  loss: 0.7832 (0.7832)  acc1: 85.6000 (85.6000)  acc5: 96.8000 (96.8000)  time: 7.8825  data: 7.4105  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9336 (0.9600)  acc1: 81.2000 (79.7091)  acc5: 96.0000 (95.8182)  time: 1.1216  data: 0.6739  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1249 (1.1444)  acc1: 73.2000 (75.6952)  acc5: 92.8000 (93.4667)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2586 (1.1500)  acc1: 73.2000 (75.4240)  acc5: 92.4000 (93.4080)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7469 s / it)
* Acc@1 76.324 Acc@5 93.698 loss 1.127
Accuracy of the model on the 50000 test images: 76.3%
Max accuracy: 76.32%
Epoch: [46]  [   0/1251]  eta: 1:39:35  lr: 0.003916  min_lr: 0.003916  loss: 3.8218 (3.8218)  weight_decay: 0.0500 (0.0500)  time: 4.7768  data: 2.9890  max mem: 62457
Epoch: [46]  [ 200/1251]  eta: 0:14:37  lr: 0.003914  min_lr: 0.003914  loss: 3.5137 (3.5951)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7574 (0.9594)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [46]  [ 400/1251]  eta: 0:11:41  lr: 0.003913  min_lr: 0.003913  loss: 3.4802 (3.5806)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7890 (0.9459)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [46]  [ 600/1251]  eta: 0:08:55  lr: 0.003912  min_lr: 0.003912  loss: 3.5687 (3.5793)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3250 (1.0487)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [46]  [ 800/1251]  eta: 0:06:10  lr: 0.003911  min_lr: 0.003911  loss: 3.6236 (3.5823)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8604 (1.0094)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [46]  [1000/1251]  eta: 0:03:25  lr: 0.003910  min_lr: 0.003910  loss: 3.8000 (3.5908)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8972 (1.0317)  time: 0.8220  data: 0.0004  max mem: 62457
Epoch: [46]  [1200/1251]  eta: 0:00:41  lr: 0.003909  min_lr: 0.003909  loss: 3.3663 (3.5937)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9192 (1.0608)  time: 0.8181  data: 0.0004  max mem: 62457
Epoch: [46]  [1250/1251]  eta: 0:00:00  lr: 0.003909  min_lr: 0.003909  loss: 3.8559 (3.5983)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8661 (1.0603)  time: 0.6915  data: 0.0006  max mem: 62457
Epoch: [46] Total time: 0:17:02 (0.8172 s / it)
Averaged stats: lr: 0.003909  min_lr: 0.003909  loss: 3.8559 (3.5766)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8661 (1.0603)
Test:  [ 0/25]  eta: 0:02:58  loss: 0.8970 (0.8970)  acc1: 84.4000 (84.4000)  acc5: 98.0000 (98.0000)  time: 7.1309  data: 6.6647  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 1.0211 (1.0623)  acc1: 80.8000 (79.7818)  acc5: 96.4000 (95.8909)  time: 1.0536  data: 0.6062  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.2515 (1.2370)  acc1: 72.8000 (75.9429)  acc5: 93.2000 (93.5048)  time: 0.4456  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3515 (1.2476)  acc1: 72.8000 (75.6640)  acc5: 93.2000 (93.4240)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7171 s / it)
* Acc@1 76.104 Acc@5 93.642 loss 1.238
Accuracy of the model on the 50000 test images: 76.1%
Max accuracy: 76.32%
Epoch: [47]  [   0/1251]  eta: 1:38:07  lr: 0.003909  min_lr: 0.003909  loss: 4.1921 (4.1921)  weight_decay: 0.0500 (0.0500)  time: 4.7064  data: 2.0616  max mem: 62457
Epoch: [47]  [ 200/1251]  eta: 0:14:37  lr: 0.003908  min_lr: 0.003908  loss: 3.6696 (3.6017)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0738 (1.1697)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [47]  [ 400/1251]  eta: 0:11:43  lr: 0.003907  min_lr: 0.003907  loss: 3.6726 (3.5798)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2702 (1.1044)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [47]  [ 600/1251]  eta: 0:08:55  lr: 0.003906  min_lr: 0.003906  loss: 3.7690 (3.5570)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7542 (1.0367)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [47]  [ 800/1251]  eta: 0:06:10  lr: 0.003905  min_lr: 0.003905  loss: 3.3864 (3.5569)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4940 (1.0138)  time: 0.8146  data: 0.0005  max mem: 62457
Epoch: [47]  [1000/1251]  eta: 0:03:25  lr: 0.003904  min_lr: 0.003904  loss: 3.6350 (3.5619)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7804 (1.0061)  time: 0.8151  data: 0.0005  max mem: 62457
Epoch: [47]  [1200/1251]  eta: 0:00:41  lr: 0.003902  min_lr: 0.003902  loss: 3.6341 (3.5642)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7287 (1.0302)  time: 0.8155  data: 0.0005  max mem: 62457
Epoch: [47]  [1250/1251]  eta: 0:00:00  lr: 0.003902  min_lr: 0.003902  loss: 3.4430 (3.5617)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9249 (1.0279)  time: 0.6923  data: 0.0007  max mem: 62457
Epoch: [47] Total time: 0:17:03 (0.8180 s / it)
Averaged stats: lr: 0.003902  min_lr: 0.003902  loss: 3.4430 (3.5578)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9249 (1.0279)
Test:  [ 0/25]  eta: 0:03:23  loss: 0.8295 (0.8295)  acc1: 85.2000 (85.2000)  acc5: 97.6000 (97.6000)  time: 8.1382  data: 7.6644  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.9734 (0.9964)  acc1: 78.4000 (79.9636)  acc5: 96.4000 (96.0000)  time: 1.1448  data: 0.6970  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.1730 (1.1970)  acc1: 74.0000 (76.0000)  acc5: 92.4000 (93.3905)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2754 (1.2071)  acc1: 74.0000 (75.6160)  acc5: 92.4000 (93.3280)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7577 s / it)
* Acc@1 76.354 Acc@5 93.634 loss 1.186
Accuracy of the model on the 50000 test images: 76.4%
Max accuracy: 76.35%
Epoch: [48]  [   0/1251]  eta: 1:23:27  lr: 0.003902  min_lr: 0.003902  loss: 2.9311 (2.9311)  weight_decay: 0.0500 (0.0500)  time: 4.0026  data: 3.1782  max mem: 62457
Epoch: [48]  [ 200/1251]  eta: 0:14:35  lr: 0.003901  min_lr: 0.003901  loss: 3.7482 (3.5344)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2926 (1.0701)  time: 0.8205  data: 0.0004  max mem: 62457
Epoch: [48]  [ 400/1251]  eta: 0:11:40  lr: 0.003900  min_lr: 0.003900  loss: 3.7244 (3.5205)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1286 (1.0726)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [48]  [ 600/1251]  eta: 0:08:54  lr: 0.003899  min_lr: 0.003899  loss: 3.8459 (3.5541)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8034 (1.0948)  time: 0.8139  data: 0.0005  max mem: 62457
Epoch: [48]  [ 800/1251]  eta: 0:06:09  lr: 0.003898  min_lr: 0.003898  loss: 3.7008 (3.5532)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9020 (1.0414)  time: 0.8140  data: 0.0005  max mem: 62457
Epoch: [48]  [1000/1251]  eta: 0:03:25  lr: 0.003897  min_lr: 0.003897  loss: 3.5177 (3.5520)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8614 (1.0711)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [48]  [1200/1251]  eta: 0:00:41  lr: 0.003895  min_lr: 0.003895  loss: 3.7078 (3.5518)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0888 (1.0612)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [48]  [1250/1251]  eta: 0:00:00  lr: 0.003895  min_lr: 0.003895  loss: 3.4383 (3.5510)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9670 (1.0562)  time: 0.6919  data: 0.0005  max mem: 62457
Epoch: [48] Total time: 0:17:01 (0.8162 s / it)
Averaged stats: lr: 0.003895  min_lr: 0.003895  loss: 3.4383 (3.5565)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9670 (1.0562)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.7073 (0.7073)  acc1: 86.0000 (86.0000)  acc5: 98.4000 (98.4000)  time: 7.7936  data: 7.3117  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8257 (0.8917)  acc1: 82.8000 (80.9818)  acc5: 97.2000 (96.3636)  time: 1.1136  data: 0.6650  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0973 (1.0939)  acc1: 74.4000 (76.6857)  acc5: 93.6000 (93.8286)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2481 (1.1071)  acc1: 73.6000 (76.2400)  acc5: 92.8000 (93.7920)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7436 s / it)
* Acc@1 77.134 Acc@5 93.822 loss 1.092
Accuracy of the model on the 50000 test images: 77.1%
Max accuracy: 77.13%
Epoch: [49]  [   0/1251]  eta: 1:25:59  lr: 0.003895  min_lr: 0.003895  loss: 2.9867 (2.9867)  weight_decay: 0.0500 (0.0500)  time: 4.1242  data: 3.3078  max mem: 62457
Epoch: [49]  [ 200/1251]  eta: 0:14:36  lr: 0.003894  min_lr: 0.003894  loss: 3.5847 (3.6042)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6324 (0.8896)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [49]  [ 400/1251]  eta: 0:11:41  lr: 0.003893  min_lr: 0.003893  loss: 3.7046 (3.5829)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9652 (1.0676)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [49]  [ 600/1251]  eta: 0:08:54  lr: 0.003892  min_lr: 0.003892  loss: 3.8023 (3.5981)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6081 (1.0792)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [49]  [ 800/1251]  eta: 0:06:09  lr: 0.003890  min_lr: 0.003890  loss: 3.5087 (3.5882)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0902 (1.0766)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [49]  [1000/1251]  eta: 0:03:25  lr: 0.003889  min_lr: 0.003889  loss: 3.8354 (3.5940)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2312 (1.1080)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [49]  [1200/1251]  eta: 0:00:41  lr: 0.003888  min_lr: 0.003888  loss: 3.5338 (3.5832)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8739 (1.0883)  time: 0.8190  data: 0.0005  max mem: 62457
Epoch: [49]  [1250/1251]  eta: 0:00:00  lr: 0.003888  min_lr: 0.003888  loss: 3.6431 (3.5818)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0806 (1.0956)  time: 0.6914  data: 0.0006  max mem: 62457
Epoch: [49] Total time: 0:17:02 (0.8171 s / it)
Averaged stats: lr: 0.003888  min_lr: 0.003888  loss: 3.6431 (3.5503)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0806 (1.0956)
Test:  [ 0/25]  eta: 0:03:20  loss: 0.8169 (0.8169)  acc1: 84.0000 (84.0000)  acc5: 98.0000 (98.0000)  time: 8.0217  data: 7.5456  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.9821 (0.9983)  acc1: 80.0000 (80.4364)  acc5: 96.4000 (96.3636)  time: 1.1340  data: 0.6863  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.1672 (1.1896)  acc1: 73.6000 (76.5714)  acc5: 94.0000 (93.6381)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2991 (1.1968)  acc1: 73.6000 (76.1600)  acc5: 92.4000 (93.6800)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7530 s / it)
* Acc@1 76.740 Acc@5 93.824 loss 1.181
Accuracy of the model on the 50000 test images: 76.7%
Max accuracy: 77.13%
Epoch: [50]  [   0/1251]  eta: 1:34:47  lr: 0.003888  min_lr: 0.003888  loss: 3.7222 (3.7222)  weight_decay: 0.0500 (0.0500)  time: 4.5463  data: 3.2458  max mem: 62457
Epoch: [50]  [ 200/1251]  eta: 0:14:36  lr: 0.003887  min_lr: 0.003887  loss: 3.7083 (3.4904)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1385 (1.1735)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [50]  [ 400/1251]  eta: 0:11:41  lr: 0.003885  min_lr: 0.003885  loss: 3.6165 (3.5011)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3345 (1.1258)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [50]  [ 600/1251]  eta: 0:08:54  lr: 0.003884  min_lr: 0.003884  loss: 3.7791 (3.4991)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0207 (1.1118)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [50]  [ 800/1251]  eta: 0:06:09  lr: 0.003883  min_lr: 0.003883  loss: 3.4692 (3.5134)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0753 (1.1452)  time: 0.8142  data: 0.0005  max mem: 62457
Epoch: [50]  [1000/1251]  eta: 0:03:25  lr: 0.003882  min_lr: 0.003882  loss: 3.9384 (3.5172)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7998 (1.1239)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [50]  [1200/1251]  eta: 0:00:41  lr: 0.003881  min_lr: 0.003881  loss: 3.4731 (3.5202)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3658 (1.1481)  time: 0.8149  data: 0.0005  max mem: 62457
Epoch: [50]  [1250/1251]  eta: 0:00:00  lr: 0.003880  min_lr: 0.003880  loss: 3.5429 (3.5199)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8439 (1.1432)  time: 0.6971  data: 0.0006  max mem: 62457
Epoch: [50] Total time: 0:17:02 (0.8171 s / it)
Averaged stats: lr: 0.003880  min_lr: 0.003880  loss: 3.5429 (3.5359)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8439 (1.1432)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.7722 (0.7722)  acc1: 86.8000 (86.8000)  acc5: 98.8000 (98.8000)  time: 7.7996  data: 7.3277  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9799 (0.9805)  acc1: 78.4000 (80.8000)  acc5: 96.8000 (96.3273)  time: 1.1139  data: 0.6664  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1821 (1.1607)  acc1: 73.6000 (76.6667)  acc5: 92.4000 (93.9238)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2979 (1.1697)  acc1: 73.2000 (76.3520)  acc5: 92.4000 (93.9200)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7436 s / it)
* Acc@1 76.976 Acc@5 94.138 loss 1.150
Accuracy of the model on the 50000 test images: 77.0%
Max accuracy: 77.13%
Epoch: [51]  [   0/1251]  eta: 1:39:28  lr: 0.003880  min_lr: 0.003880  loss: 3.6335 (3.6335)  weight_decay: 0.0500 (0.0500)  time: 4.7708  data: 3.0880  max mem: 62457
Epoch: [51]  [ 200/1251]  eta: 0:14:37  lr: 0.003879  min_lr: 0.003879  loss: 3.7063 (3.4921)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8366 (1.0349)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [51]  [ 400/1251]  eta: 0:11:42  lr: 0.003878  min_lr: 0.003878  loss: 3.6636 (3.5468)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7901 (1.1094)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [51]  [ 600/1251]  eta: 0:08:55  lr: 0.003877  min_lr: 0.003877  loss: 3.7551 (3.5254)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4597 (1.1392)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [51]  [ 800/1251]  eta: 0:06:09  lr: 0.003875  min_lr: 0.003875  loss: 3.6405 (3.5310)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7624 (1.1716)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [51]  [1000/1251]  eta: 0:03:25  lr: 0.003874  min_lr: 0.003874  loss: 3.5235 (3.5292)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9928 (1.1486)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [51]  [1200/1251]  eta: 0:00:41  lr: 0.003873  min_lr: 0.003873  loss: 3.7275 (3.5295)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7960 (1.1235)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [51]  [1250/1251]  eta: 0:00:00  lr: 0.003873  min_lr: 0.003873  loss: 3.5899 (3.5300)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8655 (1.1255)  time: 0.6917  data: 0.0005  max mem: 62457
Epoch: [51] Total time: 0:17:02 (0.8171 s / it)
Averaged stats: lr: 0.003873  min_lr: 0.003873  loss: 3.5899 (3.5311)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8655 (1.1255)
Test:  [ 0/25]  eta: 0:03:20  loss: 0.8064 (0.8064)  acc1: 84.4000 (84.4000)  acc5: 98.4000 (98.4000)  time: 8.0213  data: 7.5579  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.9369 (0.9809)  acc1: 79.2000 (79.8909)  acc5: 96.4000 (96.4364)  time: 1.1345  data: 0.6874  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.1694 (1.1440)  acc1: 74.0000 (76.3429)  acc5: 94.4000 (93.9429)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2487 (1.1544)  acc1: 73.6000 (76.1280)  acc5: 92.4000 (93.7280)  time: 0.4446  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7531 s / it)
* Acc@1 76.886 Acc@5 93.934 loss 1.142
Accuracy of the model on the 50000 test images: 76.9%
Max accuracy: 77.13%
Epoch: [52]  [   0/1251]  eta: 1:44:18  lr: 0.003873  min_lr: 0.003873  loss: 3.4742 (3.4742)  weight_decay: 0.0500 (0.0500)  time: 5.0032  data: 4.1764  max mem: 62457
Epoch: [52]  [ 200/1251]  eta: 0:14:39  lr: 0.003871  min_lr: 0.003871  loss: 3.8941 (3.5425)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0691 (1.3514)  time: 0.8223  data: 0.0005  max mem: 62457
Epoch: [52]  [ 400/1251]  eta: 0:11:43  lr: 0.003870  min_lr: 0.003870  loss: 3.6356 (3.5596)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1074 (nan)  time: 0.8145  data: 0.0005  max mem: 62457
Epoch: [52]  [ 600/1251]  eta: 0:08:55  lr: 0.003869  min_lr: 0.003869  loss: 3.7236 (3.5646)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0956 (nan)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [52]  [ 800/1251]  eta: 0:06:10  lr: 0.003867  min_lr: 0.003867  loss: 3.5747 (3.5526)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0714 (nan)  time: 0.8140  data: 0.0005  max mem: 62457
Epoch: [52]  [1000/1251]  eta: 0:03:25  lr: 0.003866  min_lr: 0.003866  loss: 3.6359 (3.5338)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7309 (nan)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [52]  [1200/1251]  eta: 0:00:41  lr: 0.003865  min_lr: 0.003865  loss: 3.4424 (3.5313)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8561 (nan)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [52]  [1250/1251]  eta: 0:00:00  lr: 0.003865  min_lr: 0.003865  loss: 3.5108 (3.5281)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7580 (nan)  time: 0.6917  data: 0.0007  max mem: 62457
Epoch: [52] Total time: 0:17:02 (0.8173 s / it)
Averaged stats: lr: 0.003865  min_lr: 0.003865  loss: 3.5108 (3.5164)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7580 (nan)
Test:  [ 0/25]  eta: 0:03:24  loss: 0.7450 (0.7450)  acc1: 85.6000 (85.6000)  acc5: 97.2000 (97.2000)  time: 8.1684  data: 7.6956  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.9217 (0.9458)  acc1: 82.0000 (80.6546)  acc5: 96.4000 (96.1091)  time: 1.1476  data: 0.6999  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.1079 (1.1313)  acc1: 73.6000 (76.6286)  acc5: 93.6000 (93.7714)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2041 (1.1384)  acc1: 74.0000 (76.4640)  acc5: 92.4000 (93.6800)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7584 s / it)
* Acc@1 76.950 Acc@5 94.042 loss 1.121
Accuracy of the model on the 50000 test images: 77.0%
Max accuracy: 77.13%
Epoch: [53]  [   0/1251]  eta: 1:32:27  lr: 0.003865  min_lr: 0.003865  loss: 2.8538 (2.8538)  weight_decay: 0.0500 (0.0500)  time: 4.4342  data: 3.0952  max mem: 62457
Epoch: [53]  [ 200/1251]  eta: 0:14:37  lr: 0.003863  min_lr: 0.003863  loss: 3.6477 (3.5159)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9388 (1.4805)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [53]  [ 400/1251]  eta: 0:11:41  lr: 0.003862  min_lr: 0.003862  loss: 3.7361 (3.5221)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8926 (1.2474)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [53]  [ 600/1251]  eta: 0:08:54  lr: 0.003861  min_lr: 0.003861  loss: 3.2293 (3.5131)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7251 (1.1824)  time: 0.8188  data: 0.0004  max mem: 62457
Epoch: [53]  [ 800/1251]  eta: 0:06:09  lr: 0.003859  min_lr: 0.003859  loss: 3.6793 (3.5163)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8535 (1.1927)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [53]  [1000/1251]  eta: 0:03:25  lr: 0.003858  min_lr: 0.003858  loss: 3.8593 (3.5144)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0942 (1.2081)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [53]  [1200/1251]  eta: 0:00:41  lr: 0.003857  min_lr: 0.003857  loss: 3.7923 (3.5161)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8993 (1.1971)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [53]  [1250/1251]  eta: 0:00:00  lr: 0.003856  min_lr: 0.003856  loss: 3.7843 (3.5202)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8240 (1.1845)  time: 0.6922  data: 0.0005  max mem: 62457
Epoch: [53] Total time: 0:17:02 (0.8171 s / it)
Averaged stats: lr: 0.003856  min_lr: 0.003856  loss: 3.7843 (3.5187)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8240 (1.1845)
Test:  [ 0/25]  eta: 0:03:06  loss: 0.8696 (0.8696)  acc1: 84.8000 (84.8000)  acc5: 97.2000 (97.2000)  time: 7.4789  data: 6.9869  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.0092 (1.0580)  acc1: 80.0000 (80.3636)  acc5: 96.4000 (96.2546)  time: 1.0850  data: 0.6355  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.2168 (1.2268)  acc1: 73.6000 (77.0286)  acc5: 93.2000 (93.7905)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3466 (1.2341)  acc1: 73.6000 (76.6880)  acc5: 92.8000 (93.8080)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7315 s / it)
* Acc@1 76.768 Acc@5 93.976 loss 1.222
Accuracy of the model on the 50000 test images: 76.8%
Max accuracy: 77.13%
Epoch: [54]  [   0/1251]  eta: 1:39:40  lr: 0.003856  min_lr: 0.003856  loss: 3.8446 (3.8446)  weight_decay: 0.0500 (0.0500)  time: 4.7808  data: 2.0399  max mem: 62457
Epoch: [54]  [ 200/1251]  eta: 0:14:37  lr: 0.003855  min_lr: 0.003855  loss: 3.6533 (3.4924)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0768 (1.3056)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [54]  [ 400/1251]  eta: 0:11:42  lr: 0.003854  min_lr: 0.003854  loss: 3.6342 (3.5056)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0103 (1.2617)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [54]  [ 600/1251]  eta: 0:08:55  lr: 0.003852  min_lr: 0.003852  loss: 3.6750 (3.5080)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8652 (1.1982)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [54]  [ 800/1251]  eta: 0:06:10  lr: 0.003851  min_lr: 0.003851  loss: 3.6590 (3.5217)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1432 (1.2056)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [54]  [1000/1251]  eta: 0:03:25  lr: 0.003849  min_lr: 0.003849  loss: 3.5178 (3.5250)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9565 (1.2415)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [54]  [1200/1251]  eta: 0:00:41  lr: 0.003848  min_lr: 0.003848  loss: 3.6193 (3.5170)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0290 (1.2108)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [54]  [1250/1251]  eta: 0:00:00  lr: 0.003848  min_lr: 0.003848  loss: 3.6957 (3.5159)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0738 (1.2114)  time: 0.6917  data: 0.0005  max mem: 62457
Epoch: [54] Total time: 0:17:02 (0.8177 s / it)
Averaged stats: lr: 0.003848  min_lr: 0.003848  loss: 3.6957 (3.5029)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0738 (1.2114)
Test:  [ 0/25]  eta: 0:03:24  loss: 0.8386 (0.8386)  acc1: 86.4000 (86.4000)  acc5: 98.4000 (98.4000)  time: 8.1761  data: 7.7000  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.9716 (1.0147)  acc1: 80.8000 (80.4727)  acc5: 96.8000 (96.7273)  time: 1.1481  data: 0.7003  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.2091 (1.1982)  acc1: 74.8000 (76.4000)  acc5: 93.6000 (94.3619)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.3517 (1.2093)  acc1: 74.8000 (75.9200)  acc5: 92.8000 (94.2560)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7584 s / it)
* Acc@1 76.798 Acc@5 94.306 loss 1.196
Accuracy of the model on the 50000 test images: 76.8%
Max accuracy: 77.13%
Epoch: [55]  [   0/1251]  eta: 1:42:21  lr: 0.003848  min_lr: 0.003848  loss: 3.7596 (3.7596)  weight_decay: 0.0500 (0.0500)  time: 4.9090  data: 2.6950  max mem: 62457
Epoch: [55]  [ 200/1251]  eta: 0:14:38  lr: 0.003846  min_lr: 0.003846  loss: 3.6713 (3.5088)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2554 (1.2843)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [55]  [ 400/1251]  eta: 0:11:43  lr: 0.003845  min_lr: 0.003845  loss: 3.5827 (3.5111)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0598 (1.2397)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [55]  [ 600/1251]  eta: 0:08:55  lr: 0.003844  min_lr: 0.003844  loss: 3.6319 (3.5373)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6591 (1.2209)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [55]  [ 800/1251]  eta: 0:06:10  lr: 0.003842  min_lr: 0.003842  loss: 3.7199 (3.5427)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3131 (1.2564)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [55]  [1000/1251]  eta: 0:03:25  lr: 0.003841  min_lr: 0.003841  loss: 3.4575 (3.5429)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7209 (1.2237)  time: 0.8148  data: 0.0005  max mem: 62457
Epoch: [55]  [1200/1251]  eta: 0:00:41  lr: 0.003839  min_lr: 0.003839  loss: 3.7283 (3.5309)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1972 (1.2083)  time: 0.8155  data: 0.0005  max mem: 62457
Epoch: [55]  [1250/1251]  eta: 0:00:00  lr: 0.003839  min_lr: 0.003839  loss: 3.5281 (3.5289)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2072 (1.2141)  time: 0.6919  data: 0.0007  max mem: 62457
Epoch: [55] Total time: 0:17:03 (0.8181 s / it)
Averaged stats: lr: 0.003839  min_lr: 0.003839  loss: 3.5281 (3.5042)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2072 (1.2141)
Test:  [ 0/25]  eta: 0:03:04  loss: 0.8052 (0.8052)  acc1: 84.8000 (84.8000)  acc5: 98.4000 (98.4000)  time: 7.3972  data: 6.9190  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8992 (0.9669)  acc1: 82.4000 (80.5455)  acc5: 96.8000 (96.6546)  time: 1.0776  data: 0.6293  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1141 (1.1242)  acc1: 76.4000 (76.8381)  acc5: 93.2000 (94.2286)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2230 (1.1365)  acc1: 76.4000 (76.7840)  acc5: 93.2000 (94.1440)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7284 s / it)
* Acc@1 77.086 Acc@5 94.246 loss 1.127
Accuracy of the model on the 50000 test images: 77.1%
Max accuracy: 77.13%
Epoch: [56]  [   0/1251]  eta: 1:37:25  lr: 0.003839  min_lr: 0.003839  loss: 4.1134 (4.1134)  weight_decay: 0.0500 (0.0500)  time: 4.6723  data: 3.4189  max mem: 62457
Epoch: [56]  [ 200/1251]  eta: 0:14:39  lr: 0.003838  min_lr: 0.003838  loss: 3.5421 (3.4548)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9259 (1.2813)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [56]  [ 400/1251]  eta: 0:11:42  lr: 0.003836  min_lr: 0.003836  loss: 3.4113 (3.4900)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8883 (1.2459)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [56]  [ 600/1251]  eta: 0:08:55  lr: 0.003835  min_lr: 0.003835  loss: 3.7159 (3.5129)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7833 (1.2298)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [56]  [ 800/1251]  eta: 0:06:10  lr: 0.003833  min_lr: 0.003833  loss: 3.5827 (3.5087)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7532 (1.2249)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [56]  [1000/1251]  eta: 0:03:25  lr: 0.003832  min_lr: 0.003832  loss: 3.4702 (3.5179)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4032 (1.2222)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [56]  [1200/1251]  eta: 0:00:41  lr: 0.003831  min_lr: 0.003831  loss: 3.7060 (3.5196)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0156 (1.2010)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [56]  [1250/1251]  eta: 0:00:00  lr: 0.003830  min_lr: 0.003830  loss: 3.7972 (3.5209)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0156 (1.2077)  time: 0.6922  data: 0.0005  max mem: 62457
Epoch: [56] Total time: 0:17:02 (0.8177 s / it)
Averaged stats: lr: 0.003830  min_lr: 0.003830  loss: 3.7972 (3.4936)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0156 (1.2077)
Test:  [ 0/25]  eta: 0:03:24  loss: 0.8115 (0.8115)  acc1: 84.8000 (84.8000)  acc5: 98.4000 (98.4000)  time: 8.1948  data: 7.7127  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.9721 (0.9781)  acc1: 81.2000 (81.2727)  acc5: 96.8000 (96.6182)  time: 1.1499  data: 0.7014  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.1986 (1.1679)  acc1: 76.0000 (77.3333)  acc5: 93.6000 (94.0381)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2572 (1.1799)  acc1: 75.6000 (76.8800)  acc5: 93.2000 (93.9680)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7590 s / it)
* Acc@1 77.080 Acc@5 94.148 loss 1.169
Accuracy of the model on the 50000 test images: 77.1%
Max accuracy: 77.13%
Epoch: [57]  [   0/1251]  eta: 1:43:59  lr: 0.003830  min_lr: 0.003830  loss: 3.5305 (3.5305)  weight_decay: 0.0500 (0.0500)  time: 4.9878  data: 3.0292  max mem: 62457
Epoch: [57]  [ 200/1251]  eta: 0:14:40  lr: 0.003829  min_lr: 0.003829  loss: 3.5525 (3.4428)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1288 (1.3141)  time: 0.8151  data: 0.0005  max mem: 62457
Epoch: [57]  [ 400/1251]  eta: 0:11:43  lr: 0.003827  min_lr: 0.003827  loss: 3.4908 (3.4554)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7424 (1.1745)  time: 0.8146  data: 0.0005  max mem: 62457
Epoch: [57]  [ 600/1251]  eta: 0:08:56  lr: 0.003826  min_lr: 0.003826  loss: 3.2087 (3.4775)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9988 (1.2060)  time: 0.8149  data: 0.0005  max mem: 62457
Epoch: [57]  [ 800/1251]  eta: 0:06:10  lr: 0.003824  min_lr: 0.003824  loss: 3.5634 (3.4853)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0213 (1.2073)  time: 0.8143  data: 0.0005  max mem: 62457
Epoch: [57]  [1000/1251]  eta: 0:03:25  lr: 0.003823  min_lr: 0.003823  loss: 3.7148 (3.4951)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3202 (1.2172)  time: 0.8148  data: 0.0005  max mem: 62457
Epoch: [57]  [1200/1251]  eta: 0:00:41  lr: 0.003821  min_lr: 0.003821  loss: 3.4679 (3.4902)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1429 (1.1976)  time: 0.8139  data: 0.0005  max mem: 62457
Epoch: [57]  [1250/1251]  eta: 0:00:00  lr: 0.003821  min_lr: 0.003821  loss: 3.5249 (3.4924)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3810 (1.2049)  time: 0.6914  data: 0.0007  max mem: 62457
Epoch: [57] Total time: 0:17:03 (0.8181 s / it)
Averaged stats: lr: 0.003821  min_lr: 0.003821  loss: 3.5249 (3.4886)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3810 (1.2049)
Test:  [ 0/25]  eta: 0:03:18  loss: 0.7507 (0.7507)  acc1: 84.4000 (84.4000)  acc5: 97.6000 (97.6000)  time: 7.9574  data: 7.4912  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9182 (0.9333)  acc1: 80.0000 (80.5091)  acc5: 96.0000 (96.4727)  time: 1.1280  data: 0.6813  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.1264 (1.1192)  acc1: 74.0000 (77.0857)  acc5: 94.0000 (94.0571)  time: 0.4448  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2648 (1.1362)  acc1: 74.0000 (76.6400)  acc5: 92.8000 (93.9680)  time: 0.4447  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7494 s / it)
* Acc@1 77.194 Acc@5 94.300 loss 1.123
Accuracy of the model on the 50000 test images: 77.2%
Max accuracy: 77.19%
Epoch: [58]  [   0/1251]  eta: 1:25:44  lr: 0.003821  min_lr: 0.003821  loss: 3.4204 (3.4204)  weight_decay: 0.0500 (0.0500)  time: 4.1120  data: 3.2905  max mem: 62457
Epoch: [58]  [ 200/1251]  eta: 0:14:33  lr: 0.003820  min_lr: 0.003820  loss: 3.6614 (3.4464)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6608 (1.3916)  time: 0.8147  data: 0.0005  max mem: 62457
Epoch: [58]  [ 400/1251]  eta: 0:11:40  lr: 0.003818  min_lr: 0.003818  loss: 3.6570 (3.5031)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9125 (1.2485)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [58]  [ 600/1251]  eta: 0:08:54  lr: 0.003817  min_lr: 0.003817  loss: 3.5626 (3.5007)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9516 (1.2961)  time: 0.8147  data: 0.0005  max mem: 62457
Epoch: [58]  [ 800/1251]  eta: 0:06:09  lr: 0.003815  min_lr: 0.003815  loss: 3.5719 (3.5051)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6571 (1.2449)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [58]  [1000/1251]  eta: 0:03:25  lr: 0.003813  min_lr: 0.003813  loss: 3.2768 (3.4958)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6869 (1.2181)  time: 0.8197  data: 0.0005  max mem: 62457
Epoch: [58]  [1200/1251]  eta: 0:00:41  lr: 0.003812  min_lr: 0.003812  loss: 3.6282 (3.5012)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9964 (1.2395)  time: 0.8141  data: 0.0005  max mem: 62457
Epoch: [58]  [1250/1251]  eta: 0:00:00  lr: 0.003812  min_lr: 0.003812  loss: 3.6310 (3.5015)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8049 (1.2274)  time: 0.6917  data: 0.0005  max mem: 62457
Epoch: [58] Total time: 0:17:01 (0.8166 s / it)
Averaged stats: lr: 0.003812  min_lr: 0.003812  loss: 3.6310 (3.4850)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8049 (1.2274)
Test:  [ 0/25]  eta: 0:03:11  loss: 0.7728 (0.7728)  acc1: 83.6000 (83.6000)  acc5: 97.2000 (97.2000)  time: 7.6634  data: 7.1907  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8839 (0.9261)  acc1: 81.6000 (80.8727)  acc5: 97.2000 (96.2546)  time: 1.1013  data: 0.6540  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0995 (1.1038)  acc1: 75.2000 (77.1619)  acc5: 93.2000 (94.1143)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2640 (1.1161)  acc1: 74.8000 (76.8160)  acc5: 92.8000 (94.0640)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7383 s / it)
* Acc@1 77.598 Acc@5 94.350 loss 1.097
Accuracy of the model on the 50000 test images: 77.6%
Max accuracy: 77.60%
Epoch: [59]  [   0/1251]  eta: 1:21:08  lr: 0.003812  min_lr: 0.003812  loss: 3.7596 (3.7596)  weight_decay: 0.0500 (0.0500)  time: 3.8916  data: 3.0781  max mem: 62457
Epoch: [59]  [ 200/1251]  eta: 0:14:31  lr: 0.003810  min_lr: 0.003810  loss: 3.4375 (3.4686)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8161 (1.3017)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [59]  [ 400/1251]  eta: 0:11:40  lr: 0.003809  min_lr: 0.003809  loss: 3.6393 (3.4786)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2253 (1.2334)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [59]  [ 600/1251]  eta: 0:08:54  lr: 0.003807  min_lr: 0.003807  loss: 3.6163 (3.4767)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8901 (1.2555)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [59]  [ 800/1251]  eta: 0:06:09  lr: 0.003805  min_lr: 0.003805  loss: 3.5614 (3.4835)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2144 (1.2425)  time: 0.8191  data: 0.0004  max mem: 62457
Epoch: [59]  [1000/1251]  eta: 0:03:25  lr: 0.003804  min_lr: 0.003804  loss: 3.6490 (3.4795)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0630 (1.2504)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [59]  [1200/1251]  eta: 0:00:41  lr: 0.003802  min_lr: 0.003802  loss: 3.4328 (3.4823)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [59]  [1250/1251]  eta: 0:00:00  lr: 0.003802  min_lr: 0.003802  loss: 3.6061 (3.4789)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.6916  data: 0.0005  max mem: 62457
Epoch: [59] Total time: 0:17:01 (0.8163 s / it)
Averaged stats: lr: 0.003802  min_lr: 0.003802  loss: 3.6061 (3.4838)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:03:23  loss: 0.7289 (0.7289)  acc1: 86.4000 (86.4000)  acc5: 99.2000 (99.2000)  time: 8.1336  data: 7.6578  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.9256 (0.9386)  acc1: 80.8000 (80.8000)  acc5: 96.8000 (96.5091)  time: 1.1440  data: 0.6964  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.1425 (1.1020)  acc1: 74.8000 (77.5238)  acc5: 93.2000 (94.3238)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2327 (1.1217)  acc1: 74.8000 (77.1200)  acc5: 92.4000 (94.0640)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7562 s / it)
* Acc@1 77.338 Acc@5 94.360 loss 1.103
Accuracy of the model on the 50000 test images: 77.3%
Max accuracy: 77.60%
Epoch: [60]  [   0/1251]  eta: 1:43:02  lr: 0.003802  min_lr: 0.003802  loss: 3.6602 (3.6602)  weight_decay: 0.0500 (0.0500)  time: 4.9424  data: 3.1262  max mem: 62457
Epoch: [60]  [ 200/1251]  eta: 0:14:40  lr: 0.003800  min_lr: 0.003800  loss: 3.3177 (3.4728)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7187 (1.2306)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [60]  [ 400/1251]  eta: 0:11:43  lr: 0.003799  min_lr: 0.003799  loss: 3.7094 (3.4733)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0987 (1.1655)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [60]  [ 600/1251]  eta: 0:08:55  lr: 0.003797  min_lr: 0.003797  loss: 3.5542 (3.4852)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9337 (1.1627)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [60]  [ 800/1251]  eta: 0:06:10  lr: 0.003796  min_lr: 0.003796  loss: 3.4128 (3.4802)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2542 (1.2441)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [60]  [1000/1251]  eta: 0:03:25  lr: 0.003794  min_lr: 0.003794  loss: 3.7227 (3.4882)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7965 (1.1605)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [60]  [1200/1251]  eta: 0:00:41  lr: 0.003793  min_lr: 0.003793  loss: 3.5216 (3.4970)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9079 (1.1662)  time: 0.8186  data: 0.0004  max mem: 62457
Epoch: [60]  [1250/1251]  eta: 0:00:00  lr: 0.003792  min_lr: 0.003792  loss: 3.6002 (3.5011)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0013 (1.1736)  time: 0.6957  data: 0.0005  max mem: 62457
Epoch: [60] Total time: 0:17:02 (0.8175 s / it)
Averaged stats: lr: 0.003792  min_lr: 0.003792  loss: 3.6002 (3.4782)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0013 (1.1736)
Test:  [ 0/25]  eta: 0:03:05  loss: 0.8355 (0.8355)  acc1: 86.0000 (86.0000)  acc5: 98.4000 (98.4000)  time: 7.4223  data: 6.9304  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9956 (0.9645)  acc1: 82.4000 (81.3818)  acc5: 96.4000 (96.4727)  time: 1.0799  data: 0.6303  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1190 (1.1312)  acc1: 76.4000 (78.0952)  acc5: 94.0000 (94.3238)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2225 (1.1463)  acc1: 76.4000 (77.7280)  acc5: 93.6000 (94.1120)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7287 s / it)
* Acc@1 77.734 Acc@5 94.370 loss 1.134
Accuracy of the model on the 50000 test images: 77.7%
Max accuracy: 77.73%
Epoch: [61]  [   0/1251]  eta: 1:31:03  lr: 0.003792  min_lr: 0.003792  loss: 3.7348 (3.7348)  weight_decay: 0.0500 (0.0500)  time: 4.3677  data: 3.5510  max mem: 62457
Epoch: [61]  [ 200/1251]  eta: 0:14:35  lr: 0.003791  min_lr: 0.003791  loss: 3.5772 (3.5164)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7148 (1.2073)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [61]  [ 400/1251]  eta: 0:11:41  lr: 0.003789  min_lr: 0.003789  loss: 3.5837 (3.4695)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9983 (1.2506)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [61]  [ 600/1251]  eta: 0:08:54  lr: 0.003787  min_lr: 0.003787  loss: 3.5322 (3.4462)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1311 (1.2651)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [61]  [ 800/1251]  eta: 0:06:09  lr: 0.003786  min_lr: 0.003786  loss: 3.6506 (3.4430)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8172 (1.2588)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [61]  [1000/1251]  eta: 0:03:25  lr: 0.003784  min_lr: 0.003784  loss: 3.3536 (3.4523)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9487 (1.2433)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [61]  [1200/1251]  eta: 0:00:41  lr: 0.003782  min_lr: 0.003782  loss: 3.5376 (3.4582)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8372 (1.2294)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [61]  [1250/1251]  eta: 0:00:00  lr: 0.003782  min_lr: 0.003782  loss: 3.6346 (3.4602)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1313 (1.2375)  time: 0.6918  data: 0.0006  max mem: 62457
Epoch: [61] Total time: 0:17:01 (0.8169 s / it)
Averaged stats: lr: 0.003782  min_lr: 0.003782  loss: 3.6346 (3.4710)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1313 (1.2375)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.7548 (0.7548)  acc1: 84.0000 (84.0000)  acc5: 98.0000 (98.0000)  time: 7.6930  data: 7.2180  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9094 (0.9253)  acc1: 82.8000 (81.6727)  acc5: 96.8000 (96.5818)  time: 1.1044  data: 0.6565  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1394 (1.1007)  acc1: 75.2000 (77.6191)  acc5: 93.6000 (94.3619)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2308 (1.1085)  acc1: 74.8000 (77.4400)  acc5: 92.4000 (94.3200)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7397 s / it)
* Acc@1 77.606 Acc@5 94.566 loss 1.096
Accuracy of the model on the 50000 test images: 77.6%
Max accuracy: 77.73%
Epoch: [62]  [   0/1251]  eta: 1:42:24  lr: 0.003782  min_lr: 0.003782  loss: 3.5466 (3.5466)  weight_decay: 0.0500 (0.0500)  time: 4.9120  data: 3.2712  max mem: 62457
Epoch: [62]  [ 200/1251]  eta: 0:14:38  lr: 0.003780  min_lr: 0.003780  loss: 3.6489 (3.4833)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8232 (1.1126)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [62]  [ 400/1251]  eta: 0:11:43  lr: 0.003779  min_lr: 0.003779  loss: 3.5124 (3.5044)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9152 (1.1909)  time: 0.8238  data: 0.0004  max mem: 62457
Epoch: [62]  [ 600/1251]  eta: 0:08:55  lr: 0.003777  min_lr: 0.003777  loss: 3.7372 (3.5080)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8792 (1.2282)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [62]  [ 800/1251]  eta: 0:06:10  lr: 0.003775  min_lr: 0.003775  loss: 3.1826 (3.4868)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9061 (1.2487)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [62]  [1000/1251]  eta: 0:03:25  lr: 0.003774  min_lr: 0.003774  loss: 3.4973 (3.4800)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2757 (1.2499)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [62]  [1200/1251]  eta: 0:00:41  lr: 0.003772  min_lr: 0.003772  loss: 3.5084 (3.4812)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8414 (1.2829)  time: 0.8192  data: 0.0004  max mem: 62457
Epoch: [62]  [1250/1251]  eta: 0:00:00  lr: 0.003772  min_lr: 0.003772  loss: 3.6855 (3.4817)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6493 (1.2584)  time: 0.6921  data: 0.0007  max mem: 62457
Epoch: [62] Total time: 0:17:02 (0.8177 s / it)
Averaged stats: lr: 0.003772  min_lr: 0.003772  loss: 3.6855 (3.4682)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6493 (1.2584)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.7760 (0.7760)  acc1: 84.8000 (84.8000)  acc5: 98.8000 (98.8000)  time: 7.6815  data: 7.2114  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9231 (0.9541)  acc1: 83.2000 (81.6000)  acc5: 96.8000 (96.6182)  time: 1.1033  data: 0.6559  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0861 (1.1273)  acc1: 75.6000 (77.7905)  acc5: 94.0000 (94.3238)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2429 (1.1409)  acc1: 75.6000 (77.3760)  acc5: 92.4000 (94.1760)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7395 s / it)
* Acc@1 77.756 Acc@5 94.354 loss 1.129
Accuracy of the model on the 50000 test images: 77.8%
Max accuracy: 77.76%
Epoch: [63]  [   0/1251]  eta: 1:30:27  lr: 0.003772  min_lr: 0.003772  loss: 2.8146 (2.8146)  weight_decay: 0.0500 (0.0500)  time: 4.3389  data: 3.5221  max mem: 62457
Epoch: [63]  [ 200/1251]  eta: 0:14:34  lr: 0.003770  min_lr: 0.003770  loss: 3.6756 (3.4875)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7889 (1.2604)  time: 0.8153  data: 0.0005  max mem: 62457
Epoch: [63]  [ 400/1251]  eta: 0:11:42  lr: 0.003768  min_lr: 0.003768  loss: 3.3807 (3.4559)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0528 (1.2736)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [63]  [ 600/1251]  eta: 0:08:54  lr: 0.003767  min_lr: 0.003767  loss: 3.1545 (3.4499)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1057 (1.2675)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [63]  [ 800/1251]  eta: 0:06:09  lr: 0.003765  min_lr: 0.003765  loss: 3.5639 (3.4471)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3428 (1.2643)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [63]  [1000/1251]  eta: 0:03:25  lr: 0.003763  min_lr: 0.003763  loss: 3.4554 (3.4480)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1197 (1.2709)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [63]  [1200/1251]  eta: 0:00:41  lr: 0.003762  min_lr: 0.003762  loss: 3.4711 (3.4470)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9455 (1.2554)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [63]  [1250/1251]  eta: 0:00:00  lr: 0.003761  min_lr: 0.003761  loss: 3.4698 (3.4495)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0745 (1.2558)  time: 0.6916  data: 0.0005  max mem: 62457
Epoch: [63] Total time: 0:17:02 (0.8172 s / it)
Averaged stats: lr: 0.003761  min_lr: 0.003761  loss: 3.4698 (3.4619)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0745 (1.2558)
Test:  [ 0/25]  eta: 0:03:20  loss: 0.7747 (0.7747)  acc1: 84.4000 (84.4000)  acc5: 98.8000 (98.8000)  time: 8.0212  data: 7.5570  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8806 (0.9621)  acc1: 83.2000 (81.2364)  acc5: 96.8000 (96.1455)  time: 1.1347  data: 0.6873  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.1243 (1.1229)  acc1: 75.2000 (78.1143)  acc5: 94.0000 (94.1143)  time: 0.4457  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2257 (1.1316)  acc1: 75.2000 (77.9520)  acc5: 93.2000 (94.1600)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7536 s / it)
* Acc@1 77.868 Acc@5 94.380 loss 1.133
Accuracy of the model on the 50000 test images: 77.9%
Max accuracy: 77.87%
Epoch: [64]  [   0/1251]  eta: 1:30:52  lr: 0.003761  min_lr: 0.003761  loss: 3.6763 (3.6763)  weight_decay: 0.0500 (0.0500)  time: 4.3581  data: 3.5285  max mem: 62457
Epoch: [64]  [ 200/1251]  eta: 0:14:37  lr: 0.003760  min_lr: 0.003760  loss: 3.4833 (3.4898)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1251 (1.3338)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [64]  [ 400/1251]  eta: 0:11:42  lr: 0.003758  min_lr: 0.003758  loss: 3.3585 (3.4828)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0854 (1.3239)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [64]  [ 600/1251]  eta: 0:08:54  lr: 0.003756  min_lr: 0.003756  loss: 3.6042 (3.4795)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2878 (1.2474)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [64]  [ 800/1251]  eta: 0:06:10  lr: 0.003754  min_lr: 0.003754  loss: 3.4063 (3.4880)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5502 (1.2596)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [64]  [1000/1251]  eta: 0:03:25  lr: 0.003753  min_lr: 0.003753  loss: 3.3888 (3.4735)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1043 (1.2407)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [64]  [1200/1251]  eta: 0:00:41  lr: 0.003751  min_lr: 0.003751  loss: 3.6390 (3.4632)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7447 (1.2037)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [64]  [1250/1251]  eta: 0:00:00  lr: 0.003751  min_lr: 0.003751  loss: 3.4489 (3.4591)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0780 (1.2135)  time: 0.6922  data: 0.0005  max mem: 62457
Epoch: [64] Total time: 0:17:02 (0.8175 s / it)
Averaged stats: lr: 0.003751  min_lr: 0.003751  loss: 3.4489 (3.4416)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0780 (1.2135)
Test:  [ 0/25]  eta: 0:03:02  loss: 0.7364 (0.7364)  acc1: 87.2000 (87.2000)  acc5: 97.6000 (97.6000)  time: 7.2937  data: 6.8146  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8891 (0.9093)  acc1: 82.0000 (81.9636)  acc5: 97.2000 (96.8000)  time: 1.0679  data: 0.6198  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0818 (1.0929)  acc1: 76.8000 (78.2667)  acc5: 94.8000 (94.3810)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2088 (1.0999)  acc1: 76.4000 (78.0640)  acc5: 92.8000 (94.3360)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7231 s / it)
* Acc@1 77.962 Acc@5 94.582 loss 1.086
Accuracy of the model on the 50000 test images: 78.0%
Max accuracy: 77.96%
Epoch: [65]  [   0/1251]  eta: 1:23:43  lr: 0.003751  min_lr: 0.003751  loss: 3.2083 (3.2083)  weight_decay: 0.0500 (0.0500)  time: 4.0157  data: 3.2044  max mem: 62457
Epoch: [65]  [ 200/1251]  eta: 0:14:33  lr: 0.003749  min_lr: 0.003749  loss: 3.4729 (3.3836)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0665 (1.3498)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [65]  [ 400/1251]  eta: 0:11:40  lr: 0.003747  min_lr: 0.003747  loss: 3.2970 (3.4290)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8515 (1.1955)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [65]  [ 600/1251]  eta: 0:08:54  lr: 0.003745  min_lr: 0.003745  loss: 3.4020 (3.4183)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0417 (1.1921)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [65]  [ 800/1251]  eta: 0:06:09  lr: 0.003744  min_lr: 0.003744  loss: 3.6312 (3.4320)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2374 (1.2399)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [65]  [1000/1251]  eta: 0:03:25  lr: 0.003742  min_lr: 0.003742  loss: 3.3675 (3.4260)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3515 (1.2231)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [65]  [1200/1251]  eta: 0:00:41  lr: 0.003740  min_lr: 0.003740  loss: 3.3771 (3.4345)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0831 (1.2632)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [65]  [1250/1251]  eta: 0:00:00  lr: 0.003740  min_lr: 0.003740  loss: 3.3819 (3.4326)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2037 (1.2630)  time: 0.6920  data: 0.0007  max mem: 62457
Epoch: [65] Total time: 0:17:01 (0.8169 s / it)
Averaged stats: lr: 0.003740  min_lr: 0.003740  loss: 3.3819 (3.4512)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2037 (1.2630)
Test:  [ 0/25]  eta: 0:02:51  loss: 0.7463 (0.7463)  acc1: 84.0000 (84.0000)  acc5: 97.2000 (97.2000)  time: 6.8768  data: 6.3791  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.9077 (0.9097)  acc1: 82.0000 (81.4909)  acc5: 96.4000 (96.1455)  time: 1.0455  data: 0.5970  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0877 (1.0878)  acc1: 74.8000 (77.8095)  acc5: 94.0000 (94.2476)  time: 0.4531  data: 0.0094  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1955 (1.0942)  acc1: 75.2000 (77.7120)  acc5: 92.8000 (94.2080)  time: 0.4438  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7196 s / it)
* Acc@1 77.650 Acc@5 94.430 loss 1.084
Accuracy of the model on the 50000 test images: 77.7%
Max accuracy: 77.96%
Epoch: [66]  [   0/1251]  eta: 1:34:56  lr: 0.003740  min_lr: 0.003740  loss: 2.5327 (2.5327)  weight_decay: 0.0500 (0.0500)  time: 4.5537  data: 3.0519  max mem: 62457
Epoch: [66]  [ 200/1251]  eta: 0:14:36  lr: 0.003738  min_lr: 0.003738  loss: 3.0551 (3.3710)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2438 (1.3240)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [66]  [ 400/1251]  eta: 0:11:42  lr: 0.003736  min_lr: 0.003736  loss: 3.0630 (3.4400)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1026 (1.2521)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [66]  [ 600/1251]  eta: 0:08:54  lr: 0.003734  min_lr: 0.003734  loss: 3.6288 (3.4386)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0028 (1.2034)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [66]  [ 800/1251]  eta: 0:06:09  lr: 0.003732  min_lr: 0.003732  loss: 3.5875 (3.4416)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9510 (1.2131)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [66]  [1000/1251]  eta: 0:03:25  lr: 0.003731  min_lr: 0.003731  loss: 3.3078 (3.4439)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8949 (1.1930)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [66]  [1200/1251]  eta: 0:00:41  lr: 0.003729  min_lr: 0.003729  loss: 3.5958 (3.4520)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8324 (1.2008)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [66]  [1250/1251]  eta: 0:00:00  lr: 0.003728  min_lr: 0.003728  loss: 3.6398 (3.4543)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1262 (1.2119)  time: 0.6920  data: 0.0005  max mem: 62457
Epoch: [66] Total time: 0:17:02 (0.8170 s / it)
Averaged stats: lr: 0.003728  min_lr: 0.003728  loss: 3.6398 (3.4499)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1262 (1.2119)
Test:  [ 0/25]  eta: 0:02:51  loss: 0.8056 (0.8056)  acc1: 83.6000 (83.6000)  acc5: 96.4000 (96.4000)  time: 6.8500  data: 6.3841  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8408 (0.9245)  acc1: 82.4000 (81.6364)  acc5: 96.4000 (96.2182)  time: 1.0283  data: 0.5806  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0895 (1.0748)  acc1: 77.6000 (78.1714)  acc5: 94.8000 (94.3048)  time: 0.4456  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1167 (1.0857)  acc1: 77.6000 (77.8720)  acc5: 92.8000 (94.2560)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7059 s / it)
* Acc@1 78.234 Acc@5 94.514 loss 1.072
Accuracy of the model on the 50000 test images: 78.2%
Max accuracy: 78.23%
Epoch: [67]  [   0/1251]  eta: 1:31:12  lr: 0.003728  min_lr: 0.003728  loss: 3.6481 (3.6481)  weight_decay: 0.0500 (0.0500)  time: 4.3747  data: 3.5535  max mem: 62457
Epoch: [67]  [ 200/1251]  eta: 0:14:34  lr: 0.003727  min_lr: 0.003727  loss: 3.5377 (3.4126)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2147 (nan)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [67]  [ 400/1251]  eta: 0:11:41  lr: 0.003725  min_lr: 0.003725  loss: 3.6219 (3.4102)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9731 (nan)  time: 0.8144  data: 0.0003  max mem: 62457
Epoch: [67]  [ 600/1251]  eta: 0:08:54  lr: 0.003723  min_lr: 0.003723  loss: 3.2751 (3.4166)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7711 (nan)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [67]  [ 800/1251]  eta: 0:06:09  lr: 0.003721  min_lr: 0.003721  loss: 3.7025 (3.4312)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2758 (nan)  time: 0.8194  data: 0.0004  max mem: 62457
Epoch: [67]  [1000/1251]  eta: 0:03:25  lr: 0.003719  min_lr: 0.003719  loss: 3.6403 (3.4396)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8948 (nan)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [67]  [1200/1251]  eta: 0:00:41  lr: 0.003717  min_lr: 0.003717  loss: 3.2784 (3.4254)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1414 (nan)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [67]  [1250/1251]  eta: 0:00:00  lr: 0.003717  min_lr: 0.003717  loss: 3.5579 (3.4232)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0619 (nan)  time: 0.6919  data: 0.0005  max mem: 62457
Epoch: [67] Total time: 0:17:01 (0.8166 s / it)
Averaged stats: lr: 0.003717  min_lr: 0.003717  loss: 3.5579 (3.4385)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0619 (nan)
Test:  [ 0/25]  eta: 0:03:16  loss: 0.7755 (0.7755)  acc1: 85.6000 (85.6000)  acc5: 98.4000 (98.4000)  time: 7.8609  data: 7.3514  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8949 (0.9453)  acc1: 82.4000 (81.3091)  acc5: 96.4000 (96.4000)  time: 1.1197  data: 0.6686  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1108 (1.0920)  acc1: 75.2000 (77.9810)  acc5: 94.4000 (94.3238)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1721 (1.0963)  acc1: 76.8000 (77.8560)  acc5: 92.8000 (94.3200)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7469 s / it)
* Acc@1 78.290 Acc@5 94.524 loss 1.078
Accuracy of the model on the 50000 test images: 78.3%
Max accuracy: 78.29%
Epoch: [68]  [   0/1251]  eta: 1:11:08  lr: 0.003717  min_lr: 0.003717  loss: 3.7621 (3.7621)  weight_decay: 0.0500 (0.0500)  time: 3.4121  data: 2.5820  max mem: 62457
Epoch: [68]  [ 200/1251]  eta: 0:14:31  lr: 0.003715  min_lr: 0.003715  loss: 3.0940 (3.4445)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2322 (1.2239)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [68]  [ 400/1251]  eta: 0:11:39  lr: 0.003713  min_lr: 0.003713  loss: 3.4040 (3.4386)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8915 (1.1966)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [68]  [ 600/1251]  eta: 0:08:53  lr: 0.003711  min_lr: 0.003711  loss: 3.5208 (3.4331)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8215 (1.1907)  time: 0.8177  data: 0.0004  max mem: 62457
Epoch: [68]  [ 800/1251]  eta: 0:06:09  lr: 0.003710  min_lr: 0.003710  loss: 3.0727 (3.4306)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7849 (1.1720)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [68]  [1000/1251]  eta: 0:03:25  lr: 0.003708  min_lr: 0.003708  loss: 3.2819 (3.4204)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2822 (1.1970)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [68]  [1200/1251]  eta: 0:00:41  lr: 0.003706  min_lr: 0.003706  loss: 3.5463 (3.4284)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7448 (1.1747)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [68]  [1250/1251]  eta: 0:00:00  lr: 0.003705  min_lr: 0.003705  loss: 3.7282 (3.4272)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2368 (1.1762)  time: 0.6918  data: 0.0005  max mem: 62457
Epoch: [68] Total time: 0:17:00 (0.8160 s / it)
Averaged stats: lr: 0.003705  min_lr: 0.003705  loss: 3.7282 (3.4297)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2368 (1.1762)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.7232 (0.7232)  acc1: 86.4000 (86.4000)  acc5: 98.0000 (98.0000)  time: 7.5738  data: 7.0935  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9251 (0.8968)  acc1: 82.4000 (81.1636)  acc5: 96.8000 (96.6909)  time: 1.0935  data: 0.6451  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0504 (1.0623)  acc1: 75.6000 (77.7524)  acc5: 94.4000 (94.6476)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1308 (1.0677)  acc1: 75.6000 (77.6000)  acc5: 94.0000 (94.6560)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7352 s / it)
* Acc@1 78.238 Acc@5 94.656 loss 1.059
Accuracy of the model on the 50000 test images: 78.2%
Max accuracy: 78.29%
Epoch: [69]  [   0/1251]  eta: 1:37:58  lr: 0.003705  min_lr: 0.003705  loss: 3.7053 (3.7053)  weight_decay: 0.0500 (0.0500)  time: 4.6993  data: 2.5987  max mem: 62457
Epoch: [69]  [ 200/1251]  eta: 0:14:36  lr: 0.003703  min_lr: 0.003703  loss: 3.4166 (3.3968)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8960 (1.3036)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [69]  [ 400/1251]  eta: 0:11:42  lr: 0.003702  min_lr: 0.003702  loss: 3.5504 (3.3956)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8386 (1.2171)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [69]  [ 600/1251]  eta: 0:08:55  lr: 0.003700  min_lr: 0.003700  loss: 3.5992 (3.4287)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5412 (1.2155)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [69]  [ 800/1251]  eta: 0:06:10  lr: 0.003698  min_lr: 0.003698  loss: 3.7281 (3.4318)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8740 (1.1775)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [69]  [1000/1251]  eta: 0:03:25  lr: 0.003696  min_lr: 0.003696  loss: 3.4478 (3.4338)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3230 (1.2160)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [69]  [1200/1251]  eta: 0:00:41  lr: 0.003694  min_lr: 0.003694  loss: 3.4779 (3.4389)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6455 (1.1908)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [69]  [1250/1251]  eta: 0:00:00  lr: 0.003694  min_lr: 0.003694  loss: 3.4432 (3.4385)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8532 (1.1868)  time: 0.6916  data: 0.0005  max mem: 62457
Epoch: [69] Total time: 0:17:02 (0.8175 s / it)
Averaged stats: lr: 0.003694  min_lr: 0.003694  loss: 3.4432 (3.4382)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8532 (1.1868)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.7815 (0.7815)  acc1: 86.0000 (86.0000)  acc5: 98.4000 (98.4000)  time: 7.7248  data: 7.2639  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8735 (0.9222)  acc1: 82.0000 (81.6000)  acc5: 96.8000 (96.4364)  time: 1.1087  data: 0.6606  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0650 (1.0968)  acc1: 76.8000 (78.4952)  acc5: 94.4000 (94.4191)  time: 0.4462  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1821 (1.1002)  acc1: 76.8000 (78.3200)  acc5: 93.2000 (94.2720)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7418 s / it)
* Acc@1 77.956 Acc@5 94.652 loss 1.096
Accuracy of the model on the 50000 test images: 78.0%
Max accuracy: 78.29%
Epoch: [70]  [   0/1251]  eta: 1:38:29  lr: 0.003694  min_lr: 0.003694  loss: 3.3550 (3.3550)  weight_decay: 0.0500 (0.0500)  time: 4.7237  data: 3.6404  max mem: 62457
Epoch: [70]  [ 200/1251]  eta: 0:14:37  lr: 0.003692  min_lr: 0.003692  loss: 3.4696 (3.3430)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0337 (1.2803)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [70]  [ 400/1251]  eta: 0:11:43  lr: 0.003690  min_lr: 0.003690  loss: 3.0525 (3.3674)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7081 (1.1872)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [70]  [ 600/1251]  eta: 0:08:55  lr: 0.003688  min_lr: 0.003688  loss: 3.4533 (3.3989)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9446 (1.1334)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [70]  [ 800/1251]  eta: 0:06:10  lr: 0.003686  min_lr: 0.003686  loss: 2.9651 (3.3986)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8974 (1.1460)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [70]  [1000/1251]  eta: 0:03:25  lr: 0.003684  min_lr: 0.003684  loss: 3.5527 (3.4094)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7754 (1.1588)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [70]  [1200/1251]  eta: 0:00:41  lr: 0.003682  min_lr: 0.003682  loss: 3.3970 (3.4141)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1108 (1.1594)  time: 0.8146  data: 0.0005  max mem: 62457
Epoch: [70]  [1250/1251]  eta: 0:00:00  lr: 0.003682  min_lr: 0.003682  loss: 3.1301 (3.4106)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8327 (1.1492)  time: 0.6918  data: 0.0005  max mem: 62457
Epoch: [70] Total time: 0:17:03 (0.8178 s / it)
Averaged stats: lr: 0.003682  min_lr: 0.003682  loss: 3.1301 (3.4251)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8327 (1.1492)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.6522 (0.6522)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 7.5398  data: 7.0408  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8057 (0.8443)  acc1: 82.8000 (82.2909)  acc5: 97.2000 (96.9091)  time: 1.0904  data: 0.6404  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9819 (1.0232)  acc1: 78.0000 (78.4191)  acc5: 94.4000 (94.7429)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1252 (1.0282)  acc1: 77.6000 (78.1440)  acc5: 94.0000 (94.7520)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7333 s / it)
* Acc@1 78.168 Acc@5 94.742 loss 1.015
Accuracy of the model on the 50000 test images: 78.2%
Max accuracy: 78.29%
Epoch: [71]  [   0/1251]  eta: 1:26:26  lr: 0.003681  min_lr: 0.003681  loss: 3.1986 (3.1986)  weight_decay: 0.0500 (0.0500)  time: 4.1457  data: 2.8136  max mem: 62457
Epoch: [71]  [ 200/1251]  eta: 0:14:34  lr: 0.003680  min_lr: 0.003680  loss: 3.7611 (3.3711)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9721 (1.2470)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [71]  [ 400/1251]  eta: 0:11:41  lr: 0.003678  min_lr: 0.003678  loss: 3.6277 (3.4137)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9590 (1.2828)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [71]  [ 600/1251]  eta: 0:08:54  lr: 0.003676  min_lr: 0.003676  loss: 3.5441 (3.3928)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7850 (1.2014)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [71]  [ 800/1251]  eta: 0:06:10  lr: 0.003674  min_lr: 0.003674  loss: 3.4645 (3.3877)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9892 (1.1950)  time: 0.8192  data: 0.0004  max mem: 62457
Epoch: [71]  [1000/1251]  eta: 0:03:25  lr: 0.003672  min_lr: 0.003672  loss: 3.6722 (3.4075)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9187 (1.1811)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [71]  [1200/1251]  eta: 0:00:41  lr: 0.003670  min_lr: 0.003670  loss: 3.5663 (3.4111)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7158 (1.1549)  time: 0.8144  data: 0.0005  max mem: 62457
Epoch: [71]  [1250/1251]  eta: 0:00:00  lr: 0.003669  min_lr: 0.003669  loss: 3.6001 (3.4094)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9097 (1.1504)  time: 0.6913  data: 0.0007  max mem: 62457
Epoch: [71] Total time: 0:17:02 (0.8173 s / it)
Averaged stats: lr: 0.003669  min_lr: 0.003669  loss: 3.6001 (3.4203)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9097 (1.1504)
Test:  [ 0/25]  eta: 0:02:37  loss: 0.7758 (0.7758)  acc1: 86.0000 (86.0000)  acc5: 98.4000 (98.4000)  time: 6.2989  data: 5.8005  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.9188 (0.9331)  acc1: 81.6000 (81.6364)  acc5: 96.8000 (96.4727)  time: 1.0259  data: 0.5769  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0963 (1.0978)  acc1: 76.4000 (77.9619)  acc5: 94.0000 (94.6857)  time: 0.4713  data: 0.0273  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1805 (1.1067)  acc1: 75.2000 (77.6320)  acc5: 92.8000 (94.5440)  time: 0.4440  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7050 s / it)
* Acc@1 78.210 Acc@5 94.830 loss 1.092
Accuracy of the model on the 50000 test images: 78.2%
Max accuracy: 78.29%
Epoch: [72]  [   0/1251]  eta: 1:38:05  lr: 0.003669  min_lr: 0.003669  loss: 3.8797 (3.8797)  weight_decay: 0.0500 (0.0500)  time: 4.7047  data: 2.4691  max mem: 62457
Epoch: [72]  [ 200/1251]  eta: 0:14:39  lr: 0.003667  min_lr: 0.003667  loss: 3.6885 (3.4574)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2408 (1.2491)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [72]  [ 400/1251]  eta: 0:11:42  lr: 0.003665  min_lr: 0.003665  loss: 3.4779 (3.4437)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6995 (1.1122)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [72]  [ 600/1251]  eta: 0:08:55  lr: 0.003663  min_lr: 0.003663  loss: 3.7390 (3.4454)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9838 (1.1394)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [72]  [ 800/1251]  eta: 0:06:10  lr: 0.003661  min_lr: 0.003661  loss: 3.7213 (3.4582)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8806 (1.1407)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [72]  [1000/1251]  eta: 0:03:25  lr: 0.003659  min_lr: 0.003659  loss: 3.5677 (3.4497)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7521 (1.1232)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [72]  [1200/1251]  eta: 0:00:41  lr: 0.003657  min_lr: 0.003657  loss: 3.4374 (3.4343)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8270 (1.1390)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [72]  [1250/1251]  eta: 0:00:00  lr: 0.003657  min_lr: 0.003657  loss: 3.4648 (3.4295)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1543 (1.1450)  time: 0.6916  data: 0.0005  max mem: 62457
Epoch: [72] Total time: 0:17:02 (0.8175 s / it)
Averaged stats: lr: 0.003657  min_lr: 0.003657  loss: 3.4648 (3.4159)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1543 (1.1450)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.8358 (0.8358)  acc1: 85.6000 (85.6000)  acc5: 99.2000 (99.2000)  time: 7.5336  data: 7.0718  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9496 (0.9997)  acc1: 80.4000 (81.2364)  acc5: 96.8000 (96.7273)  time: 1.0910  data: 0.6431  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1471 (1.1493)  acc1: 78.0000 (78.1714)  acc5: 94.8000 (94.7238)  time: 0.4459  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2439 (1.1577)  acc1: 76.8000 (78.0320)  acc5: 93.6000 (94.6400)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7347 s / it)
* Acc@1 78.182 Acc@5 94.656 loss 1.150
Accuracy of the model on the 50000 test images: 78.2%
Max accuracy: 78.29%
Epoch: [73]  [   0/1251]  eta: 1:48:20  lr: 0.003657  min_lr: 0.003657  loss: 3.0465 (3.0465)  weight_decay: 0.0500 (0.0500)  time: 5.1961  data: 3.7940  max mem: 62457
Epoch: [73]  [ 200/1251]  eta: 0:14:39  lr: 0.003655  min_lr: 0.003655  loss: 3.3334 (3.4315)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7123 (0.9109)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [73]  [ 400/1251]  eta: 0:11:42  lr: 0.003653  min_lr: 0.003653  loss: 3.5826 (3.4248)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7597 (1.0052)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [73]  [ 600/1251]  eta: 0:08:55  lr: 0.003651  min_lr: 0.003651  loss: 3.5125 (3.4065)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0326 (0.9863)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [73]  [ 800/1251]  eta: 0:06:10  lr: 0.003649  min_lr: 0.003649  loss: 3.4991 (3.4095)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0715 (1.0306)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [73]  [1000/1251]  eta: 0:03:25  lr: 0.003647  min_lr: 0.003647  loss: 3.5678 (3.4232)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8384 (1.0418)  time: 0.8199  data: 0.0004  max mem: 62457
Epoch: [73]  [1200/1251]  eta: 0:00:41  lr: 0.003645  min_lr: 0.003645  loss: 3.6229 (3.4266)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9684 (1.0405)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [73]  [1250/1251]  eta: 0:00:00  lr: 0.003644  min_lr: 0.003644  loss: 3.8043 (3.4265)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8076 (1.0373)  time: 0.6913  data: 0.0005  max mem: 62457
Epoch: [73] Total time: 0:17:03 (0.8180 s / it)
Averaged stats: lr: 0.003644  min_lr: 0.003644  loss: 3.8043 (3.4140)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8076 (1.0373)
Test:  [ 0/25]  eta: 0:03:04  loss: 0.8600 (0.8600)  acc1: 85.6000 (85.6000)  acc5: 98.0000 (98.0000)  time: 7.3918  data: 6.8973  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 1.0077 (1.0003)  acc1: 81.6000 (81.7455)  acc5: 96.8000 (96.7273)  time: 1.0757  data: 0.6273  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1741 (1.1400)  acc1: 76.8000 (78.4571)  acc5: 94.0000 (94.5524)  time: 0.4441  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2057 (1.1524)  acc1: 76.8000 (78.0480)  acc5: 93.2000 (94.4320)  time: 0.4440  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7257 s / it)
* Acc@1 78.194 Acc@5 94.678 loss 1.144
Accuracy of the model on the 50000 test images: 78.2%
Max accuracy: 78.29%
Epoch: [74]  [   0/1251]  eta: 1:42:25  lr: 0.003644  min_lr: 0.003644  loss: 3.5692 (3.5692)  weight_decay: 0.0500 (0.0500)  time: 4.9128  data: 3.1376  max mem: 62457
Epoch: [74]  [ 200/1251]  eta: 0:14:37  lr: 0.003642  min_lr: 0.003642  loss: 3.4347 (3.4210)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [74]  [ 400/1251]  eta: 0:11:43  lr: 0.003640  min_lr: 0.003640  loss: 3.4520 (3.4182)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1131 (nan)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [74]  [ 600/1251]  eta: 0:08:56  lr: 0.003638  min_lr: 0.003638  loss: 3.2485 (3.4184)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4278 (nan)  time: 0.8157  data: 0.0005  max mem: 62457
Epoch: [74]  [ 800/1251]  eta: 0:06:10  lr: 0.003636  min_lr: 0.003636  loss: 3.4848 (3.4147)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7404 (nan)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [74]  [1000/1251]  eta: 0:03:26  lr: 0.003634  min_lr: 0.003634  loss: 3.2786 (3.4080)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3272 (nan)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [74]  [1200/1251]  eta: 0:00:41  lr: 0.003632  min_lr: 0.003632  loss: 3.5494 (3.4200)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7562 (nan)  time: 0.8156  data: 0.0005  max mem: 62457
Epoch: [74]  [1250/1251]  eta: 0:00:00  lr: 0.003631  min_lr: 0.003631  loss: 3.3925 (3.4213)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0786 (nan)  time: 0.6925  data: 0.0006  max mem: 62457
Epoch: [74] Total time: 0:17:04 (0.8187 s / it)
Averaged stats: lr: 0.003631  min_lr: 0.003631  loss: 3.3925 (3.4073)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0786 (nan)
Test:  [ 0/25]  eta: 0:02:59  loss: 0.6946 (0.6946)  acc1: 87.2000 (87.2000)  acc5: 98.4000 (98.4000)  time: 7.1756  data: 6.7030  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8374 (0.8647)  acc1: 84.0000 (82.0727)  acc5: 97.6000 (96.9455)  time: 1.0570  data: 0.6096  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0432 (1.0259)  acc1: 74.8000 (78.4000)  acc5: 94.8000 (94.8381)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1012 (1.0322)  acc1: 76.4000 (78.4800)  acc5: 93.6000 (94.8000)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7181 s / it)
* Acc@1 78.606 Acc@5 94.792 loss 1.030
Accuracy of the model on the 50000 test images: 78.6%
Max accuracy: 78.61%
Epoch: [75]  [   0/1251]  eta: 1:20:30  lr: 0.003631  min_lr: 0.003631  loss: 3.6396 (3.6396)  weight_decay: 0.0500 (0.0500)  time: 3.8616  data: 3.0407  max mem: 62457
Epoch: [75]  [ 200/1251]  eta: 0:14:33  lr: 0.003629  min_lr: 0.003629  loss: 3.4566 (3.3831)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9446 (1.1959)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [75]  [ 400/1251]  eta: 0:11:41  lr: 0.003627  min_lr: 0.003627  loss: 3.1104 (3.3821)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8160 (1.1234)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [75]  [ 600/1251]  eta: 0:08:54  lr: 0.003625  min_lr: 0.003625  loss: 3.4825 (3.3746)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8632 (1.0614)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [75]  [ 800/1251]  eta: 0:06:09  lr: 0.003623  min_lr: 0.003623  loss: 3.3831 (3.3775)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8736 (1.0199)  time: 0.8193  data: 0.0004  max mem: 62457
Epoch: [75]  [1000/1251]  eta: 0:03:25  lr: 0.003621  min_lr: 0.003621  loss: 3.3679 (3.3814)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1261 (1.0393)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [75]  [1200/1251]  eta: 0:00:41  lr: 0.003619  min_lr: 0.003619  loss: 3.5125 (3.3897)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7792 (1.0189)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [75]  [1250/1251]  eta: 0:00:00  lr: 0.003618  min_lr: 0.003618  loss: 3.5243 (3.3867)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8044 (1.0204)  time: 0.6925  data: 0.0007  max mem: 62457
Epoch: [75] Total time: 0:17:02 (0.8171 s / it)
Averaged stats: lr: 0.003618  min_lr: 0.003618  loss: 3.5243 (3.3965)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8044 (1.0204)
Test:  [ 0/25]  eta: 0:03:16  loss: 0.6758 (0.6758)  acc1: 85.2000 (85.2000)  acc5: 99.2000 (99.2000)  time: 7.8473  data: 7.3664  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8889 (0.8784)  acc1: 82.4000 (82.1818)  acc5: 96.4000 (96.9818)  time: 1.1182  data: 0.6700  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0263 (1.0532)  acc1: 78.0000 (78.0000)  acc5: 95.2000 (95.0476)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1396 (1.0652)  acc1: 76.4000 (77.6800)  acc5: 94.0000 (94.9600)  time: 0.4451  data: 0.0002  max mem: 62457
Test: Total time: 0:00:18 (0.7456 s / it)
* Acc@1 78.408 Acc@5 94.854 loss 1.055
Accuracy of the model on the 50000 test images: 78.4%
Max accuracy: 78.61%
Epoch: [76]  [   0/1251]  eta: 1:43:27  lr: 0.003618  min_lr: 0.003618  loss: 3.1550 (3.1550)  weight_decay: 0.0500 (0.0500)  time: 4.9617  data: 2.8395  max mem: 62457
Epoch: [76]  [ 200/1251]  eta: 0:14:41  lr: 0.003616  min_lr: 0.003616  loss: 3.5067 (3.3883)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8744 (1.0438)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [76]  [ 400/1251]  eta: 0:11:43  lr: 0.003614  min_lr: 0.003614  loss: 3.2979 (3.3836)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7896 (1.0588)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [76]  [ 600/1251]  eta: 0:08:55  lr: 0.003612  min_lr: 0.003612  loss: 3.5482 (3.3979)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9778 (1.0386)  time: 0.8149  data: 0.0005  max mem: 62457
Epoch: [76]  [ 800/1251]  eta: 0:06:10  lr: 0.003610  min_lr: 0.003610  loss: 3.4220 (3.3980)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7231 (1.0176)  time: 0.8154  data: 0.0005  max mem: 62457
Epoch: [76]  [1000/1251]  eta: 0:03:25  lr: 0.003607  min_lr: 0.003607  loss: 3.1361 (3.3999)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8835 (1.0326)  time: 0.8147  data: 0.0005  max mem: 62457
Epoch: [76]  [1200/1251]  eta: 0:00:41  lr: 0.003605  min_lr: 0.003605  loss: 3.3014 (3.3967)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9714 (1.0074)  time: 0.8159  data: 0.0005  max mem: 62457
Epoch: [76]  [1250/1251]  eta: 0:00:00  lr: 0.003605  min_lr: 0.003605  loss: 3.3871 (3.3995)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7831 (0.9990)  time: 0.6951  data: 0.0007  max mem: 62457
Epoch: [76] Total time: 0:17:04 (0.8186 s / it)
Averaged stats: lr: 0.003605  min_lr: 0.003605  loss: 3.3871 (3.3924)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7831 (0.9990)
Test:  [ 0/25]  eta: 0:03:27  loss: 0.7609 (0.7609)  acc1: 85.2000 (85.2000)  acc5: 97.6000 (97.6000)  time: 8.2872  data: 7.8193  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8579 (0.8860)  acc1: 83.2000 (81.3818)  acc5: 96.8000 (96.6546)  time: 1.1577  data: 0.7111  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0513 (1.0611)  acc1: 76.8000 (78.1333)  acc5: 94.4000 (94.7429)  time: 0.4446  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1802 (1.0681)  acc1: 76.8000 (77.8720)  acc5: 93.6000 (94.6560)  time: 0.4445  data: 0.0001  max mem: 62457
Test: Total time: 0:00:19 (0.7631 s / it)
* Acc@1 78.424 Acc@5 94.862 loss 1.052
Accuracy of the model on the 50000 test images: 78.4%
Max accuracy: 78.61%
Epoch: [77]  [   0/1251]  eta: 1:29:17  lr: 0.003605  min_lr: 0.003605  loss: 3.5767 (3.5767)  weight_decay: 0.0500 (0.0500)  time: 4.2826  data: 3.1441  max mem: 62457
Epoch: [77]  [ 200/1251]  eta: 0:14:34  lr: 0.003603  min_lr: 0.003603  loss: 3.2728 (3.3445)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7628 (1.0955)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [77]  [ 400/1251]  eta: 0:11:41  lr: 0.003601  min_lr: 0.003601  loss: 3.4533 (3.3731)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0083 (1.0937)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [77]  [ 600/1251]  eta: 0:08:54  lr: 0.003598  min_lr: 0.003598  loss: 3.4633 (3.3794)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6301 (1.0605)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [77]  [ 800/1251]  eta: 0:06:09  lr: 0.003596  min_lr: 0.003596  loss: 3.3565 (3.3894)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7086 (1.0903)  time: 0.8213  data: 0.0004  max mem: 62457
Epoch: [77]  [1000/1251]  eta: 0:03:25  lr: 0.003594  min_lr: 0.003594  loss: 3.1292 (3.3981)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7508 (1.0510)  time: 0.8184  data: 0.0004  max mem: 62457
Epoch: [77]  [1200/1251]  eta: 0:00:41  lr: 0.003592  min_lr: 0.003592  loss: 3.5610 (3.3993)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8131 (1.0530)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [77]  [1250/1251]  eta: 0:00:00  lr: 0.003591  min_lr: 0.003591  loss: 3.6954 (3.4009)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7937 (1.0464)  time: 0.6916  data: 0.0005  max mem: 62457
Epoch: [77] Total time: 0:17:02 (0.8173 s / it)
Averaged stats: lr: 0.003591  min_lr: 0.003591  loss: 3.6954 (3.3896)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7937 (1.0464)
Test:  [ 0/25]  eta: 0:03:03  loss: 0.7498 (0.7498)  acc1: 86.8000 (86.8000)  acc5: 98.4000 (98.4000)  time: 7.3426  data: 6.8519  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9018 (0.9361)  acc1: 82.4000 (81.8182)  acc5: 97.2000 (96.9091)  time: 1.0721  data: 0.6233  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1344 (1.0970)  acc1: 76.8000 (78.7048)  acc5: 94.8000 (94.8191)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1888 (1.1074)  acc1: 76.8000 (78.3520)  acc5: 93.6000 (94.7040)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7254 s / it)
* Acc@1 78.670 Acc@5 94.870 loss 1.101
Accuracy of the model on the 50000 test images: 78.7%
Max accuracy: 78.67%
Epoch: [78]  [   0/1251]  eta: 1:25:11  lr: 0.003591  min_lr: 0.003591  loss: 4.1484 (4.1484)  weight_decay: 0.0500 (0.0500)  time: 4.0856  data: 3.2598  max mem: 62457
Epoch: [78]  [ 200/1251]  eta: 0:14:33  lr: 0.003589  min_lr: 0.003589  loss: 3.2076 (3.3595)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9058 (1.0256)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [78]  [ 400/1251]  eta: 0:11:41  lr: 0.003587  min_lr: 0.003587  loss: 3.4532 (3.3773)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9331 (0.9880)  time: 0.8217  data: 0.0004  max mem: 62457
Epoch: [78]  [ 600/1251]  eta: 0:08:54  lr: 0.003585  min_lr: 0.003585  loss: 3.3677 (3.3867)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9503 (1.0080)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [78]  [ 800/1251]  eta: 0:06:09  lr: 0.003583  min_lr: 0.003583  loss: 3.5484 (3.3817)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7655 (0.9347)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [78]  [1000/1251]  eta: 0:03:25  lr: 0.003580  min_lr: 0.003580  loss: 3.2104 (3.3829)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8822 (0.9497)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [78]  [1200/1251]  eta: 0:00:41  lr: 0.003578  min_lr: 0.003578  loss: 3.6589 (3.3764)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7676 (0.9423)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [78]  [1250/1251]  eta: 0:00:00  lr: 0.003578  min_lr: 0.003578  loss: 3.4072 (3.3734)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1271 (0.9700)  time: 0.6919  data: 0.0005  max mem: 62457
Epoch: [78] Total time: 0:17:01 (0.8168 s / it)
Averaged stats: lr: 0.003578  min_lr: 0.003578  loss: 3.4072 (3.3783)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1271 (0.9700)
Test:  [ 0/25]  eta: 0:02:48  loss: 0.6911 (0.6911)  acc1: 87.2000 (87.2000)  acc5: 98.4000 (98.4000)  time: 6.7586  data: 6.2549  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8627 (0.8719)  acc1: 83.2000 (82.0727)  acc5: 96.8000 (96.9455)  time: 1.0192  data: 0.5689  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0330 (1.0386)  acc1: 75.6000 (78.4191)  acc5: 94.8000 (94.7810)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1313 (1.0487)  acc1: 75.6000 (78.2720)  acc5: 93.6000 (94.7520)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7015 s / it)
* Acc@1 78.588 Acc@5 94.888 loss 1.038
Accuracy of the model on the 50000 test images: 78.6%
Max accuracy: 78.67%
Epoch: [79]  [   0/1251]  eta: 1:39:12  lr: 0.003578  min_lr: 0.003578  loss: 3.3357 (3.3357)  weight_decay: 0.0500 (0.0500)  time: 4.7583  data: 1.9409  max mem: 62457
Epoch: [79]  [ 200/1251]  eta: 0:14:39  lr: 0.003575  min_lr: 0.003575  loss: 3.3946 (3.3072)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6467 (0.9206)  time: 0.8226  data: 0.0004  max mem: 62457
Epoch: [79]  [ 400/1251]  eta: 0:11:43  lr: 0.003573  min_lr: 0.003573  loss: 3.3183 (3.3583)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7478 (0.8528)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [79]  [ 600/1251]  eta: 0:08:55  lr: 0.003571  min_lr: 0.003571  loss: 3.3589 (3.3819)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7285 (0.9071)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [79]  [ 800/1251]  eta: 0:06:10  lr: 0.003569  min_lr: 0.003569  loss: 3.3541 (3.3853)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8609 (0.9086)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [79]  [1000/1251]  eta: 0:03:25  lr: 0.003567  min_lr: 0.003567  loss: 2.9940 (3.3865)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7652 (0.9077)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [79]  [1200/1251]  eta: 0:00:41  lr: 0.003564  min_lr: 0.003564  loss: 3.5427 (3.3807)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1178 (0.9159)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [79]  [1250/1251]  eta: 0:00:00  lr: 0.003564  min_lr: 0.003564  loss: 3.4195 (3.3801)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6798 (0.9076)  time: 0.6921  data: 0.0005  max mem: 62457
Epoch: [79] Total time: 0:17:03 (0.8181 s / it)
Averaged stats: lr: 0.003564  min_lr: 0.003564  loss: 3.4195 (3.3908)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6798 (0.9076)
Test:  [ 0/25]  eta: 0:02:59  loss: 0.6674 (0.6674)  acc1: 86.0000 (86.0000)  acc5: 98.4000 (98.4000)  time: 7.1995  data: 6.7235  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8169 (0.8497)  acc1: 82.8000 (82.1818)  acc5: 97.2000 (96.9818)  time: 1.0593  data: 0.6115  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0246 (1.0061)  acc1: 77.2000 (78.9143)  acc5: 94.4000 (95.2191)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0758 (1.0132)  acc1: 77.2000 (78.7680)  acc5: 94.0000 (95.1040)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7192 s / it)
* Acc@1 78.906 Acc@5 94.958 loss 1.008
Accuracy of the model on the 50000 test images: 78.9%
Max accuracy: 78.91%
Epoch: [80]  [   0/1251]  eta: 1:34:36  lr: 0.003564  min_lr: 0.003564  loss: 3.9771 (3.9771)  weight_decay: 0.0500 (0.0500)  time: 4.5373  data: 3.7248  max mem: 62457
Epoch: [80]  [ 200/1251]  eta: 0:14:40  lr: 0.003562  min_lr: 0.003562  loss: 3.4206 (3.3474)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0660 (1.0737)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [80]  [ 400/1251]  eta: 0:11:42  lr: 0.003559  min_lr: 0.003559  loss: 3.6740 (3.3757)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7020 (0.9225)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [80]  [ 600/1251]  eta: 0:08:55  lr: 0.003557  min_lr: 0.003557  loss: 3.4906 (3.3598)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0329 (0.9440)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [80]  [ 800/1251]  eta: 0:06:10  lr: 0.003555  min_lr: 0.003555  loss: 2.9118 (3.3635)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7592 (0.8994)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [80]  [1000/1251]  eta: 0:03:25  lr: 0.003553  min_lr: 0.003553  loss: 3.2970 (3.3754)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8661 (0.9128)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [80]  [1200/1251]  eta: 0:00:41  lr: 0.003550  min_lr: 0.003550  loss: 3.4488 (3.3794)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5038 (0.8859)  time: 0.8184  data: 0.0004  max mem: 62457
Epoch: [80]  [1250/1251]  eta: 0:00:00  lr: 0.003550  min_lr: 0.003550  loss: 3.0237 (3.3756)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6033 (0.8776)  time: 0.6917  data: 0.0005  max mem: 62457
Epoch: [80] Total time: 0:17:03 (0.8178 s / it)
Averaged stats: lr: 0.003550  min_lr: 0.003550  loss: 3.0237 (3.3820)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6033 (0.8776)
Test:  [ 0/25]  eta: 0:02:19  loss: 0.6767 (0.6767)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 5.5698  data: 5.0741  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8605 (0.8431)  acc1: 83.2000 (82.5455)  acc5: 97.6000 (97.0182)  time: 1.0110  data: 0.5615  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0134 (1.0145)  acc1: 76.4000 (78.9143)  acc5: 94.0000 (94.8571)  time: 0.5000  data: 0.0551  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1204 (1.0250)  acc1: 76.4000 (78.6560)  acc5: 93.6000 (94.7680)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.6986 s / it)
* Acc@1 78.914 Acc@5 94.952 loss 1.014
Accuracy of the model on the 50000 test images: 78.9%
Max accuracy: 78.91%
Epoch: [81]  [   0/1251]  eta: 1:27:49  lr: 0.003550  min_lr: 0.003550  loss: 3.6463 (3.6463)  weight_decay: 0.0500 (0.0500)  time: 4.2125  data: 3.4048  max mem: 62457
Epoch: [81]  [ 200/1251]  eta: 0:14:33  lr: 0.003547  min_lr: 0.003547  loss: 2.8702 (3.3362)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7254 (0.8509)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [81]  [ 400/1251]  eta: 0:11:40  lr: 0.003545  min_lr: 0.003545  loss: 3.5357 (3.3201)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0231 (0.9080)  time: 0.8149  data: 0.0005  max mem: 62457
Epoch: [81]  [ 600/1251]  eta: 0:08:54  lr: 0.003543  min_lr: 0.003543  loss: 3.3765 (3.3383)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6278 (0.8496)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [81]  [ 800/1251]  eta: 0:06:09  lr: 0.003541  min_lr: 0.003541  loss: 3.4584 (3.3409)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0292 (0.9139)  time: 0.8156  data: 0.0005  max mem: 62457
Epoch: [81]  [1000/1251]  eta: 0:03:25  lr: 0.003538  min_lr: 0.003538  loss: 3.4811 (3.3404)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6679 (0.8988)  time: 0.8149  data: 0.0005  max mem: 62457
Epoch: [81]  [1200/1251]  eta: 0:00:41  lr: 0.003536  min_lr: 0.003536  loss: 3.5705 (3.3435)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7863 (0.8915)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [81]  [1250/1251]  eta: 0:00:00  lr: 0.003535  min_lr: 0.003535  loss: 3.3070 (3.3446)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8346 (0.8936)  time: 0.6917  data: 0.0006  max mem: 62457
Epoch: [81] Total time: 0:17:02 (0.8174 s / it)
Averaged stats: lr: 0.003535  min_lr: 0.003535  loss: 3.3070 (3.3700)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8346 (0.8936)
Test:  [ 0/25]  eta: 0:03:21  loss: 0.7960 (0.7960)  acc1: 84.4000 (84.4000)  acc5: 98.0000 (98.0000)  time: 8.0641  data: 7.5915  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.9142 (0.9009)  acc1: 81.6000 (81.5273)  acc5: 96.8000 (96.6909)  time: 1.1377  data: 0.6904  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0903 (1.0443)  acc1: 75.2000 (78.4000)  acc5: 94.4000 (94.5905)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1197 (1.0544)  acc1: 76.4000 (78.2560)  acc5: 93.6000 (94.5920)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7546 s / it)
* Acc@1 78.788 Acc@5 94.970 loss 1.043
Accuracy of the model on the 50000 test images: 78.8%
Max accuracy: 78.91%
Epoch: [82]  [   0/1251]  eta: 1:39:41  lr: 0.003535  min_lr: 0.003535  loss: 1.9832 (1.9832)  weight_decay: 0.0500 (0.0500)  time: 4.7812  data: 2.8380  max mem: 62457
Epoch: [82]  [ 200/1251]  eta: 0:14:37  lr: 0.003533  min_lr: 0.003533  loss: 3.5262 (3.4566)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7807 (0.8760)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [82]  [ 400/1251]  eta: 0:11:43  lr: 0.003531  min_lr: 0.003531  loss: 3.3881 (3.4194)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7308 (0.9227)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [82]  [ 600/1251]  eta: 0:08:55  lr: 0.003528  min_lr: 0.003528  loss: 3.4100 (3.4147)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5645 (0.8832)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [82]  [ 800/1251]  eta: 0:06:10  lr: 0.003526  min_lr: 0.003526  loss: 3.3610 (3.4070)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7229 (0.8759)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [82]  [1000/1251]  eta: 0:03:25  lr: 0.003524  min_lr: 0.003524  loss: 3.4904 (3.3912)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8300 (0.8883)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [82]  [1200/1251]  eta: 0:00:41  lr: 0.003521  min_lr: 0.003521  loss: 3.5172 (3.3907)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6906 (0.8752)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [82]  [1250/1251]  eta: 0:00:00  lr: 0.003521  min_lr: 0.003521  loss: 3.4637 (3.3931)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7486 (0.8735)  time: 0.6918  data: 0.0005  max mem: 62457
Epoch: [82] Total time: 0:17:02 (0.8177 s / it)
Averaged stats: lr: 0.003521  min_lr: 0.003521  loss: 3.4637 (3.3738)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7486 (0.8735)
Test:  [ 0/25]  eta: 0:03:19  loss: 0.8011 (0.8011)  acc1: 86.0000 (86.0000)  acc5: 98.0000 (98.0000)  time: 7.9858  data: 7.5018  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9924 (0.9643)  acc1: 81.6000 (82.4364)  acc5: 97.6000 (97.2000)  time: 1.1308  data: 0.6824  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.1192 (1.1151)  acc1: 78.0000 (78.8952)  acc5: 93.6000 (94.9524)  time: 0.4451  data: 0.0003  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2073 (1.1310)  acc1: 76.8000 (78.4800)  acc5: 93.2000 (94.7520)  time: 0.4450  data: 0.0002  max mem: 62457
Test: Total time: 0:00:18 (0.7518 s / it)
* Acc@1 78.742 Acc@5 94.808 loss 1.116
Accuracy of the model on the 50000 test images: 78.7%
Max accuracy: 78.91%
Epoch: [83]  [   0/1251]  eta: 1:48:04  lr: 0.003521  min_lr: 0.003521  loss: 3.0488 (3.0488)  weight_decay: 0.0500 (0.0500)  time: 5.1838  data: 3.0439  max mem: 62457
Epoch: [83]  [ 200/1251]  eta: 0:14:40  lr: 0.003519  min_lr: 0.003519  loss: 3.1457 (3.3834)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7215 (0.8707)  time: 0.8213  data: 0.0004  max mem: 62457
Epoch: [83]  [ 400/1251]  eta: 0:11:43  lr: 0.003516  min_lr: 0.003516  loss: 3.2346 (3.3648)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6934 (0.9136)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [83]  [ 600/1251]  eta: 0:08:55  lr: 0.003514  min_lr: 0.003514  loss: 3.6108 (3.3620)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7770 (0.9077)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [83]  [ 800/1251]  eta: 0:06:10  lr: 0.003512  min_lr: 0.003512  loss: 3.3329 (3.3664)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6235 (0.8965)  time: 0.8183  data: 0.0004  max mem: 62457
Epoch: [83]  [1000/1251]  eta: 0:03:25  lr: 0.003509  min_lr: 0.003509  loss: 3.5678 (3.3676)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6609 (0.8678)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [83]  [1200/1251]  eta: 0:00:41  lr: 0.003507  min_lr: 0.003507  loss: 3.6381 (3.3680)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0038 (0.8816)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [83]  [1250/1251]  eta: 0:00:00  lr: 0.003506  min_lr: 0.003506  loss: 3.5463 (3.3711)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9818 (0.8869)  time: 0.6916  data: 0.0006  max mem: 62457
Epoch: [83] Total time: 0:17:02 (0.8174 s / it)
Averaged stats: lr: 0.003506  min_lr: 0.003506  loss: 3.5463 (3.3729)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9818 (0.8869)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.8203 (0.8203)  acc1: 85.2000 (85.2000)  acc5: 97.2000 (97.2000)  time: 7.5724  data: 7.1062  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9102 (0.9341)  acc1: 82.4000 (82.1091)  acc5: 97.2000 (97.0546)  time: 1.0932  data: 0.6463  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0644 (1.1026)  acc1: 77.6000 (78.6476)  acc5: 94.4000 (94.8191)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1643 (1.1147)  acc1: 77.6000 (78.1760)  acc5: 94.0000 (94.7200)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7356 s / it)
* Acc@1 78.654 Acc@5 94.794 loss 1.099
Accuracy of the model on the 50000 test images: 78.7%
Max accuracy: 78.91%
Epoch: [84]  [   0/1251]  eta: 1:48:46  lr: 0.003506  min_lr: 0.003506  loss: 3.8351 (3.8351)  weight_decay: 0.0500 (0.0500)  time: 5.2167  data: 3.8222  max mem: 62457
Epoch: [84]  [ 200/1251]  eta: 0:14:42  lr: 0.003504  min_lr: 0.003504  loss: 3.3855 (3.3513)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7639 (0.8012)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [84]  [ 400/1251]  eta: 0:11:44  lr: 0.003502  min_lr: 0.003502  loss: 3.3906 (3.3553)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9158 (0.8572)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [84]  [ 600/1251]  eta: 0:08:56  lr: 0.003499  min_lr: 0.003499  loss: 3.4293 (3.3443)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7760 (0.8559)  time: 0.8225  data: 0.0004  max mem: 62457
Epoch: [84]  [ 800/1251]  eta: 0:06:10  lr: 0.003497  min_lr: 0.003497  loss: 3.2630 (3.3405)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9376 (0.8643)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [84]  [1000/1251]  eta: 0:03:25  lr: 0.003494  min_lr: 0.003494  loss: 3.2640 (3.3390)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8221 (0.8495)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [84]  [1200/1251]  eta: 0:00:41  lr: 0.003492  min_lr: 0.003492  loss: 3.7490 (3.3444)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7418 (0.8643)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [84]  [1250/1251]  eta: 0:00:00  lr: 0.003491  min_lr: 0.003491  loss: 3.2782 (3.3425)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8834 (0.8672)  time: 0.6913  data: 0.0007  max mem: 62457
Epoch: [84] Total time: 0:17:03 (0.8184 s / it)
Averaged stats: lr: 0.003491  min_lr: 0.003491  loss: 3.2782 (3.3540)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8834 (0.8672)
Test:  [ 0/25]  eta: 0:03:16  loss: 0.7197 (0.7197)  acc1: 86.8000 (86.8000)  acc5: 99.2000 (99.2000)  time: 7.8467  data: 7.3764  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8888 (0.8824)  acc1: 83.2000 (82.5818)  acc5: 97.2000 (96.9091)  time: 1.1170  data: 0.6709  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1039 (1.0368)  acc1: 78.0000 (79.2571)  acc5: 94.0000 (95.0095)  time: 0.4440  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1232 (1.0473)  acc1: 76.8000 (79.0240)  acc5: 94.0000 (94.9600)  time: 0.4439  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7453 s / it)
* Acc@1 78.786 Acc@5 95.072 loss 1.040
Accuracy of the model on the 50000 test images: 78.8%
Max accuracy: 78.91%
Epoch: [85]  [   0/1251]  eta: 1:44:17  lr: 0.003491  min_lr: 0.003491  loss: 2.7029 (2.7029)  weight_decay: 0.0500 (0.0500)  time: 5.0023  data: 3.4913  max mem: 62457
Epoch: [85]  [ 200/1251]  eta: 0:14:37  lr: 0.003489  min_lr: 0.003489  loss: 3.6762 (3.3130)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6687 (0.7175)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [85]  [ 400/1251]  eta: 0:11:42  lr: 0.003487  min_lr: 0.003487  loss: 3.5153 (3.3378)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6081 (0.7501)  time: 0.8223  data: 0.0004  max mem: 62457
Epoch: [85]  [ 600/1251]  eta: 0:08:55  lr: 0.003484  min_lr: 0.003484  loss: 3.6024 (3.3487)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7509 (0.8009)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [85]  [ 800/1251]  eta: 0:06:10  lr: 0.003482  min_lr: 0.003482  loss: 3.4094 (3.3563)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8311 (0.8525)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [85]  [1000/1251]  eta: 0:03:25  lr: 0.003479  min_lr: 0.003479  loss: 3.1787 (3.3589)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6261 (0.8314)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [85]  [1200/1251]  eta: 0:00:41  lr: 0.003477  min_lr: 0.003477  loss: 3.0047 (3.3514)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6398 (0.8270)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [85]  [1250/1251]  eta: 0:00:00  lr: 0.003476  min_lr: 0.003476  loss: 3.4765 (3.3547)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6398 (0.8232)  time: 0.6917  data: 0.0007  max mem: 62457
Epoch: [85] Total time: 0:17:02 (0.8177 s / it)
Averaged stats: lr: 0.003476  min_lr: 0.003476  loss: 3.4765 (3.3549)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6398 (0.8232)
Test:  [ 0/25]  eta: 0:03:10  loss: 0.6658 (0.6658)  acc1: 88.0000 (88.0000)  acc5: 99.2000 (99.2000)  time: 7.6194  data: 7.1406  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8706 (0.8759)  acc1: 82.4000 (82.3636)  acc5: 96.4000 (97.0182)  time: 1.0973  data: 0.6494  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0142 (1.0227)  acc1: 77.6000 (79.0857)  acc5: 95.6000 (95.0286)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0958 (1.0330)  acc1: 77.6000 (78.8480)  acc5: 93.6000 (94.9280)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7360 s / it)
* Acc@1 79.008 Acc@5 95.016 loss 1.035
Accuracy of the model on the 50000 test images: 79.0%
Max accuracy: 79.01%
Epoch: [86]  [   0/1251]  eta: 1:34:14  lr: 0.003476  min_lr: 0.003476  loss: 2.5122 (2.5122)  weight_decay: 0.0500 (0.0500)  time: 4.5200  data: 3.7119  max mem: 62457
Epoch: [86]  [ 200/1251]  eta: 0:14:35  lr: 0.003474  min_lr: 0.003474  loss: 3.5071 (3.3391)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5627 (0.8798)  time: 0.8218  data: 0.0004  max mem: 62457
Epoch: [86]  [ 400/1251]  eta: 0:11:42  lr: 0.003472  min_lr: 0.003472  loss: 3.4170 (3.3521)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6325 (0.8378)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [86]  [ 600/1251]  eta: 0:08:54  lr: 0.003469  min_lr: 0.003469  loss: 3.2884 (3.3629)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8469 (0.8348)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [86]  [ 800/1251]  eta: 0:06:09  lr: 0.003467  min_lr: 0.003467  loss: 3.4062 (3.3606)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6637 (0.8063)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [86]  [1000/1251]  eta: 0:03:25  lr: 0.003464  min_lr: 0.003464  loss: 3.2854 (3.3568)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0735 (0.8170)  time: 0.8143  data: 0.0005  max mem: 62457
Epoch: [86]  [1200/1251]  eta: 0:00:41  lr: 0.003462  min_lr: 0.003462  loss: 3.4523 (3.3651)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7849 (0.8451)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [86]  [1250/1251]  eta: 0:00:00  lr: 0.003461  min_lr: 0.003461  loss: 3.4099 (3.3643)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8083 (0.8469)  time: 0.6914  data: 0.0006  max mem: 62457
Epoch: [86] Total time: 0:17:02 (0.8170 s / it)
Averaged stats: lr: 0.003461  min_lr: 0.003461  loss: 3.4099 (3.3675)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8083 (0.8469)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.6951 (0.6951)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 7.5377  data: 7.0701  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9717 (0.9253)  acc1: 82.0000 (82.2909)  acc5: 97.2000 (96.9818)  time: 1.0898  data: 0.6430  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0651 (1.0869)  acc1: 77.2000 (78.8571)  acc5: 95.2000 (95.0476)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1922 (1.0996)  acc1: 76.8000 (78.7360)  acc5: 94.0000 (94.9760)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7331 s / it)
* Acc@1 78.802 Acc@5 94.906 loss 1.088
Accuracy of the model on the 50000 test images: 78.8%
Max accuracy: 79.01%
Epoch: [87]  [   0/1251]  eta: 1:37:47  lr: 0.003461  min_lr: 0.003461  loss: 2.8347 (2.8347)  weight_decay: 0.0500 (0.0500)  time: 4.6906  data: 3.4318  max mem: 62457
Epoch: [87]  [ 200/1251]  eta: 0:14:38  lr: 0.003459  min_lr: 0.003459  loss: 3.4044 (3.3335)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6794 (nan)  time: 0.8219  data: 0.0004  max mem: 62457
Epoch: [87]  [ 400/1251]  eta: 0:11:42  lr: 0.003456  min_lr: 0.003456  loss: 3.2538 (3.3340)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6089 (nan)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [87]  [ 600/1251]  eta: 0:08:55  lr: 0.003454  min_lr: 0.003454  loss: 3.5778 (3.3106)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7321 (nan)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [87]  [ 800/1251]  eta: 0:06:10  lr: 0.003451  min_lr: 0.003451  loss: 3.4588 (3.3253)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7424 (nan)  time: 0.8188  data: 0.0004  max mem: 62457
Epoch: [87]  [1000/1251]  eta: 0:03:25  lr: 0.003449  min_lr: 0.003449  loss: 3.1627 (3.3328)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8891 (nan)  time: 0.8135  data: 0.0004  max mem: 62457
Epoch: [87]  [1200/1251]  eta: 0:00:41  lr: 0.003446  min_lr: 0.003446  loss: 3.6868 (3.3419)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5374 (nan)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [87]  [1250/1251]  eta: 0:00:00  lr: 0.003446  min_lr: 0.003446  loss: 3.2609 (3.3398)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5227 (nan)  time: 0.6931  data: 0.0006  max mem: 62457
Epoch: [87] Total time: 0:17:01 (0.8169 s / it)
Averaged stats: lr: 0.003446  min_lr: 0.003446  loss: 3.2609 (3.3496)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5227 (nan)
Test:  [ 0/25]  eta: 0:03:16  loss: 0.6730 (0.6730)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 7.8558  data: 7.3902  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8833 (0.8643)  acc1: 80.4000 (82.5091)  acc5: 97.2000 (97.4182)  time: 1.1190  data: 0.6721  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9943 (1.0172)  acc1: 77.6000 (79.2952)  acc5: 94.8000 (95.2571)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1053 (1.0281)  acc1: 77.6000 (78.9120)  acc5: 93.2000 (95.1200)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7457 s / it)
* Acc@1 79.138 Acc@5 95.186 loss 1.016
Accuracy of the model on the 50000 test images: 79.1%
Max accuracy: 79.14%
Epoch: [88]  [   0/1251]  eta: 1:20:28  lr: 0.003446  min_lr: 0.003446  loss: 4.1507 (4.1507)  weight_decay: 0.0500 (0.0500)  time: 3.8594  data: 3.0384  max mem: 62457
Epoch: [88]  [ 200/1251]  eta: 0:14:34  lr: 0.003443  min_lr: 0.003443  loss: 3.3343 (3.2948)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7558 (0.7852)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [88]  [ 400/1251]  eta: 0:11:40  lr: 0.003441  min_lr: 0.003441  loss: 3.4416 (3.3153)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7106 (0.8640)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [88]  [ 600/1251]  eta: 0:08:54  lr: 0.003438  min_lr: 0.003438  loss: 3.3834 (3.3373)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6795 (0.8028)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [88]  [ 800/1251]  eta: 0:06:09  lr: 0.003436  min_lr: 0.003436  loss: 3.4808 (3.3300)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6688 (0.7841)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [88]  [1000/1251]  eta: 0:03:25  lr: 0.003433  min_lr: 0.003433  loss: 3.5408 (3.3413)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6446 (0.7774)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [88]  [1200/1251]  eta: 0:00:41  lr: 0.003431  min_lr: 0.003431  loss: 3.4381 (3.3293)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7534 (0.7875)  time: 0.8185  data: 0.0004  max mem: 62457
Epoch: [88]  [1250/1251]  eta: 0:00:00  lr: 0.003430  min_lr: 0.003430  loss: 3.2435 (3.3282)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6283 (0.7817)  time: 0.6915  data: 0.0006  max mem: 62457
Epoch: [88] Total time: 0:17:01 (0.8163 s / it)
Averaged stats: lr: 0.003430  min_lr: 0.003430  loss: 3.2435 (3.3414)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6283 (0.7817)
Test:  [ 0/25]  eta: 0:03:25  loss: 0.6438 (0.6438)  acc1: 87.6000 (87.6000)  acc5: 98.8000 (98.8000)  time: 8.2213  data: 7.7415  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8128 (0.8510)  acc1: 81.6000 (82.3636)  acc5: 97.2000 (97.0182)  time: 1.1519  data: 0.7040  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9831 (1.0031)  acc1: 78.4000 (79.1619)  acc5: 94.8000 (95.0667)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0590 (1.0170)  acc1: 76.0000 (78.7040)  acc5: 94.0000 (94.8960)  time: 0.4447  data: 0.0001  max mem: 62457
Test: Total time: 0:00:19 (0.7604 s / it)
* Acc@1 79.186 Acc@5 95.034 loss 0.997
Accuracy of the model on the 50000 test images: 79.2%
Max accuracy: 79.19%
Epoch: [89]  [   0/1251]  eta: 1:27:33  lr: 0.003430  min_lr: 0.003430  loss: 3.2125 (3.2125)  weight_decay: 0.0500 (0.0500)  time: 4.1994  data: 3.3809  max mem: 62457
Epoch: [89]  [ 200/1251]  eta: 0:14:34  lr: 0.003428  min_lr: 0.003428  loss: 3.2544 (3.3485)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6432 (0.6957)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [89]  [ 400/1251]  eta: 0:11:40  lr: 0.003425  min_lr: 0.003425  loss: 3.4235 (3.3706)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7422 (0.7320)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [89]  [ 600/1251]  eta: 0:08:54  lr: 0.003423  min_lr: 0.003423  loss: 3.4812 (3.3693)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5734 (0.7500)  time: 0.8230  data: 0.0004  max mem: 62457
Epoch: [89]  [ 800/1251]  eta: 0:06:09  lr: 0.003420  min_lr: 0.003420  loss: 3.4558 (3.3558)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6853 (0.7705)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [89]  [1000/1251]  eta: 0:03:25  lr: 0.003418  min_lr: 0.003418  loss: 3.5097 (3.3505)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8658 (0.7907)  time: 0.8216  data: 0.0004  max mem: 62457
Epoch: [89]  [1200/1251]  eta: 0:00:41  lr: 0.003415  min_lr: 0.003415  loss: 3.5159 (3.3533)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7450 (0.8143)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [89]  [1250/1251]  eta: 0:00:00  lr: 0.003414  min_lr: 0.003414  loss: 3.5039 (3.3515)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7408 (0.8103)  time: 0.6916  data: 0.0006  max mem: 62457
Epoch: [89] Total time: 0:17:02 (0.8172 s / it)
Averaged stats: lr: 0.003414  min_lr: 0.003414  loss: 3.5039 (3.3378)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7408 (0.8103)
Test:  [ 0/25]  eta: 0:03:10  loss: 0.6545 (0.6545)  acc1: 87.6000 (87.6000)  acc5: 98.8000 (98.8000)  time: 7.6326  data: 7.1709  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8615 (0.8651)  acc1: 84.0000 (82.2545)  acc5: 97.2000 (97.0546)  time: 1.0999  data: 0.6522  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9838 (1.0256)  acc1: 77.2000 (78.5905)  acc5: 94.8000 (95.1048)  time: 0.4458  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0562 (1.0380)  acc1: 76.4000 (78.4320)  acc5: 94.4000 (94.9760)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7369 s / it)
* Acc@1 79.126 Acc@5 95.142 loss 1.013
Accuracy of the model on the 50000 test images: 79.1%
Max accuracy: 79.19%
Epoch: [90]  [   0/1251]  eta: 1:39:46  lr: 0.003414  min_lr: 0.003414  loss: 4.4554 (4.4554)  weight_decay: 0.0500 (0.0500)  time: 4.7851  data: 2.0059  max mem: 62457
Epoch: [90]  [ 200/1251]  eta: 0:14:36  lr: 0.003412  min_lr: 0.003412  loss: 3.5441 (3.3305)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6027 (0.6869)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [90]  [ 400/1251]  eta: 0:11:42  lr: 0.003409  min_lr: 0.003409  loss: 3.2814 (3.3122)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6305 (0.7510)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [90]  [ 600/1251]  eta: 0:08:55  lr: 0.003407  min_lr: 0.003407  loss: 3.3453 (3.3281)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7927 (0.7662)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [90]  [ 800/1251]  eta: 0:06:10  lr: 0.003404  min_lr: 0.003404  loss: 3.6214 (3.3181)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6513 (0.7480)  time: 0.8228  data: 0.0004  max mem: 62457
Epoch: [90]  [1000/1251]  eta: 0:03:25  lr: 0.003402  min_lr: 0.003402  loss: 3.6111 (3.3220)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5410 (0.7470)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [90]  [1200/1251]  eta: 0:00:41  lr: 0.003399  min_lr: 0.003399  loss: 3.5311 (3.3247)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7052 (0.7526)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [90]  [1250/1251]  eta: 0:00:00  lr: 0.003398  min_lr: 0.003398  loss: 3.6114 (3.3268)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9050 (0.7624)  time: 0.6920  data: 0.0006  max mem: 62457
Epoch: [90] Total time: 0:17:02 (0.8175 s / it)
Averaged stats: lr: 0.003398  min_lr: 0.003398  loss: 3.6114 (3.3406)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9050 (0.7624)
Test:  [ 0/25]  eta: 0:03:00  loss: 0.7526 (0.7526)  acc1: 89.6000 (89.6000)  acc5: 98.0000 (98.0000)  time: 7.2105  data: 6.7315  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8987 (0.9279)  acc1: 83.6000 (82.5818)  acc5: 97.2000 (96.9455)  time: 1.0603  data: 0.6122  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1096 (1.0737)  acc1: 76.8000 (79.1429)  acc5: 94.0000 (95.0095)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1653 (1.0847)  acc1: 76.8000 (78.8640)  acc5: 94.0000 (94.8480)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7200 s / it)
* Acc@1 79.312 Acc@5 95.078 loss 1.072
Accuracy of the model on the 50000 test images: 79.3%
Max accuracy: 79.31%
Epoch: [91]  [   0/1251]  eta: 1:29:55  lr: 0.003398  min_lr: 0.003398  loss: 3.2959 (3.2959)  weight_decay: 0.0500 (0.0500)  time: 4.3130  data: 3.4921  max mem: 62457
Epoch: [91]  [ 200/1251]  eta: 0:14:36  lr: 0.003396  min_lr: 0.003396  loss: 3.2972 (3.3196)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7847 (0.7723)  time: 0.8210  data: 0.0004  max mem: 62457
Epoch: [91]  [ 400/1251]  eta: 0:11:41  lr: 0.003393  min_lr: 0.003393  loss: 3.6575 (3.3327)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7671 (0.7735)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [91]  [ 600/1251]  eta: 0:08:54  lr: 0.003391  min_lr: 0.003391  loss: 3.5371 (3.3303)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6626 (0.7624)  time: 0.8143  data: 0.0005  max mem: 62457
Epoch: [91]  [ 800/1251]  eta: 0:06:09  lr: 0.003388  min_lr: 0.003388  loss: 3.3990 (3.3452)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7307 (0.7801)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [91]  [1000/1251]  eta: 0:03:25  lr: 0.003385  min_lr: 0.003385  loss: 3.5861 (3.3562)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6754 (0.7771)  time: 0.8144  data: 0.0005  max mem: 62457
Epoch: [91]  [1200/1251]  eta: 0:00:41  lr: 0.003383  min_lr: 0.003383  loss: 3.2147 (3.3512)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6223 (0.7680)  time: 0.8260  data: 0.0005  max mem: 62457
Epoch: [91]  [1250/1251]  eta: 0:00:00  lr: 0.003382  min_lr: 0.003382  loss: 3.3996 (3.3556)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5722 (0.7656)  time: 0.6915  data: 0.0005  max mem: 62457
Epoch: [91] Total time: 0:17:01 (0.8169 s / it)
Averaged stats: lr: 0.003382  min_lr: 0.003382  loss: 3.3996 (3.3406)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5722 (0.7656)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.8755 (0.8755)  acc1: 84.8000 (84.8000)  acc5: 97.2000 (97.2000)  time: 7.7141  data: 7.2446  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9392 (0.9723)  acc1: 81.2000 (82.3636)  acc5: 97.2000 (96.8727)  time: 1.1057  data: 0.6589  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1108 (1.1240)  acc1: 76.8000 (78.7429)  acc5: 94.8000 (95.0286)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.2636 (1.1323)  acc1: 75.2000 (78.5120)  acc5: 93.6000 (94.7680)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7401 s / it)
* Acc@1 78.828 Acc@5 94.962 loss 1.117
Accuracy of the model on the 50000 test images: 78.8%
Max accuracy: 79.31%
Epoch: [92]  [   0/1251]  eta: 1:38:04  lr: 0.003382  min_lr: 0.003382  loss: 3.4802 (3.4802)  weight_decay: 0.0500 (0.0500)  time: 4.7035  data: 2.1370  max mem: 62457
Epoch: [92]  [ 200/1251]  eta: 0:14:38  lr: 0.003380  min_lr: 0.003380  loss: 3.5031 (3.3720)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5424 (0.8323)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [92]  [ 400/1251]  eta: 0:11:42  lr: 0.003377  min_lr: 0.003377  loss: 3.4910 (3.3352)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9165 (0.8588)  time: 0.8147  data: 0.0003  max mem: 62457
Epoch: [92]  [ 600/1251]  eta: 0:08:55  lr: 0.003374  min_lr: 0.003374  loss: 3.2194 (3.3348)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7770 (0.8761)  time: 0.8197  data: 0.0004  max mem: 62457
Epoch: [92]  [ 800/1251]  eta: 0:06:10  lr: 0.003372  min_lr: 0.003372  loss: 3.4476 (3.3461)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5364 (0.8185)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [92]  [1000/1251]  eta: 0:03:25  lr: 0.003369  min_lr: 0.003369  loss: 3.5399 (3.3505)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9802 (0.8341)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [92]  [1200/1251]  eta: 0:00:41  lr: 0.003367  min_lr: 0.003367  loss: 3.4930 (3.3453)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6936 (0.8339)  time: 0.8221  data: 0.0004  max mem: 62457
Epoch: [92]  [1250/1251]  eta: 0:00:00  lr: 0.003366  min_lr: 0.003366  loss: 3.6072 (3.3495)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7033 (0.8279)  time: 0.6918  data: 0.0005  max mem: 62457
Epoch: [92] Total time: 0:17:03 (0.8177 s / it)
Averaged stats: lr: 0.003366  min_lr: 0.003366  loss: 3.6072 (3.3410)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7033 (0.8279)
Test:  [ 0/25]  eta: 0:03:07  loss: 0.7022 (0.7022)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 7.4963  data: 7.0390  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8999 (0.9007)  acc1: 83.6000 (82.4364)  acc5: 97.6000 (97.1636)  time: 1.0892  data: 0.6402  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0846 (1.0703)  acc1: 76.8000 (79.0286)  acc5: 94.8000 (95.0476)  time: 0.4467  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1992 (1.0845)  acc1: 76.8000 (78.6560)  acc5: 93.2000 (94.9120)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7330 s / it)
* Acc@1 79.054 Acc@5 95.180 loss 1.074
Accuracy of the model on the 50000 test images: 79.1%
Max accuracy: 79.31%
Epoch: [93]  [   0/1251]  eta: 1:37:32  lr: 0.003366  min_lr: 0.003366  loss: 3.6711 (3.6711)  weight_decay: 0.0500 (0.0500)  time: 4.6782  data: 3.6291  max mem: 62457
Epoch: [93]  [ 200/1251]  eta: 0:14:37  lr: 0.003363  min_lr: 0.003363  loss: 3.3994 (3.2328)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7071 (0.8631)  time: 0.8215  data: 0.0004  max mem: 62457
Epoch: [93]  [ 400/1251]  eta: 0:11:41  lr: 0.003361  min_lr: 0.003361  loss: 3.4273 (3.2780)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7739 (0.8053)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [93]  [ 600/1251]  eta: 0:08:55  lr: 0.003358  min_lr: 0.003358  loss: 3.1629 (3.2811)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [93]  [ 800/1251]  eta: 0:06:09  lr: 0.003355  min_lr: 0.003355  loss: 3.2999 (3.2888)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8677 (nan)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [93]  [1000/1251]  eta: 0:03:25  lr: 0.003353  min_lr: 0.003353  loss: 3.2843 (3.3035)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5611 (nan)  time: 0.8219  data: 0.0005  max mem: 62457
Epoch: [93]  [1200/1251]  eta: 0:00:41  lr: 0.003350  min_lr: 0.003350  loss: 3.3679 (3.3073)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5916 (nan)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [93]  [1250/1251]  eta: 0:00:00  lr: 0.003350  min_lr: 0.003350  loss: 3.2893 (3.3093)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8252 (nan)  time: 0.6918  data: 0.0007  max mem: 62457
Epoch: [93] Total time: 0:17:02 (0.8173 s / it)
Averaged stats: lr: 0.003350  min_lr: 0.003350  loss: 3.2893 (3.3338)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8252 (nan)
Test:  [ 0/25]  eta: 0:03:17  loss: 0.6205 (0.6205)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 7.9062  data: 7.4324  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8303 (0.8222)  acc1: 84.4000 (84.0000)  acc5: 97.6000 (97.2000)  time: 1.1233  data: 0.6760  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0022 (1.0002)  acc1: 79.2000 (80.3238)  acc5: 94.4000 (95.2762)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0787 (1.0097)  acc1: 78.0000 (79.9840)  acc5: 94.4000 (95.1200)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7477 s / it)
* Acc@1 79.372 Acc@5 95.138 loss 1.013
Accuracy of the model on the 50000 test images: 79.4%
Max accuracy: 79.37%
Epoch: [94]  [   0/1251]  eta: 1:33:08  lr: 0.003350  min_lr: 0.003350  loss: 4.0036 (4.0036)  weight_decay: 0.0500 (0.0500)  time: 4.4674  data: 3.6553  max mem: 62457
Epoch: [94]  [ 200/1251]  eta: 0:14:34  lr: 0.003347  min_lr: 0.003347  loss: 3.2747 (3.2798)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5505 (0.6547)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [94]  [ 400/1251]  eta: 0:11:41  lr: 0.003344  min_lr: 0.003344  loss: 3.6030 (3.3207)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7256 (0.7625)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [94]  [ 600/1251]  eta: 0:08:54  lr: 0.003342  min_lr: 0.003342  loss: 3.2378 (3.3181)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6437 (0.7496)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [94]  [ 800/1251]  eta: 0:06:09  lr: 0.003339  min_lr: 0.003339  loss: 3.1153 (3.2967)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7151 (0.7560)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [94]  [1000/1251]  eta: 0:03:25  lr: 0.003336  min_lr: 0.003336  loss: 3.4040 (3.3145)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7873 (0.7673)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [94]  [1200/1251]  eta: 0:00:41  lr: 0.003334  min_lr: 0.003334  loss: 3.3239 (3.3117)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7054 (0.7692)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [94]  [1250/1251]  eta: 0:00:00  lr: 0.003333  min_lr: 0.003333  loss: 3.4291 (3.3134)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6465 (0.7651)  time: 0.6915  data: 0.0005  max mem: 62457
Epoch: [94] Total time: 0:17:01 (0.8168 s / it)
Averaged stats: lr: 0.003333  min_lr: 0.003333  loss: 3.4291 (3.3207)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6465 (0.7651)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.6763 (0.6763)  acc1: 88.4000 (88.4000)  acc5: 98.4000 (98.4000)  time: 7.7652  data: 7.2760  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7963 (0.8528)  acc1: 83.2000 (83.1636)  acc5: 97.6000 (97.1273)  time: 1.1105  data: 0.6617  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9756 (1.0018)  acc1: 78.4000 (79.9619)  acc5: 94.8000 (95.3905)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0924 (1.0115)  acc1: 77.2000 (79.6320)  acc5: 94.4000 (95.3440)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7439 s / it)
* Acc@1 79.360 Acc@5 95.256 loss 1.014
Accuracy of the model on the 50000 test images: 79.4%
Max accuracy: 79.37%
Epoch: [95]  [   0/1251]  eta: 1:45:53  lr: 0.003333  min_lr: 0.003333  loss: 2.9360 (2.9360)  weight_decay: 0.0500 (0.0500)  time: 5.0787  data: 4.2633  max mem: 62457
Epoch: [95]  [ 200/1251]  eta: 0:14:42  lr: 0.003330  min_lr: 0.003330  loss: 3.4752 (3.3879)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6547 (0.8837)  time: 0.8218  data: 0.0004  max mem: 62457
Epoch: [95]  [ 400/1251]  eta: 0:11:44  lr: 0.003327  min_lr: 0.003327  loss: 3.3657 (3.3504)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7205 (0.7871)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [95]  [ 600/1251]  eta: 0:08:56  lr: 0.003325  min_lr: 0.003325  loss: 3.7330 (3.3695)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6438 (0.7937)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [95]  [ 800/1251]  eta: 0:06:10  lr: 0.003322  min_lr: 0.003322  loss: 3.3663 (3.3558)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6606 (0.7804)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [95]  [1000/1251]  eta: 0:03:26  lr: 0.003319  min_lr: 0.003319  loss: 3.4656 (3.3592)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7020 (0.7899)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [95]  [1200/1251]  eta: 0:00:41  lr: 0.003317  min_lr: 0.003317  loss: 3.2773 (3.3556)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7055 (0.7864)  time: 0.8212  data: 0.0004  max mem: 62457
Epoch: [95]  [1250/1251]  eta: 0:00:00  lr: 0.003316  min_lr: 0.003316  loss: 3.3954 (3.3524)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8718 (0.7958)  time: 0.6922  data: 0.0005  max mem: 62457
Epoch: [95] Total time: 0:17:03 (0.8185 s / it)
Averaged stats: lr: 0.003316  min_lr: 0.003316  loss: 3.3954 (3.3215)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8718 (0.7958)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.6295 (0.6295)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 7.5425  data: 7.0687  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8593 (0.8477)  acc1: 84.4000 (83.0182)  acc5: 97.6000 (97.3818)  time: 1.0904  data: 0.6429  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9821 (1.0055)  acc1: 77.6000 (79.5810)  acc5: 94.0000 (95.4095)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1151 (1.0175)  acc1: 77.2000 (79.0720)  acc5: 94.0000 (95.2960)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7329 s / it)
* Acc@1 79.460 Acc@5 95.236 loss 1.009
Accuracy of the model on the 50000 test images: 79.5%
Max accuracy: 79.46%
Epoch: [96]  [   0/1251]  eta: 1:28:53  lr: 0.003316  min_lr: 0.003316  loss: 3.2862 (3.2862)  weight_decay: 0.0500 (0.0500)  time: 4.2637  data: 3.4566  max mem: 62457
Epoch: [96]  [ 200/1251]  eta: 0:14:35  lr: 0.003313  min_lr: 0.003313  loss: 3.4782 (3.2990)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6954 (0.7718)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [96]  [ 400/1251]  eta: 0:11:40  lr: 0.003311  min_lr: 0.003311  loss: 3.1442 (3.2649)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6629 (0.7463)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [96]  [ 600/1251]  eta: 0:08:54  lr: 0.003308  min_lr: 0.003308  loss: 3.4812 (3.2849)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8535 (0.7780)  time: 0.8305  data: 0.0004  max mem: 62457
Epoch: [96]  [ 800/1251]  eta: 0:06:09  lr: 0.003305  min_lr: 0.003305  loss: 3.5912 (3.3066)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7769 (0.7940)  time: 0.8139  data: 0.0005  max mem: 62457
Epoch: [96]  [1000/1251]  eta: 0:03:25  lr: 0.003302  min_lr: 0.003302  loss: 3.3614 (3.3066)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7098 (0.7815)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [96]  [1200/1251]  eta: 0:00:41  lr: 0.003300  min_lr: 0.003300  loss: 3.0904 (3.3142)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5930 (0.7787)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [96]  [1250/1251]  eta: 0:00:00  lr: 0.003299  min_lr: 0.003299  loss: 3.3498 (3.3162)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6602 (0.7761)  time: 0.6915  data: 0.0006  max mem: 62457
Epoch: [96] Total time: 0:17:02 (0.8170 s / it)
Averaged stats: lr: 0.003299  min_lr: 0.003299  loss: 3.3498 (3.3168)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6602 (0.7761)
Test:  [ 0/25]  eta: 0:03:18  loss: 0.6927 (0.6927)  acc1: 87.6000 (87.6000)  acc5: 98.8000 (98.8000)  time: 7.9397  data: 7.4608  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9128 (0.8803)  acc1: 82.4000 (83.5636)  acc5: 96.8000 (97.2727)  time: 1.1263  data: 0.6785  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0534 (1.0250)  acc1: 78.8000 (79.8095)  acc5: 95.2000 (95.3143)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1159 (1.0344)  acc1: 77.2000 (79.4720)  acc5: 94.4000 (95.2320)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7488 s / it)
* Acc@1 79.686 Acc@5 95.306 loss 1.030
Accuracy of the model on the 50000 test images: 79.7%
Max accuracy: 79.69%
Epoch: [97]  [   0/1251]  eta: 1:30:05  lr: 0.003299  min_lr: 0.003299  loss: 2.7250 (2.7250)  weight_decay: 0.0500 (0.0500)  time: 4.3206  data: 3.5129  max mem: 62457
Epoch: [97]  [ 200/1251]  eta: 0:14:33  lr: 0.003296  min_lr: 0.003296  loss: 3.3140 (3.2917)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6601 (0.9448)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [97]  [ 400/1251]  eta: 0:11:40  lr: 0.003294  min_lr: 0.003294  loss: 3.3870 (3.3028)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6481 (0.8243)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [97]  [ 600/1251]  eta: 0:08:54  lr: 0.003291  min_lr: 0.003291  loss: 3.4046 (3.2996)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8089 (0.8141)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [97]  [ 800/1251]  eta: 0:06:09  lr: 0.003288  min_lr: 0.003288  loss: 3.3344 (3.3089)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6931 (0.8249)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [97]  [1000/1251]  eta: 0:03:25  lr: 0.003285  min_lr: 0.003285  loss: 3.4973 (3.3091)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6109 (0.8069)  time: 0.8241  data: 0.0004  max mem: 62457
Epoch: [97]  [1200/1251]  eta: 0:00:41  lr: 0.003283  min_lr: 0.003283  loss: 3.2442 (3.3138)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5621 (0.7780)  time: 0.8131  data: 0.0005  max mem: 62457
Epoch: [97]  [1250/1251]  eta: 0:00:00  lr: 0.003282  min_lr: 0.003282  loss: 3.4504 (3.3125)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5528 (0.7717)  time: 0.6905  data: 0.0006  max mem: 62457
Epoch: [97] Total time: 0:17:01 (0.8168 s / it)
Averaged stats: lr: 0.003282  min_lr: 0.003282  loss: 3.4504 (3.3194)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5528 (0.7717)
Test:  [ 0/25]  eta: 0:03:27  loss: 0.6787 (0.6787)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 8.2843  data: 7.8040  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8392 (0.8448)  acc1: 83.2000 (83.2727)  acc5: 97.2000 (96.9818)  time: 1.1571  data: 0.7097  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0531 (1.0025)  acc1: 77.2000 (79.6952)  acc5: 94.8000 (95.2762)  time: 0.4444  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1257 (1.0190)  acc1: 77.2000 (79.2960)  acc5: 94.4000 (94.9920)  time: 0.4443  data: 0.0001  max mem: 62457
Test: Total time: 0:00:19 (0.7621 s / it)
* Acc@1 79.558 Acc@5 95.170 loss 1.003
Accuracy of the model on the 50000 test images: 79.6%
Max accuracy: 79.69%
Epoch: [98]  [   0/1251]  eta: 1:25:28  lr: 0.003282  min_lr: 0.003282  loss: 3.5231 (3.5231)  weight_decay: 0.0500 (0.0500)  time: 4.0997  data: 3.2513  max mem: 62457
Epoch: [98]  [ 200/1251]  eta: 0:14:34  lr: 0.003279  min_lr: 0.003279  loss: 3.4646 (3.2954)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8829 (0.8718)  time: 0.8141  data: 0.0005  max mem: 62457
Epoch: [98]  [ 400/1251]  eta: 0:11:42  lr: 0.003276  min_lr: 0.003276  loss: 3.2608 (3.2769)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7518 (0.8359)  time: 0.8148  data: 0.0005  max mem: 62457
Epoch: [98]  [ 600/1251]  eta: 0:08:55  lr: 0.003274  min_lr: 0.003274  loss: 3.3722 (3.2997)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6604 (0.8112)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [98]  [ 800/1251]  eta: 0:06:09  lr: 0.003271  min_lr: 0.003271  loss: 3.5273 (3.3115)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6058 (0.7996)  time: 0.8145  data: 0.0005  max mem: 62457
Epoch: [98]  [1000/1251]  eta: 0:03:25  lr: 0.003268  min_lr: 0.003268  loss: 3.2889 (3.3226)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7044 (0.7812)  time: 0.8145  data: 0.0005  max mem: 62457
Epoch: [98]  [1200/1251]  eta: 0:00:41  lr: 0.003265  min_lr: 0.003265  loss: 3.5150 (3.3280)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7812 (0.7686)  time: 0.8199  data: 0.0005  max mem: 62457
Epoch: [98]  [1250/1251]  eta: 0:00:00  lr: 0.003265  min_lr: 0.003265  loss: 3.5112 (3.3298)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7458 (0.7680)  time: 0.6919  data: 0.0007  max mem: 62457
Epoch: [98] Total time: 0:17:02 (0.8176 s / it)
Averaged stats: lr: 0.003265  min_lr: 0.003265  loss: 3.5112 (3.3156)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7458 (0.7680)
Test:  [ 0/25]  eta: 0:03:06  loss: 0.6979 (0.6979)  acc1: 87.2000 (87.2000)  acc5: 98.0000 (98.0000)  time: 7.4692  data: 6.9876  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8964 (0.9134)  acc1: 82.4000 (83.2000)  acc5: 97.2000 (96.8727)  time: 1.0838  data: 0.6356  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0752 (1.0641)  acc1: 77.6000 (79.5048)  acc5: 94.4000 (95.2000)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1830 (1.0768)  acc1: 77.6000 (79.1840)  acc5: 94.4000 (94.9760)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7305 s / it)
* Acc@1 79.558 Acc@5 95.320 loss 1.059
Accuracy of the model on the 50000 test images: 79.6%
Max accuracy: 79.69%
Epoch: [99]  [   0/1251]  eta: 1:34:48  lr: 0.003265  min_lr: 0.003265  loss: 2.9016 (2.9016)  weight_decay: 0.0500 (0.0500)  time: 4.5470  data: 3.7245  max mem: 62457
Epoch: [99]  [ 200/1251]  eta: 0:14:39  lr: 0.003262  min_lr: 0.003262  loss: 3.3675 (3.3111)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5855 (0.8380)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [99]  [ 400/1251]  eta: 0:11:42  lr: 0.003259  min_lr: 0.003259  loss: 3.3424 (3.3234)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8198 (0.8091)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [99]  [ 600/1251]  eta: 0:08:55  lr: 0.003256  min_lr: 0.003256  loss: 3.2744 (3.3268)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6494 (0.8067)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [99]  [ 800/1251]  eta: 0:06:10  lr: 0.003253  min_lr: 0.003253  loss: 3.1574 (3.3123)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6991 (0.8228)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [99]  [1000/1251]  eta: 0:03:25  lr: 0.003251  min_lr: 0.003251  loss: 3.3640 (3.3164)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6444 (0.7968)  time: 0.8137  data: 0.0004  max mem: 62457
Epoch: [99]  [1200/1251]  eta: 0:00:41  lr: 0.003248  min_lr: 0.003248  loss: 3.5588 (3.3135)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6542 (0.7871)  time: 0.8172  data: 0.0004  max mem: 62457
Epoch: [99]  [1250/1251]  eta: 0:00:00  lr: 0.003247  min_lr: 0.003247  loss: 3.1473 (3.3128)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6756 (0.7912)  time: 0.6913  data: 0.0006  max mem: 62457
Epoch: [99] Total time: 0:17:02 (0.8171 s / it)
Averaged stats: lr: 0.003247  min_lr: 0.003247  loss: 3.1473 (3.3106)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6756 (0.7912)
Test:  [ 0/25]  eta: 0:03:07  loss: 0.6167 (0.6167)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 7.4816  data: 7.0055  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8375 (0.8441)  acc1: 83.2000 (82.4727)  acc5: 97.2000 (97.1636)  time: 1.0850  data: 0.6372  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9857 (1.0013)  acc1: 77.2000 (78.9143)  acc5: 94.8000 (95.4476)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1010 (1.0118)  acc1: 77.2000 (78.9600)  acc5: 94.4000 (95.0880)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7315 s / it)
* Acc@1 79.672 Acc@5 95.332 loss 0.996
Accuracy of the model on the 50000 test images: 79.7%
Max accuracy: 79.69%
Epoch: [100]  [   0/1251]  eta: 1:42:30  lr: 0.003247  min_lr: 0.003247  loss: 3.7140 (3.7140)  weight_decay: 0.0500 (0.0500)  time: 4.9164  data: 3.0144  max mem: 62457
Epoch: [100]  [ 200/1251]  eta: 0:14:41  lr: 0.003244  min_lr: 0.003244  loss: 3.1238 (3.2055)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6385 (0.7739)  time: 0.8221  data: 0.0004  max mem: 62457
Epoch: [100]  [ 400/1251]  eta: 0:11:43  lr: 0.003242  min_lr: 0.003242  loss: 3.6323 (3.2183)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6517 (0.7688)  time: 0.8136  data: 0.0004  max mem: 62457
Epoch: [100]  [ 600/1251]  eta: 0:08:55  lr: 0.003239  min_lr: 0.003239  loss: 3.3293 (3.2421)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5830 (0.7746)  time: 0.8132  data: 0.0004  max mem: 62457
Epoch: [100]  [ 800/1251]  eta: 0:06:10  lr: 0.003236  min_lr: 0.003236  loss: 3.3535 (3.2593)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6945 (0.8071)  time: 0.8136  data: 0.0004  max mem: 62457
Epoch: [100]  [1000/1251]  eta: 0:03:25  lr: 0.003233  min_lr: 0.003233  loss: 2.8479 (3.2733)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5201 (0.7898)  time: 0.8132  data: 0.0004  max mem: 62457
Epoch: [100]  [1200/1251]  eta: 0:00:41  lr: 0.003230  min_lr: 0.003230  loss: 3.5872 (3.2806)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8374 (0.7899)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [100]  [1250/1251]  eta: 0:00:00  lr: 0.003230  min_lr: 0.003230  loss: 3.1151 (3.2790)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7333 (0.7860)  time: 0.6916  data: 0.0005  max mem: 62457
Epoch: [100] Total time: 0:17:02 (0.8174 s / it)
Averaged stats: lr: 0.003230  min_lr: 0.003230  loss: 3.1151 (3.3005)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7333 (0.7860)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.6773 (0.6773)  acc1: 87.6000 (87.6000)  acc5: 98.8000 (98.8000)  time: 7.7875  data: 7.3260  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7761 (0.8238)  acc1: 83.6000 (83.2364)  acc5: 97.2000 (96.9818)  time: 1.1146  data: 0.6663  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9694 (0.9720)  acc1: 77.2000 (79.5048)  acc5: 94.8000 (95.2952)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0449 (0.9817)  acc1: 76.4000 (79.1200)  acc5: 94.8000 (95.1840)  time: 0.4442  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7437 s / it)
* Acc@1 79.540 Acc@5 95.198 loss 0.969
Accuracy of the model on the 50000 test images: 79.5%
Max accuracy: 79.69%
Epoch: [101]  [   0/1251]  eta: 1:42:22  lr: 0.003230  min_lr: 0.003230  loss: 3.7934 (3.7934)  weight_decay: 0.0500 (0.0500)  time: 4.9103  data: 2.0928  max mem: 62457
Epoch: [101]  [ 200/1251]  eta: 0:14:37  lr: 0.003227  min_lr: 0.003227  loss: 3.4346 (3.2710)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6564 (0.7404)  time: 0.8149  data: 0.0005  max mem: 62457
Epoch: [101]  [ 400/1251]  eta: 0:11:42  lr: 0.003224  min_lr: 0.003224  loss: 3.1239 (3.2662)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6566 (0.7817)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [101]  [ 600/1251]  eta: 0:08:55  lr: 0.003221  min_lr: 0.003221  loss: 2.9015 (3.2589)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5531 (0.7664)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [101]  [ 800/1251]  eta: 0:06:10  lr: 0.003218  min_lr: 0.003218  loss: 3.5967 (3.2669)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9804 (0.7905)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [101]  [1000/1251]  eta: 0:03:25  lr: 0.003215  min_lr: 0.003215  loss: 3.5131 (3.2683)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6959 (0.7764)  time: 0.8187  data: 0.0004  max mem: 62457
Epoch: [101]  [1200/1251]  eta: 0:00:41  lr: 0.003212  min_lr: 0.003212  loss: 3.5173 (3.2854)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7039 (0.7712)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [101]  [1250/1251]  eta: 0:00:00  lr: 0.003212  min_lr: 0.003212  loss: 3.4544 (3.2890)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6753 (0.7663)  time: 0.6919  data: 0.0007  max mem: 62457
Epoch: [101] Total time: 0:17:02 (0.8176 s / it)
Averaged stats: lr: 0.003212  min_lr: 0.003212  loss: 3.4544 (3.3021)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6753 (0.7663)
Test:  [ 0/25]  eta: 0:03:07  loss: 0.7355 (0.7355)  acc1: 86.0000 (86.0000)  acc5: 98.8000 (98.8000)  time: 7.5167  data: 7.0309  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9158 (0.9059)  acc1: 84.0000 (82.7636)  acc5: 97.2000 (97.0909)  time: 1.0881  data: 0.6395  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0681 (1.0581)  acc1: 76.8000 (79.2000)  acc5: 96.0000 (95.2381)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1940 (1.0728)  acc1: 75.6000 (78.6720)  acc5: 93.6000 (95.0240)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7325 s / it)
* Acc@1 79.468 Acc@5 95.162 loss 1.059
Accuracy of the model on the 50000 test images: 79.5%
Max accuracy: 79.69%
Epoch: [102]  [   0/1251]  eta: 1:40:25  lr: 0.003212  min_lr: 0.003212  loss: 3.2902 (3.2902)  weight_decay: 0.0500 (0.0500)  time: 4.8167  data: 3.9983  max mem: 62457
Epoch: [102]  [ 200/1251]  eta: 0:14:37  lr: 0.003209  min_lr: 0.003209  loss: 3.3805 (3.2704)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6545 (0.7695)  time: 0.8214  data: 0.0005  max mem: 62457
Epoch: [102]  [ 400/1251]  eta: 0:11:43  lr: 0.003206  min_lr: 0.003206  loss: 3.4199 (3.2786)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8144 (nan)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [102]  [ 600/1251]  eta: 0:08:55  lr: 0.003203  min_lr: 0.003203  loss: 3.2863 (3.2744)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4921 (nan)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [102]  [ 800/1251]  eta: 0:06:09  lr: 0.003200  min_lr: 0.003200  loss: 3.5980 (3.2686)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5169 (nan)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [102]  [1000/1251]  eta: 0:03:25  lr: 0.003197  min_lr: 0.003197  loss: 3.5171 (3.2872)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6354 (nan)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [102]  [1200/1251]  eta: 0:00:41  lr: 0.003195  min_lr: 0.003195  loss: 3.2593 (3.2790)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6873 (nan)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [102]  [1250/1251]  eta: 0:00:00  lr: 0.003194  min_lr: 0.003194  loss: 3.6268 (3.2843)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7447 (nan)  time: 0.6920  data: 0.0007  max mem: 62457
Epoch: [102] Total time: 0:17:02 (0.8174 s / it)
Averaged stats: lr: 0.003194  min_lr: 0.003194  loss: 3.6268 (3.2998)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7447 (nan)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.7551 (0.7551)  acc1: 87.6000 (87.6000)  acc5: 98.4000 (98.4000)  time: 7.8187  data: 7.3588  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9737 (0.9567)  acc1: 84.4000 (82.7636)  acc5: 97.2000 (97.0182)  time: 1.1176  data: 0.6693  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1300 (1.1079)  acc1: 78.0000 (79.1619)  acc5: 95.6000 (95.2000)  time: 0.4462  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1788 (1.1160)  acc1: 76.8000 (79.1040)  acc5: 93.6000 (95.0720)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7459 s / it)
* Acc@1 79.614 Acc@5 95.224 loss 1.100
Accuracy of the model on the 50000 test images: 79.6%
Max accuracy: 79.69%
Epoch: [103]  [   0/1251]  eta: 1:44:15  lr: 0.003194  min_lr: 0.003194  loss: 3.6750 (3.6750)  weight_decay: 0.0500 (0.0500)  time: 5.0000  data: 3.5112  max mem: 62457
Epoch: [103]  [ 200/1251]  eta: 0:14:42  lr: 0.003191  min_lr: 0.003191  loss: 3.3701 (3.3417)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9312 (0.8074)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [103]  [ 400/1251]  eta: 0:11:43  lr: 0.003188  min_lr: 0.003188  loss: 3.3174 (3.3427)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6684 (0.7803)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [103]  [ 600/1251]  eta: 0:08:55  lr: 0.003185  min_lr: 0.003185  loss: 3.4434 (3.3503)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8694 (0.7885)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [103]  [ 800/1251]  eta: 0:06:10  lr: 0.003182  min_lr: 0.003182  loss: 3.4383 (3.3496)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6046 (0.7921)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [103]  [1000/1251]  eta: 0:03:25  lr: 0.003179  min_lr: 0.003179  loss: 3.2866 (3.3497)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7452 (0.7923)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [103]  [1200/1251]  eta: 0:00:41  lr: 0.003176  min_lr: 0.003176  loss: 3.3599 (3.3635)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6597 (0.7781)  time: 0.8145  data: 0.0005  max mem: 62457
Epoch: [103]  [1250/1251]  eta: 0:00:00  lr: 0.003176  min_lr: 0.003176  loss: 3.6357 (3.3634)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6769 (0.7833)  time: 0.6968  data: 0.0006  max mem: 62457
Epoch: [103] Total time: 0:17:03 (0.8178 s / it)
Averaged stats: lr: 0.003176  min_lr: 0.003176  loss: 3.6357 (3.3022)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6769 (0.7833)
Test:  [ 0/25]  eta: 0:03:04  loss: 0.6950 (0.6950)  acc1: 88.0000 (88.0000)  acc5: 99.6000 (99.6000)  time: 7.3810  data: 6.8989  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9185 (0.9071)  acc1: 82.8000 (83.2000)  acc5: 97.6000 (97.3455)  time: 1.0757  data: 0.6275  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0726 (1.0580)  acc1: 78.0000 (79.8286)  acc5: 95.2000 (95.4095)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1376 (1.0680)  acc1: 77.2000 (79.4560)  acc5: 94.8000 (95.3440)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7267 s / it)
* Acc@1 79.704 Acc@5 95.384 loss 1.060
Accuracy of the model on the 50000 test images: 79.7%
Max accuracy: 79.70%
Epoch: [104]  [   0/1251]  eta: 1:19:44  lr: 0.003176  min_lr: 0.003176  loss: 3.8332 (3.8332)  weight_decay: 0.0500 (0.0500)  time: 3.8246  data: 2.9995  max mem: 62457
Epoch: [104]  [ 200/1251]  eta: 0:14:33  lr: 0.003173  min_lr: 0.003173  loss: 3.0663 (3.2813)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6410 (0.8578)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [104]  [ 400/1251]  eta: 0:11:40  lr: 0.003170  min_lr: 0.003170  loss: 3.5269 (3.2897)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6270 (0.7820)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [104]  [ 600/1251]  eta: 0:08:54  lr: 0.003167  min_lr: 0.003167  loss: 3.5138 (3.3007)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6681 (0.8053)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [104]  [ 800/1251]  eta: 0:06:09  lr: 0.003164  min_lr: 0.003164  loss: 3.6794 (3.3072)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5650 (0.7769)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [104]  [1000/1251]  eta: 0:03:25  lr: 0.003161  min_lr: 0.003161  loss: 3.1502 (3.3106)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7836 (0.7904)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [104]  [1200/1251]  eta: 0:00:41  lr: 0.003158  min_lr: 0.003158  loss: 3.4569 (3.3114)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9170 (0.8164)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [104]  [1250/1251]  eta: 0:00:00  lr: 0.003158  min_lr: 0.003158  loss: 3.3314 (3.3116)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7514 (0.8125)  time: 0.6922  data: 0.0005  max mem: 62457
Epoch: [104] Total time: 0:17:02 (0.8170 s / it)
Averaged stats: lr: 0.003158  min_lr: 0.003158  loss: 3.3314 (3.2845)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7514 (0.8125)
Test:  [ 0/25]  eta: 0:02:26  loss: 0.6845 (0.6845)  acc1: 86.4000 (86.4000)  acc5: 98.4000 (98.4000)  time: 5.8475  data: 5.3393  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8869 (0.8778)  acc1: 83.2000 (83.3455)  acc5: 97.6000 (97.0545)  time: 1.0173  data: 0.5660  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0114 (1.0210)  acc1: 78.8000 (80.3238)  acc5: 95.2000 (95.2952)  time: 0.4895  data: 0.0444  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1227 (1.0353)  acc1: 78.8000 (79.7600)  acc5: 94.4000 (95.2320)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7014 s / it)
* Acc@1 80.032 Acc@5 95.450 loss 1.025
Accuracy of the model on the 50000 test images: 80.0%
Max accuracy: 80.03%
Epoch: [105]  [   0/1251]  eta: 1:36:37  lr: 0.003158  min_lr: 0.003158  loss: 3.5681 (3.5681)  weight_decay: 0.0500 (0.0500)  time: 4.6345  data: 3.8095  max mem: 62457
Epoch: [105]  [ 200/1251]  eta: 0:14:36  lr: 0.003155  min_lr: 0.003155  loss: 3.4255 (3.1787)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5091 (0.6797)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [105]  [ 400/1251]  eta: 0:11:42  lr: 0.003152  min_lr: 0.003152  loss: 3.2808 (3.2423)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8799 (0.7229)  time: 0.8224  data: 0.0004  max mem: 62457
Epoch: [105]  [ 600/1251]  eta: 0:08:55  lr: 0.003149  min_lr: 0.003149  loss: 3.5165 (3.2429)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6994 (0.7117)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [105]  [ 800/1251]  eta: 0:06:09  lr: 0.003146  min_lr: 0.003146  loss: 3.3011 (3.2612)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6645 (0.7168)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [105]  [1000/1251]  eta: 0:03:25  lr: 0.003143  min_lr: 0.003143  loss: 3.3266 (3.2631)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6904 (0.7466)  time: 0.8148  data: 0.0005  max mem: 62457
Epoch: [105]  [1200/1251]  eta: 0:00:41  lr: 0.003140  min_lr: 0.003140  loss: 3.2195 (3.2617)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7555 (0.7691)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [105]  [1250/1251]  eta: 0:00:00  lr: 0.003139  min_lr: 0.003139  loss: 3.4071 (3.2623)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7591 (0.7670)  time: 0.6919  data: 0.0006  max mem: 62457
Epoch: [105] Total time: 0:17:02 (0.8175 s / it)
Averaged stats: lr: 0.003139  min_lr: 0.003139  loss: 3.4071 (3.2820)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7591 (0.7670)
Test:  [ 0/25]  eta: 0:03:10  loss: 0.6911 (0.6911)  acc1: 86.8000 (86.8000)  acc5: 98.8000 (98.8000)  time: 7.6295  data: 7.1434  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8498 (0.8504)  acc1: 84.0000 (82.9818)  acc5: 97.6000 (97.3455)  time: 1.0977  data: 0.6497  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9677 (0.9916)  acc1: 78.4000 (80.1143)  acc5: 95.2000 (95.6191)  time: 0.4445  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0553 (1.0024)  acc1: 78.4000 (79.7280)  acc5: 94.8000 (95.4560)  time: 0.4444  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7366 s / it)
* Acc@1 79.702 Acc@5 95.544 loss 0.987
Accuracy of the model on the 50000 test images: 79.7%
Max accuracy: 80.03%
Epoch: [106]  [   0/1251]  eta: 1:32:38  lr: 0.003139  min_lr: 0.003139  loss: 3.7152 (3.7152)  weight_decay: 0.0500 (0.0500)  time: 4.4434  data: 2.0030  max mem: 62457
Epoch: [106]  [ 200/1251]  eta: 0:14:36  lr: 0.003136  min_lr: 0.003136  loss: 3.3996 (3.2986)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7214 (0.7096)  time: 0.8151  data: 0.0005  max mem: 62457
Epoch: [106]  [ 400/1251]  eta: 0:11:42  lr: 0.003133  min_lr: 0.003133  loss: 3.2793 (3.3016)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7437 (0.7480)  time: 0.8144  data: 0.0005  max mem: 62457
Epoch: [106]  [ 600/1251]  eta: 0:08:55  lr: 0.003130  min_lr: 0.003130  loss: 3.2644 (3.2907)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6020 (0.7622)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [106]  [ 800/1251]  eta: 0:06:10  lr: 0.003127  min_lr: 0.003127  loss: 3.3396 (3.2936)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7273 (0.7655)  time: 0.8145  data: 0.0005  max mem: 62457
Epoch: [106]  [1000/1251]  eta: 0:03:25  lr: 0.003124  min_lr: 0.003124  loss: 3.4871 (3.3069)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6370 (0.7555)  time: 0.8149  data: 0.0005  max mem: 62457
Epoch: [106]  [1200/1251]  eta: 0:00:41  lr: 0.003121  min_lr: 0.003121  loss: 3.2394 (3.2959)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6507 (0.7556)  time: 0.8146  data: 0.0005  max mem: 62457
Epoch: [106]  [1250/1251]  eta: 0:00:00  lr: 0.003121  min_lr: 0.003121  loss: 3.5224 (3.2952)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7349 (0.7614)  time: 0.6919  data: 0.0007  max mem: 62457
Epoch: [106] Total time: 0:17:02 (0.8176 s / it)
Averaged stats: lr: 0.003121  min_lr: 0.003121  loss: 3.5224 (3.2785)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7349 (0.7614)
Test:  [ 0/25]  eta: 0:03:10  loss: 0.6287 (0.6287)  acc1: 88.8000 (88.8000)  acc5: 99.2000 (99.2000)  time: 7.6205  data: 7.1385  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8634 (0.8379)  acc1: 82.4000 (83.0182)  acc5: 97.6000 (97.3091)  time: 1.0975  data: 0.6492  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9814 (0.9900)  acc1: 76.0000 (79.3524)  acc5: 95.2000 (95.6952)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1086 (0.9984)  acc1: 76.0000 (79.0720)  acc5: 94.8000 (95.6000)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7367 s / it)
* Acc@1 79.714 Acc@5 95.424 loss 0.991
Accuracy of the model on the 50000 test images: 79.7%
Max accuracy: 80.03%
Epoch: [107]  [   0/1251]  eta: 1:42:35  lr: 0.003121  min_lr: 0.003121  loss: 3.4196 (3.4196)  weight_decay: 0.0500 (0.0500)  time: 4.9203  data: 2.9090  max mem: 62457
Epoch: [107]  [ 200/1251]  eta: 0:14:41  lr: 0.003118  min_lr: 0.003118  loss: 3.2710 (3.3139)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6210 (0.7964)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [107]  [ 400/1251]  eta: 0:11:43  lr: 0.003115  min_lr: 0.003115  loss: 3.3703 (3.3050)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6764 (0.7701)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [107]  [ 600/1251]  eta: 0:08:55  lr: 0.003112  min_lr: 0.003112  loss: 3.2944 (3.2764)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7323 (0.7885)  time: 0.8203  data: 0.0004  max mem: 62457
Epoch: [107]  [ 800/1251]  eta: 0:06:10  lr: 0.003109  min_lr: 0.003109  loss: 3.3087 (3.2808)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7530 (0.8004)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [107]  [1000/1251]  eta: 0:03:25  lr: 0.003106  min_lr: 0.003106  loss: 3.4110 (3.2878)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5780 (0.7884)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [107]  [1200/1251]  eta: 0:00:41  lr: 0.003103  min_lr: 0.003103  loss: 3.1445 (3.2829)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7558 (0.7925)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [107]  [1250/1251]  eta: 0:00:00  lr: 0.003102  min_lr: 0.003102  loss: 3.3108 (3.2842)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6428 (0.7896)  time: 0.6966  data: 0.0007  max mem: 62457
Epoch: [107] Total time: 0:17:03 (0.8179 s / it)
Averaged stats: lr: 0.003102  min_lr: 0.003102  loss: 3.3108 (3.2905)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6428 (0.7896)
Test:  [ 0/25]  eta: 0:03:22  loss: 0.7445 (0.7445)  acc1: 85.6000 (85.6000)  acc5: 98.8000 (98.8000)  time: 8.1181  data: 7.6526  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8909 (0.8971)  acc1: 82.4000 (82.7636)  acc5: 97.6000 (97.3091)  time: 1.1427  data: 0.6959  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0824 (1.0283)  acc1: 77.2000 (79.8667)  acc5: 94.8000 (95.3905)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1016 (1.0394)  acc1: 76.8000 (79.6640)  acc5: 94.0000 (95.2000)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7554 s / it)
* Acc@1 79.820 Acc@5 95.442 loss 1.031
Accuracy of the model on the 50000 test images: 79.8%
Max accuracy: 80.03%
Epoch: [108]  [   0/1251]  eta: 1:37:16  lr: 0.003102  min_lr: 0.003102  loss: 3.7218 (3.7218)  weight_decay: 0.0500 (0.0500)  time: 4.6654  data: 3.6902  max mem: 62457
Epoch: [108]  [ 200/1251]  eta: 0:14:36  lr: 0.003099  min_lr: 0.003099  loss: 3.3885 (3.3139)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7818 (0.7434)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [108]  [ 400/1251]  eta: 0:11:41  lr: 0.003096  min_lr: 0.003096  loss: 3.3321 (3.2982)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8149 (0.7614)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [108]  [ 600/1251]  eta: 0:08:55  lr: 0.003093  min_lr: 0.003093  loss: 3.2948 (3.2890)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7646 (0.7926)  time: 0.8208  data: 0.0004  max mem: 62457
Epoch: [108]  [ 800/1251]  eta: 0:06:10  lr: 0.003090  min_lr: 0.003090  loss: 3.3740 (3.2792)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7708 (0.7903)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [108]  [1000/1251]  eta: 0:03:25  lr: 0.003087  min_lr: 0.003087  loss: 2.7319 (3.2782)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7511 (0.7880)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [108]  [1200/1251]  eta: 0:00:41  lr: 0.003084  min_lr: 0.003084  loss: 3.2263 (3.2816)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6229 (0.7871)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [108]  [1250/1251]  eta: 0:00:00  lr: 0.003083  min_lr: 0.003083  loss: 3.1967 (3.2762)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6427 (0.7855)  time: 0.6918  data: 0.0007  max mem: 62457
Epoch: [108] Total time: 0:17:02 (0.8176 s / it)
Averaged stats: lr: 0.003083  min_lr: 0.003083  loss: 3.1967 (3.2766)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6427 (0.7855)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.6444 (0.6444)  acc1: 87.2000 (87.2000)  acc5: 98.0000 (98.0000)  time: 7.7349  data: 7.2580  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8420 (0.8267)  acc1: 83.6000 (83.2000)  acc5: 97.6000 (97.1273)  time: 1.1080  data: 0.6601  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9541 (0.9653)  acc1: 78.4000 (79.6191)  acc5: 95.2000 (95.2381)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0437 (0.9764)  acc1: 77.2000 (79.2800)  acc5: 94.4000 (95.1040)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7414 s / it)
* Acc@1 79.938 Acc@5 95.346 loss 0.959
Accuracy of the model on the 50000 test images: 79.9%
Max accuracy: 80.03%
Epoch: [109]  [   0/1251]  eta: 1:31:25  lr: 0.003083  min_lr: 0.003083  loss: 3.5152 (3.5152)  weight_decay: 0.0500 (0.0500)  time: 4.3852  data: 2.0234  max mem: 62457
Epoch: [109]  [ 200/1251]  eta: 0:14:35  lr: 0.003080  min_lr: 0.003080  loss: 3.3954 (3.1282)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7024 (0.8736)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [109]  [ 400/1251]  eta: 0:11:42  lr: 0.003077  min_lr: 0.003077  loss: 3.2540 (3.1884)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7171 (nan)  time: 0.8218  data: 0.0004  max mem: 62457
Epoch: [109]  [ 600/1251]  eta: 0:08:55  lr: 0.003074  min_lr: 0.003074  loss: 3.5885 (3.2126)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7520 (nan)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [109]  [ 800/1251]  eta: 0:06:09  lr: 0.003071  min_lr: 0.003071  loss: 3.3985 (3.2329)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6886 (nan)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [109]  [1000/1251]  eta: 0:03:25  lr: 0.003068  min_lr: 0.003068  loss: 3.2501 (3.2340)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8262 (nan)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [109]  [1200/1251]  eta: 0:00:41  lr: 0.003065  min_lr: 0.003065  loss: 3.2323 (3.2371)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6668 (nan)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [109]  [1250/1251]  eta: 0:00:00  lr: 0.003064  min_lr: 0.003064  loss: 3.1681 (3.2373)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5889 (nan)  time: 0.6924  data: 0.0005  max mem: 62457
Epoch: [109] Total time: 0:17:02 (0.8172 s / it)
Averaged stats: lr: 0.003064  min_lr: 0.003064  loss: 3.1681 (3.2635)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5889 (nan)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.6617 (0.6617)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 7.7049  data: 7.2097  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8558 (0.8490)  acc1: 82.0000 (82.5455)  acc5: 97.6000 (97.4545)  time: 1.1053  data: 0.6558  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0240 (0.9870)  acc1: 78.0000 (79.7905)  acc5: 95.2000 (95.5429)  time: 0.4452  data: 0.0003  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0950 (0.9975)  acc1: 77.6000 (79.3440)  acc5: 94.4000 (95.4400)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7394 s / it)
* Acc@1 80.336 Acc@5 95.554 loss 0.972
Accuracy of the model on the 50000 test images: 80.3%
Max accuracy: 80.34%
Epoch: [110]  [   0/1251]  eta: 1:36:18  lr: 0.003064  min_lr: 0.003064  loss: 3.1405 (3.1405)  weight_decay: 0.0500 (0.0500)  time: 4.6190  data: 3.7897  max mem: 62457
Epoch: [110]  [ 200/1251]  eta: 0:14:37  lr: 0.003061  min_lr: 0.003061  loss: 3.5028 (3.2588)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0603 (0.9041)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [110]  [ 400/1251]  eta: 0:11:42  lr: 0.003058  min_lr: 0.003058  loss: 3.1023 (3.2594)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4638 (0.8093)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [110]  [ 600/1251]  eta: 0:08:55  lr: 0.003055  min_lr: 0.003055  loss: 3.0896 (3.2672)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6862 (0.8263)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [110]  [ 800/1251]  eta: 0:06:10  lr: 0.003052  min_lr: 0.003052  loss: 3.0014 (3.2603)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6662 (0.8348)  time: 0.8218  data: 0.0004  max mem: 62457
Epoch: [110]  [1000/1251]  eta: 0:03:25  lr: 0.003049  min_lr: 0.003049  loss: 3.3446 (3.2554)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6698 (0.8157)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [110]  [1200/1251]  eta: 0:00:41  lr: 0.003046  min_lr: 0.003046  loss: 3.2863 (3.2556)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7671 (0.8213)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [110]  [1250/1251]  eta: 0:00:00  lr: 0.003045  min_lr: 0.003045  loss: 3.5506 (3.2578)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6991 (0.8171)  time: 0.6914  data: 0.0006  max mem: 62457
Epoch: [110] Total time: 0:17:02 (0.8175 s / it)
Averaged stats: lr: 0.003045  min_lr: 0.003045  loss: 3.5506 (3.2640)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6991 (0.8171)
Test:  [ 0/25]  eta: 0:03:11  loss: 0.7070 (0.7070)  acc1: 86.4000 (86.4000)  acc5: 98.0000 (98.0000)  time: 7.6587  data: 7.1724  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9316 (0.8739)  acc1: 82.4000 (82.6182)  acc5: 97.2000 (97.0182)  time: 1.1001  data: 0.6524  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9750 (1.0060)  acc1: 79.2000 (79.7524)  acc5: 95.2000 (95.4095)  time: 0.4441  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0247 (1.0175)  acc1: 78.0000 (79.2960)  acc5: 94.8000 (95.3440)  time: 0.4440  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7373 s / it)
* Acc@1 79.732 Acc@5 95.402 loss 1.008
Accuracy of the model on the 50000 test images: 79.7%
Max accuracy: 80.34%
Epoch: [111]  [   0/1251]  eta: 1:38:49  lr: 0.003045  min_lr: 0.003045  loss: 4.1912 (4.1912)  weight_decay: 0.0500 (0.0500)  time: 4.7402  data: 3.6714  max mem: 62457
Epoch: [111]  [ 200/1251]  eta: 0:14:39  lr: 0.003042  min_lr: 0.003042  loss: 3.5387 (3.3109)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7215 (0.7376)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [111]  [ 400/1251]  eta: 0:11:43  lr: 0.003039  min_lr: 0.003039  loss: 3.3025 (3.2635)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6128 (0.7775)  time: 0.8217  data: 0.0004  max mem: 62457
Epoch: [111]  [ 600/1251]  eta: 0:08:55  lr: 0.003036  min_lr: 0.003036  loss: 3.3949 (3.2469)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7137 (0.7957)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [111]  [ 800/1251]  eta: 0:06:10  lr: 0.003033  min_lr: 0.003033  loss: 3.4057 (3.2531)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6273 (0.7843)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [111]  [1000/1251]  eta: 0:03:25  lr: 0.003030  min_lr: 0.003030  loss: 2.8891 (3.2567)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6912 (0.8022)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [111]  [1200/1251]  eta: 0:00:41  lr: 0.003027  min_lr: 0.003027  loss: 3.5325 (3.2572)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5816 (0.7802)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [111]  [1250/1251]  eta: 0:00:00  lr: 0.003026  min_lr: 0.003026  loss: 3.3802 (3.2585)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6516 (0.7756)  time: 0.6920  data: 0.0007  max mem: 62457
Epoch: [111] Total time: 0:17:03 (0.8179 s / it)
Averaged stats: lr: 0.003026  min_lr: 0.003026  loss: 3.3802 (3.2629)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6516 (0.7756)
Test:  [ 0/25]  eta: 0:02:57  loss: 0.7444 (0.7444)  acc1: 86.4000 (86.4000)  acc5: 98.8000 (98.8000)  time: 7.0805  data: 6.5905  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9361 (0.9224)  acc1: 85.6000 (83.4546)  acc5: 97.2000 (97.2727)  time: 1.0936  data: 0.6460  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0872 (1.0646)  acc1: 78.8000 (80.3238)  acc5: 95.2000 (95.2191)  time: 0.4692  data: 0.0258  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1482 (1.0776)  acc1: 78.4000 (79.7760)  acc5: 94.0000 (95.0880)  time: 0.4435  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7351 s / it)
* Acc@1 79.864 Acc@5 95.338 loss 1.067
Accuracy of the model on the 50000 test images: 79.9%
Max accuracy: 80.34%
Epoch: [112]  [   0/1251]  eta: 1:40:38  lr: 0.003026  min_lr: 0.003026  loss: 2.9050 (2.9050)  weight_decay: 0.0500 (0.0500)  time: 4.8268  data: 2.1437  max mem: 62457
Epoch: [112]  [ 200/1251]  eta: 0:14:37  lr: 0.003023  min_lr: 0.003023  loss: 3.2398 (3.2314)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7478 (0.8786)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [112]  [ 400/1251]  eta: 0:11:41  lr: 0.003020  min_lr: 0.003020  loss: 3.3977 (3.2791)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8244 (0.8692)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [112]  [ 600/1251]  eta: 0:08:55  lr: 0.003017  min_lr: 0.003017  loss: 3.0100 (3.2697)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7275 (0.8592)  time: 0.8141  data: 0.0005  max mem: 62457
Epoch: [112]  [ 800/1251]  eta: 0:06:09  lr: 0.003014  min_lr: 0.003014  loss: 3.3943 (3.2762)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6226 (0.8410)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [112]  [1000/1251]  eta: 0:03:25  lr: 0.003011  min_lr: 0.003011  loss: 3.3278 (3.2829)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8668 (0.8333)  time: 0.8187  data: 0.0005  max mem: 62457
Epoch: [112]  [1200/1251]  eta: 0:00:41  lr: 0.003007  min_lr: 0.003007  loss: 3.4629 (3.2775)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6328 (0.8158)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [112]  [1250/1251]  eta: 0:00:00  lr: 0.003007  min_lr: 0.003007  loss: 3.3818 (3.2782)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8812 (0.8176)  time: 0.6916  data: 0.0007  max mem: 62457
Epoch: [112] Total time: 0:17:02 (0.8170 s / it)
Averaged stats: lr: 0.003007  min_lr: 0.003007  loss: 3.3818 (3.2688)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8812 (0.8176)
Test:  [ 0/25]  eta: 0:03:10  loss: 0.6850 (0.6850)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.6100  data: 7.1258  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9371 (0.8999)  acc1: 82.8000 (83.3818)  acc5: 96.8000 (97.2364)  time: 1.0966  data: 0.6481  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0643 (1.0560)  acc1: 78.0000 (80.0191)  acc5: 95.6000 (95.3905)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1367 (1.0645)  acc1: 78.0000 (79.6800)  acc5: 94.4000 (95.2960)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7357 s / it)
* Acc@1 80.016 Acc@5 95.490 loss 1.046
Accuracy of the model on the 50000 test images: 80.0%
Max accuracy: 80.34%
Epoch: [113]  [   0/1251]  eta: 1:41:51  lr: 0.003007  min_lr: 0.003007  loss: 3.2295 (3.2295)  weight_decay: 0.0500 (0.0500)  time: 4.8856  data: 3.2590  max mem: 62457
Epoch: [113]  [ 200/1251]  eta: 0:14:36  lr: 0.003004  min_lr: 0.003004  loss: 3.2005 (3.2235)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6358 (0.6950)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [113]  [ 400/1251]  eta: 0:11:42  lr: 0.003000  min_lr: 0.003000  loss: 2.9443 (3.2300)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6178 (0.7087)  time: 0.8216  data: 0.0004  max mem: 62457
Epoch: [113]  [ 600/1251]  eta: 0:08:55  lr: 0.002997  min_lr: 0.002997  loss: 3.3083 (3.2426)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7385 (0.7724)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [113]  [ 800/1251]  eta: 0:06:10  lr: 0.002994  min_lr: 0.002994  loss: 3.2723 (3.2339)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7790 (0.7861)  time: 0.8144  data: 0.0005  max mem: 62457
Epoch: [113]  [1000/1251]  eta: 0:03:25  lr: 0.002991  min_lr: 0.002991  loss: 3.4684 (3.2314)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6781 (0.7805)  time: 0.8147  data: 0.0005  max mem: 62457
Epoch: [113]  [1200/1251]  eta: 0:00:41  lr: 0.002988  min_lr: 0.002988  loss: 3.1365 (3.2455)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7335 (0.7954)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [113]  [1250/1251]  eta: 0:00:00  lr: 0.002987  min_lr: 0.002987  loss: 3.2910 (3.2483)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7696 (0.7965)  time: 0.6918  data: 0.0007  max mem: 62457
Epoch: [113] Total time: 0:17:02 (0.8176 s / it)
Averaged stats: lr: 0.002987  min_lr: 0.002987  loss: 3.2910 (3.2589)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7696 (0.7965)
Test:  [ 0/25]  eta: 0:03:23  loss: 0.6612 (0.6612)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 8.1401  data: 7.6691  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8353 (0.8420)  acc1: 82.8000 (82.8000)  acc5: 97.2000 (97.3091)  time: 1.1446  data: 0.6974  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0079 (0.9879)  acc1: 78.0000 (79.8286)  acc5: 95.6000 (95.6762)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0704 (0.9978)  acc1: 79.2000 (79.6800)  acc5: 94.8000 (95.6160)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7567 s / it)
* Acc@1 80.144 Acc@5 95.588 loss 0.987
Accuracy of the model on the 50000 test images: 80.1%
Max accuracy: 80.34%
Epoch: [114]  [   0/1251]  eta: 1:40:13  lr: 0.002987  min_lr: 0.002987  loss: 3.7079 (3.7079)  weight_decay: 0.0500 (0.0500)  time: 4.8071  data: 2.1549  max mem: 62457
Epoch: [114]  [ 200/1251]  eta: 0:14:37  lr: 0.002984  min_lr: 0.002984  loss: 3.2666 (3.2371)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6190 (0.7500)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [114]  [ 400/1251]  eta: 0:11:42  lr: 0.002981  min_lr: 0.002981  loss: 3.4132 (3.2374)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9736 (0.8630)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [114]  [ 600/1251]  eta: 0:08:55  lr: 0.002978  min_lr: 0.002978  loss: 3.4058 (3.2439)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6705 (0.8433)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [114]  [ 800/1251]  eta: 0:06:09  lr: 0.002975  min_lr: 0.002975  loss: 3.5542 (3.2544)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6790 (0.8074)  time: 0.8225  data: 0.0004  max mem: 62457
Epoch: [114]  [1000/1251]  eta: 0:03:25  lr: 0.002972  min_lr: 0.002972  loss: 3.1193 (3.2450)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7288 (0.8224)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [114]  [1200/1251]  eta: 0:00:41  lr: 0.002968  min_lr: 0.002968  loss: 3.3420 (3.2519)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7389 (0.8091)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [114]  [1250/1251]  eta: 0:00:00  lr: 0.002968  min_lr: 0.002968  loss: 3.1985 (3.2534)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7035 (0.8044)  time: 0.6915  data: 0.0005  max mem: 62457
Epoch: [114] Total time: 0:17:02 (0.8170 s / it)
Averaged stats: lr: 0.002968  min_lr: 0.002968  loss: 3.1985 (3.2483)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7035 (0.8044)
Test:  [ 0/25]  eta: 0:03:23  loss: 0.7196 (0.7196)  acc1: 87.2000 (87.2000)  acc5: 99.6000 (99.6000)  time: 8.1438  data: 7.6569  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.9411 (0.8785)  acc1: 83.2000 (83.3818)  acc5: 96.8000 (97.2000)  time: 1.1450  data: 0.6964  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0238 (1.0234)  acc1: 77.6000 (80.0952)  acc5: 95.6000 (95.3524)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1035 (1.0307)  acc1: 78.0000 (80.0000)  acc5: 94.4000 (95.2800)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7569 s / it)
* Acc@1 80.030 Acc@5 95.460 loss 1.023
Accuracy of the model on the 50000 test images: 80.0%
Max accuracy: 80.34%
Epoch: [115]  [   0/1251]  eta: 1:44:37  lr: 0.002968  min_lr: 0.002968  loss: 3.4661 (3.4661)  weight_decay: 0.0500 (0.0500)  time: 5.0182  data: 3.3453  max mem: 62457
Epoch: [115]  [ 200/1251]  eta: 0:14:41  lr: 0.002965  min_lr: 0.002965  loss: 3.2021 (3.1578)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6964 (0.7846)  time: 0.8146  data: 0.0005  max mem: 62457
Epoch: [115]  [ 400/1251]  eta: 0:11:43  lr: 0.002961  min_lr: 0.002961  loss: 3.1498 (3.1900)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6977 (0.8116)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [115]  [ 600/1251]  eta: 0:08:55  lr: 0.002958  min_lr: 0.002958  loss: 2.9480 (3.2145)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7899 (0.7875)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [115]  [ 800/1251]  eta: 0:06:10  lr: 0.002955  min_lr: 0.002955  loss: 3.3557 (3.2091)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8504 (0.8093)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [115]  [1000/1251]  eta: 0:03:25  lr: 0.002952  min_lr: 0.002952  loss: 3.4378 (3.2358)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6342 (0.8263)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [115]  [1200/1251]  eta: 0:00:41  lr: 0.002949  min_lr: 0.002949  loss: 3.1883 (3.2356)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5383 (0.8074)  time: 0.8205  data: 0.0004  max mem: 62457
Epoch: [115]  [1250/1251]  eta: 0:00:00  lr: 0.002948  min_lr: 0.002948  loss: 3.2731 (3.2347)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5767 (0.8048)  time: 0.6940  data: 0.0007  max mem: 62457
Epoch: [115] Total time: 0:17:02 (0.8177 s / it)
Averaged stats: lr: 0.002948  min_lr: 0.002948  loss: 3.2731 (3.2447)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5767 (0.8048)
Test:  [ 0/25]  eta: 0:03:04  loss: 0.6969 (0.6969)  acc1: 88.8000 (88.8000)  acc5: 99.6000 (99.6000)  time: 7.3904  data: 6.8991  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8738 (0.8897)  acc1: 83.2000 (83.8545)  acc5: 97.2000 (97.3091)  time: 1.0767  data: 0.6275  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0439 (1.0179)  acc1: 79.6000 (80.2667)  acc5: 95.2000 (95.7714)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0979 (1.0285)  acc1: 79.6000 (79.9840)  acc5: 95.2000 (95.6640)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7271 s / it)
* Acc@1 80.384 Acc@5 95.606 loss 1.016
Accuracy of the model on the 50000 test images: 80.4%
Max accuracy: 80.38%
Epoch: [116]  [   0/1251]  eta: 1:29:42  lr: 0.002948  min_lr: 0.002948  loss: 2.1799 (2.1799)  weight_decay: 0.0500 (0.0500)  time: 4.3028  data: 3.4776  max mem: 62457
Epoch: [116]  [ 200/1251]  eta: 0:14:33  lr: 0.002945  min_lr: 0.002945  loss: 3.4346 (3.2700)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8097 (0.8735)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [116]  [ 400/1251]  eta: 0:11:40  lr: 0.002942  min_lr: 0.002942  loss: 2.9020 (3.2098)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7089 (0.8290)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [116]  [ 600/1251]  eta: 0:08:54  lr: 0.002938  min_lr: 0.002938  loss: 3.4116 (3.2297)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8974 (0.8189)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [116]  [ 800/1251]  eta: 0:06:09  lr: 0.002935  min_lr: 0.002935  loss: 3.2549 (3.2280)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8701 (0.8196)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [116]  [1000/1251]  eta: 0:03:25  lr: 0.002932  min_lr: 0.002932  loss: 3.3769 (3.2366)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6452 (0.8118)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [116]  [1200/1251]  eta: 0:00:41  lr: 0.002929  min_lr: 0.002929  loss: 3.3685 (3.2467)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7975 (0.8146)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [116]  [1250/1251]  eta: 0:00:00  lr: 0.002928  min_lr: 0.002928  loss: 3.4104 (3.2438)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8234 (0.8182)  time: 0.6914  data: 0.0006  max mem: 62457
Epoch: [116] Total time: 0:17:01 (0.8166 s / it)
Averaged stats: lr: 0.002928  min_lr: 0.002928  loss: 3.4104 (3.2504)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8234 (0.8182)
Test:  [ 0/25]  eta: 0:03:03  loss: 0.7258 (0.7258)  acc1: 86.0000 (86.0000)  acc5: 98.8000 (98.8000)  time: 7.3550  data: 6.8668  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8531 (0.8352)  acc1: 85.6000 (83.3818)  acc5: 96.8000 (96.9818)  time: 1.0733  data: 0.6245  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9416 (0.9939)  acc1: 79.2000 (80.0952)  acc5: 94.8000 (95.0476)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0662 (1.0018)  acc1: 78.4000 (79.7600)  acc5: 94.0000 (95.1200)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7255 s / it)
* Acc@1 80.288 Acc@5 95.552 loss 0.987
Accuracy of the model on the 50000 test images: 80.3%
Max accuracy: 80.38%
Epoch: [117]  [   0/1251]  eta: 1:40:02  lr: 0.002928  min_lr: 0.002928  loss: 3.1236 (3.1236)  weight_decay: 0.0500 (0.0500)  time: 4.7983  data: 3.6071  max mem: 62457
Epoch: [117]  [ 200/1251]  eta: 0:14:37  lr: 0.002925  min_lr: 0.002925  loss: 3.2909 (3.1947)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6651 (0.7701)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [117]  [ 400/1251]  eta: 0:11:42  lr: 0.002922  min_lr: 0.002922  loss: 3.4637 (3.2359)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6171 (0.8097)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [117]  [ 600/1251]  eta: 0:08:55  lr: 0.002919  min_lr: 0.002919  loss: 3.2244 (3.2263)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8777 (0.8128)  time: 0.8136  data: 0.0005  max mem: 62457
Epoch: [117]  [ 800/1251]  eta: 0:06:09  lr: 0.002915  min_lr: 0.002915  loss: 3.1140 (3.2373)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6735 (0.8167)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [117]  [1000/1251]  eta: 0:03:25  lr: 0.002912  min_lr: 0.002912  loss: 3.3281 (3.2302)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7751 (0.8066)  time: 0.8138  data: 0.0005  max mem: 62457
Epoch: [117]  [1200/1251]  eta: 0:00:41  lr: 0.002909  min_lr: 0.002909  loss: 3.3839 (3.2350)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6310 (0.7976)  time: 0.8134  data: 0.0004  max mem: 62457
Epoch: [117]  [1250/1251]  eta: 0:00:00  lr: 0.002908  min_lr: 0.002908  loss: 3.2258 (3.2342)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6058 (0.7941)  time: 0.6936  data: 0.0007  max mem: 62457
Epoch: [117] Total time: 0:17:02 (0.8171 s / it)
Averaged stats: lr: 0.002908  min_lr: 0.002908  loss: 3.2258 (3.2417)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6058 (0.7941)
Test:  [ 0/25]  eta: 0:03:20  loss: 0.6859 (0.6859)  acc1: 86.0000 (86.0000)  acc5: 98.8000 (98.8000)  time: 8.0022  data: 7.5183  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8174 (0.8451)  acc1: 85.2000 (82.9818)  acc5: 97.6000 (97.4546)  time: 1.1316  data: 0.6837  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9740 (0.9900)  acc1: 78.0000 (79.9238)  acc5: 96.0000 (95.5238)  time: 0.4444  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0662 (0.9995)  acc1: 77.2000 (79.6800)  acc5: 94.4000 (95.3280)  time: 0.4444  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7519 s / it)
* Acc@1 80.182 Acc@5 95.562 loss 0.989
Accuracy of the model on the 50000 test images: 80.2%
Max accuracy: 80.38%
Epoch: [118]  [   0/1251]  eta: 1:32:20  lr: 0.002908  min_lr: 0.002908  loss: 3.7450 (3.7450)  weight_decay: 0.0500 (0.0500)  time: 4.4288  data: 3.4905  max mem: 62457
Epoch: [118]  [ 200/1251]  eta: 0:14:35  lr: 0.002905  min_lr: 0.002905  loss: 3.3820 (3.2418)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6971 (0.8956)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [118]  [ 400/1251]  eta: 0:11:42  lr: 0.002902  min_lr: 0.002902  loss: 3.3042 (3.2369)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8265 (0.8871)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [118]  [ 600/1251]  eta: 0:08:55  lr: 0.002899  min_lr: 0.002899  loss: 3.4144 (3.2292)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6493 (0.8245)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [118]  [ 800/1251]  eta: 0:06:10  lr: 0.002895  min_lr: 0.002895  loss: 3.1753 (3.2362)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8200  data: 0.0004  max mem: 62457
Epoch: [118]  [1000/1251]  eta: 0:03:25  lr: 0.002892  min_lr: 0.002892  loss: 3.3224 (3.2284)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7396 (nan)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [118]  [1200/1251]  eta: 0:00:41  lr: 0.002889  min_lr: 0.002889  loss: 3.2856 (3.2363)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6966 (nan)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [118]  [1250/1251]  eta: 0:00:00  lr: 0.002888  min_lr: 0.002888  loss: 3.3571 (3.2353)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8429 (nan)  time: 0.6915  data: 0.0005  max mem: 62457
Epoch: [118] Total time: 0:17:02 (0.8172 s / it)
Averaged stats: lr: 0.002888  min_lr: 0.002888  loss: 3.3571 (3.2416)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8429 (nan)
Test:  [ 0/25]  eta: 0:03:19  loss: 0.6888 (0.6888)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 7.9852  data: 7.4956  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8894 (0.8542)  acc1: 83.2000 (83.8182)  acc5: 97.6000 (97.2364)  time: 1.1300  data: 0.6817  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0240 (1.0057)  acc1: 79.2000 (80.5905)  acc5: 95.2000 (95.3524)  time: 0.4445  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0890 (1.0134)  acc1: 78.0000 (80.1600)  acc5: 94.8000 (95.3920)  time: 0.4445  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7504 s / it)
* Acc@1 80.366 Acc@5 95.618 loss 1.004
Accuracy of the model on the 50000 test images: 80.4%
Max accuracy: 80.38%
Epoch: [119]  [   0/1251]  eta: 1:43:04  lr: 0.002888  min_lr: 0.002888  loss: 3.4410 (3.4410)  weight_decay: 0.0500 (0.0500)  time: 4.9438  data: 3.4018  max mem: 62457
Epoch: [119]  [ 200/1251]  eta: 0:14:40  lr: 0.002885  min_lr: 0.002885  loss: 3.3364 (3.2360)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8042 (0.9493)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [119]  [ 400/1251]  eta: 0:11:43  lr: 0.002882  min_lr: 0.002882  loss: 3.2882 (3.2403)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8052 (0.8760)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [119]  [ 600/1251]  eta: 0:08:55  lr: 0.002879  min_lr: 0.002879  loss: 3.3075 (3.2438)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7851 (0.8543)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [119]  [ 800/1251]  eta: 0:06:10  lr: 0.002875  min_lr: 0.002875  loss: 3.2267 (3.2315)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7874 (0.8434)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [119]  [1000/1251]  eta: 0:03:25  lr: 0.002872  min_lr: 0.002872  loss: 3.4611 (3.2296)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7278 (0.8536)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [119]  [1200/1251]  eta: 0:00:41  lr: 0.002869  min_lr: 0.002869  loss: 3.4584 (3.2330)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5758 (0.8504)  time: 0.8287  data: 0.0004  max mem: 62457
Epoch: [119]  [1250/1251]  eta: 0:00:00  lr: 0.002868  min_lr: 0.002868  loss: 3.3372 (3.2301)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5347 (0.8446)  time: 0.6921  data: 0.0007  max mem: 62457
Epoch: [119] Total time: 0:17:03 (0.8182 s / it)
Averaged stats: lr: 0.002868  min_lr: 0.002868  loss: 3.3372 (3.2373)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5347 (0.8446)
Test:  [ 0/25]  eta: 0:03:01  loss: 0.6957 (0.6957)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 7.2672  data: 6.7713  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9053 (0.8886)  acc1: 83.2000 (82.7273)  acc5: 97.2000 (97.3091)  time: 1.1062  data: 0.6564  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0950 (1.0208)  acc1: 78.0000 (80.0381)  acc5: 96.0000 (95.6571)  time: 0.4677  data: 0.0225  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0966 (1.0321)  acc1: 78.0000 (79.7920)  acc5: 94.8000 (95.5520)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7506 s / it)
* Acc@1 80.114 Acc@5 95.488 loss 1.020
Accuracy of the model on the 50000 test images: 80.1%
Max accuracy: 80.38%
Epoch: [120]  [   0/1251]  eta: 1:43:18  lr: 0.002868  min_lr: 0.002868  loss: 2.3650 (2.3650)  weight_decay: 0.0500 (0.0500)  time: 4.9545  data: 3.9784  max mem: 62457
Epoch: [120]  [ 200/1251]  eta: 0:14:39  lr: 0.002865  min_lr: 0.002865  loss: 3.0407 (3.1669)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7248 (0.8654)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [120]  [ 400/1251]  eta: 0:11:42  lr: 0.002862  min_lr: 0.002862  loss: 3.3032 (3.1969)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9569 (0.9033)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [120]  [ 600/1251]  eta: 0:08:56  lr: 0.002858  min_lr: 0.002858  loss: 3.1182 (3.1970)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6224 (0.8604)  time: 0.8191  data: 0.0004  max mem: 62457
Epoch: [120]  [ 800/1251]  eta: 0:06:10  lr: 0.002855  min_lr: 0.002855  loss: 3.2573 (3.1969)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6584 (0.8352)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [120]  [1000/1251]  eta: 0:03:25  lr: 0.002852  min_lr: 0.002852  loss: 2.8769 (3.2041)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5773 (0.8214)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [120]  [1200/1251]  eta: 0:00:41  lr: 0.002849  min_lr: 0.002849  loss: 3.3956 (3.2092)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8576 (0.8185)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [120]  [1250/1251]  eta: 0:00:00  lr: 0.002848  min_lr: 0.002848  loss: 3.2067 (3.2070)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8897 (0.8272)  time: 0.6914  data: 0.0005  max mem: 62457
Epoch: [120] Total time: 0:17:03 (0.8184 s / it)
Averaged stats: lr: 0.002848  min_lr: 0.002848  loss: 3.2067 (3.2304)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8897 (0.8272)
Test:  [ 0/25]  eta: 0:03:20  loss: 0.6846 (0.6846)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 8.0013  data: 7.5337  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8581 (0.8355)  acc1: 83.6000 (83.7091)  acc5: 97.6000 (97.4182)  time: 1.1311  data: 0.6851  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9988 (0.9782)  acc1: 78.4000 (80.2095)  acc5: 96.0000 (95.7524)  time: 0.4442  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0323 (0.9905)  acc1: 78.4000 (79.8240)  acc5: 94.8000 (95.6160)  time: 0.4442  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7518 s / it)
* Acc@1 80.258 Acc@5 95.652 loss 0.978
Accuracy of the model on the 50000 test images: 80.3%
Max accuracy: 80.38%
Epoch: [121]  [   0/1251]  eta: 1:44:23  lr: 0.002848  min_lr: 0.002848  loss: 3.0894 (3.0894)  weight_decay: 0.0500 (0.0500)  time: 5.0070  data: 2.2899  max mem: 62457
Epoch: [121]  [ 200/1251]  eta: 0:14:38  lr: 0.002845  min_lr: 0.002845  loss: 3.2943 (3.2030)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6823 (0.7248)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [121]  [ 400/1251]  eta: 0:11:44  lr: 0.002841  min_lr: 0.002841  loss: 3.3257 (3.2089)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8428 (0.8063)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [121]  [ 600/1251]  eta: 0:08:55  lr: 0.002838  min_lr: 0.002838  loss: 3.1041 (3.2069)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7324 (0.8012)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [121]  [ 800/1251]  eta: 0:06:10  lr: 0.002835  min_lr: 0.002835  loss: 3.4622 (3.1989)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0083 (0.7966)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [121]  [1000/1251]  eta: 0:03:25  lr: 0.002831  min_lr: 0.002831  loss: 3.4105 (3.2034)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8267 (0.8232)  time: 0.8141  data: 0.0005  max mem: 62457
Epoch: [121]  [1200/1251]  eta: 0:00:41  lr: 0.002828  min_lr: 0.002828  loss: 3.3741 (3.2066)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7523 (0.8218)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [121]  [1250/1251]  eta: 0:00:00  lr: 0.002827  min_lr: 0.002827  loss: 3.4744 (3.2113)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9535 (0.8330)  time: 0.6925  data: 0.0007  max mem: 62457
Epoch: [121] Total time: 0:17:03 (0.8179 s / it)
Averaged stats: lr: 0.002827  min_lr: 0.002827  loss: 3.4744 (3.2252)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9535 (0.8330)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.6956 (0.6956)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 7.7232  data: 7.2476  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9041 (0.8928)  acc1: 83.6000 (83.2727)  acc5: 97.2000 (97.2364)  time: 1.1070  data: 0.6591  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0970 (1.0297)  acc1: 78.0000 (80.0381)  acc5: 94.8000 (95.5619)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1373 (1.0437)  acc1: 78.0000 (79.8240)  acc5: 94.4000 (95.4080)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7415 s / it)
* Acc@1 80.250 Acc@5 95.544 loss 1.034
Accuracy of the model on the 50000 test images: 80.3%
Max accuracy: 80.38%
Epoch: [122]  [   0/1251]  eta: 1:37:06  lr: 0.002827  min_lr: 0.002827  loss: 3.8846 (3.8846)  weight_decay: 0.0500 (0.0500)  time: 4.6574  data: 3.6653  max mem: 62457
Epoch: [122]  [ 200/1251]  eta: 0:14:38  lr: 0.002824  min_lr: 0.002824  loss: 3.3524 (3.2381)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6238 (0.7810)  time: 0.8219  data: 0.0004  max mem: 62457
Epoch: [122]  [ 400/1251]  eta: 0:11:42  lr: 0.002821  min_lr: 0.002821  loss: 3.4751 (3.2371)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8198 (0.7848)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [122]  [ 600/1251]  eta: 0:08:55  lr: 0.002818  min_lr: 0.002818  loss: 3.3274 (3.2430)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6128 (0.8027)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [122]  [ 800/1251]  eta: 0:06:10  lr: 0.002814  min_lr: 0.002814  loss: 3.1953 (3.2419)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8149 (0.7958)  time: 0.8139  data: 0.0004  max mem: 62457
Epoch: [122]  [1000/1251]  eta: 0:03:25  lr: 0.002811  min_lr: 0.002811  loss: 3.2490 (3.2436)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6346 (0.7842)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [122]  [1200/1251]  eta: 0:00:41  lr: 0.002808  min_lr: 0.002808  loss: 3.4222 (3.2449)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8750 (0.7965)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [122]  [1250/1251]  eta: 0:00:00  lr: 0.002807  min_lr: 0.002807  loss: 3.3894 (3.2458)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6434 (0.7920)  time: 0.6919  data: 0.0007  max mem: 62457
Epoch: [122] Total time: 0:17:02 (0.8175 s / it)
Averaged stats: lr: 0.002807  min_lr: 0.002807  loss: 3.3894 (3.2364)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6434 (0.7920)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.6470 (0.6470)  acc1: 88.8000 (88.8000)  acc5: 99.6000 (99.6000)  time: 7.5959  data: 7.1147  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8275 (0.8138)  acc1: 86.0000 (83.1636)  acc5: 97.2000 (97.4182)  time: 1.0956  data: 0.6471  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9587 (0.9410)  acc1: 78.0000 (80.1333)  acc5: 95.2000 (96.0571)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0203 (0.9547)  acc1: 78.0000 (79.8560)  acc5: 95.2000 (95.8080)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7352 s / it)
* Acc@1 80.390 Acc@5 95.682 loss 0.950
Accuracy of the model on the 50000 test images: 80.4%
Max accuracy: 80.39%
Epoch: [123]  [   0/1251]  eta: 1:30:12  lr: 0.002807  min_lr: 0.002807  loss: 3.2786 (3.2786)  weight_decay: 0.0500 (0.0500)  time: 4.3269  data: 3.5108  max mem: 62457
Epoch: [123]  [ 200/1251]  eta: 0:14:37  lr: 0.002804  min_lr: 0.002804  loss: 3.1716 (3.1856)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9505 (0.8727)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [123]  [ 400/1251]  eta: 0:11:41  lr: 0.002800  min_lr: 0.002800  loss: 3.3352 (3.2061)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8101 (0.8221)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [123]  [ 600/1251]  eta: 0:08:54  lr: 0.002797  min_lr: 0.002797  loss: 3.4534 (3.2060)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6244 (0.8179)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [123]  [ 800/1251]  eta: 0:06:10  lr: 0.002794  min_lr: 0.002794  loss: 3.5094 (3.2127)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6422 (0.8328)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [123]  [1000/1251]  eta: 0:03:25  lr: 0.002790  min_lr: 0.002790  loss: 3.2786 (3.2200)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5930 (0.8179)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [123]  [1200/1251]  eta: 0:00:41  lr: 0.002787  min_lr: 0.002787  loss: 3.4109 (3.2250)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8283 (0.8125)  time: 0.8213  data: 0.0004  max mem: 62457
Epoch: [123]  [1250/1251]  eta: 0:00:00  lr: 0.002786  min_lr: 0.002786  loss: 3.3161 (3.2278)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7405 (0.8133)  time: 0.6921  data: 0.0005  max mem: 62457
Epoch: [123] Total time: 0:17:02 (0.8175 s / it)
Averaged stats: lr: 0.002786  min_lr: 0.002786  loss: 3.3161 (3.2258)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7405 (0.8133)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.6613 (0.6613)  acc1: 88.0000 (88.0000)  acc5: 99.2000 (99.2000)  time: 7.7070  data: 7.2429  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8473 (0.8422)  acc1: 85.2000 (83.4909)  acc5: 96.8000 (97.2727)  time: 1.1063  data: 0.6587  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9972 (0.9703)  acc1: 79.6000 (80.4191)  acc5: 94.8000 (95.6191)  time: 0.4457  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0603 (0.9794)  acc1: 79.6000 (80.0320)  acc5: 94.8000 (95.5520)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7400 s / it)
* Acc@1 80.372 Acc@5 95.784 loss 0.970
Accuracy of the model on the 50000 test images: 80.4%
Max accuracy: 80.39%
Epoch: [124]  [   0/1251]  eta: 1:33:56  lr: 0.002786  min_lr: 0.002786  loss: 3.7066 (3.7066)  weight_decay: 0.0500 (0.0500)  time: 4.5053  data: 3.4519  max mem: 62457
Epoch: [124]  [ 200/1251]  eta: 0:14:35  lr: 0.002783  min_lr: 0.002783  loss: 3.4315 (3.2482)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6674 (0.8785)  time: 0.8146  data: 0.0005  max mem: 62457
Epoch: [124]  [ 400/1251]  eta: 0:11:41  lr: 0.002780  min_lr: 0.002780  loss: 2.9336 (3.2167)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8458 (0.8778)  time: 0.8211  data: 0.0004  max mem: 62457
Epoch: [124]  [ 600/1251]  eta: 0:08:54  lr: 0.002776  min_lr: 0.002776  loss: 3.2389 (3.2101)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6777 (0.8606)  time: 0.8146  data: 0.0005  max mem: 62457
Epoch: [124]  [ 800/1251]  eta: 0:06:09  lr: 0.002773  min_lr: 0.002773  loss: 3.2886 (3.2113)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7103 (0.8499)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [124]  [1000/1251]  eta: 0:03:25  lr: 0.002770  min_lr: 0.002770  loss: 3.4171 (3.2232)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8234 (0.8448)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [124]  [1200/1251]  eta: 0:00:41  lr: 0.002766  min_lr: 0.002766  loss: 3.3627 (3.2298)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7118 (0.8352)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [124]  [1250/1251]  eta: 0:00:00  lr: 0.002766  min_lr: 0.002766  loss: 3.3588 (3.2269)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9133 (0.8413)  time: 0.6917  data: 0.0007  max mem: 62457
Epoch: [124] Total time: 0:17:01 (0.8169 s / it)
Averaged stats: lr: 0.002766  min_lr: 0.002766  loss: 3.3588 (3.2164)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9133 (0.8413)
Test:  [ 0/25]  eta: 0:03:04  loss: 0.6538 (0.6538)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 7.3965  data: 6.9204  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8447 (0.8332)  acc1: 84.4000 (84.0364)  acc5: 97.2000 (97.2364)  time: 1.0774  data: 0.6294  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9761 (0.9832)  acc1: 78.4000 (80.5143)  acc5: 95.2000 (95.7714)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1042 (0.9991)  acc1: 78.4000 (80.2560)  acc5: 94.4000 (95.6320)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7281 s / it)
* Acc@1 80.272 Acc@5 95.708 loss 0.988
Accuracy of the model on the 50000 test images: 80.3%
Max accuracy: 80.39%
Epoch: [125]  [   0/1251]  eta: 1:33:00  lr: 0.002766  min_lr: 0.002766  loss: 3.4050 (3.4050)  weight_decay: 0.0500 (0.0500)  time: 4.4611  data: 2.9733  max mem: 62457
Epoch: [125]  [ 200/1251]  eta: 0:14:34  lr: 0.002762  min_lr: 0.002762  loss: 3.2231 (3.2280)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8734 (0.9521)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [125]  [ 400/1251]  eta: 0:11:41  lr: 0.002759  min_lr: 0.002759  loss: 3.5259 (3.2010)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6326 (0.8377)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [125]  [ 600/1251]  eta: 0:08:54  lr: 0.002756  min_lr: 0.002756  loss: 3.3558 (3.2258)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6885 (0.8555)  time: 0.8138  data: 0.0004  max mem: 62457
Epoch: [125]  [ 800/1251]  eta: 0:06:09  lr: 0.002752  min_lr: 0.002752  loss: 3.3320 (3.2253)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0011 (0.8501)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [125]  [1000/1251]  eta: 0:03:25  lr: 0.002749  min_lr: 0.002749  loss: 3.3626 (3.2222)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7188 (nan)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [125]  [1200/1251]  eta: 0:00:41  lr: 0.002746  min_lr: 0.002746  loss: 3.2554 (3.2323)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6251 (nan)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [125]  [1250/1251]  eta: 0:00:00  lr: 0.002745  min_lr: 0.002745  loss: 3.2274 (3.2288)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8280 (nan)  time: 0.6917  data: 0.0006  max mem: 62457
Epoch: [125] Total time: 0:17:01 (0.8169 s / it)
Averaged stats: lr: 0.002745  min_lr: 0.002745  loss: 3.2274 (3.2116)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8280 (nan)
Test:  [ 0/25]  eta: 0:03:03  loss: 0.7028 (0.7028)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 7.3348  data: 6.8556  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9105 (0.8830)  acc1: 82.4000 (83.4909)  acc5: 96.8000 (97.0909)  time: 1.0713  data: 0.6235  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0210 (1.0124)  acc1: 79.2000 (80.4762)  acc5: 96.0000 (95.8095)  time: 0.4448  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0664 (1.0234)  acc1: 76.4000 (79.9360)  acc5: 95.2000 (95.7760)  time: 0.4447  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7244 s / it)
* Acc@1 80.546 Acc@5 95.656 loss 1.011
Accuracy of the model on the 50000 test images: 80.5%
Max accuracy: 80.55%
Epoch: [126]  [   0/1251]  eta: 1:26:48  lr: 0.002745  min_lr: 0.002745  loss: 3.4756 (3.4756)  weight_decay: 0.0500 (0.0500)  time: 4.1635  data: 3.3537  max mem: 62457
Epoch: [126]  [ 200/1251]  eta: 0:14:36  lr: 0.002742  min_lr: 0.002742  loss: 3.4472 (3.2276)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6711 (0.7265)  time: 0.8235  data: 0.0005  max mem: 62457
Epoch: [126]  [ 400/1251]  eta: 0:11:41  lr: 0.002738  min_lr: 0.002738  loss: 3.0076 (3.2234)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7210 (0.7477)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [126]  [ 600/1251]  eta: 0:08:54  lr: 0.002735  min_lr: 0.002735  loss: 3.1896 (3.2199)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5531 (0.7495)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [126]  [ 800/1251]  eta: 0:06:10  lr: 0.002732  min_lr: 0.002732  loss: 3.1632 (3.2220)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7909 (0.8102)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [126]  [1000/1251]  eta: 0:03:25  lr: 0.002728  min_lr: 0.002728  loss: 3.4386 (3.2269)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6928 (0.8262)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [126]  [1200/1251]  eta: 0:00:41  lr: 0.002725  min_lr: 0.002725  loss: 3.1777 (3.2201)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6331 (0.8096)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [126]  [1250/1251]  eta: 0:00:00  lr: 0.002724  min_lr: 0.002724  loss: 3.2787 (3.2204)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7277 (0.8141)  time: 0.6950  data: 0.0005  max mem: 62457
Epoch: [126] Total time: 0:17:02 (0.8174 s / it)
Averaged stats: lr: 0.002724  min_lr: 0.002724  loss: 3.2787 (3.2067)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7277 (0.8141)
Test:  [ 0/25]  eta: 0:03:06  loss: 0.7264 (0.7264)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 7.4540  data: 6.9792  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8830 (0.8738)  acc1: 84.0000 (83.3818)  acc5: 96.8000 (97.2000)  time: 1.0826  data: 0.6348  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0475 (0.9945)  acc1: 78.8000 (80.5143)  acc5: 95.2000 (95.6762)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1171 (1.0120)  acc1: 77.2000 (80.0160)  acc5: 94.4000 (95.4880)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7301 s / it)
* Acc@1 80.584 Acc@5 95.626 loss 1.000
Accuracy of the model on the 50000 test images: 80.6%
Max accuracy: 80.58%
Epoch: [127]  [   0/1251]  eta: 1:27:04  lr: 0.002724  min_lr: 0.002724  loss: 3.5195 (3.5195)  weight_decay: 0.0500 (0.0500)  time: 4.1762  data: 3.3595  max mem: 62457
Epoch: [127]  [ 200/1251]  eta: 0:14:35  lr: 0.002721  min_lr: 0.002721  loss: 2.9143 (3.1858)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8498 (0.8998)  time: 0.8146  data: 0.0005  max mem: 62457
Epoch: [127]  [ 400/1251]  eta: 0:11:41  lr: 0.002717  min_lr: 0.002717  loss: 3.2066 (3.2039)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7250 (0.8875)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [127]  [ 600/1251]  eta: 0:08:54  lr: 0.002714  min_lr: 0.002714  loss: 3.4795 (3.1936)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7877 (0.8607)  time: 0.8346  data: 0.0004  max mem: 62457
Epoch: [127]  [ 800/1251]  eta: 0:06:09  lr: 0.002711  min_lr: 0.002711  loss: 3.4121 (3.1964)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7225 (0.8656)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [127]  [1000/1251]  eta: 0:03:25  lr: 0.002707  min_lr: 0.002707  loss: 3.2262 (3.1904)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6855 (0.8654)  time: 0.8152  data: 0.0005  max mem: 62457
Epoch: [127]  [1200/1251]  eta: 0:00:41  lr: 0.002704  min_lr: 0.002704  loss: 3.3587 (3.1933)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7619 (0.8661)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [127]  [1250/1251]  eta: 0:00:00  lr: 0.002703  min_lr: 0.002703  loss: 3.3817 (3.1962)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8468 (0.8675)  time: 0.6918  data: 0.0006  max mem: 62457
Epoch: [127] Total time: 0:17:02 (0.8172 s / it)
Averaged stats: lr: 0.002703  min_lr: 0.002703  loss: 3.3817 (3.2056)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8468 (0.8675)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.6722 (0.6722)  acc1: 88.0000 (88.0000)  acc5: 98.0000 (98.0000)  time: 7.8277  data: 7.3624  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8999 (0.8761)  acc1: 83.2000 (83.2364)  acc5: 97.6000 (97.1636)  time: 1.1167  data: 0.6696  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0566 (1.0228)  acc1: 78.0000 (80.2476)  acc5: 95.2000 (95.3333)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0928 (1.0315)  acc1: 78.0000 (79.9200)  acc5: 94.4000 (95.2960)  time: 0.4446  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7454 s / it)
* Acc@1 80.432 Acc@5 95.640 loss 1.016
Accuracy of the model on the 50000 test images: 80.4%
Max accuracy: 80.58%
Epoch: [128]  [   0/1251]  eta: 1:49:48  lr: 0.002703  min_lr: 0.002703  loss: 3.0178 (3.0178)  weight_decay: 0.0500 (0.0500)  time: 5.2666  data: 3.5327  max mem: 62457
Epoch: [128]  [ 200/1251]  eta: 0:14:39  lr: 0.002700  min_lr: 0.002700  loss: 3.4493 (3.2707)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6013 (0.7782)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [128]  [ 400/1251]  eta: 0:11:43  lr: 0.002696  min_lr: 0.002696  loss: 3.4030 (3.2395)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7519 (0.8125)  time: 0.8211  data: 0.0004  max mem: 62457
Epoch: [128]  [ 600/1251]  eta: 0:08:55  lr: 0.002693  min_lr: 0.002693  loss: 3.2689 (3.2202)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5507 (0.7972)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [128]  [ 800/1251]  eta: 0:06:10  lr: 0.002690  min_lr: 0.002690  loss: 3.2435 (3.2135)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6353 (0.8022)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [128]  [1000/1251]  eta: 0:03:25  lr: 0.002686  min_lr: 0.002686  loss: 3.3923 (3.2137)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8276 (0.8129)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [128]  [1200/1251]  eta: 0:00:41  lr: 0.002683  min_lr: 0.002683  loss: 3.1956 (3.2134)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5531 (0.8146)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [128]  [1250/1251]  eta: 0:00:00  lr: 0.002682  min_lr: 0.002682  loss: 3.1403 (3.2142)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7809 (0.8165)  time: 0.6918  data: 0.0007  max mem: 62457
Epoch: [128] Total time: 0:17:03 (0.8177 s / it)
Averaged stats: lr: 0.002682  min_lr: 0.002682  loss: 3.1403 (3.2085)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7809 (0.8165)
Test:  [ 0/25]  eta: 0:03:19  loss: 0.6061 (0.6061)  acc1: 89.2000 (89.2000)  acc5: 98.0000 (98.0000)  time: 7.9831  data: 7.5067  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8167 (0.8114)  acc1: 84.0000 (83.6364)  acc5: 97.6000 (97.2727)  time: 1.1306  data: 0.6827  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9767 (0.9491)  acc1: 80.4000 (80.4762)  acc5: 95.6000 (95.7524)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0608 (0.9643)  acc1: 78.4000 (79.8880)  acc5: 94.4000 (95.6160)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7515 s / it)
* Acc@1 80.528 Acc@5 95.690 loss 0.948
Accuracy of the model on the 50000 test images: 80.5%
Max accuracy: 80.58%
Epoch: [129]  [   0/1251]  eta: 1:49:41  lr: 0.002682  min_lr: 0.002682  loss: 2.7951 (2.7951)  weight_decay: 0.0500 (0.0500)  time: 5.2608  data: 2.9427  max mem: 62457
Epoch: [129]  [ 200/1251]  eta: 0:14:40  lr: 0.002679  min_lr: 0.002679  loss: 3.0309 (3.2610)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9760 (0.9480)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [129]  [ 400/1251]  eta: 0:11:44  lr: 0.002675  min_lr: 0.002675  loss: 3.2321 (3.2449)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6539 (0.8763)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [129]  [ 600/1251]  eta: 0:08:55  lr: 0.002672  min_lr: 0.002672  loss: 3.3098 (3.2309)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6698 (0.8515)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [129]  [ 800/1251]  eta: 0:06:10  lr: 0.002668  min_lr: 0.002668  loss: 3.0725 (3.2279)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7746 (0.8641)  time: 0.8197  data: 0.0004  max mem: 62457
Epoch: [129]  [1000/1251]  eta: 0:03:25  lr: 0.002665  min_lr: 0.002665  loss: 3.2417 (3.2350)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7897 (0.8649)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [129]  [1200/1251]  eta: 0:00:41  lr: 0.002662  min_lr: 0.002662  loss: 3.3512 (3.2224)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7317 (0.8618)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [129]  [1250/1251]  eta: 0:00:00  lr: 0.002661  min_lr: 0.002661  loss: 3.4836 (3.2256)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9555 (0.8739)  time: 0.6945  data: 0.0007  max mem: 62457
Epoch: [129] Total time: 0:17:03 (0.8180 s / it)
Averaged stats: lr: 0.002661  min_lr: 0.002661  loss: 3.4836 (3.1947)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9555 (0.8739)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.7725 (0.7725)  acc1: 87.2000 (87.2000)  acc5: 98.8000 (98.8000)  time: 7.7475  data: 7.2592  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9218 (0.9126)  acc1: 84.0000 (83.4909)  acc5: 97.2000 (97.2000)  time: 1.1094  data: 0.6602  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0721 (1.0457)  acc1: 79.2000 (80.3619)  acc5: 94.8000 (95.6762)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1545 (1.0574)  acc1: 78.4000 (79.8400)  acc5: 94.8000 (95.4720)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7409 s / it)
* Acc@1 80.556 Acc@5 95.678 loss 1.039
Accuracy of the model on the 50000 test images: 80.6%
Max accuracy: 80.58%
Epoch: [130]  [   0/1251]  eta: 1:40:20  lr: 0.002661  min_lr: 0.002661  loss: 2.8413 (2.8413)  weight_decay: 0.0500 (0.0500)  time: 4.8126  data: 2.0196  max mem: 62457
Epoch: [130]  [ 200/1251]  eta: 0:14:40  lr: 0.002657  min_lr: 0.002657  loss: 3.5587 (3.1730)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7358 (0.7476)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [130]  [ 400/1251]  eta: 0:11:43  lr: 0.002654  min_lr: 0.002654  loss: 3.2005 (3.1782)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7076 (0.7671)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [130]  [ 600/1251]  eta: 0:08:55  lr: 0.002651  min_lr: 0.002651  loss: 2.9664 (3.1694)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6666 (0.8347)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [130]  [ 800/1251]  eta: 0:06:10  lr: 0.002647  min_lr: 0.002647  loss: 3.0974 (3.1891)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5891 (0.8005)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [130]  [1000/1251]  eta: 0:03:25  lr: 0.002644  min_lr: 0.002644  loss: 3.2246 (3.1960)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7698 (0.8183)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [130]  [1200/1251]  eta: 0:00:41  lr: 0.002640  min_lr: 0.002640  loss: 3.3010 (3.1996)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9222 (0.8311)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [130]  [1250/1251]  eta: 0:00:00  lr: 0.002640  min_lr: 0.002640  loss: 3.3445 (3.1979)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7980 (0.8281)  time: 0.6919  data: 0.0005  max mem: 62457
Epoch: [130] Total time: 0:17:03 (0.8180 s / it)
Averaged stats: lr: 0.002640  min_lr: 0.002640  loss: 3.3445 (3.1891)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7980 (0.8281)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.6886 (0.6886)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.5262  data: 7.0637  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8739 (0.8610)  acc1: 83.6000 (84.0364)  acc5: 98.0000 (97.6364)  time: 1.0901  data: 0.6425  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0016 (1.0051)  acc1: 78.8000 (80.7429)  acc5: 95.6000 (95.6191)  time: 0.4459  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1047 (1.0153)  acc1: 78.8000 (80.5600)  acc5: 94.8000 (95.4880)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7332 s / it)
* Acc@1 80.766 Acc@5 95.734 loss 0.995
Accuracy of the model on the 50000 test images: 80.8%
Max accuracy: 80.77%
Epoch: [131]  [   0/1251]  eta: 1:36:58  lr: 0.002640  min_lr: 0.002640  loss: 2.8140 (2.8140)  weight_decay: 0.0500 (0.0500)  time: 4.6509  data: 3.8390  max mem: 62457
Epoch: [131]  [ 200/1251]  eta: 0:14:38  lr: 0.002636  min_lr: 0.002636  loss: 3.2621 (3.2087)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9534 (0.8593)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [131]  [ 400/1251]  eta: 0:11:42  lr: 0.002633  min_lr: 0.002633  loss: 3.4655 (3.1776)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7813 (0.8915)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [131]  [ 600/1251]  eta: 0:08:55  lr: 0.002629  min_lr: 0.002629  loss: 3.2967 (3.1787)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8701 (0.9033)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [131]  [ 800/1251]  eta: 0:06:10  lr: 0.002626  min_lr: 0.002626  loss: 3.3664 (3.1756)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7666 (0.8783)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [131]  [1000/1251]  eta: 0:03:25  lr: 0.002623  min_lr: 0.002623  loss: 3.1942 (3.1819)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7808 (0.8648)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [131]  [1200/1251]  eta: 0:00:41  lr: 0.002619  min_lr: 0.002619  loss: 3.1723 (3.1767)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8900 (0.8874)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [131]  [1250/1251]  eta: 0:00:00  lr: 0.002618  min_lr: 0.002618  loss: 3.1785 (3.1769)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6938 (0.8787)  time: 0.6918  data: 0.0005  max mem: 62457
Epoch: [131] Total time: 0:17:02 (0.8177 s / it)
Averaged stats: lr: 0.002618  min_lr: 0.002618  loss: 3.1785 (3.1877)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6938 (0.8787)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.6986 (0.6986)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 7.7079  data: 7.2346  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9056 (0.8689)  acc1: 84.0000 (83.9636)  acc5: 97.6000 (97.4182)  time: 1.1050  data: 0.6579  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0235 (1.0037)  acc1: 80.0000 (81.1619)  acc5: 95.2000 (95.5810)  time: 0.4447  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0831 (1.0134)  acc1: 79.6000 (80.7360)  acc5: 94.8000 (95.4400)  time: 0.4446  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7403 s / it)
* Acc@1 80.674 Acc@5 95.716 loss 1.001
Accuracy of the model on the 50000 test images: 80.7%
Max accuracy: 80.77%
Epoch: [132]  [   0/1251]  eta: 1:47:00  lr: 0.002618  min_lr: 0.002618  loss: 3.4558 (3.4558)  weight_decay: 0.0500 (0.0500)  time: 5.1327  data: 3.8154  max mem: 62457
Epoch: [132]  [ 200/1251]  eta: 0:14:38  lr: 0.002615  min_lr: 0.002615  loss: 3.3362 (3.1700)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6619 (0.7581)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [132]  [ 400/1251]  eta: 0:11:42  lr: 0.002612  min_lr: 0.002612  loss: 3.3235 (3.1646)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5473 (0.7630)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [132]  [ 600/1251]  eta: 0:08:55  lr: 0.002608  min_lr: 0.002608  loss: 3.3084 (3.1723)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8379 (0.8267)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [132]  [ 800/1251]  eta: 0:06:09  lr: 0.002605  min_lr: 0.002605  loss: 3.3502 (3.1735)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9092 (0.8344)  time: 0.8140  data: 0.0004  max mem: 62457
Epoch: [132]  [1000/1251]  eta: 0:03:25  lr: 0.002601  min_lr: 0.002601  loss: 3.2718 (3.1801)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7756 (0.8354)  time: 0.8192  data: 0.0005  max mem: 62457
Epoch: [132]  [1200/1251]  eta: 0:00:41  lr: 0.002598  min_lr: 0.002598  loss: 3.1781 (3.1811)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7711 (0.8479)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [132]  [1250/1251]  eta: 0:00:00  lr: 0.002597  min_lr: 0.002597  loss: 3.2817 (3.1861)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8495 (0.8493)  time: 0.6915  data: 0.0007  max mem: 62457
Epoch: [132] Total time: 0:17:02 (0.8173 s / it)
Averaged stats: lr: 0.002597  min_lr: 0.002597  loss: 3.2817 (3.1954)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8495 (0.8493)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.7418 (0.7418)  acc1: 87.6000 (87.6000)  acc5: 98.8000 (98.8000)  time: 7.7865  data: 7.3191  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9213 (0.8873)  acc1: 82.8000 (82.9818)  acc5: 97.2000 (97.2727)  time: 1.1129  data: 0.6656  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0224 (1.0159)  acc1: 78.4000 (80.3048)  acc5: 95.6000 (95.3905)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0921 (1.0234)  acc1: 78.4000 (79.9200)  acc5: 94.0000 (95.3760)  time: 0.4455  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7443 s / it)
* Acc@1 80.668 Acc@5 95.732 loss 0.996
Accuracy of the model on the 50000 test images: 80.7%
Max accuracy: 80.77%
Epoch: [133]  [   0/1251]  eta: 1:46:18  lr: 0.002597  min_lr: 0.002597  loss: 2.6141 (2.6141)  weight_decay: 0.0500 (0.0500)  time: 5.0987  data: 4.0947  max mem: 62457
Epoch: [133]  [ 200/1251]  eta: 0:14:38  lr: 0.002594  min_lr: 0.002594  loss: 3.2933 (3.1393)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8426 (0.8628)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [133]  [ 400/1251]  eta: 0:11:43  lr: 0.002590  min_lr: 0.002590  loss: 3.0211 (3.1326)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9415 (0.8857)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [133]  [ 600/1251]  eta: 0:08:55  lr: 0.002587  min_lr: 0.002587  loss: 3.1718 (3.1520)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6370 (0.8655)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [133]  [ 800/1251]  eta: 0:06:10  lr: 0.002583  min_lr: 0.002583  loss: 3.3589 (3.1518)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9635 (0.8584)  time: 0.8181  data: 0.0004  max mem: 62457
Epoch: [133]  [1000/1251]  eta: 0:03:25  lr: 0.002580  min_lr: 0.002580  loss: 3.4371 (3.1596)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6528 (0.8463)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [133]  [1200/1251]  eta: 0:00:41  lr: 0.002576  min_lr: 0.002576  loss: 3.3338 (3.1568)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9696 (0.8555)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [133]  [1250/1251]  eta: 0:00:00  lr: 0.002576  min_lr: 0.002576  loss: 3.1532 (3.1582)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0926 (0.8598)  time: 0.6917  data: 0.0005  max mem: 62457
Epoch: [133] Total time: 0:17:02 (0.8176 s / it)
Averaged stats: lr: 0.002576  min_lr: 0.002576  loss: 3.1532 (3.1827)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0926 (0.8598)
Test:  [ 0/25]  eta: 0:02:24  loss: 0.6653 (0.6653)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 5.7812  data: 5.3125  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8501 (0.8206)  acc1: 84.4000 (83.5636)  acc5: 97.6000 (97.3818)  time: 1.0464  data: 0.5991  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9848 (0.9594)  acc1: 78.8000 (80.6857)  acc5: 95.2000 (95.9238)  time: 0.5091  data: 0.0639  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0161 (0.9652)  acc1: 78.8000 (80.3840)  acc5: 95.2000 (95.7920)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7144 s / it)
* Acc@1 80.954 Acc@5 95.854 loss 0.954
Accuracy of the model on the 50000 test images: 81.0%
Max accuracy: 80.95%
Epoch: [134]  [   0/1251]  eta: 1:33:01  lr: 0.002576  min_lr: 0.002576  loss: 3.4390 (3.4390)  weight_decay: 0.0500 (0.0500)  time: 4.4615  data: 3.6502  max mem: 62457
Epoch: [134]  [ 200/1251]  eta: 0:14:37  lr: 0.002572  min_lr: 0.002572  loss: 3.3804 (3.1792)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8434 (0.7424)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [134]  [ 400/1251]  eta: 0:11:41  lr: 0.002569  min_lr: 0.002569  loss: 3.1909 (3.1851)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8743 (0.8230)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [134]  [ 600/1251]  eta: 0:08:54  lr: 0.002565  min_lr: 0.002565  loss: 3.3911 (3.2043)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9987 (0.8608)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [134]  [ 800/1251]  eta: 0:06:09  lr: 0.002562  min_lr: 0.002562  loss: 3.3319 (3.1943)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6215 (0.8428)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [134]  [1000/1251]  eta: 0:03:25  lr: 0.002558  min_lr: 0.002558  loss: 3.3937 (3.1899)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8208 (nan)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [134]  [1200/1251]  eta: 0:00:41  lr: 0.002555  min_lr: 0.002555  loss: 3.0149 (3.1934)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7516 (nan)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [134]  [1250/1251]  eta: 0:00:00  lr: 0.002554  min_lr: 0.002554  loss: 3.3154 (3.1949)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8231 (nan)  time: 0.6927  data: 0.0005  max mem: 62457
Epoch: [134] Total time: 0:17:02 (0.8173 s / it)
Averaged stats: lr: 0.002554  min_lr: 0.002554  loss: 3.3154 (3.1884)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8231 (nan)
Test:  [ 0/25]  eta: 0:03:18  loss: 0.6743 (0.6743)  acc1: 87.6000 (87.6000)  acc5: 98.8000 (98.8000)  time: 7.9361  data: 7.4659  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8439 (0.8249)  acc1: 84.0000 (83.9636)  acc5: 97.6000 (97.5273)  time: 1.1264  data: 0.6790  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0174 (0.9577)  acc1: 80.0000 (80.9905)  acc5: 96.0000 (95.8857)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0174 (0.9686)  acc1: 79.6000 (80.7040)  acc5: 95.2000 (95.7600)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7496 s / it)
* Acc@1 80.960 Acc@5 95.840 loss 0.958
Accuracy of the model on the 50000 test images: 81.0%
Max accuracy: 80.96%
Epoch: [135]  [   0/1251]  eta: 1:32:23  lr: 0.002554  min_lr: 0.002554  loss: 2.7137 (2.7137)  weight_decay: 0.0500 (0.0500)  time: 4.4311  data: 3.6216  max mem: 62457
Epoch: [135]  [ 200/1251]  eta: 0:14:36  lr: 0.002551  min_lr: 0.002551  loss: 3.1066 (3.1503)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8016 (0.8598)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [135]  [ 400/1251]  eta: 0:11:42  lr: 0.002547  min_lr: 0.002547  loss: 3.1573 (3.1900)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9831 (0.9062)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [135]  [ 600/1251]  eta: 0:08:55  lr: 0.002544  min_lr: 0.002544  loss: 3.1088 (3.1760)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0857 (0.9040)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [135]  [ 800/1251]  eta: 0:06:10  lr: 0.002540  min_lr: 0.002540  loss: 3.1582 (3.1789)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6746 (0.8771)  time: 0.8151  data: 0.0005  max mem: 62457
Epoch: [135]  [1000/1251]  eta: 0:03:25  lr: 0.002537  min_lr: 0.002537  loss: 3.1914 (3.1810)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6808 (0.8792)  time: 0.8157  data: 0.0005  max mem: 62457
Epoch: [135]  [1200/1251]  eta: 0:00:41  lr: 0.002533  min_lr: 0.002533  loss: 3.2574 (3.1744)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8248 (0.8771)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [135]  [1250/1251]  eta: 0:00:00  lr: 0.002533  min_lr: 0.002533  loss: 3.4091 (3.1773)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8035 (0.8770)  time: 0.6924  data: 0.0006  max mem: 62457
Epoch: [135] Total time: 0:17:03 (0.8180 s / it)
Averaged stats: lr: 0.002533  min_lr: 0.002533  loss: 3.4091 (3.1817)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8035 (0.8770)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.6843 (0.6843)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 7.8256  data: 7.3505  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8853 (0.8514)  acc1: 82.4000 (83.6364)  acc5: 98.0000 (97.7091)  time: 1.1162  data: 0.6686  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9913 (0.9913)  acc1: 78.8000 (80.5905)  acc5: 96.0000 (95.8857)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0575 (0.9996)  acc1: 77.6000 (80.1280)  acc5: 95.2000 (95.8240)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7449 s / it)
* Acc@1 80.926 Acc@5 95.838 loss 0.984
Accuracy of the model on the 50000 test images: 80.9%
Max accuracy: 80.96%
Epoch: [136]  [   0/1251]  eta: 1:36:37  lr: 0.002532  min_lr: 0.002532  loss: 3.1576 (3.1576)  weight_decay: 0.0500 (0.0500)  time: 4.6342  data: 3.5253  max mem: 62457
Epoch: [136]  [ 200/1251]  eta: 0:14:37  lr: 0.002529  min_lr: 0.002529  loss: 3.1179 (3.2242)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6124 (0.8279)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [136]  [ 400/1251]  eta: 0:11:42  lr: 0.002526  min_lr: 0.002526  loss: 3.1357 (3.1836)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0366 (0.8685)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [136]  [ 600/1251]  eta: 0:08:55  lr: 0.002522  min_lr: 0.002522  loss: 3.3419 (3.2014)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6686 (0.8527)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [136]  [ 800/1251]  eta: 0:06:10  lr: 0.002519  min_lr: 0.002519  loss: 3.1071 (3.1758)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8315 (0.8770)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [136]  [1000/1251]  eta: 0:03:25  lr: 0.002515  min_lr: 0.002515  loss: 3.4188 (3.1659)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9339 (0.8860)  time: 0.8209  data: 0.0004  max mem: 62457
Epoch: [136]  [1200/1251]  eta: 0:00:41  lr: 0.002512  min_lr: 0.002512  loss: 3.0576 (3.1605)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7726 (0.8754)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [136]  [1250/1251]  eta: 0:00:00  lr: 0.002511  min_lr: 0.002511  loss: 3.3796 (3.1635)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6795 (0.8668)  time: 0.6919  data: 0.0005  max mem: 62457
Epoch: [136] Total time: 0:17:03 (0.8182 s / it)
Averaged stats: lr: 0.002511  min_lr: 0.002511  loss: 3.3796 (3.1677)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6795 (0.8668)
Test:  [ 0/25]  eta: 0:02:26  loss: 0.6675 (0.6675)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 5.8427  data: 5.3251  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8265 (0.8104)  acc1: 82.8000 (84.4727)  acc5: 97.2000 (97.5273)  time: 1.0626  data: 0.6122  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9314 (0.9428)  acc1: 80.4000 (81.2000)  acc5: 95.6000 (95.8667)  time: 0.5141  data: 0.0705  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0324 (0.9548)  acc1: 80.0000 (80.7360)  acc5: 95.2000 (95.8240)  time: 0.4437  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7210 s / it)
* Acc@1 81.046 Acc@5 95.870 loss 0.944
Accuracy of the model on the 50000 test images: 81.0%
Max accuracy: 81.05%
Epoch: [137]  [   0/1251]  eta: 1:23:08  lr: 0.002511  min_lr: 0.002511  loss: 3.4924 (3.4924)  weight_decay: 0.0500 (0.0500)  time: 3.9878  data: 3.1660  max mem: 62457
Epoch: [137]  [ 200/1251]  eta: 0:14:32  lr: 0.002507  min_lr: 0.002507  loss: 3.0353 (3.0838)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8838 (0.9635)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [137]  [ 400/1251]  eta: 0:11:41  lr: 0.002504  min_lr: 0.002504  loss: 3.3800 (3.1209)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1170 (0.9326)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [137]  [ 600/1251]  eta: 0:08:54  lr: 0.002500  min_lr: 0.002500  loss: 3.1973 (3.1245)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5252 (0.8772)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [137]  [ 800/1251]  eta: 0:06:09  lr: 0.002497  min_lr: 0.002497  loss: 3.3396 (3.1342)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6775 (0.8725)  time: 0.8200  data: 0.0004  max mem: 62457
Epoch: [137]  [1000/1251]  eta: 0:03:25  lr: 0.002493  min_lr: 0.002493  loss: 3.0562 (3.1441)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7043 (0.8625)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [137]  [1200/1251]  eta: 0:00:41  lr: 0.002490  min_lr: 0.002490  loss: 3.1463 (3.1555)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6912 (0.8582)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [137]  [1250/1251]  eta: 0:00:00  lr: 0.002489  min_lr: 0.002489  loss: 3.2650 (3.1559)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9696 (0.8616)  time: 0.6925  data: 0.0005  max mem: 62457
Epoch: [137] Total time: 0:17:02 (0.8170 s / it)
Averaged stats: lr: 0.002489  min_lr: 0.002489  loss: 3.2650 (3.1593)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9696 (0.8616)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.6895 (0.6895)  acc1: 86.8000 (86.8000)  acc5: 98.8000 (98.8000)  time: 7.5372  data: 7.0452  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9017 (0.8610)  acc1: 82.0000 (83.0909)  acc5: 97.2000 (97.2727)  time: 1.0902  data: 0.6407  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0147 (0.9937)  acc1: 78.4000 (80.4571)  acc5: 94.8000 (95.8095)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0731 (0.9993)  acc1: 78.8000 (80.1920)  acc5: 94.8000 (95.8560)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7334 s / it)
* Acc@1 80.726 Acc@5 95.910 loss 0.981
Accuracy of the model on the 50000 test images: 80.7%
Max accuracy: 81.05%
Epoch: [138]  [   0/1251]  eta: 1:44:09  lr: 0.002489  min_lr: 0.002489  loss: 2.8110 (2.8110)  weight_decay: 0.0500 (0.0500)  time: 4.9958  data: 3.2548  max mem: 62457
Epoch: [138]  [ 200/1251]  eta: 0:14:41  lr: 0.002486  min_lr: 0.002486  loss: 3.1513 (3.1456)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9333 (0.8534)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [138]  [ 400/1251]  eta: 0:11:43  lr: 0.002482  min_lr: 0.002482  loss: 3.2280 (3.1580)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7354 (0.8815)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [138]  [ 600/1251]  eta: 0:08:55  lr: 0.002479  min_lr: 0.002479  loss: 3.3764 (3.1727)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7198 (0.8795)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [138]  [ 800/1251]  eta: 0:06:10  lr: 0.002475  min_lr: 0.002475  loss: 3.2133 (3.1585)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0036 (0.8900)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [138]  [1000/1251]  eta: 0:03:25  lr: 0.002472  min_lr: 0.002472  loss: 3.0637 (3.1615)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7319 (0.8753)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [138]  [1200/1251]  eta: 0:00:41  lr: 0.002468  min_lr: 0.002468  loss: 3.2216 (3.1545)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8007 (0.8772)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [138]  [1250/1251]  eta: 0:00:00  lr: 0.002467  min_lr: 0.002467  loss: 3.2152 (3.1550)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6595 (0.8703)  time: 0.6923  data: 0.0005  max mem: 62457
Epoch: [138] Total time: 0:17:03 (0.8182 s / it)
Averaged stats: lr: 0.002467  min_lr: 0.002467  loss: 3.2152 (3.1617)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6595 (0.8703)
Test:  [ 0/25]  eta: 0:03:21  loss: 0.6943 (0.6943)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 8.0621  data: 7.5997  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8652 (0.8247)  acc1: 84.8000 (84.2182)  acc5: 97.2000 (97.5273)  time: 1.1388  data: 0.6912  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9660 (0.9656)  acc1: 80.0000 (80.9905)  acc5: 96.0000 (95.8857)  time: 0.4458  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0689 (0.9744)  acc1: 79.2000 (80.8480)  acc5: 94.8000 (95.7760)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7559 s / it)
* Acc@1 80.802 Acc@5 95.796 loss 0.972
Accuracy of the model on the 50000 test images: 80.8%
Max accuracy: 81.05%
Epoch: [139]  [   0/1251]  eta: 1:30:32  lr: 0.002467  min_lr: 0.002467  loss: 3.5773 (3.5773)  weight_decay: 0.0500 (0.0500)  time: 4.3428  data: 2.1492  max mem: 62457
Epoch: [139]  [ 200/1251]  eta: 0:14:36  lr: 0.002464  min_lr: 0.002464  loss: 3.2119 (3.1298)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7617 (0.7821)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [139]  [ 400/1251]  eta: 0:11:41  lr: 0.002460  min_lr: 0.002460  loss: 3.0853 (3.1673)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9254 (0.8834)  time: 0.8150  data: 0.0005  max mem: 62457
Epoch: [139]  [ 600/1251]  eta: 0:08:55  lr: 0.002457  min_lr: 0.002457  loss: 3.3975 (3.1763)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8740 (0.8864)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [139]  [ 800/1251]  eta: 0:06:10  lr: 0.002453  min_lr: 0.002453  loss: 3.1953 (3.1575)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8457 (0.9039)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [139]  [1000/1251]  eta: 0:03:25  lr: 0.002450  min_lr: 0.002450  loss: 2.9121 (3.1599)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8270 (0.8905)  time: 0.8214  data: 0.0004  max mem: 62457
Epoch: [139]  [1200/1251]  eta: 0:00:41  lr: 0.002446  min_lr: 0.002446  loss: 3.0060 (3.1649)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8405 (0.8918)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [139]  [1250/1251]  eta: 0:00:00  lr: 0.002446  min_lr: 0.002446  loss: 3.2248 (3.1638)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8487 (0.8952)  time: 0.6926  data: 0.0007  max mem: 62457
Epoch: [139] Total time: 0:17:02 (0.8176 s / it)
Averaged stats: lr: 0.002446  min_lr: 0.002446  loss: 3.2248 (3.1626)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8487 (0.8952)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.6233 (0.6233)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 7.7033  data: 7.2164  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8428 (0.8052)  acc1: 82.8000 (84.2182)  acc5: 97.2000 (97.1273)  time: 1.1058  data: 0.6563  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9219 (0.9387)  acc1: 80.0000 (81.3333)  acc5: 96.0000 (95.7714)  time: 0.4461  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0223 (0.9490)  acc1: 79.2000 (81.0880)  acc5: 95.2000 (95.6800)  time: 0.4461  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7402 s / it)
* Acc@1 81.238 Acc@5 95.922 loss 0.940
Accuracy of the model on the 50000 test images: 81.2%
Max accuracy: 81.24%
Epoch: [140]  [   0/1251]  eta: 1:28:42  lr: 0.002445  min_lr: 0.002445  loss: 2.2314 (2.2314)  weight_decay: 0.0500 (0.0500)  time: 4.2550  data: 3.4325  max mem: 62457
Epoch: [140]  [ 200/1251]  eta: 0:14:35  lr: 0.002442  min_lr: 0.002442  loss: 3.3169 (3.1298)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7825 (0.8468)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [140]  [ 400/1251]  eta: 0:11:42  lr: 0.002438  min_lr: 0.002438  loss: 3.2802 (3.1390)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3077 (0.9207)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [140]  [ 600/1251]  eta: 0:08:55  lr: 0.002435  min_lr: 0.002435  loss: 3.2589 (3.1531)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6804 (0.8789)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [140]  [ 800/1251]  eta: 0:06:10  lr: 0.002431  min_lr: 0.002431  loss: 3.1637 (3.1560)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6744 (0.8749)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [140]  [1000/1251]  eta: 0:03:25  lr: 0.002428  min_lr: 0.002428  loss: 3.4360 (3.1544)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6252 (0.8621)  time: 0.8193  data: 0.0004  max mem: 62457
Epoch: [140]  [1200/1251]  eta: 0:00:41  lr: 0.002424  min_lr: 0.002424  loss: 3.2967 (3.1486)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7939 (0.8581)  time: 0.8151  data: 0.0005  max mem: 62457
Epoch: [140]  [1250/1251]  eta: 0:00:00  lr: 0.002424  min_lr: 0.002424  loss: 2.9740 (3.1446)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9041 (0.8632)  time: 0.6924  data: 0.0006  max mem: 62457
Epoch: [140] Total time: 0:17:03 (0.8179 s / it)
Averaged stats: lr: 0.002424  min_lr: 0.002424  loss: 2.9740 (3.1593)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9041 (0.8632)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.5838 (0.5838)  acc1: 87.2000 (87.2000)  acc5: 99.2000 (99.2000)  time: 7.7854  data: 7.3115  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7751 (0.7492)  acc1: 83.2000 (83.5273)  acc5: 97.2000 (97.4909)  time: 1.1127  data: 0.6649  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9266 (0.8711)  acc1: 79.2000 (80.8762)  acc5: 96.0000 (95.9619)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9443 (0.8827)  acc1: 79.2000 (80.6880)  acc5: 95.2000 (95.8560)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7431 s / it)
* Acc@1 81.000 Acc@5 96.008 loss 0.880
Accuracy of the model on the 50000 test images: 81.0%
Max accuracy: 81.24%
Epoch: [141]  [   0/1251]  eta: 1:42:16  lr: 0.002424  min_lr: 0.002424  loss: 3.2600 (3.2600)  weight_decay: 0.0500 (0.0500)  time: 4.9054  data: 3.2111  max mem: 62457
Epoch: [141]  [ 200/1251]  eta: 0:14:38  lr: 0.002420  min_lr: 0.002420  loss: 3.3690 (3.1536)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7799 (0.8841)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [141]  [ 400/1251]  eta: 0:11:43  lr: 0.002417  min_lr: 0.002417  loss: 3.4348 (3.1618)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7995 (0.9269)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [141]  [ 600/1251]  eta: 0:08:55  lr: 0.002413  min_lr: 0.002413  loss: 3.0273 (3.1575)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9206 (0.9112)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [141]  [ 800/1251]  eta: 0:06:10  lr: 0.002409  min_lr: 0.002409  loss: 3.1435 (3.1543)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9795 (0.9320)  time: 0.8230  data: 0.0004  max mem: 62457
Epoch: [141]  [1000/1251]  eta: 0:03:25  lr: 0.002406  min_lr: 0.002406  loss: 2.9978 (3.1567)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7489 (0.9213)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [141]  [1200/1251]  eta: 0:00:41  lr: 0.002402  min_lr: 0.002402  loss: 3.3464 (3.1587)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6400 (0.9002)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [141]  [1250/1251]  eta: 0:00:00  lr: 0.002402  min_lr: 0.002402  loss: 3.3581 (3.1601)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8613 (0.9039)  time: 0.6921  data: 0.0005  max mem: 62457
Epoch: [141] Total time: 0:17:03 (0.8178 s / it)
Averaged stats: lr: 0.002402  min_lr: 0.002402  loss: 3.3581 (3.1565)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8613 (0.9039)
Test:  [ 0/25]  eta: 0:03:19  loss: 0.6921 (0.6921)  acc1: 87.2000 (87.2000)  acc5: 98.4000 (98.4000)  time: 7.9776  data: 7.5016  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8248 (0.8507)  acc1: 83.2000 (83.8909)  acc5: 97.2000 (97.3818)  time: 1.1309  data: 0.6822  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9694 (0.9895)  acc1: 79.6000 (80.4381)  acc5: 95.6000 (95.8095)  time: 0.4461  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0671 (1.0002)  acc1: 78.8000 (80.2240)  acc5: 94.8000 (95.7440)  time: 0.4460  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7516 s / it)
* Acc@1 80.884 Acc@5 95.846 loss 0.983
Accuracy of the model on the 50000 test images: 80.9%
Max accuracy: 81.24%
Epoch: [142]  [   0/1251]  eta: 1:42:40  lr: 0.002402  min_lr: 0.002402  loss: 3.1933 (3.1933)  weight_decay: 0.0500 (0.0500)  time: 4.9242  data: 4.1012  max mem: 62457
Epoch: [142]  [ 200/1251]  eta: 0:14:41  lr: 0.002398  min_lr: 0.002398  loss: 3.2256 (3.1183)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6437 (0.9502)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [142]  [ 400/1251]  eta: 0:11:43  lr: 0.002395  min_lr: 0.002395  loss: 2.7266 (3.1104)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7401 (0.8982)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [142]  [ 600/1251]  eta: 0:08:55  lr: 0.002391  min_lr: 0.002391  loss: 3.1271 (3.1302)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7864 (0.8960)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [142]  [ 800/1251]  eta: 0:06:10  lr: 0.002387  min_lr: 0.002387  loss: 2.9486 (3.1313)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7119 (0.8844)  time: 0.8188  data: 0.0004  max mem: 62457
Epoch: [142]  [1000/1251]  eta: 0:03:25  lr: 0.002384  min_lr: 0.002384  loss: 3.0256 (3.1255)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7722 (0.8876)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [142]  [1200/1251]  eta: 0:00:41  lr: 0.002380  min_lr: 0.002380  loss: 2.9740 (3.1261)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7394 (0.8945)  time: 0.8190  data: 0.0004  max mem: 62457
Epoch: [142]  [1250/1251]  eta: 0:00:00  lr: 0.002380  min_lr: 0.002380  loss: 2.9952 (3.1224)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7192 (0.8901)  time: 0.6920  data: 0.0007  max mem: 62457
Epoch: [142] Total time: 0:17:03 (0.8181 s / it)
Averaged stats: lr: 0.002380  min_lr: 0.002380  loss: 2.9952 (3.1500)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7192 (0.8901)
Test:  [ 0/25]  eta: 0:03:01  loss: 0.6082 (0.6082)  acc1: 87.6000 (87.6000)  acc5: 98.0000 (98.0000)  time: 7.2668  data: 6.7855  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.7820 (0.7779)  acc1: 83.6000 (84.4727)  acc5: 97.2000 (97.2727)  time: 1.0658  data: 0.6172  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9470 (0.9054)  acc1: 80.4000 (81.4667)  acc5: 95.6000 (96.0571)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9885 (0.9156)  acc1: 80.4000 (81.1520)  acc5: 95.2000 (95.9680)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7228 s / it)
* Acc@1 81.272 Acc@5 95.944 loss 0.911
Accuracy of the model on the 50000 test images: 81.3%
Max accuracy: 81.27%
Epoch: [143]  [   0/1251]  eta: 1:29:27  lr: 0.002380  min_lr: 0.002380  loss: 2.3048 (2.3048)  weight_decay: 0.0500 (0.0500)  time: 4.2905  data: 3.4745  max mem: 62457
Epoch: [143]  [ 200/1251]  eta: 0:14:35  lr: 0.002376  min_lr: 0.002376  loss: 3.0845 (3.0871)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8818 (0.8867)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [143]  [ 400/1251]  eta: 0:11:41  lr: 0.002373  min_lr: 0.002373  loss: 3.3319 (3.1102)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8605 (0.9047)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [143]  [ 600/1251]  eta: 0:08:55  lr: 0.002369  min_lr: 0.002369  loss: 2.9873 (3.0957)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8144 (nan)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [143]  [ 800/1251]  eta: 0:06:10  lr: 0.002365  min_lr: 0.002365  loss: 3.3759 (3.1236)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8282 (nan)  time: 0.8152  data: 0.0003  max mem: 62457
Epoch: [143]  [1000/1251]  eta: 0:03:25  lr: 0.002362  min_lr: 0.002362  loss: 3.4220 (3.1248)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7930 (nan)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [143]  [1200/1251]  eta: 0:00:41  lr: 0.002358  min_lr: 0.002358  loss: 3.3417 (3.1213)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8352 (nan)  time: 0.8155  data: 0.0005  max mem: 62457
Epoch: [143]  [1250/1251]  eta: 0:00:00  lr: 0.002358  min_lr: 0.002358  loss: 3.3460 (3.1247)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8726 (nan)  time: 0.6925  data: 0.0006  max mem: 62457
Epoch: [143] Total time: 0:17:03 (0.8178 s / it)
Averaged stats: lr: 0.002358  min_lr: 0.002358  loss: 3.3460 (3.1444)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8726 (nan)
Test:  [ 0/25]  eta: 0:03:17  loss: 0.6625 (0.6625)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 7.8832  data: 7.4082  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8282 (0.8220)  acc1: 83.6000 (83.8546)  acc5: 97.6000 (97.6000)  time: 1.1216  data: 0.6737  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9982 (0.9510)  acc1: 79.2000 (81.2000)  acc5: 96.4000 (96.2667)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0088 (0.9650)  acc1: 79.2000 (80.7680)  acc5: 95.6000 (96.0800)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7468 s / it)
* Acc@1 81.256 Acc@5 95.980 loss 0.953
Accuracy of the model on the 50000 test images: 81.3%
Max accuracy: 81.27%
Epoch: [144]  [   0/1251]  eta: 1:37:54  lr: 0.002358  min_lr: 0.002358  loss: 2.4129 (2.4129)  weight_decay: 0.0500 (0.0500)  time: 4.6960  data: 3.2649  max mem: 62457
Epoch: [144]  [ 200/1251]  eta: 0:14:37  lr: 0.002354  min_lr: 0.002354  loss: 3.2373 (3.1567)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7225 (0.9266)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [144]  [ 400/1251]  eta: 0:11:43  lr: 0.002350  min_lr: 0.002350  loss: 3.3227 (3.1364)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7951 (0.8580)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [144]  [ 600/1251]  eta: 0:08:55  lr: 0.002347  min_lr: 0.002347  loss: 3.1145 (3.1323)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3491 (0.9300)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [144]  [ 800/1251]  eta: 0:06:10  lr: 0.002343  min_lr: 0.002343  loss: 3.3297 (3.1454)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6680 (0.8928)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [144]  [1000/1251]  eta: 0:03:25  lr: 0.002340  min_lr: 0.002340  loss: 3.2019 (3.1417)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7823 (0.8824)  time: 0.8230  data: 0.0004  max mem: 62457
Epoch: [144]  [1200/1251]  eta: 0:00:41  lr: 0.002336  min_lr: 0.002336  loss: 3.1255 (3.1427)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9904 (0.8853)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [144]  [1250/1251]  eta: 0:00:00  lr: 0.002335  min_lr: 0.002335  loss: 3.1964 (3.1472)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8005 (0.8883)  time: 0.6925  data: 0.0006  max mem: 62457
Epoch: [144] Total time: 0:17:03 (0.8185 s / it)
Averaged stats: lr: 0.002335  min_lr: 0.002335  loss: 3.1964 (3.1450)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8005 (0.8883)
Test:  [ 0/25]  eta: 0:02:42  loss: 0.7000 (0.7000)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 6.5191  data: 6.0266  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8931 (0.8734)  acc1: 84.8000 (84.6909)  acc5: 97.6000 (97.4546)  time: 1.0636  data: 0.6151  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0488 (1.0039)  acc1: 79.2000 (81.5048)  acc5: 95.2000 (95.7333)  time: 0.4811  data: 0.0370  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0895 (1.0149)  acc1: 79.2000 (80.9440)  acc5: 94.8000 (95.5840)  time: 0.4442  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7220 s / it)
* Acc@1 81.344 Acc@5 95.862 loss 0.999
Accuracy of the model on the 50000 test images: 81.3%
Max accuracy: 81.34%
Epoch: [145]  [   0/1251]  eta: 1:27:03  lr: 0.002335  min_lr: 0.002335  loss: 3.4548 (3.4548)  weight_decay: 0.0500 (0.0500)  time: 4.1755  data: 3.3550  max mem: 62457
Epoch: [145]  [ 200/1251]  eta: 0:14:34  lr: 0.002332  min_lr: 0.002332  loss: 3.1023 (3.1124)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8259 (0.8509)  time: 0.8214  data: 0.0004  max mem: 62457
Epoch: [145]  [ 400/1251]  eta: 0:11:41  lr: 0.002328  min_lr: 0.002328  loss: 2.7795 (3.0970)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7510 (0.8562)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [145]  [ 600/1251]  eta: 0:08:54  lr: 0.002325  min_lr: 0.002325  loss: 3.2785 (3.0970)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8873 (0.8473)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [145]  [ 800/1251]  eta: 0:06:10  lr: 0.002321  min_lr: 0.002321  loss: 2.9880 (3.1092)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9793 (0.8717)  time: 0.8307  data: 0.0004  max mem: 62457
Epoch: [145]  [1000/1251]  eta: 0:03:25  lr: 0.002318  min_lr: 0.002318  loss: 3.1799 (3.1216)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9365 (0.8865)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [145]  [1200/1251]  eta: 0:00:41  lr: 0.002314  min_lr: 0.002314  loss: 3.0312 (3.1225)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7891 (0.8888)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [145]  [1250/1251]  eta: 0:00:00  lr: 0.002313  min_lr: 0.002313  loss: 3.0048 (3.1223)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7891 (0.8889)  time: 0.6930  data: 0.0006  max mem: 62457
Epoch: [145] Total time: 0:17:02 (0.8177 s / it)
Averaged stats: lr: 0.002313  min_lr: 0.002313  loss: 3.0048 (3.1393)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7891 (0.8889)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.7129 (0.7129)  acc1: 88.0000 (88.0000)  acc5: 99.2000 (99.2000)  time: 7.7203  data: 7.2239  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8413 (0.8461)  acc1: 84.0000 (83.8182)  acc5: 97.6000 (97.4546)  time: 1.1071  data: 0.6571  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0041 (0.9711)  acc1: 79.2000 (80.8571)  acc5: 96.4000 (95.7714)  time: 0.4456  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0041 (0.9829)  acc1: 78.8000 (80.5280)  acc5: 95.2000 (95.6160)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7409 s / it)
* Acc@1 81.188 Acc@5 95.962 loss 0.966
Accuracy of the model on the 50000 test images: 81.2%
Max accuracy: 81.34%
Epoch: [146]  [   0/1251]  eta: 1:40:11  lr: 0.002313  min_lr: 0.002313  loss: 3.6110 (3.6110)  weight_decay: 0.0500 (0.0500)  time: 4.8050  data: 3.1846  max mem: 62457
Epoch: [146]  [ 200/1251]  eta: 0:14:40  lr: 0.002310  min_lr: 0.002310  loss: 3.2988 (3.1334)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8367 (0.8730)  time: 0.8162  data: 0.0004  max mem: 62457
Epoch: [146]  [ 400/1251]  eta: 0:11:44  lr: 0.002306  min_lr: 0.002306  loss: 2.7850 (3.1158)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7954 (0.9189)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [146]  [ 600/1251]  eta: 0:08:56  lr: 0.002303  min_lr: 0.002303  loss: 3.3210 (3.1143)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7666 (0.9229)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [146]  [ 800/1251]  eta: 0:06:10  lr: 0.002299  min_lr: 0.002299  loss: 2.8558 (3.1266)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9670 (0.9215)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [146]  [1000/1251]  eta: 0:03:26  lr: 0.002296  min_lr: 0.002296  loss: 3.2951 (3.1190)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6223 (0.9122)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [146]  [1200/1251]  eta: 0:00:41  lr: 0.002292  min_lr: 0.002292  loss: 3.2814 (3.1288)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7329 (0.9025)  time: 0.8223  data: 0.0004  max mem: 62457
Epoch: [146]  [1250/1251]  eta: 0:00:00  lr: 0.002291  min_lr: 0.002291  loss: 2.9897 (3.1279)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8789 (0.9077)  time: 0.6922  data: 0.0005  max mem: 62457
Epoch: [146] Total time: 0:17:04 (0.8186 s / it)
Averaged stats: lr: 0.002291  min_lr: 0.002291  loss: 2.9897 (3.1328)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8789 (0.9077)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.6513 (0.6513)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 7.8013  data: 7.3139  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8071 (0.8189)  acc1: 84.4000 (84.1455)  acc5: 97.6000 (97.4909)  time: 1.1142  data: 0.6651  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9573 (0.9543)  acc1: 79.2000 (81.1429)  acc5: 95.6000 (96.0191)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0641 (0.9666)  acc1: 79.2000 (80.8960)  acc5: 95.2000 (95.9040)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7435 s / it)
* Acc@1 81.290 Acc@5 95.918 loss 0.950
Accuracy of the model on the 50000 test images: 81.3%
Max accuracy: 81.34%
Epoch: [147]  [   0/1251]  eta: 1:39:17  lr: 0.002291  min_lr: 0.002291  loss: 3.1658 (3.1658)  weight_decay: 0.0500 (0.0500)  time: 4.7625  data: 2.3674  max mem: 62457
Epoch: [147]  [ 200/1251]  eta: 0:14:39  lr: 0.002288  min_lr: 0.002288  loss: 3.1753 (3.1011)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8842 (0.8957)  time: 0.8156  data: 0.0005  max mem: 62457
Epoch: [147]  [ 400/1251]  eta: 0:11:43  lr: 0.002284  min_lr: 0.002284  loss: 3.1367 (3.1004)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7806 (0.8833)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [147]  [ 600/1251]  eta: 0:08:56  lr: 0.002280  min_lr: 0.002280  loss: 3.2371 (3.0938)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6809 (0.8840)  time: 0.8150  data: 0.0005  max mem: 62457
Epoch: [147]  [ 800/1251]  eta: 0:06:10  lr: 0.002277  min_lr: 0.002277  loss: 3.3343 (3.1147)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8790 (0.9480)  time: 0.8153  data: 0.0005  max mem: 62457
Epoch: [147]  [1000/1251]  eta: 0:03:25  lr: 0.002273  min_lr: 0.002273  loss: 3.2605 (3.1145)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0423 (0.9486)  time: 0.8158  data: 0.0005  max mem: 62457
Epoch: [147]  [1200/1251]  eta: 0:00:41  lr: 0.002270  min_lr: 0.002270  loss: 3.3417 (3.1218)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7056 (0.9281)  time: 0.8158  data: 0.0005  max mem: 62457
Epoch: [147]  [1250/1251]  eta: 0:00:00  lr: 0.002269  min_lr: 0.002269  loss: 3.0637 (3.1197)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9087 (0.9360)  time: 0.6922  data: 0.0006  max mem: 62457
Epoch: [147] Total time: 0:17:03 (0.8185 s / it)
Averaged stats: lr: 0.002269  min_lr: 0.002269  loss: 3.0637 (3.1355)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9087 (0.9360)
Test:  [ 0/25]  eta: 0:03:18  loss: 0.6419 (0.6419)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 7.9238  data: 7.4572  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8152 (0.8404)  acc1: 83.2000 (83.8182)  acc5: 97.2000 (97.4182)  time: 1.1254  data: 0.6782  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0393 (0.9505)  acc1: 79.6000 (81.3524)  acc5: 96.4000 (96.2095)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0393 (0.9724)  acc1: 79.6000 (80.7840)  acc5: 95.2000 (96.0000)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7485 s / it)
* Acc@1 81.122 Acc@5 95.962 loss 0.967
Accuracy of the model on the 50000 test images: 81.1%
Max accuracy: 81.34%
Epoch: [148]  [   0/1251]  eta: 1:38:56  lr: 0.002269  min_lr: 0.002269  loss: 2.7370 (2.7370)  weight_decay: 0.0500 (0.0500)  time: 4.7453  data: 3.0720  max mem: 62457
Epoch: [148]  [ 200/1251]  eta: 0:14:37  lr: 0.002265  min_lr: 0.002265  loss: 3.3327 (3.1253)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7962 (0.9082)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [148]  [ 400/1251]  eta: 0:11:43  lr: 0.002262  min_lr: 0.002262  loss: 3.2340 (3.1080)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8323 (0.9140)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [148]  [ 600/1251]  eta: 0:08:55  lr: 0.002258  min_lr: 0.002258  loss: 3.1319 (3.1135)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9927 (0.9349)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [148]  [ 800/1251]  eta: 0:06:10  lr: 0.002255  min_lr: 0.002255  loss: 3.3606 (3.0965)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6929 (0.9245)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [148]  [1000/1251]  eta: 0:03:25  lr: 0.002251  min_lr: 0.002251  loss: 3.1063 (3.1131)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6966 (0.9377)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [148]  [1200/1251]  eta: 0:00:41  lr: 0.002248  min_lr: 0.002248  loss: 3.2873 (3.1132)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9032 (0.9287)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [148]  [1250/1251]  eta: 0:00:00  lr: 0.002247  min_lr: 0.002247  loss: 3.3493 (3.1179)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9269 (0.9324)  time: 0.6928  data: 0.0006  max mem: 62457
Epoch: [148] Total time: 0:17:03 (0.8184 s / it)
Averaged stats: lr: 0.002247  min_lr: 0.002247  loss: 3.3493 (3.1282)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9269 (0.9324)
Test:  [ 0/25]  eta: 0:03:03  loss: 0.7245 (0.7245)  acc1: 86.8000 (86.8000)  acc5: 98.4000 (98.4000)  time: 7.3293  data: 6.8387  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8138 (0.8294)  acc1: 83.6000 (83.9636)  acc5: 98.0000 (97.4909)  time: 1.0713  data: 0.6220  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9879 (0.9440)  acc1: 80.8000 (81.4667)  acc5: 96.0000 (96.1524)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0005 (0.9635)  acc1: 80.4000 (80.9920)  acc5: 95.2000 (95.9520)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7243 s / it)
* Acc@1 81.322 Acc@5 95.978 loss 0.956
Accuracy of the model on the 50000 test images: 81.3%
Max accuracy: 81.34%
Epoch: [149]  [   0/1251]  eta: 1:45:15  lr: 0.002247  min_lr: 0.002247  loss: 3.3589 (3.3589)  weight_decay: 0.0500 (0.0500)  time: 5.0484  data: 3.6647  max mem: 62457
Epoch: [149]  [ 200/1251]  eta: 0:14:40  lr: 0.002243  min_lr: 0.002243  loss: 3.2189 (3.1265)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9534 (0.8982)  time: 0.8233  data: 0.0004  max mem: 62457
Epoch: [149]  [ 400/1251]  eta: 0:11:44  lr: 0.002240  min_lr: 0.002240  loss: 3.2654 (3.1228)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7839 (0.9765)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [149]  [ 600/1251]  eta: 0:08:56  lr: 0.002236  min_lr: 0.002236  loss: 3.1634 (3.1372)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7623 (0.9340)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [149]  [ 800/1251]  eta: 0:06:10  lr: 0.002232  min_lr: 0.002232  loss: 3.0643 (3.1273)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9258 (0.9366)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [149]  [1000/1251]  eta: 0:03:26  lr: 0.002229  min_lr: 0.002229  loss: 2.9677 (3.1286)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9343 (0.9643)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [149]  [1200/1251]  eta: 0:00:41  lr: 0.002225  min_lr: 0.002225  loss: 3.1152 (3.1226)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9444 (0.9647)  time: 0.8153  data: 0.0005  max mem: 62457
Epoch: [149]  [1250/1251]  eta: 0:00:00  lr: 0.002224  min_lr: 0.002224  loss: 2.8132 (3.1174)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8952 (0.9623)  time: 0.6925  data: 0.0006  max mem: 62457
Epoch: [149] Total time: 0:17:03 (0.8185 s / it)
Averaged stats: lr: 0.002224  min_lr: 0.002224  loss: 2.8132 (3.1239)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8952 (0.9623)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.5752 (0.5752)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 7.5921  data: 7.0989  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8020 (0.7476)  acc1: 84.4000 (84.4000)  acc5: 98.0000 (97.5636)  time: 1.0952  data: 0.6456  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8540 (0.8655)  acc1: 79.2000 (81.5048)  acc5: 96.0000 (96.2095)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9349 (0.8780)  acc1: 79.2000 (81.2320)  acc5: 95.6000 (96.0960)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7353 s / it)
* Acc@1 81.656 Acc@5 96.016 loss 0.870
Accuracy of the model on the 50000 test images: 81.7%
Max accuracy: 81.66%
Epoch: [150]  [   0/1251]  eta: 1:18:48  lr: 0.002224  min_lr: 0.002224  loss: 3.3228 (3.3228)  weight_decay: 0.0500 (0.0500)  time: 3.7800  data: 2.9653  max mem: 62457
Epoch: [150]  [ 200/1251]  eta: 0:14:35  lr: 0.002221  min_lr: 0.002221  loss: 3.2737 (3.1858)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7560 (0.8693)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [150]  [ 400/1251]  eta: 0:11:41  lr: 0.002217  min_lr: 0.002217  loss: 3.1837 (3.1414)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7822 (0.9558)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [150]  [ 600/1251]  eta: 0:08:54  lr: 0.002214  min_lr: 0.002214  loss: 3.2698 (3.1299)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6333 (0.9261)  time: 0.8193  data: 0.0004  max mem: 62457
Epoch: [150]  [ 800/1251]  eta: 0:06:09  lr: 0.002210  min_lr: 0.002210  loss: 3.2807 (3.1209)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9753 (0.9306)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [150]  [1000/1251]  eta: 0:03:25  lr: 0.002207  min_lr: 0.002207  loss: 3.2387 (3.1201)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1705 (0.9513)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [150]  [1200/1251]  eta: 0:00:41  lr: 0.002203  min_lr: 0.002203  loss: 3.2387 (3.1251)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6716 (0.9202)  time: 0.8190  data: 0.0004  max mem: 62457
Epoch: [150]  [1250/1251]  eta: 0:00:00  lr: 0.002202  min_lr: 0.002202  loss: 3.3215 (3.1207)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6753 (0.9187)  time: 0.6952  data: 0.0006  max mem: 62457
Epoch: [150] Total time: 0:17:02 (0.8171 s / it)
Averaged stats: lr: 0.002202  min_lr: 0.002202  loss: 3.3215 (3.1243)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6753 (0.9187)
Test:  [ 0/25]  eta: 0:02:26  loss: 0.6881 (0.6881)  acc1: 89.6000 (89.6000)  acc5: 97.6000 (97.6000)  time: 5.8752  data: 5.3743  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8525 (0.8345)  acc1: 86.8000 (84.6909)  acc5: 97.6000 (97.2364)  time: 1.0773  data: 0.6283  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0082 (0.9572)  acc1: 78.4000 (81.5429)  acc5: 96.0000 (95.9429)  time: 0.5207  data: 0.0769  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0446 (0.9681)  acc1: 78.4000 (81.2320)  acc5: 95.6000 (95.8880)  time: 0.4439  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7268 s / it)
* Acc@1 81.400 Acc@5 96.020 loss 0.957
Accuracy of the model on the 50000 test images: 81.4%
Max accuracy: 81.66%
Epoch: [151]  [   0/1251]  eta: 1:25:44  lr: 0.002202  min_lr: 0.002202  loss: 3.7293 (3.7293)  weight_decay: 0.0500 (0.0500)  time: 4.1125  data: 3.0543  max mem: 62457
Epoch: [151]  [ 200/1251]  eta: 0:14:34  lr: 0.002198  min_lr: 0.002198  loss: 3.2356 (3.1346)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8139 (1.0004)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [151]  [ 400/1251]  eta: 0:11:41  lr: 0.002195  min_lr: 0.002195  loss: 3.2408 (3.1162)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8069 (0.9973)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [151]  [ 600/1251]  eta: 0:08:54  lr: 0.002191  min_lr: 0.002191  loss: 3.1542 (3.1209)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0390 (0.9932)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [151]  [ 800/1251]  eta: 0:06:09  lr: 0.002188  min_lr: 0.002188  loss: 2.8989 (3.1201)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9794 (0.9764)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [151]  [1000/1251]  eta: 0:03:25  lr: 0.002184  min_lr: 0.002184  loss: 3.0980 (3.1195)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7256 (0.9433)  time: 0.8142  data: 0.0004  max mem: 62457
Epoch: [151]  [1200/1251]  eta: 0:00:41  lr: 0.002181  min_lr: 0.002181  loss: 3.1702 (3.1147)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8680 (0.9261)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [151]  [1250/1251]  eta: 0:00:00  lr: 0.002180  min_lr: 0.002180  loss: 3.2612 (3.1171)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7579 (0.9216)  time: 0.6920  data: 0.0008  max mem: 62457
Epoch: [151] Total time: 0:17:02 (0.8172 s / it)
Averaged stats: lr: 0.002180  min_lr: 0.002180  loss: 3.2612 (3.1151)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7579 (0.9216)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.7206 (0.7206)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 7.7268  data: 7.2402  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8989 (0.9131)  acc1: 86.0000 (84.4364)  acc5: 98.0000 (97.3818)  time: 1.1073  data: 0.6585  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.1193 (1.0306)  acc1: 78.8000 (80.9143)  acc5: 95.2000 (95.9238)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1193 (1.0378)  acc1: 78.8000 (80.6080)  acc5: 95.2000 (95.8720)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7403 s / it)
* Acc@1 81.158 Acc@5 95.962 loss 1.022
Accuracy of the model on the 50000 test images: 81.2%
Max accuracy: 81.66%
Epoch: [152]  [   0/1251]  eta: 1:41:59  lr: 0.002180  min_lr: 0.002180  loss: 2.6485 (2.6485)  weight_decay: 0.0500 (0.0500)  time: 4.8915  data: 2.6903  max mem: 62457
Epoch: [152]  [ 200/1251]  eta: 0:14:38  lr: 0.002176  min_lr: 0.002176  loss: 3.0847 (3.1170)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8123 (nan)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [152]  [ 400/1251]  eta: 0:11:43  lr: 0.002173  min_lr: 0.002173  loss: 3.4122 (3.1211)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8502 (nan)  time: 0.8217  data: 0.0004  max mem: 62457
Epoch: [152]  [ 600/1251]  eta: 0:08:55  lr: 0.002169  min_lr: 0.002169  loss: 3.0287 (3.1123)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9514 (nan)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [152]  [ 800/1251]  eta: 0:06:10  lr: 0.002165  min_lr: 0.002165  loss: 3.3118 (3.1038)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7695 (nan)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [152]  [1000/1251]  eta: 0:03:25  lr: 0.002162  min_lr: 0.002162  loss: 3.2863 (3.1009)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9455 (nan)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [152]  [1200/1251]  eta: 0:00:41  lr: 0.002158  min_lr: 0.002158  loss: 3.2592 (3.0903)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7952 (nan)  time: 0.8151  data: 0.0005  max mem: 62457
Epoch: [152]  [1250/1251]  eta: 0:00:00  lr: 0.002157  min_lr: 0.002157  loss: 3.4093 (3.0931)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9937 (nan)  time: 0.6922  data: 0.0007  max mem: 62457
Epoch: [152] Total time: 0:17:03 (0.8179 s / it)
Averaged stats: lr: 0.002157  min_lr: 0.002157  loss: 3.4093 (3.1049)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9937 (nan)
Test:  [ 0/25]  eta: 0:03:07  loss: 0.7246 (0.7246)  acc1: 87.2000 (87.2000)  acc5: 98.4000 (98.4000)  time: 7.5054  data: 6.9975  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8604 (0.8767)  acc1: 84.0000 (84.0364)  acc5: 97.6000 (97.5273)  time: 1.0873  data: 0.6364  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0633 (0.9885)  acc1: 80.0000 (81.1619)  acc5: 95.6000 (96.1333)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0633 (0.9953)  acc1: 80.0000 (80.8960)  acc5: 95.2000 (96.0000)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7320 s / it)
* Acc@1 81.444 Acc@5 96.054 loss 0.983
Accuracy of the model on the 50000 test images: 81.4%
Max accuracy: 81.66%
Epoch: [153]  [   0/1251]  eta: 1:30:11  lr: 0.002157  min_lr: 0.002157  loss: 2.3241 (2.3241)  weight_decay: 0.0500 (0.0500)  time: 4.3261  data: 2.3147  max mem: 62457
Epoch: [153]  [ 200/1251]  eta: 0:14:36  lr: 0.002154  min_lr: 0.002154  loss: 3.1997 (3.0896)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8120 (0.9168)  time: 0.8236  data: 0.0004  max mem: 62457
Epoch: [153]  [ 400/1251]  eta: 0:11:42  lr: 0.002150  min_lr: 0.002150  loss: 3.3460 (3.1070)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9228 (1.0119)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [153]  [ 600/1251]  eta: 0:08:55  lr: 0.002147  min_lr: 0.002147  loss: 3.0335 (3.1006)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8023 (0.9883)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [153]  [ 800/1251]  eta: 0:06:10  lr: 0.002143  min_lr: 0.002143  loss: 3.2092 (3.0946)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8851 (0.9661)  time: 0.8164  data: 0.0004  max mem: 62457
Epoch: [153]  [1000/1251]  eta: 0:03:25  lr: 0.002139  min_lr: 0.002139  loss: 3.0913 (3.0936)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7850 (0.9395)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [153]  [1200/1251]  eta: 0:00:41  lr: 0.002136  min_lr: 0.002136  loss: 3.3658 (3.0965)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7870 (0.9443)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [153]  [1250/1251]  eta: 0:00:00  lr: 0.002135  min_lr: 0.002135  loss: 3.3188 (3.0953)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7812 (0.9401)  time: 0.6926  data: 0.0007  max mem: 62457
Epoch: [153] Total time: 0:17:03 (0.8181 s / it)
Averaged stats: lr: 0.002135  min_lr: 0.002135  loss: 3.3188 (3.1027)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7812 (0.9401)
Test:  [ 0/25]  eta: 0:02:50  loss: 0.7347 (0.7347)  acc1: 86.4000 (86.4000)  acc5: 99.6000 (99.6000)  time: 6.8327  data: 6.3658  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8463 (0.8350)  acc1: 84.0000 (84.6182)  acc5: 97.6000 (97.6000)  time: 1.0741  data: 0.6270  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9958 (0.9599)  acc1: 79.2000 (81.3333)  acc5: 96.0000 (96.2857)  time: 0.4716  data: 0.0266  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0531 (0.9717)  acc1: 79.2000 (81.1520)  acc5: 95.6000 (96.1760)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7269 s / it)
* Acc@1 81.606 Acc@5 96.084 loss 0.963
Accuracy of the model on the 50000 test images: 81.6%
Max accuracy: 81.66%
Epoch: [154]  [   0/1251]  eta: 1:44:01  lr: 0.002135  min_lr: 0.002135  loss: 2.1577 (2.1577)  weight_decay: 0.0500 (0.0500)  time: 4.9889  data: 3.0624  max mem: 62457
Epoch: [154]  [ 200/1251]  eta: 0:14:41  lr: 0.002131  min_lr: 0.002131  loss: 3.0874 (3.0799)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8162  data: 0.0004  max mem: 62457
Epoch: [154]  [ 400/1251]  eta: 0:11:44  lr: 0.002128  min_lr: 0.002128  loss: 3.1022 (3.0887)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7595 (nan)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [154]  [ 600/1251]  eta: 0:08:56  lr: 0.002124  min_lr: 0.002124  loss: 3.2713 (3.0878)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9700 (nan)  time: 0.8199  data: 0.0004  max mem: 62457
Epoch: [154]  [ 800/1251]  eta: 0:06:10  lr: 0.002121  min_lr: 0.002121  loss: 3.1231 (3.0867)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9505 (nan)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [154]  [1000/1251]  eta: 0:03:26  lr: 0.002117  min_lr: 0.002117  loss: 3.3244 (3.0965)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0030 (nan)  time: 0.8155  data: 0.0005  max mem: 62457
Epoch: [154]  [1200/1251]  eta: 0:00:41  lr: 0.002113  min_lr: 0.002113  loss: 3.1081 (3.1037)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7824 (nan)  time: 0.8159  data: 0.0005  max mem: 62457
Epoch: [154]  [1250/1251]  eta: 0:00:00  lr: 0.002113  min_lr: 0.002113  loss: 3.0116 (3.1037)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9484 (nan)  time: 0.6925  data: 0.0007  max mem: 62457
Epoch: [154] Total time: 0:17:04 (0.8191 s / it)
Averaged stats: lr: 0.002113  min_lr: 0.002113  loss: 3.0116 (3.1036)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9484 (nan)
Test:  [ 0/25]  eta: 0:03:17  loss: 0.6275 (0.6275)  acc1: 90.8000 (90.8000)  acc5: 99.2000 (99.2000)  time: 7.8890  data: 7.4214  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7781 (0.7731)  acc1: 84.0000 (84.6909)  acc5: 98.0000 (97.9273)  time: 1.1220  data: 0.6750  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9017 (0.9017)  acc1: 79.6000 (81.7333)  acc5: 96.0000 (96.4571)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0127 (0.9158)  acc1: 79.6000 (81.4240)  acc5: 95.6000 (96.3040)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7475 s / it)
* Acc@1 81.520 Acc@5 96.162 loss 0.910
Accuracy of the model on the 50000 test images: 81.5%
Max accuracy: 81.66%
Epoch: [155]  [   0/1251]  eta: 1:40:49  lr: 0.002113  min_lr: 0.002113  loss: 3.3901 (3.3901)  weight_decay: 0.0500 (0.0500)  time: 4.8359  data: 2.7896  max mem: 62457
Epoch: [155]  [ 200/1251]  eta: 0:14:39  lr: 0.002109  min_lr: 0.002109  loss: 3.2307 (3.0850)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8551 (0.9793)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [155]  [ 400/1251]  eta: 0:11:42  lr: 0.002105  min_lr: 0.002105  loss: 3.1911 (3.0847)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9757 (0.9652)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [155]  [ 600/1251]  eta: 0:08:56  lr: 0.002102  min_lr: 0.002102  loss: 3.2156 (3.0689)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0107 (0.9541)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [155]  [ 800/1251]  eta: 0:06:10  lr: 0.002098  min_lr: 0.002098  loss: 3.2584 (3.0847)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8633 (0.9250)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [155]  [1000/1251]  eta: 0:03:25  lr: 0.002095  min_lr: 0.002095  loss: 3.0675 (3.0894)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9016 (0.9458)  time: 0.8193  data: 0.0004  max mem: 62457
Epoch: [155]  [1200/1251]  eta: 0:00:41  lr: 0.002091  min_lr: 0.002091  loss: 2.8099 (3.0932)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8307 (0.9567)  time: 0.8201  data: 0.0004  max mem: 62457
Epoch: [155]  [1250/1251]  eta: 0:00:00  lr: 0.002090  min_lr: 0.002090  loss: 2.8285 (3.0906)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9894 (0.9655)  time: 0.6923  data: 0.0005  max mem: 62457
Epoch: [155] Total time: 0:17:03 (0.8184 s / it)
Averaged stats: lr: 0.002090  min_lr: 0.002090  loss: 2.8285 (3.0908)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9894 (0.9655)
Test:  [ 0/25]  eta: 0:03:20  loss: 0.6383 (0.6383)  acc1: 87.2000 (87.2000)  acc5: 98.4000 (98.4000)  time: 8.0047  data: 7.5159  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7884 (0.7752)  acc1: 86.0000 (84.7273)  acc5: 98.0000 (97.7091)  time: 1.1316  data: 0.6835  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.8980 (0.8926)  acc1: 80.0000 (82.0571)  acc5: 96.0000 (96.2857)  time: 0.4443  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9497 (0.9021)  acc1: 79.6000 (81.6640)  acc5: 95.2000 (96.0800)  time: 0.4443  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7530 s / it)
* Acc@1 81.830 Acc@5 96.166 loss 0.893
Accuracy of the model on the 50000 test images: 81.8%
Max accuracy: 81.83%
Epoch: [156]  [   0/1251]  eta: 1:30:04  lr: 0.002090  min_lr: 0.002090  loss: 2.8983 (2.8983)  weight_decay: 0.0500 (0.0500)  time: 4.3202  data: 3.5023  max mem: 62457
Epoch: [156]  [ 200/1251]  eta: 0:14:35  lr: 0.002087  min_lr: 0.002087  loss: 3.2673 (3.0364)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8195 (0.8770)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [156]  [ 400/1251]  eta: 0:11:42  lr: 0.002083  min_lr: 0.002083  loss: 3.0353 (3.0382)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9285 (0.9899)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [156]  [ 600/1251]  eta: 0:08:55  lr: 0.002079  min_lr: 0.002079  loss: 3.1894 (3.0551)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7909 (0.9518)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [156]  [ 800/1251]  eta: 0:06:10  lr: 0.002076  min_lr: 0.002076  loss: 3.0922 (3.0605)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0972 (1.0040)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [156]  [1000/1251]  eta: 0:03:25  lr: 0.002072  min_lr: 0.002072  loss: 3.0516 (3.0710)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7395 (0.9660)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [156]  [1200/1251]  eta: 0:00:41  lr: 0.002069  min_lr: 0.002069  loss: 3.1193 (3.0792)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8292 (0.9624)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [156]  [1250/1251]  eta: 0:00:00  lr: 0.002068  min_lr: 0.002068  loss: 3.0828 (3.0742)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0386 (0.9740)  time: 0.6929  data: 0.0006  max mem: 62457
Epoch: [156] Total time: 0:17:03 (0.8178 s / it)
Averaged stats: lr: 0.002068  min_lr: 0.002068  loss: 3.0828 (3.0997)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0386 (0.9740)
Test:  [ 0/25]  eta: 0:03:29  loss: 0.6753 (0.6753)  acc1: 87.6000 (87.6000)  acc5: 97.2000 (97.2000)  time: 8.3848  data: 7.9140  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8004 (0.7829)  acc1: 83.6000 (83.6364)  acc5: 97.2000 (97.2000)  time: 1.1662  data: 0.7197  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9070 (0.8994)  acc1: 80.4000 (80.9714)  acc5: 95.6000 (95.9238)  time: 0.4444  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9225 (0.9074)  acc1: 80.8000 (80.9760)  acc5: 95.2000 (95.8560)  time: 0.4443  data: 0.0001  max mem: 62457
Test: Total time: 0:00:19 (0.7660 s / it)
* Acc@1 81.612 Acc@5 96.126 loss 0.892
Accuracy of the model on the 50000 test images: 81.6%
Max accuracy: 81.83%
Epoch: [157]  [   0/1251]  eta: 1:47:51  lr: 0.002068  min_lr: 0.002068  loss: 3.3084 (3.3084)  weight_decay: 0.0500 (0.0500)  time: 5.1727  data: 3.2041  max mem: 62457
Epoch: [157]  [ 200/1251]  eta: 0:14:42  lr: 0.002064  min_lr: 0.002064  loss: 3.2069 (3.1390)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6889 (0.8474)  time: 0.8216  data: 0.0004  max mem: 62457
Epoch: [157]  [ 400/1251]  eta: 0:11:44  lr: 0.002061  min_lr: 0.002061  loss: 3.2066 (3.1391)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7951 (0.8782)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [157]  [ 600/1251]  eta: 0:08:56  lr: 0.002057  min_lr: 0.002057  loss: 3.2889 (3.1447)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9467 (0.9119)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [157]  [ 800/1251]  eta: 0:06:11  lr: 0.002053  min_lr: 0.002053  loss: 2.9514 (3.1288)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0287 (0.9513)  time: 0.8206  data: 0.0004  max mem: 62457
Epoch: [157]  [1000/1251]  eta: 0:03:26  lr: 0.002050  min_lr: 0.002050  loss: 3.1641 (3.1191)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8774 (0.9426)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [157]  [1200/1251]  eta: 0:00:41  lr: 0.002046  min_lr: 0.002046  loss: 3.3067 (3.1183)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8004 (0.9508)  time: 0.8162  data: 0.0005  max mem: 62457
Epoch: [157]  [1250/1251]  eta: 0:00:00  lr: 0.002045  min_lr: 0.002045  loss: 3.2179 (3.1190)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8548 (0.9564)  time: 0.6925  data: 0.0006  max mem: 62457
Epoch: [157] Total time: 0:17:04 (0.8192 s / it)
Averaged stats: lr: 0.002045  min_lr: 0.002045  loss: 3.2179 (3.1051)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8548 (0.9564)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.7465 (0.7465)  acc1: 86.0000 (86.0000)  acc5: 98.4000 (98.4000)  time: 7.8234  data: 7.3430  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9368 (0.8836)  acc1: 85.2000 (83.7818)  acc5: 97.6000 (97.3818)  time: 1.1158  data: 0.6678  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0013 (1.0045)  acc1: 79.6000 (81.1619)  acc5: 95.6000 (95.9619)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0937 (1.0140)  acc1: 79.6000 (80.9280)  acc5: 95.2000 (95.8560)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7443 s / it)
* Acc@1 81.412 Acc@5 96.008 loss 1.003
Accuracy of the model on the 50000 test images: 81.4%
Max accuracy: 81.83%
Epoch: [158]  [   0/1251]  eta: 1:39:38  lr: 0.002045  min_lr: 0.002045  loss: 3.4234 (3.4234)  weight_decay: 0.0500 (0.0500)  time: 4.7790  data: 3.9475  max mem: 62457
Epoch: [158]  [ 200/1251]  eta: 0:14:41  lr: 0.002042  min_lr: 0.002042  loss: 2.9045 (3.0557)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7227 (0.8760)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [158]  [ 400/1251]  eta: 0:11:43  lr: 0.002038  min_lr: 0.002038  loss: 3.2648 (3.0909)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1085 (0.9751)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [158]  [ 600/1251]  eta: 0:08:56  lr: 0.002035  min_lr: 0.002035  loss: 3.1784 (3.0729)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8962 (0.9872)  time: 0.8232  data: 0.0004  max mem: 62457
Epoch: [158]  [ 800/1251]  eta: 0:06:10  lr: 0.002031  min_lr: 0.002031  loss: 2.8500 (3.0776)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6456 (0.9656)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [158]  [1000/1251]  eta: 0:03:26  lr: 0.002027  min_lr: 0.002027  loss: 3.4253 (3.0819)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0059 (0.9688)  time: 0.8213  data: 0.0004  max mem: 62457
Epoch: [158]  [1200/1251]  eta: 0:00:41  lr: 0.002024  min_lr: 0.002024  loss: 3.3204 (3.0878)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9987 (1.0015)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [158]  [1250/1251]  eta: 0:00:00  lr: 0.002023  min_lr: 0.002023  loss: 3.1584 (3.0885)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8514 (0.9960)  time: 0.6923  data: 0.0005  max mem: 62457
Epoch: [158] Total time: 0:17:04 (0.8189 s / it)
Averaged stats: lr: 0.002023  min_lr: 0.002023  loss: 3.1584 (3.0872)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8514 (0.9960)
Test:  [ 0/25]  eta: 0:03:05  loss: 0.7149 (0.7149)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 7.4240  data: 6.9398  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.9071 (0.8848)  acc1: 84.4000 (84.3636)  acc5: 97.6000 (97.3818)  time: 1.0788  data: 0.6312  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0461 (1.0056)  acc1: 80.0000 (81.5238)  acc5: 95.2000 (96.0381)  time: 0.4440  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.1040 (1.0175)  acc1: 80.0000 (81.2160)  acc5: 95.2000 (95.8880)  time: 0.4439  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7277 s / it)
* Acc@1 81.554 Acc@5 96.000 loss 1.005
Accuracy of the model on the 50000 test images: 81.6%
Max accuracy: 81.83%
Epoch: [159]  [   0/1251]  eta: 1:40:51  lr: 0.002023  min_lr: 0.002023  loss: 2.6534 (2.6534)  weight_decay: 0.0500 (0.0500)  time: 4.8375  data: 3.1136  max mem: 62457
Epoch: [159]  [ 200/1251]  eta: 0:14:38  lr: 0.002019  min_lr: 0.002019  loss: 3.2608 (3.0707)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7586 (0.9683)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [159]  [ 400/1251]  eta: 0:11:42  lr: 0.002016  min_lr: 0.002016  loss: 2.9832 (3.0666)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9961 (0.9155)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [159]  [ 600/1251]  eta: 0:08:56  lr: 0.002012  min_lr: 0.002012  loss: 2.7459 (3.0643)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8727 (0.9427)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [159]  [ 800/1251]  eta: 0:06:10  lr: 0.002009  min_lr: 0.002009  loss: 3.3208 (3.0674)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8138 (0.9117)  time: 0.8204  data: 0.0004  max mem: 62457
Epoch: [159]  [1000/1251]  eta: 0:03:25  lr: 0.002005  min_lr: 0.002005  loss: 3.2985 (3.0689)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0483 (0.9270)  time: 0.8164  data: 0.0004  max mem: 62457
Epoch: [159]  [1200/1251]  eta: 0:00:41  lr: 0.002001  min_lr: 0.002001  loss: 3.1331 (3.0698)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8206 (0.9350)  time: 0.8164  data: 0.0004  max mem: 62457
Epoch: [159]  [1250/1251]  eta: 0:00:00  lr: 0.002001  min_lr: 0.002001  loss: 3.3434 (3.0726)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8881 (0.9364)  time: 0.6931  data: 0.0005  max mem: 62457
Epoch: [159] Total time: 0:17:04 (0.8186 s / it)
Averaged stats: lr: 0.002001  min_lr: 0.002001  loss: 3.3434 (3.0818)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8881 (0.9364)
Test:  [ 0/25]  eta: 0:02:31  loss: 0.6428 (0.6428)  acc1: 89.2000 (89.2000)  acc5: 98.4000 (98.4000)  time: 6.0458  data: 5.5303  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8407 (0.8118)  acc1: 86.4000 (84.1818)  acc5: 98.0000 (97.6000)  time: 1.0789  data: 0.6273  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9320 (0.9483)  acc1: 78.4000 (81.1238)  acc5: 96.0000 (96.1714)  time: 0.5137  data: 0.0685  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0291 (0.9603)  acc1: 78.4000 (80.7840)  acc5: 95.6000 (96.0960)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7291 s / it)
* Acc@1 81.506 Acc@5 96.038 loss 0.956
Accuracy of the model on the 50000 test images: 81.5%
Max accuracy: 81.83%
Epoch: [160]  [   0/1251]  eta: 1:42:23  lr: 0.002001  min_lr: 0.002001  loss: 3.0358 (3.0358)  weight_decay: 0.0500 (0.0500)  time: 4.9110  data: 3.2786  max mem: 62457
Epoch: [160]  [ 200/1251]  eta: 0:14:40  lr: 0.001997  min_lr: 0.001997  loss: 3.1332 (3.0533)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7939 (0.8822)  time: 0.8166  data: 0.0005  max mem: 62457
Epoch: [160]  [ 400/1251]  eta: 0:11:44  lr: 0.001993  min_lr: 0.001993  loss: 3.0262 (3.0863)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0248 (0.9584)  time: 0.8161  data: 0.0005  max mem: 62457
Epoch: [160]  [ 600/1251]  eta: 0:08:56  lr: 0.001990  min_lr: 0.001990  loss: 3.1085 (3.0845)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9283 (0.9576)  time: 0.8234  data: 0.0005  max mem: 62457
Epoch: [160]  [ 800/1251]  eta: 0:06:10  lr: 0.001986  min_lr: 0.001986  loss: 3.1674 (3.0910)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7754 (1.0072)  time: 0.8152  data: 0.0005  max mem: 62457
Epoch: [160]  [1000/1251]  eta: 0:03:26  lr: 0.001983  min_lr: 0.001983  loss: 3.3658 (3.1081)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7687 (0.9811)  time: 0.8156  data: 0.0005  max mem: 62457
Epoch: [160]  [1200/1251]  eta: 0:00:41  lr: 0.001979  min_lr: 0.001979  loss: 3.0511 (3.1025)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7809 (0.9581)  time: 0.8154  data: 0.0005  max mem: 62457
Epoch: [160]  [1250/1251]  eta: 0:00:00  lr: 0.001978  min_lr: 0.001978  loss: 3.3014 (3.1031)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7809 (0.9521)  time: 0.6927  data: 0.0007  max mem: 62457
Epoch: [160] Total time: 0:17:04 (0.8188 s / it)
Averaged stats: lr: 0.001978  min_lr: 0.001978  loss: 3.3014 (3.0798)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7809 (0.9521)
Test:  [ 0/25]  eta: 0:02:52  loss: 0.6290 (0.6290)  acc1: 87.6000 (87.6000)  acc5: 99.2000 (99.2000)  time: 6.8814  data: 6.4031  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8407 (0.7951)  acc1: 84.4000 (84.6182)  acc5: 97.6000 (97.4182)  time: 1.0345  data: 0.5876  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8999 (0.9263)  acc1: 80.0000 (81.7714)  acc5: 95.6000 (96.0762)  time: 0.4470  data: 0.0030  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0152 (0.9367)  acc1: 79.2000 (81.4560)  acc5: 95.2000 (96.0160)  time: 0.4441  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7079 s / it)
* Acc@1 81.768 Acc@5 96.170 loss 0.926
Accuracy of the model on the 50000 test images: 81.8%
Max accuracy: 81.83%
Epoch: [161]  [   0/1251]  eta: 1:42:55  lr: 0.001978  min_lr: 0.001978  loss: 3.3044 (3.3044)  weight_decay: 0.0500 (0.0500)  time: 4.9366  data: 3.0916  max mem: 62457
Epoch: [161]  [ 200/1251]  eta: 0:14:39  lr: 0.001974  min_lr: 0.001974  loss: 3.0653 (2.9748)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7657 (1.0194)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [161]  [ 400/1251]  eta: 0:11:43  lr: 0.001971  min_lr: 0.001971  loss: 3.2804 (3.0494)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7385 (0.9574)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [161]  [ 600/1251]  eta: 0:08:55  lr: 0.001967  min_lr: 0.001967  loss: 3.2000 (3.0833)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8148 (1.0150)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [161]  [ 800/1251]  eta: 0:06:10  lr: 0.001964  min_lr: 0.001964  loss: 3.0827 (3.0726)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8211  data: 0.0005  max mem: 62457
Epoch: [161]  [1000/1251]  eta: 0:03:25  lr: 0.001960  min_lr: 0.001960  loss: 3.1655 (3.0561)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0297 (nan)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [161]  [1200/1251]  eta: 0:00:41  lr: 0.001956  min_lr: 0.001956  loss: 3.1533 (3.0608)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1059 (nan)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [161]  [1250/1251]  eta: 0:00:00  lr: 0.001956  min_lr: 0.001956  loss: 3.3407 (3.0606)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9416 (nan)  time: 0.6926  data: 0.0005  max mem: 62457
Epoch: [161] Total time: 0:17:03 (0.8181 s / it)
Averaged stats: lr: 0.001956  min_lr: 0.001956  loss: 3.3407 (3.0710)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9416 (nan)
Test:  [ 0/25]  eta: 0:03:23  loss: 0.6528 (0.6528)  acc1: 87.2000 (87.2000)  acc5: 99.6000 (99.6000)  time: 8.1262  data: 7.6580  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8000 (0.8009)  acc1: 84.8000 (84.2545)  acc5: 98.0000 (97.5636)  time: 1.1436  data: 0.6964  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9418 (0.9211)  acc1: 80.4000 (81.4476)  acc5: 96.0000 (96.2857)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9852 (0.9290)  acc1: 80.4000 (81.2160)  acc5: 95.6000 (96.1440)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7572 s / it)
* Acc@1 81.696 Acc@5 96.154 loss 0.929
Accuracy of the model on the 50000 test images: 81.7%
Max accuracy: 81.83%
Epoch: [162]  [   0/1251]  eta: 1:41:42  lr: 0.001956  min_lr: 0.001956  loss: 2.5184 (2.5184)  weight_decay: 0.0500 (0.0500)  time: 4.8784  data: 2.9238  max mem: 62457
Epoch: [162]  [ 200/1251]  eta: 0:14:41  lr: 0.001952  min_lr: 0.001952  loss: 3.3386 (3.0935)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8163  data: 0.0004  max mem: 62457
Epoch: [162]  [ 400/1251]  eta: 0:11:44  lr: 0.001948  min_lr: 0.001948  loss: 3.1213 (3.0744)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7886 (nan)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [162]  [ 600/1251]  eta: 0:08:56  lr: 0.001945  min_lr: 0.001945  loss: 3.1062 (3.0525)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9380 (nan)  time: 0.8220  data: 0.0004  max mem: 62457
Epoch: [162]  [ 800/1251]  eta: 0:06:11  lr: 0.001941  min_lr: 0.001941  loss: 3.1566 (3.0561)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7915 (nan)  time: 0.8166  data: 0.0004  max mem: 62457
Epoch: [162]  [1000/1251]  eta: 0:03:26  lr: 0.001938  min_lr: 0.001938  loss: 3.0576 (3.0605)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8365 (nan)  time: 0.8169  data: 0.0004  max mem: 62457
Epoch: [162]  [1200/1251]  eta: 0:00:41  lr: 0.001934  min_lr: 0.001934  loss: 3.1513 (3.0649)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8010 (nan)  time: 0.8220  data: 0.0005  max mem: 62457
Epoch: [162]  [1250/1251]  eta: 0:00:00  lr: 0.001933  min_lr: 0.001933  loss: 3.2259 (3.0692)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8284 (nan)  time: 0.6935  data: 0.0005  max mem: 62457
Epoch: [162] Total time: 0:17:05 (0.8196 s / it)
Averaged stats: lr: 0.001933  min_lr: 0.001933  loss: 3.2259 (3.0764)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8284 (nan)
Test:  [ 0/25]  eta: 0:03:06  loss: 0.6235 (0.6235)  acc1: 88.4000 (88.4000)  acc5: 99.2000 (99.2000)  time: 7.4768  data: 7.0000  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7987 (0.7774)  acc1: 85.2000 (85.0182)  acc5: 97.2000 (97.4182)  time: 1.0838  data: 0.6366  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9040 (0.9083)  acc1: 81.2000 (82.0000)  acc5: 96.0000 (96.2286)  time: 0.4445  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9949 (0.9223)  acc1: 80.4000 (81.4400)  acc5: 96.0000 (96.2400)  time: 0.4445  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7297 s / it)
* Acc@1 81.930 Acc@5 96.158 loss 0.907
Accuracy of the model on the 50000 test images: 81.9%
Max accuracy: 81.93%
Epoch: [163]  [   0/1251]  eta: 1:39:00  lr: 0.001933  min_lr: 0.001933  loss: 2.2041 (2.2041)  weight_decay: 0.0500 (0.0500)  time: 4.7483  data: 3.9217  max mem: 62457
Epoch: [163]  [ 200/1251]  eta: 0:14:38  lr: 0.001930  min_lr: 0.001930  loss: 3.2109 (3.0396)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0575 (0.9742)  time: 0.8170  data: 0.0005  max mem: 62457
Epoch: [163]  [ 400/1251]  eta: 0:11:43  lr: 0.001926  min_lr: 0.001926  loss: 3.1855 (3.0512)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7343 (0.9732)  time: 0.8229  data: 0.0004  max mem: 62457
Epoch: [163]  [ 600/1251]  eta: 0:08:56  lr: 0.001922  min_lr: 0.001922  loss: 3.3293 (3.0536)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1427 (0.9990)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [163]  [ 800/1251]  eta: 0:06:10  lr: 0.001919  min_lr: 0.001919  loss: 3.1531 (3.0482)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9806 (0.9822)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [163]  [1000/1251]  eta: 0:03:26  lr: 0.001915  min_lr: 0.001915  loss: 3.1581 (3.0446)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0465 (0.9651)  time: 0.8162  data: 0.0004  max mem: 62457
Epoch: [163]  [1200/1251]  eta: 0:00:41  lr: 0.001912  min_lr: 0.001912  loss: 3.1587 (3.0480)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8563 (0.9724)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [163]  [1250/1251]  eta: 0:00:00  lr: 0.001911  min_lr: 0.001911  loss: 2.9800 (3.0449)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8382 (0.9726)  time: 0.6934  data: 0.0005  max mem: 62457
Epoch: [163] Total time: 0:17:04 (0.8189 s / it)
Averaged stats: lr: 0.001911  min_lr: 0.001911  loss: 2.9800 (3.0655)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8382 (0.9726)
Test:  [ 0/25]  eta: 0:03:19  loss: 0.6439 (0.6439)  acc1: 88.8000 (88.8000)  acc5: 99.2000 (99.2000)  time: 7.9967  data: 7.5188  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7978 (0.7823)  acc1: 83.6000 (84.4364)  acc5: 97.2000 (97.5636)  time: 1.1315  data: 0.6838  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9084 (0.9052)  acc1: 79.6000 (81.5048)  acc5: 96.4000 (96.4000)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9864 (0.9138)  acc1: 79.6000 (81.2640)  acc5: 96.0000 (96.2880)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7510 s / it)
* Acc@1 81.710 Acc@5 96.196 loss 0.907
Accuracy of the model on the 50000 test images: 81.7%
Max accuracy: 81.93%
Epoch: [164]  [   0/1251]  eta: 1:44:59  lr: 0.001911  min_lr: 0.001911  loss: 2.9928 (2.9928)  weight_decay: 0.0500 (0.0500)  time: 5.0355  data: 3.7228  max mem: 62457
Epoch: [164]  [ 200/1251]  eta: 0:14:41  lr: 0.001907  min_lr: 0.001907  loss: 3.1459 (3.0173)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9265 (1.0391)  time: 0.8238  data: 0.0004  max mem: 62457
Epoch: [164]  [ 400/1251]  eta: 0:11:45  lr: 0.001904  min_lr: 0.001904  loss: 3.1885 (3.0329)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8698 (1.0209)  time: 0.8164  data: 0.0004  max mem: 62457
Epoch: [164]  [ 600/1251]  eta: 0:08:56  lr: 0.001900  min_lr: 0.001900  loss: 3.1751 (3.0450)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8178 (1.0077)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [164]  [ 800/1251]  eta: 0:06:11  lr: 0.001896  min_lr: 0.001896  loss: 3.3024 (3.0404)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7532 (1.0220)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [164]  [1000/1251]  eta: 0:03:26  lr: 0.001893  min_lr: 0.001893  loss: 3.0619 (3.0462)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8452 (1.0233)  time: 0.8161  data: 0.0005  max mem: 62457
Epoch: [164]  [1200/1251]  eta: 0:00:41  lr: 0.001889  min_lr: 0.001889  loss: 3.3095 (3.0534)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9607 (1.0143)  time: 0.8174  data: 0.0004  max mem: 62457
Epoch: [164]  [1250/1251]  eta: 0:00:00  lr: 0.001888  min_lr: 0.001888  loss: 3.1249 (3.0532)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8917 (1.0062)  time: 0.6935  data: 0.0006  max mem: 62457
Epoch: [164] Total time: 0:17:05 (0.8196 s / it)
Averaged stats: lr: 0.001888  min_lr: 0.001888  loss: 3.1249 (3.0640)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8917 (1.0062)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.6511 (0.6511)  acc1: 88.4000 (88.4000)  acc5: 99.6000 (99.6000)  time: 7.7488  data: 7.2682  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8548 (0.8385)  acc1: 84.4000 (84.0000)  acc5: 97.6000 (97.3455)  time: 1.1092  data: 0.6610  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9658 (0.9528)  acc1: 80.8000 (81.6571)  acc5: 96.4000 (96.3048)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9990 (0.9610)  acc1: 79.2000 (81.3440)  acc5: 96.0000 (96.2080)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7418 s / it)
* Acc@1 81.852 Acc@5 96.286 loss 0.945
Accuracy of the model on the 50000 test images: 81.9%
Max accuracy: 81.93%
Epoch: [165]  [   0/1251]  eta: 1:26:32  lr: 0.001888  min_lr: 0.001888  loss: 2.0544 (2.0544)  weight_decay: 0.0500 (0.0500)  time: 4.1507  data: 3.0730  max mem: 62457
Epoch: [165]  [ 200/1251]  eta: 0:14:38  lr: 0.001885  min_lr: 0.001885  loss: 3.2482 (3.0223)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7780 (1.1431)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [165]  [ 400/1251]  eta: 0:11:43  lr: 0.001881  min_lr: 0.001881  loss: 3.1824 (3.0606)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8585 (1.0411)  time: 0.8166  data: 0.0004  max mem: 62457
Epoch: [165]  [ 600/1251]  eta: 0:08:56  lr: 0.001878  min_lr: 0.001878  loss: 3.1381 (3.0784)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9786 (1.0248)  time: 0.8167  data: 0.0005  max mem: 62457
Epoch: [165]  [ 800/1251]  eta: 0:06:10  lr: 0.001874  min_lr: 0.001874  loss: 3.1375 (3.0776)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1033 (1.0519)  time: 0.8166  data: 0.0005  max mem: 62457
Epoch: [165]  [1000/1251]  eta: 0:03:26  lr: 0.001870  min_lr: 0.001870  loss: 3.1803 (3.0739)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8139 (1.0238)  time: 0.8169  data: 0.0004  max mem: 62457
Epoch: [165]  [1200/1251]  eta: 0:00:41  lr: 0.001867  min_lr: 0.001867  loss: 3.1335 (3.0694)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9122 (1.0203)  time: 0.8169  data: 0.0005  max mem: 62457
Epoch: [165]  [1250/1251]  eta: 0:00:00  lr: 0.001866  min_lr: 0.001866  loss: 3.3014 (3.0718)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8995 (1.0152)  time: 0.6937  data: 0.0007  max mem: 62457
Epoch: [165] Total time: 0:17:04 (0.8193 s / it)
Averaged stats: lr: 0.001866  min_lr: 0.001866  loss: 3.3014 (3.0600)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8995 (1.0152)
Test:  [ 0/25]  eta: 0:03:22  loss: 0.6602 (0.6602)  acc1: 87.2000 (87.2000)  acc5: 99.2000 (99.2000)  time: 8.1046  data: 7.6258  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.7992 (0.7927)  acc1: 84.8000 (84.2909)  acc5: 97.6000 (97.7455)  time: 1.1415  data: 0.6935  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9819 (0.9152)  acc1: 81.6000 (81.8667)  acc5: 96.0000 (96.4571)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9904 (0.9273)  acc1: 81.2000 (81.6160)  acc5: 95.6000 (96.3840)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7561 s / it)
* Acc@1 82.006 Acc@5 96.278 loss 0.919
Accuracy of the model on the 50000 test images: 82.0%
Max accuracy: 82.01%
Epoch: [166]  [   0/1251]  eta: 1:32:54  lr: 0.001866  min_lr: 0.001866  loss: 3.2488 (3.2488)  weight_decay: 0.0500 (0.0500)  time: 4.4558  data: 3.6341  max mem: 62457
Epoch: [166]  [ 200/1251]  eta: 0:14:39  lr: 0.001862  min_lr: 0.001862  loss: 2.9407 (3.0239)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9135 (0.9307)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [166]  [ 400/1251]  eta: 0:11:43  lr: 0.001859  min_lr: 0.001859  loss: 3.0271 (3.0458)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4922 (1.1126)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [166]  [ 600/1251]  eta: 0:08:56  lr: 0.001855  min_lr: 0.001855  loss: 3.0443 (3.0484)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0361 (1.0623)  time: 0.8177  data: 0.0004  max mem: 62457
Epoch: [166]  [ 800/1251]  eta: 0:06:10  lr: 0.001852  min_lr: 0.001852  loss: 2.8753 (3.0463)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7776 (1.0381)  time: 0.8208  data: 0.0004  max mem: 62457
Epoch: [166]  [1000/1251]  eta: 0:03:26  lr: 0.001848  min_lr: 0.001848  loss: 3.1567 (3.0662)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8556 (1.0235)  time: 0.8171  data: 0.0004  max mem: 62457
Epoch: [166]  [1200/1251]  eta: 0:00:41  lr: 0.001844  min_lr: 0.001844  loss: 2.9640 (3.0578)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7138 (1.0315)  time: 0.8202  data: 0.0004  max mem: 62457
Epoch: [166]  [1250/1251]  eta: 0:00:00  lr: 0.001844  min_lr: 0.001844  loss: 3.1628 (3.0607)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7138 (1.0237)  time: 0.6930  data: 0.0006  max mem: 62457
Epoch: [166] Total time: 0:17:05 (0.8196 s / it)
Averaged stats: lr: 0.001844  min_lr: 0.001844  loss: 3.1628 (3.0606)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7138 (1.0237)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.6637 (0.6637)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.5940  data: 7.1092  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8329 (0.8334)  acc1: 84.4000 (84.8000)  acc5: 97.2000 (97.4545)  time: 1.0949  data: 0.6466  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9537 (0.9561)  acc1: 80.0000 (81.6762)  acc5: 95.6000 (96.2286)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0164 (0.9679)  acc1: 79.2000 (81.3120)  acc5: 95.6000 (96.1600)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7378 s / it)
* Acc@1 81.890 Acc@5 96.214 loss 0.956
Accuracy of the model on the 50000 test images: 81.9%
Max accuracy: 82.01%
Epoch: [167]  [   0/1251]  eta: 1:44:08  lr: 0.001844  min_lr: 0.001844  loss: 2.6716 (2.6716)  weight_decay: 0.0500 (0.0500)  time: 4.9950  data: 1.9893  max mem: 62457
Epoch: [167]  [ 200/1251]  eta: 0:14:41  lr: 0.001840  min_lr: 0.001840  loss: 2.9023 (3.0504)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6933 (0.9187)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [167]  [ 400/1251]  eta: 0:11:44  lr: 0.001836  min_lr: 0.001836  loss: 2.6740 (3.0607)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7663 (0.9211)  time: 0.8168  data: 0.0005  max mem: 62457
Epoch: [167]  [ 600/1251]  eta: 0:08:57  lr: 0.001833  min_lr: 0.001833  loss: 2.9629 (3.0485)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9462 (0.9606)  time: 0.8172  data: 0.0005  max mem: 62457
Epoch: [167]  [ 800/1251]  eta: 0:06:11  lr: 0.001829  min_lr: 0.001829  loss: 3.2613 (3.0405)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8846 (0.9268)  time: 0.8167  data: 0.0005  max mem: 62457
Epoch: [167]  [1000/1251]  eta: 0:03:26  lr: 0.001826  min_lr: 0.001826  loss: 2.9296 (3.0390)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1675 (0.9465)  time: 0.8267  data: 0.0005  max mem: 62457
Epoch: [167]  [1200/1251]  eta: 0:00:41  lr: 0.001822  min_lr: 0.001822  loss: 3.2282 (3.0403)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9498 (0.9472)  time: 0.8169  data: 0.0005  max mem: 62457
Epoch: [167]  [1250/1251]  eta: 0:00:00  lr: 0.001821  min_lr: 0.001821  loss: 2.8332 (3.0345)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9546 (0.9575)  time: 0.6939  data: 0.0007  max mem: 62457
Epoch: [167] Total time: 0:17:05 (0.8201 s / it)
Averaged stats: lr: 0.001821  min_lr: 0.001821  loss: 2.8332 (3.0455)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9546 (0.9575)
Test:  [ 0/25]  eta: 0:02:59  loss: 0.6542 (0.6542)  acc1: 87.2000 (87.2000)  acc5: 98.4000 (98.4000)  time: 7.1803  data: 6.7069  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.7696 (0.7499)  acc1: 85.6000 (85.3818)  acc5: 98.0000 (97.7818)  time: 1.0575  data: 0.6100  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9027 (0.8677)  acc1: 80.8000 (82.0571)  acc5: 96.4000 (96.4952)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9233 (0.8875)  acc1: 80.0000 (81.4560)  acc5: 95.6000 (96.2560)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7192 s / it)
* Acc@1 82.314 Acc@5 96.356 loss 0.866
Accuracy of the model on the 50000 test images: 82.3%
Max accuracy: 82.31%
Epoch: [168]  [   0/1251]  eta: 1:25:11  lr: 0.001821  min_lr: 0.001821  loss: 3.0359 (3.0359)  weight_decay: 0.0500 (0.0500)  time: 4.0863  data: 3.2716  max mem: 62457
Epoch: [168]  [ 200/1251]  eta: 0:14:35  lr: 0.001818  min_lr: 0.001818  loss: 3.2509 (3.0515)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7975 (0.9308)  time: 0.8174  data: 0.0004  max mem: 62457
Epoch: [168]  [ 400/1251]  eta: 0:11:43  lr: 0.001814  min_lr: 0.001814  loss: 2.9326 (3.0483)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9378 (1.0534)  time: 0.8163  data: 0.0004  max mem: 62457
Epoch: [168]  [ 600/1251]  eta: 0:08:55  lr: 0.001811  min_lr: 0.001811  loss: 3.2558 (3.0529)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9012 (1.0104)  time: 0.8164  data: 0.0004  max mem: 62457
Epoch: [168]  [ 800/1251]  eta: 0:06:10  lr: 0.001807  min_lr: 0.001807  loss: 3.2776 (3.0650)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8179 (0.9790)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [168]  [1000/1251]  eta: 0:03:25  lr: 0.001803  min_lr: 0.001803  loss: 3.1242 (3.0506)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8734 (0.9891)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [168]  [1200/1251]  eta: 0:00:41  lr: 0.001800  min_lr: 0.001800  loss: 2.7249 (3.0549)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7335 (0.9965)  time: 0.8154  data: 0.0003  max mem: 62457
Epoch: [168]  [1250/1251]  eta: 0:00:00  lr: 0.001799  min_lr: 0.001799  loss: 3.1551 (3.0559)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9030 (0.9999)  time: 0.6926  data: 0.0004  max mem: 62457
Epoch: [168] Total time: 0:17:03 (0.8182 s / it)
Averaged stats: lr: 0.001799  min_lr: 0.001799  loss: 3.1551 (3.0509)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9030 (0.9999)
Test:  [ 0/25]  eta: 0:03:16  loss: 0.7257 (0.7257)  acc1: 88.0000 (88.0000)  acc5: 98.0000 (98.0000)  time: 7.8404  data: 7.3479  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8648 (0.8504)  acc1: 85.2000 (85.0909)  acc5: 97.6000 (97.5636)  time: 1.1174  data: 0.6683  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9967 (0.9714)  acc1: 80.0000 (82.0000)  acc5: 96.4000 (96.4000)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9967 (0.9762)  acc1: 80.4000 (81.7920)  acc5: 95.6000 (96.3040)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7453 s / it)
* Acc@1 82.170 Acc@5 96.298 loss 0.964
Accuracy of the model on the 50000 test images: 82.2%
Max accuracy: 82.31%
Epoch: [169]  [   0/1251]  eta: 1:35:48  lr: 0.001799  min_lr: 0.001799  loss: 3.0601 (3.0601)  weight_decay: 0.0500 (0.0500)  time: 4.5952  data: 3.5920  max mem: 62457
Epoch: [169]  [ 200/1251]  eta: 0:14:40  lr: 0.001795  min_lr: 0.001795  loss: 3.2086 (3.0749)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9800 (1.1067)  time: 0.8220  data: 0.0005  max mem: 62457
Epoch: [169]  [ 400/1251]  eta: 0:11:43  lr: 0.001792  min_lr: 0.001792  loss: 3.1725 (3.0578)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8864 (1.0575)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [169]  [ 600/1251]  eta: 0:08:56  lr: 0.001788  min_lr: 0.001788  loss: 3.1113 (3.0537)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7284 (1.0249)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [169]  [ 800/1251]  eta: 0:06:10  lr: 0.001785  min_lr: 0.001785  loss: 2.7703 (3.0560)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1382 (1.0167)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [169]  [1000/1251]  eta: 0:03:26  lr: 0.001781  min_lr: 0.001781  loss: 3.0790 (3.0597)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8222 (1.0073)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [169]  [1200/1251]  eta: 0:00:41  lr: 0.001777  min_lr: 0.001777  loss: 2.9738 (3.0555)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2298 (0.9991)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [169]  [1250/1251]  eta: 0:00:00  lr: 0.001777  min_lr: 0.001777  loss: 3.3155 (3.0594)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0246 (0.9995)  time: 0.6969  data: 0.0005  max mem: 62457
Epoch: [169] Total time: 0:17:04 (0.8187 s / it)
Averaged stats: lr: 0.001777  min_lr: 0.001777  loss: 3.3155 (3.0468)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0246 (0.9995)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.7811 (0.7811)  acc1: 88.8000 (88.8000)  acc5: 97.6000 (97.6000)  time: 7.8158  data: 7.3239  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8733 (0.8689)  acc1: 84.8000 (84.5455)  acc5: 97.6000 (97.6364)  time: 1.1151  data: 0.6661  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9994 (0.9997)  acc1: 80.4000 (81.6571)  acc5: 96.0000 (96.1905)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0982 (1.0097)  acc1: 80.4000 (81.2000)  acc5: 95.6000 (96.1760)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7438 s / it)
* Acc@1 81.962 Acc@5 96.214 loss 0.996
Accuracy of the model on the 50000 test images: 82.0%
Max accuracy: 82.31%
Epoch: [170]  [   0/1251]  eta: 1:24:36  lr: 0.001777  min_lr: 0.001777  loss: 3.9637 (3.9637)  weight_decay: 0.0500 (0.0500)  time: 4.0583  data: 2.2800  max mem: 62457
Epoch: [170]  [ 200/1251]  eta: 0:14:35  lr: 0.001773  min_lr: 0.001773  loss: 3.1063 (2.9760)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8920 (1.0870)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [170]  [ 400/1251]  eta: 0:11:41  lr: 0.001769  min_lr: 0.001769  loss: 3.2225 (2.9931)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6954 (0.9606)  time: 0.8154  data: 0.0003  max mem: 62457
Epoch: [170]  [ 600/1251]  eta: 0:08:55  lr: 0.001766  min_lr: 0.001766  loss: 3.1053 (2.9974)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8342 (0.9911)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [170]  [ 800/1251]  eta: 0:06:10  lr: 0.001762  min_lr: 0.001762  loss: 3.0534 (3.0059)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8713 (0.9766)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [170]  [1000/1251]  eta: 0:03:25  lr: 0.001759  min_lr: 0.001759  loss: 3.1858 (3.0200)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9590 (0.9985)  time: 0.8157  data: 0.0003  max mem: 62457
Epoch: [170]  [1200/1251]  eta: 0:00:41  lr: 0.001755  min_lr: 0.001755  loss: 3.0789 (3.0237)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9487 (1.0042)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [170]  [1250/1251]  eta: 0:00:00  lr: 0.001754  min_lr: 0.001754  loss: 3.2882 (3.0295)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9234 (1.0046)  time: 0.6926  data: 0.0005  max mem: 62457
Epoch: [170] Total time: 0:17:03 (0.8179 s / it)
Averaged stats: lr: 0.001754  min_lr: 0.001754  loss: 3.2882 (3.0363)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9234 (1.0046)
Test:  [ 0/25]  eta: 0:02:26  loss: 0.7186 (0.7186)  acc1: 88.4000 (88.4000)  acc5: 98.4000 (98.4000)  time: 5.8776  data: 5.3534  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8680 (0.8456)  acc1: 84.0000 (84.8727)  acc5: 97.6000 (97.6000)  time: 1.0449  data: 0.5928  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9741 (0.9683)  acc1: 80.8000 (81.6571)  acc5: 96.0000 (96.2476)  time: 0.5032  data: 0.0584  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0388 (0.9779)  acc1: 79.6000 (81.4560)  acc5: 95.6000 (96.1120)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7132 s / it)
* Acc@1 82.062 Acc@5 96.328 loss 0.964
Accuracy of the model on the 50000 test images: 82.1%
Max accuracy: 82.31%
Epoch: [171]  [   0/1251]  eta: 1:46:44  lr: 0.001754  min_lr: 0.001754  loss: 2.9755 (2.9755)  weight_decay: 0.0500 (0.0500)  time: 5.1198  data: 1.9819  max mem: 62457
Epoch: [171]  [ 200/1251]  eta: 0:14:40  lr: 0.001751  min_lr: 0.001751  loss: 3.2486 (3.0186)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0635 (1.0077)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [171]  [ 400/1251]  eta: 0:11:43  lr: 0.001747  min_lr: 0.001747  loss: 2.9966 (2.9873)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0130 (1.0395)  time: 0.8234  data: 0.0004  max mem: 62457
Epoch: [171]  [ 600/1251]  eta: 0:08:56  lr: 0.001744  min_lr: 0.001744  loss: 2.9751 (2.9959)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9009 (1.1101)  time: 0.8153  data: 0.0005  max mem: 62457
Epoch: [171]  [ 800/1251]  eta: 0:06:10  lr: 0.001740  min_lr: 0.001740  loss: 2.9721 (3.0157)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8226 (1.0636)  time: 0.8157  data: 0.0005  max mem: 62457
Epoch: [171]  [1000/1251]  eta: 0:03:26  lr: 0.001737  min_lr: 0.001737  loss: 3.0794 (3.0223)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8737 (1.0658)  time: 0.8153  data: 0.0005  max mem: 62457
Epoch: [171]  [1200/1251]  eta: 0:00:41  lr: 0.001733  min_lr: 0.001733  loss: 2.9768 (3.0208)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7840 (1.0468)  time: 0.8154  data: 0.0005  max mem: 62457
Epoch: [171]  [1250/1251]  eta: 0:00:00  lr: 0.001732  min_lr: 0.001732  loss: 3.0448 (3.0220)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7578 (1.0407)  time: 0.6927  data: 0.0007  max mem: 62457
Epoch: [171] Total time: 0:17:04 (0.8189 s / it)
Averaged stats: lr: 0.001732  min_lr: 0.001732  loss: 3.0448 (3.0293)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7578 (1.0407)
Test:  [ 0/25]  eta: 0:03:05  loss: 0.6312 (0.6312)  acc1: 88.0000 (88.0000)  acc5: 99.2000 (99.2000)  time: 7.4365  data: 6.9661  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7882 (0.7597)  acc1: 86.0000 (84.7636)  acc5: 98.0000 (97.9273)  time: 1.0808  data: 0.6335  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9305 (0.8836)  acc1: 80.4000 (81.9429)  acc5: 96.4000 (96.4762)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9351 (0.8943)  acc1: 80.0000 (81.3920)  acc5: 96.0000 (96.4160)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7287 s / it)
* Acc@1 82.146 Acc@5 96.270 loss 0.888
Accuracy of the model on the 50000 test images: 82.1%
Max accuracy: 82.31%
Epoch: [172]  [   0/1251]  eta: 1:43:40  lr: 0.001732  min_lr: 0.001732  loss: 3.3313 (3.3313)  weight_decay: 0.0500 (0.0500)  time: 4.9726  data: 1.9271  max mem: 62457
Epoch: [172]  [ 200/1251]  eta: 0:14:39  lr: 0.001729  min_lr: 0.001729  loss: 3.1001 (3.0055)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2872 (1.1261)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [172]  [ 400/1251]  eta: 0:11:44  lr: 0.001725  min_lr: 0.001725  loss: 3.1801 (3.0079)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9205 (1.0438)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [172]  [ 600/1251]  eta: 0:08:56  lr: 0.001721  min_lr: 0.001721  loss: 3.1546 (3.0054)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8115 (1.0300)  time: 0.8159  data: 0.0005  max mem: 62457
Epoch: [172]  [ 800/1251]  eta: 0:06:10  lr: 0.001718  min_lr: 0.001718  loss: 3.1651 (3.0229)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7336 (1.0211)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [172]  [1000/1251]  eta: 0:03:26  lr: 0.001714  min_lr: 0.001714  loss: 2.7973 (3.0084)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0736 (1.0622)  time: 0.8163  data: 0.0004  max mem: 62457
Epoch: [172]  [1200/1251]  eta: 0:00:41  lr: 0.001711  min_lr: 0.001711  loss: 3.0561 (3.0131)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8529 (1.0468)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [172]  [1250/1251]  eta: 0:00:00  lr: 0.001710  min_lr: 0.001710  loss: 3.1035 (3.0127)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8638 (1.0440)  time: 0.6928  data: 0.0005  max mem: 62457
Epoch: [172] Total time: 0:17:04 (0.8190 s / it)
Averaged stats: lr: 0.001710  min_lr: 0.001710  loss: 3.1035 (3.0346)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8638 (1.0440)
Test:  [ 0/25]  eta: 0:02:49  loss: 0.6371 (0.6371)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 6.7975  data: 6.3034  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.7923 (0.7867)  acc1: 84.8000 (84.7636)  acc5: 97.6000 (97.8545)  time: 1.0228  data: 0.5734  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9162 (0.9042)  acc1: 81.2000 (82.0762)  acc5: 96.4000 (96.3238)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9265 (0.9123)  acc1: 81.2000 (81.8720)  acc5: 95.6000 (96.2240)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7034 s / it)
* Acc@1 82.150 Acc@5 96.232 loss 0.900
Accuracy of the model on the 50000 test images: 82.2%
Max accuracy: 82.31%
Epoch: [173]  [   0/1251]  eta: 1:40:07  lr: 0.001710  min_lr: 0.001710  loss: 2.9192 (2.9192)  weight_decay: 0.0500 (0.0500)  time: 4.8018  data: 3.2824  max mem: 62457
Epoch: [173]  [ 200/1251]  eta: 0:14:41  lr: 0.001706  min_lr: 0.001706  loss: 3.0319 (3.0210)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8094 (0.9822)  time: 0.8163  data: 0.0004  max mem: 62457
Epoch: [173]  [ 400/1251]  eta: 0:11:44  lr: 0.001703  min_lr: 0.001703  loss: 3.0894 (3.0022)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8814 (0.9562)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [173]  [ 600/1251]  eta: 0:08:56  lr: 0.001699  min_lr: 0.001699  loss: 2.8418 (2.9951)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1343 (1.0225)  time: 0.8164  data: 0.0005  max mem: 62457
Epoch: [173]  [ 800/1251]  eta: 0:06:10  lr: 0.001696  min_lr: 0.001696  loss: 3.0961 (3.0042)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8426 (0.9980)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [173]  [1000/1251]  eta: 0:03:26  lr: 0.001692  min_lr: 0.001692  loss: 2.8021 (3.0036)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7867 (0.9798)  time: 0.8156  data: 0.0005  max mem: 62457
Epoch: [173]  [1200/1251]  eta: 0:00:41  lr: 0.001689  min_lr: 0.001689  loss: 3.2492 (3.0113)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2310 (1.0070)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [173]  [1250/1251]  eta: 0:00:00  lr: 0.001688  min_lr: 0.001688  loss: 3.0745 (3.0096)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3708 (1.0196)  time: 0.6930  data: 0.0007  max mem: 62457
Epoch: [173] Total time: 0:17:04 (0.8188 s / it)
Averaged stats: lr: 0.001688  min_lr: 0.001688  loss: 3.0745 (3.0190)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3708 (1.0196)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.6452 (0.6452)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 7.7092  data: 7.2508  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8129 (0.8111)  acc1: 85.6000 (85.2000)  acc5: 97.6000 (97.6727)  time: 1.1080  data: 0.6594  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9065 (0.9226)  acc1: 80.8000 (82.3619)  acc5: 96.0000 (96.4000)  time: 0.4465  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9622 (0.9329)  acc1: 80.4000 (82.0960)  acc5: 96.0000 (96.3680)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7417 s / it)
* Acc@1 82.134 Acc@5 96.226 loss 0.923
Accuracy of the model on the 50000 test images: 82.1%
Max accuracy: 82.31%
Epoch: [174]  [   0/1251]  eta: 1:40:05  lr: 0.001688  min_lr: 0.001688  loss: 2.4517 (2.4517)  weight_decay: 0.0500 (0.0500)  time: 4.8002  data: 3.4927  max mem: 62457
Epoch: [174]  [ 200/1251]  eta: 0:14:41  lr: 0.001684  min_lr: 0.001684  loss: 3.1173 (2.9427)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8987 (1.0025)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [174]  [ 400/1251]  eta: 0:11:43  lr: 0.001681  min_lr: 0.001681  loss: 3.0229 (2.9891)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9953 (1.0181)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [174]  [ 600/1251]  eta: 0:08:56  lr: 0.001677  min_lr: 0.001677  loss: 3.1117 (2.9976)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0520 (1.0016)  time: 0.8192  data: 0.0005  max mem: 62457
Epoch: [174]  [ 800/1251]  eta: 0:06:10  lr: 0.001674  min_lr: 0.001674  loss: 3.0363 (3.0038)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0863 (1.0342)  time: 0.8151  data: 0.0005  max mem: 62457
Epoch: [174]  [1000/1251]  eta: 0:03:25  lr: 0.001670  min_lr: 0.001670  loss: 2.9670 (2.9975)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9105 (1.0331)  time: 0.8153  data: 0.0005  max mem: 62457
Epoch: [174]  [1200/1251]  eta: 0:00:41  lr: 0.001666  min_lr: 0.001666  loss: 2.8966 (2.9903)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1784 (1.0338)  time: 0.8141  data: 0.0004  max mem: 62457
Epoch: [174]  [1250/1251]  eta: 0:00:00  lr: 0.001666  min_lr: 0.001666  loss: 2.9226 (2.9922)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9150 (1.0280)  time: 0.6954  data: 0.0007  max mem: 62457
Epoch: [174] Total time: 0:17:03 (0.8183 s / it)
Averaged stats: lr: 0.001666  min_lr: 0.001666  loss: 2.9226 (3.0159)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9150 (1.0280)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.6266 (0.6266)  acc1: 88.4000 (88.4000)  acc5: 98.0000 (98.0000)  time: 7.5607  data: 7.0879  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7711 (0.7730)  acc1: 85.2000 (85.1273)  acc5: 98.0000 (97.6727)  time: 1.0910  data: 0.6446  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9164 (0.8789)  acc1: 80.4000 (82.0952)  acc5: 96.0000 (96.5524)  time: 0.4441  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9241 (0.8858)  acc1: 80.0000 (81.9200)  acc5: 96.0000 (96.5120)  time: 0.4441  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7354 s / it)
* Acc@1 82.178 Acc@5 96.384 loss 0.880
Accuracy of the model on the 50000 test images: 82.2%
Max accuracy: 82.31%
Epoch: [175]  [   0/1251]  eta: 1:34:41  lr: 0.001666  min_lr: 0.001666  loss: 3.2925 (3.2925)  weight_decay: 0.0500 (0.0500)  time: 4.5414  data: 3.1136  max mem: 62457
Epoch: [175]  [ 200/1251]  eta: 0:14:36  lr: 0.001662  min_lr: 0.001662  loss: 3.0759 (3.0112)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8345 (1.0276)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [175]  [ 400/1251]  eta: 0:11:42  lr: 0.001658  min_lr: 0.001658  loss: 3.1194 (2.9859)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1291 (1.0540)  time: 0.8235  data: 0.0004  max mem: 62457
Epoch: [175]  [ 600/1251]  eta: 0:08:55  lr: 0.001655  min_lr: 0.001655  loss: 3.1501 (2.9900)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8661 (1.0675)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [175]  [ 800/1251]  eta: 0:06:10  lr: 0.001651  min_lr: 0.001651  loss: 3.1911 (3.0104)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0062 (1.0605)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [175]  [1000/1251]  eta: 0:03:25  lr: 0.001648  min_lr: 0.001648  loss: 3.2542 (3.0173)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0063 (1.0505)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [175]  [1200/1251]  eta: 0:00:41  lr: 0.001644  min_lr: 0.001644  loss: 3.0780 (3.0159)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0503 (1.0731)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [175]  [1250/1251]  eta: 0:00:00  lr: 0.001644  min_lr: 0.001644  loss: 3.1503 (3.0184)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8996 (1.0631)  time: 0.6921  data: 0.0005  max mem: 62457
Epoch: [175] Total time: 0:17:03 (0.8180 s / it)
Averaged stats: lr: 0.001644  min_lr: 0.001644  loss: 3.1503 (3.0209)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8996 (1.0631)
Test:  [ 0/25]  eta: 0:03:22  loss: 0.6911 (0.6911)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 8.1055  data: 7.6187  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8970 (0.8693)  acc1: 85.2000 (84.5455)  acc5: 98.0000 (97.6364)  time: 1.1415  data: 0.6929  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 1.0506 (0.9817)  acc1: 80.8000 (81.8857)  acc5: 96.0000 (96.3810)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0506 (0.9910)  acc1: 80.4000 (81.7120)  acc5: 96.0000 (96.2720)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7560 s / it)
* Acc@1 81.936 Acc@5 96.214 loss 0.983
Accuracy of the model on the 50000 test images: 81.9%
Max accuracy: 82.31%
Epoch: [176]  [   0/1251]  eta: 1:28:26  lr: 0.001643  min_lr: 0.001643  loss: 3.1550 (3.1550)  weight_decay: 0.0500 (0.0500)  time: 4.2417  data: 2.0914  max mem: 62457
Epoch: [176]  [ 200/1251]  eta: 0:14:34  lr: 0.001640  min_lr: 0.001640  loss: 3.0862 (3.0266)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8987 (0.9040)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [176]  [ 400/1251]  eta: 0:11:42  lr: 0.001636  min_lr: 0.001636  loss: 3.2138 (3.0120)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8346 (0.9330)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [176]  [ 600/1251]  eta: 0:08:55  lr: 0.001633  min_lr: 0.001633  loss: 3.0468 (3.0157)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9932 (1.0349)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [176]  [ 800/1251]  eta: 0:06:10  lr: 0.001629  min_lr: 0.001629  loss: 3.1095 (3.0120)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2435 (1.0672)  time: 0.8192  data: 0.0004  max mem: 62457
Epoch: [176]  [1000/1251]  eta: 0:03:25  lr: 0.001626  min_lr: 0.001626  loss: 3.1333 (3.0173)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7895 (1.0577)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [176]  [1200/1251]  eta: 0:00:41  lr: 0.001622  min_lr: 0.001622  loss: 3.2290 (3.0296)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0345 (1.0494)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [176]  [1250/1251]  eta: 0:00:00  lr: 0.001621  min_lr: 0.001621  loss: 3.2487 (3.0344)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8446 (1.0420)  time: 0.6926  data: 0.0007  max mem: 62457
Epoch: [176] Total time: 0:17:02 (0.8175 s / it)
Averaged stats: lr: 0.001621  min_lr: 0.001621  loss: 3.2487 (3.0118)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8446 (1.0420)
Test:  [ 0/25]  eta: 0:02:46  loss: 0.6933 (0.6933)  acc1: 87.6000 (87.6000)  acc5: 98.4000 (98.4000)  time: 6.6775  data: 6.1954  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8798 (0.8550)  acc1: 84.4000 (84.7273)  acc5: 97.6000 (97.6727)  time: 1.0621  data: 0.5990  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9833 (0.9837)  acc1: 80.0000 (81.8095)  acc5: 96.4000 (96.4571)  time: 0.4758  data: 0.0197  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0537 (0.9934)  acc1: 80.0000 (81.4560)  acc5: 96.0000 (96.3200)  time: 0.4537  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7227 s / it)
* Acc@1 82.020 Acc@5 96.224 loss 0.983
Accuracy of the model on the 50000 test images: 82.0%
Max accuracy: 82.31%
Epoch: [177]  [   0/1251]  eta: 1:36:39  lr: 0.001621  min_lr: 0.001621  loss: 2.4324 (2.4324)  weight_decay: 0.0500 (0.0500)  time: 4.6359  data: 3.8171  max mem: 62457
Epoch: [177]  [ 200/1251]  eta: 0:14:39  lr: 0.001618  min_lr: 0.001618  loss: 3.1916 (2.9949)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9000 (0.9869)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [177]  [ 400/1251]  eta: 0:11:42  lr: 0.001614  min_lr: 0.001614  loss: 3.1830 (2.9959)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9803 (1.0426)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [177]  [ 600/1251]  eta: 0:08:55  lr: 0.001611  min_lr: 0.001611  loss: 3.2058 (3.0010)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9572 (1.0392)  time: 0.8191  data: 0.0004  max mem: 62457
Epoch: [177]  [ 800/1251]  eta: 0:06:10  lr: 0.001607  min_lr: 0.001607  loss: 3.0082 (3.0156)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7605 (0.9983)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [177]  [1000/1251]  eta: 0:03:25  lr: 0.001604  min_lr: 0.001604  loss: 2.8047 (3.0029)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9443 (1.0096)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [177]  [1200/1251]  eta: 0:00:41  lr: 0.001600  min_lr: 0.001600  loss: 3.0461 (3.0034)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7387 (1.0080)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [177]  [1250/1251]  eta: 0:00:00  lr: 0.001599  min_lr: 0.001599  loss: 3.2310 (3.0063)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8467 (1.0078)  time: 0.6923  data: 0.0005  max mem: 62457
Epoch: [177] Total time: 0:17:03 (0.8179 s / it)
Averaged stats: lr: 0.001599  min_lr: 0.001599  loss: 3.2310 (3.0083)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8467 (1.0078)
Test:  [ 0/25]  eta: 0:03:00  loss: 0.6793 (0.6793)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 7.2377  data: 6.7350  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8679 (0.8386)  acc1: 83.6000 (85.0909)  acc5: 97.6000 (97.6364)  time: 1.0819  data: 0.6318  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9796 (0.9621)  acc1: 80.4000 (81.9429)  acc5: 96.0000 (96.4381)  time: 0.4556  data: 0.0108  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0160 (0.9700)  acc1: 80.4000 (81.6800)  acc5: 96.0000 (96.3680)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7309 s / it)
* Acc@1 81.992 Acc@5 96.292 loss 0.962
Accuracy of the model on the 50000 test images: 82.0%
Max accuracy: 82.31%
Epoch: [178]  [   0/1251]  eta: 1:38:27  lr: 0.001599  min_lr: 0.001599  loss: 3.4985 (3.4985)  weight_decay: 0.0500 (0.0500)  time: 4.7221  data: 3.7597  max mem: 62457
Epoch: [178]  [ 200/1251]  eta: 0:14:39  lr: 0.001596  min_lr: 0.001596  loss: 3.1329 (2.9901)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9968 (0.9991)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [178]  [ 400/1251]  eta: 0:11:43  lr: 0.001592  min_lr: 0.001592  loss: 3.1069 (2.9959)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8349 (1.0040)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [178]  [ 600/1251]  eta: 0:08:55  lr: 0.001589  min_lr: 0.001589  loss: 3.2311 (3.0044)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9702 (1.0514)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [178]  [ 800/1251]  eta: 0:06:10  lr: 0.001585  min_lr: 0.001585  loss: 2.6542 (3.0011)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3019 (1.0815)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [178]  [1000/1251]  eta: 0:03:25  lr: 0.001582  min_lr: 0.001582  loss: 2.9445 (2.9989)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2596 (1.0967)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [178]  [1200/1251]  eta: 0:00:41  lr: 0.001578  min_lr: 0.001578  loss: 3.1817 (2.9988)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7212 (1.0720)  time: 0.8143  data: 0.0004  max mem: 62457
Epoch: [178]  [1250/1251]  eta: 0:00:00  lr: 0.001578  min_lr: 0.001578  loss: 2.9664 (2.9994)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8074 (1.0693)  time: 0.6926  data: 0.0007  max mem: 62457
Epoch: [178] Total time: 0:17:02 (0.8177 s / it)
Averaged stats: lr: 0.001578  min_lr: 0.001578  loss: 2.9664 (3.0045)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8074 (1.0693)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.5768 (0.5768)  acc1: 90.8000 (90.8000)  acc5: 98.4000 (98.4000)  time: 7.6938  data: 7.2327  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7658 (0.7770)  acc1: 86.0000 (85.1273)  acc5: 97.6000 (97.6364)  time: 1.1058  data: 0.6578  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9256 (0.8916)  acc1: 81.2000 (82.2476)  acc5: 96.4000 (96.4191)  time: 0.4459  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9499 (0.9000)  acc1: 81.2000 (82.1120)  acc5: 95.6000 (96.3520)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7395 s / it)
* Acc@1 82.312 Acc@5 96.294 loss 0.896
Accuracy of the model on the 50000 test images: 82.3%
Max accuracy: 82.31%
Epoch: [179]  [   0/1251]  eta: 1:44:49  lr: 0.001577  min_lr: 0.001577  loss: 3.5166 (3.5166)  weight_decay: 0.0500 (0.0500)  time: 5.0278  data: 4.2067  max mem: 62457
Epoch: [179]  [ 200/1251]  eta: 0:14:39  lr: 0.001574  min_lr: 0.001574  loss: 2.9772 (2.9984)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0537 (1.1595)  time: 0.8150  data: 0.0005  max mem: 62457
Epoch: [179]  [ 400/1251]  eta: 0:11:43  lr: 0.001570  min_lr: 0.001570  loss: 3.1585 (2.9935)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9206 (1.1344)  time: 0.8239  data: 0.0004  max mem: 62457
Epoch: [179]  [ 600/1251]  eta: 0:08:55  lr: 0.001567  min_lr: 0.001567  loss: 3.3222 (3.0019)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0340 (1.1098)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [179]  [ 800/1251]  eta: 0:06:10  lr: 0.001563  min_lr: 0.001563  loss: 2.8553 (3.0052)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8987 (1.0837)  time: 0.8171  data: 0.0004  max mem: 62457
Epoch: [179]  [1000/1251]  eta: 0:03:25  lr: 0.001560  min_lr: 0.001560  loss: 3.0906 (3.0181)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9544 (1.0804)  time: 0.8196  data: 0.0004  max mem: 62457
Epoch: [179]  [1200/1251]  eta: 0:00:41  lr: 0.001556  min_lr: 0.001556  loss: 3.2911 (3.0232)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9435 (1.0508)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [179]  [1250/1251]  eta: 0:00:00  lr: 0.001556  min_lr: 0.001556  loss: 3.2486 (3.0238)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9766 (1.0475)  time: 0.6921  data: 0.0006  max mem: 62457
Epoch: [179] Total time: 0:17:03 (0.8180 s / it)
Averaged stats: lr: 0.001556  min_lr: 0.001556  loss: 3.2486 (3.0039)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9766 (1.0475)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.6971 (0.6971)  acc1: 90.4000 (90.4000)  acc5: 98.4000 (98.4000)  time: 7.5617  data: 7.0715  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8337 (0.8512)  acc1: 85.6000 (85.0909)  acc5: 98.0000 (97.6727)  time: 1.0921  data: 0.6432  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9966 (0.9644)  acc1: 80.8000 (82.4381)  acc5: 96.0000 (96.4952)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0177 (0.9741)  acc1: 80.4000 (82.0800)  acc5: 96.0000 (96.4160)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7334 s / it)
* Acc@1 82.492 Acc@5 96.494 loss 0.963
Accuracy of the model on the 50000 test images: 82.5%
Max accuracy: 82.49%
Epoch: [180]  [   0/1251]  eta: 1:34:44  lr: 0.001556  min_lr: 0.001556  loss: 3.3117 (3.3117)  weight_decay: 0.0500 (0.0500)  time: 4.5443  data: 3.7276  max mem: 62457
Epoch: [180]  [ 200/1251]  eta: 0:14:35  lr: 0.001552  min_lr: 0.001552  loss: 3.1917 (2.9625)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0107 (1.0848)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [180]  [ 400/1251]  eta: 0:11:42  lr: 0.001549  min_lr: 0.001549  loss: 3.2243 (2.9724)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9446 (1.0226)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [180]  [ 600/1251]  eta: 0:08:55  lr: 0.001545  min_lr: 0.001545  loss: 2.9378 (3.0041)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0783 (1.0649)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [180]  [ 800/1251]  eta: 0:06:10  lr: 0.001542  min_lr: 0.001542  loss: 2.9200 (2.9967)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8468 (1.0426)  time: 0.8216  data: 0.0004  max mem: 62457
Epoch: [180]  [1000/1251]  eta: 0:03:25  lr: 0.001538  min_lr: 0.001538  loss: 3.2497 (2.9987)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8142 (1.0630)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [180]  [1200/1251]  eta: 0:00:41  lr: 0.001535  min_lr: 0.001535  loss: 3.3075 (2.9988)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0480 (1.0625)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [180]  [1250/1251]  eta: 0:00:00  lr: 0.001534  min_lr: 0.001534  loss: 3.3817 (2.9993)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2235 (1.0684)  time: 0.6926  data: 0.0006  max mem: 62457
Epoch: [180] Total time: 0:17:03 (0.8182 s / it)
Averaged stats: lr: 0.001534  min_lr: 0.001534  loss: 3.3817 (2.9995)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2235 (1.0684)
Test:  [ 0/25]  eta: 0:03:06  loss: 0.6066 (0.6066)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 7.4545  data: 6.9965  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7727 (0.7699)  acc1: 84.4000 (84.9818)  acc5: 97.6000 (97.8546)  time: 1.0852  data: 0.6363  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8743 (0.8950)  acc1: 81.6000 (82.1333)  acc5: 96.0000 (96.4762)  time: 0.4466  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9555 (0.9008)  acc1: 81.6000 (81.9840)  acc5: 96.0000 (96.5120)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7310 s / it)
* Acc@1 82.530 Acc@5 96.540 loss 0.891
Accuracy of the model on the 50000 test images: 82.5%
Max accuracy: 82.53%
Epoch: [181]  [   0/1251]  eta: 1:30:56  lr: 0.001534  min_lr: 0.001534  loss: 3.4701 (3.4701)  weight_decay: 0.0500 (0.0500)  time: 4.3618  data: 3.5366  max mem: 62457
Epoch: [181]  [ 200/1251]  eta: 0:14:38  lr: 0.001530  min_lr: 0.001530  loss: 3.1518 (2.9928)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0605 (1.0349)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [181]  [ 400/1251]  eta: 0:11:42  lr: 0.001527  min_lr: 0.001527  loss: 3.1126 (3.0067)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9981 (1.0881)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [181]  [ 600/1251]  eta: 0:08:55  lr: 0.001523  min_lr: 0.001523  loss: 2.9626 (2.9935)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8468 (1.0722)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [181]  [ 800/1251]  eta: 0:06:10  lr: 0.001520  min_lr: 0.001520  loss: 3.1951 (2.9964)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9087 (nan)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [181]  [1000/1251]  eta: 0:03:25  lr: 0.001516  min_lr: 0.001516  loss: 2.9692 (2.9972)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2958 (nan)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [181]  [1200/1251]  eta: 0:00:41  lr: 0.001513  min_lr: 0.001513  loss: 3.1910 (2.9960)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0920 (nan)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [181]  [1250/1251]  eta: 0:00:00  lr: 0.001512  min_lr: 0.001512  loss: 3.1940 (2.9979)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0920 (nan)  time: 0.6919  data: 0.0006  max mem: 62457
Epoch: [181] Total time: 0:17:02 (0.8174 s / it)
Averaged stats: lr: 0.001512  min_lr: 0.001512  loss: 3.1940 (2.9951)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0920 (nan)
Test:  [ 0/25]  eta: 0:03:06  loss: 0.6544 (0.6544)  acc1: 88.8000 (88.8000)  acc5: 99.2000 (99.2000)  time: 7.4745  data: 7.0056  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8283 (0.8261)  acc1: 85.6000 (85.0182)  acc5: 98.0000 (97.8182)  time: 1.0840  data: 0.6371  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9795 (0.9568)  acc1: 80.8000 (82.1524)  acc5: 96.4000 (96.3048)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9797 (0.9601)  acc1: 80.8000 (82.0000)  acc5: 96.0000 (96.2560)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7297 s / it)
* Acc@1 82.476 Acc@5 96.370 loss 0.950
Accuracy of the model on the 50000 test images: 82.5%
Max accuracy: 82.53%
Epoch: [182]  [   0/1251]  eta: 1:46:33  lr: 0.001512  min_lr: 0.001512  loss: 3.2554 (3.2554)  weight_decay: 0.0500 (0.0500)  time: 5.1107  data: 2.8541  max mem: 62457
Epoch: [182]  [ 200/1251]  eta: 0:14:41  lr: 0.001508  min_lr: 0.001508  loss: 3.0296 (2.9489)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8590 (1.0889)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [182]  [ 400/1251]  eta: 0:11:43  lr: 0.001505  min_lr: 0.001505  loss: 2.9806 (2.9418)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9679 (1.0529)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [182]  [ 600/1251]  eta: 0:08:56  lr: 0.001501  min_lr: 0.001501  loss: 2.9199 (2.9474)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9009 (1.0283)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [182]  [ 800/1251]  eta: 0:06:10  lr: 0.001498  min_lr: 0.001498  loss: 2.8281 (2.9649)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9588 (1.0467)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [182]  [1000/1251]  eta: 0:03:25  lr: 0.001495  min_lr: 0.001495  loss: 3.0778 (2.9786)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9061 (1.0446)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [182]  [1200/1251]  eta: 0:00:41  lr: 0.001491  min_lr: 0.001491  loss: 2.9820 (2.9804)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8913 (1.0262)  time: 0.8153  data: 0.0003  max mem: 62457
Epoch: [182]  [1250/1251]  eta: 0:00:00  lr: 0.001490  min_lr: 0.001490  loss: 2.8870 (2.9801)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.6923  data: 0.0005  max mem: 62457
Epoch: [182] Total time: 0:17:03 (0.8185 s / it)
Averaged stats: lr: 0.001490  min_lr: 0.001490  loss: 2.8870 (2.9864)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:03:03  loss: 0.5574 (0.5574)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 7.3286  data: 6.8322  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7349 (0.7380)  acc1: 85.2000 (86.0727)  acc5: 98.0000 (97.9273)  time: 1.0710  data: 0.6214  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8790 (0.8573)  acc1: 82.0000 (83.0667)  acc5: 96.4000 (96.5524)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9233 (0.8631)  acc1: 82.0000 (82.8480)  acc5: 95.6000 (96.5120)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7258 s / it)
* Acc@1 82.754 Acc@5 96.518 loss 0.860
Accuracy of the model on the 50000 test images: 82.8%
Max accuracy: 82.75%
Epoch: [183]  [   0/1251]  eta: 1:29:54  lr: 0.001490  min_lr: 0.001490  loss: 3.1250 (3.1250)  weight_decay: 0.0500 (0.0500)  time: 4.3123  data: 3.5012  max mem: 62457
Epoch: [183]  [ 200/1251]  eta: 0:14:36  lr: 0.001487  min_lr: 0.001487  loss: 3.2694 (3.0141)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2462 (1.1952)  time: 0.8162  data: 0.0004  max mem: 62457
Epoch: [183]  [ 400/1251]  eta: 0:11:42  lr: 0.001483  min_lr: 0.001483  loss: 3.0486 (2.9848)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0605 (1.1320)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [183]  [ 600/1251]  eta: 0:08:55  lr: 0.001480  min_lr: 0.001480  loss: 2.9271 (2.9666)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8446 (1.1156)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [183]  [ 800/1251]  eta: 0:06:10  lr: 0.001476  min_lr: 0.001476  loss: 3.0200 (2.9663)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9526 (1.0879)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [183]  [1000/1251]  eta: 0:03:25  lr: 0.001473  min_lr: 0.001473  loss: 3.0162 (2.9655)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7694 (1.0643)  time: 0.8200  data: 0.0004  max mem: 62457
Epoch: [183]  [1200/1251]  eta: 0:00:41  lr: 0.001469  min_lr: 0.001469  loss: 2.9534 (2.9647)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7735 (1.0637)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [183]  [1250/1251]  eta: 0:00:00  lr: 0.001469  min_lr: 0.001469  loss: 3.1470 (2.9662)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8209 (1.0583)  time: 0.6921  data: 0.0005  max mem: 62457
Epoch: [183] Total time: 0:17:03 (0.8182 s / it)
Averaged stats: lr: 0.001469  min_lr: 0.001469  loss: 3.1470 (2.9799)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8209 (1.0583)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.6103 (0.6103)  acc1: 87.6000 (87.6000)  acc5: 98.8000 (98.8000)  time: 7.7912  data: 7.3268  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8074 (0.7805)  acc1: 85.6000 (84.9818)  acc5: 98.0000 (97.8909)  time: 1.1125  data: 0.6663  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9227 (0.9054)  acc1: 80.4000 (82.1714)  acc5: 96.4000 (96.4191)  time: 0.4444  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0087 (0.9145)  acc1: 80.8000 (82.0000)  acc5: 95.6000 (96.3840)  time: 0.4440  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7426 s / it)
* Acc@1 82.600 Acc@5 96.416 loss 0.898
Accuracy of the model on the 50000 test images: 82.6%
Max accuracy: 82.75%
Epoch: [184]  [   0/1251]  eta: 1:29:21  lr: 0.001469  min_lr: 0.001469  loss: 2.1933 (2.1933)  weight_decay: 0.0500 (0.0500)  time: 4.2858  data: 3.0465  max mem: 62457
Epoch: [184]  [ 200/1251]  eta: 0:14:35  lr: 0.001465  min_lr: 0.001465  loss: 3.1788 (2.9946)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9541 (1.1158)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [184]  [ 400/1251]  eta: 0:11:42  lr: 0.001462  min_lr: 0.001462  loss: 2.8466 (2.9905)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2349 (1.1274)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [184]  [ 600/1251]  eta: 0:08:55  lr: 0.001458  min_lr: 0.001458  loss: 2.9629 (2.9873)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9891 (1.0874)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [184]  [ 800/1251]  eta: 0:06:10  lr: 0.001455  min_lr: 0.001455  loss: 3.1188 (2.9779)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3529 (1.0773)  time: 0.8210  data: 0.0004  max mem: 62457
Epoch: [184]  [1000/1251]  eta: 0:03:25  lr: 0.001451  min_lr: 0.001451  loss: 2.9881 (2.9736)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0371 (1.0864)  time: 0.8163  data: 0.0004  max mem: 62457
Epoch: [184]  [1200/1251]  eta: 0:00:41  lr: 0.001448  min_lr: 0.001448  loss: 3.1291 (2.9774)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8118 (1.0671)  time: 0.8161  data: 0.0005  max mem: 62457
Epoch: [184]  [1250/1251]  eta: 0:00:00  lr: 0.001447  min_lr: 0.001447  loss: 3.2373 (2.9793)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8192 (1.0667)  time: 0.6932  data: 0.0007  max mem: 62457
Epoch: [184] Total time: 0:17:04 (0.8186 s / it)
Averaged stats: lr: 0.001447  min_lr: 0.001447  loss: 3.2373 (2.9843)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8192 (1.0667)
Test:  [ 0/25]  eta: 0:03:17  loss: 0.6356 (0.6356)  acc1: 91.6000 (91.6000)  acc5: 99.2000 (99.2000)  time: 7.9116  data: 7.4330  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8060 (0.8092)  acc1: 84.0000 (85.2364)  acc5: 97.2000 (97.5636)  time: 1.1240  data: 0.6760  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9450 (0.9315)  acc1: 80.8000 (82.1714)  acc5: 96.0000 (96.4191)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0078 (0.9377)  acc1: 80.8000 (82.0320)  acc5: 95.6000 (96.3200)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7485 s / it)
* Acc@1 82.546 Acc@5 96.378 loss 0.922
Accuracy of the model on the 50000 test images: 82.5%
Max accuracy: 82.75%
Epoch: [185]  [   0/1251]  eta: 1:45:56  lr: 0.001447  min_lr: 0.001447  loss: 2.2639 (2.2639)  weight_decay: 0.0500 (0.0500)  time: 5.0813  data: 4.0102  max mem: 62457
Epoch: [185]  [ 200/1251]  eta: 0:14:42  lr: 0.001444  min_lr: 0.001444  loss: 2.9399 (2.9186)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8751 (1.0990)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [185]  [ 400/1251]  eta: 0:11:44  lr: 0.001440  min_lr: 0.001440  loss: 3.1457 (2.9533)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7914 (1.1284)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [185]  [ 600/1251]  eta: 0:08:56  lr: 0.001437  min_lr: 0.001437  loss: 2.9144 (2.9444)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8596 (1.1124)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [185]  [ 800/1251]  eta: 0:06:10  lr: 0.001433  min_lr: 0.001433  loss: 2.9480 (2.9390)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9130 (1.1042)  time: 0.8162  data: 0.0004  max mem: 62457
Epoch: [185]  [1000/1251]  eta: 0:03:26  lr: 0.001430  min_lr: 0.001430  loss: 2.5120 (2.9358)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9908 (1.1040)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [185]  [1200/1251]  eta: 0:00:41  lr: 0.001426  min_lr: 0.001426  loss: 2.9536 (2.9414)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8056 (1.0776)  time: 0.8225  data: 0.0004  max mem: 62457
Epoch: [185]  [1250/1251]  eta: 0:00:00  lr: 0.001426  min_lr: 0.001426  loss: 3.1455 (2.9429)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8921 (1.0768)  time: 0.6992  data: 0.0005  max mem: 62457
Epoch: [185] Total time: 0:17:04 (0.8192 s / it)
Averaged stats: lr: 0.001426  min_lr: 0.001426  loss: 3.1455 (2.9691)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8921 (1.0768)
Test:  [ 0/25]  eta: 0:03:25  loss: 0.6048 (0.6048)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 8.2114  data: 7.7433  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8065 (0.7808)  acc1: 85.2000 (85.1636)  acc5: 98.0000 (97.7455)  time: 1.1511  data: 0.7042  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9186 (0.8911)  acc1: 80.4000 (82.1524)  acc5: 96.0000 (96.4571)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9464 (0.8998)  acc1: 80.4000 (82.0160)  acc5: 95.6000 (96.2560)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:19 (0.7604 s / it)
* Acc@1 82.614 Acc@5 96.486 loss 0.879
Accuracy of the model on the 50000 test images: 82.6%
Max accuracy: 82.75%
Epoch: [186]  [   0/1251]  eta: 1:43:39  lr: 0.001425  min_lr: 0.001425  loss: 2.2796 (2.2796)  weight_decay: 0.0500 (0.0500)  time: 4.9720  data: 3.1426  max mem: 62457
Epoch: [186]  [ 200/1251]  eta: 0:14:41  lr: 0.001422  min_lr: 0.001422  loss: 2.6978 (2.9164)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2661 (1.1642)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [186]  [ 400/1251]  eta: 0:11:44  lr: 0.001419  min_lr: 0.001419  loss: 3.0304 (2.9497)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7991 (1.1358)  time: 0.8154  data: 0.0005  max mem: 62457
Epoch: [186]  [ 600/1251]  eta: 0:08:56  lr: 0.001415  min_lr: 0.001415  loss: 2.7672 (2.9507)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1464 (1.0944)  time: 0.8171  data: 0.0005  max mem: 62457
Epoch: [186]  [ 800/1251]  eta: 0:06:10  lr: 0.001412  min_lr: 0.001412  loss: 3.2021 (2.9625)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2070 (1.1012)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [186]  [1000/1251]  eta: 0:03:26  lr: 0.001408  min_lr: 0.001408  loss: 2.9850 (2.9767)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8255 (1.1038)  time: 0.8155  data: 0.0005  max mem: 62457
Epoch: [186]  [1200/1251]  eta: 0:00:41  lr: 0.001405  min_lr: 0.001405  loss: 3.0117 (2.9744)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8505 (1.0916)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [186]  [1250/1251]  eta: 0:00:00  lr: 0.001404  min_lr: 0.001404  loss: 2.7941 (2.9714)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7723 (1.0841)  time: 0.6977  data: 0.0006  max mem: 62457
Epoch: [186] Total time: 0:17:04 (0.8189 s / it)
Averaged stats: lr: 0.001404  min_lr: 0.001404  loss: 2.7941 (2.9691)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7723 (1.0841)
Test:  [ 0/25]  eta: 0:03:11  loss: 0.5783 (0.5783)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.6625  data: 7.1839  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7386 (0.7326)  acc1: 85.6000 (85.6000)  acc5: 98.0000 (98.1091)  time: 1.1012  data: 0.6533  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8563 (0.8566)  acc1: 82.4000 (82.6095)  acc5: 96.8000 (96.9333)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9031 (0.8705)  acc1: 80.8000 (82.1600)  acc5: 96.0000 (96.7840)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7377 s / it)
* Acc@1 82.486 Acc@5 96.452 loss 0.865
Accuracy of the model on the 50000 test images: 82.5%
Max accuracy: 82.75%
Epoch: [187]  [   0/1251]  eta: 1:43:18  lr: 0.001404  min_lr: 0.001404  loss: 3.2476 (3.2476)  weight_decay: 0.0500 (0.0500)  time: 4.9549  data: 4.1177  max mem: 62457
Epoch: [187]  [ 200/1251]  eta: 0:14:38  lr: 0.001401  min_lr: 0.001401  loss: 3.0627 (2.9134)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2284 (1.2879)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [187]  [ 400/1251]  eta: 0:11:43  lr: 0.001397  min_lr: 0.001397  loss: 3.0124 (2.9452)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8791 (1.1675)  time: 0.8236  data: 0.0004  max mem: 62457
Epoch: [187]  [ 600/1251]  eta: 0:08:56  lr: 0.001394  min_lr: 0.001394  loss: 2.9512 (2.9583)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8688 (1.1555)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [187]  [ 800/1251]  eta: 0:06:10  lr: 0.001390  min_lr: 0.001390  loss: 2.9775 (2.9471)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0610 (1.1525)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [187]  [1000/1251]  eta: 0:03:26  lr: 0.001387  min_lr: 0.001387  loss: 3.0571 (2.9477)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7622 (1.0985)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [187]  [1200/1251]  eta: 0:00:41  lr: 0.001383  min_lr: 0.001383  loss: 3.1326 (2.9468)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8429 (1.0837)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [187]  [1250/1251]  eta: 0:00:00  lr: 0.001383  min_lr: 0.001383  loss: 3.2207 (2.9478)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8533 (1.0818)  time: 0.6923  data: 0.0006  max mem: 62457
Epoch: [187] Total time: 0:17:04 (0.8186 s / it)
Averaged stats: lr: 0.001383  min_lr: 0.001383  loss: 3.2207 (2.9548)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8533 (1.0818)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.6382 (0.6382)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 7.6890  data: 7.2189  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8175 (0.8082)  acc1: 86.0000 (85.4182)  acc5: 97.6000 (97.6000)  time: 1.1037  data: 0.6565  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9249 (0.9302)  acc1: 81.6000 (82.5905)  acc5: 96.0000 (96.3238)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9527 (0.9373)  acc1: 80.8000 (82.0800)  acc5: 96.0000 (96.3360)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7393 s / it)
* Acc@1 82.706 Acc@5 96.486 loss 0.925
Accuracy of the model on the 50000 test images: 82.7%
Max accuracy: 82.75%
Epoch: [188]  [   0/1251]  eta: 1:40:21  lr: 0.001383  min_lr: 0.001383  loss: 3.1040 (3.1040)  weight_decay: 0.0500 (0.0500)  time: 4.8131  data: 3.6234  max mem: 62457
Epoch: [188]  [ 200/1251]  eta: 0:14:38  lr: 0.001379  min_lr: 0.001379  loss: 2.9225 (2.8867)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8941 (1.0112)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [188]  [ 400/1251]  eta: 0:11:44  lr: 0.001376  min_lr: 0.001376  loss: 3.0785 (2.9112)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1194 (1.0643)  time: 0.8165  data: 0.0005  max mem: 62457
Epoch: [188]  [ 600/1251]  eta: 0:08:56  lr: 0.001372  min_lr: 0.001372  loss: 3.1440 (2.9256)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2058 (1.0792)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [188]  [ 800/1251]  eta: 0:06:10  lr: 0.001369  min_lr: 0.001369  loss: 3.1460 (2.9429)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4507 (1.1460)  time: 0.8264  data: 0.0004  max mem: 62457
Epoch: [188]  [1000/1251]  eta: 0:03:26  lr: 0.001366  min_lr: 0.001366  loss: 3.0462 (2.9471)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8912 (1.1433)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [188]  [1200/1251]  eta: 0:00:41  lr: 0.001362  min_lr: 0.001362  loss: 3.1132 (2.9523)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0564 (1.1229)  time: 0.8163  data: 0.0004  max mem: 62457
Epoch: [188]  [1250/1251]  eta: 0:00:00  lr: 0.001361  min_lr: 0.001361  loss: 3.1760 (2.9532)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0562 (1.1252)  time: 0.6925  data: 0.0006  max mem: 62457
Epoch: [188] Total time: 0:17:04 (0.8187 s / it)
Averaged stats: lr: 0.001361  min_lr: 0.001361  loss: 3.1760 (2.9557)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0562 (1.1252)
Test:  [ 0/25]  eta: 0:03:03  loss: 0.6237 (0.6237)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 7.3579  data: 6.8632  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7523 (0.7551)  acc1: 85.2000 (85.3455)  acc5: 98.0000 (97.8545)  time: 1.0736  data: 0.6242  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8883 (0.8741)  acc1: 81.6000 (82.6095)  acc5: 96.4000 (96.4381)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9317 (0.8868)  acc1: 81.6000 (82.1120)  acc5: 95.6000 (96.3520)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7250 s / it)
* Acc@1 82.658 Acc@5 96.534 loss 0.871
Accuracy of the model on the 50000 test images: 82.7%
Max accuracy: 82.75%
Epoch: [189]  [   0/1251]  eta: 1:42:12  lr: 0.001361  min_lr: 0.001361  loss: 2.7962 (2.7962)  weight_decay: 0.0500 (0.0500)  time: 4.9023  data: 4.0862  max mem: 62457
Epoch: [189]  [ 200/1251]  eta: 0:14:41  lr: 0.001358  min_lr: 0.001358  loss: 3.0197 (3.0052)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0598 (1.1067)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [189]  [ 400/1251]  eta: 0:11:44  lr: 0.001355  min_lr: 0.001355  loss: 3.0858 (2.9689)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3917 (1.2190)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [189]  [ 600/1251]  eta: 0:08:56  lr: 0.001351  min_lr: 0.001351  loss: 3.0859 (2.9644)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9673 (1.1646)  time: 0.8199  data: 0.0004  max mem: 62457
Epoch: [189]  [ 800/1251]  eta: 0:06:10  lr: 0.001348  min_lr: 0.001348  loss: 3.0811 (2.9722)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8964 (1.1539)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [189]  [1000/1251]  eta: 0:03:25  lr: 0.001344  min_lr: 0.001344  loss: 2.8543 (2.9655)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1163 (1.1774)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [189]  [1200/1251]  eta: 0:00:41  lr: 0.001341  min_lr: 0.001341  loss: 3.2978 (2.9744)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0934 (1.1573)  time: 0.8185  data: 0.0004  max mem: 62457
Epoch: [189]  [1250/1251]  eta: 0:00:00  lr: 0.001340  min_lr: 0.001340  loss: 2.9843 (2.9737)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1704 (1.1620)  time: 0.6942  data: 0.0005  max mem: 62457
Epoch: [189] Total time: 0:17:03 (0.8182 s / it)
Averaged stats: lr: 0.001340  min_lr: 0.001340  loss: 2.9843 (2.9649)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1704 (1.1620)
Test:  [ 0/25]  eta: 0:03:06  loss: 0.6419 (0.6419)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 7.4421  data: 6.9799  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8159 (0.8132)  acc1: 84.8000 (85.2000)  acc5: 97.6000 (97.9273)  time: 1.0827  data: 0.6348  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9472 (0.9337)  acc1: 81.6000 (82.2667)  acc5: 96.4000 (96.4952)  time: 0.4459  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9676 (0.9413)  acc1: 81.6000 (82.1920)  acc5: 96.0000 (96.4800)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7302 s / it)
* Acc@1 82.626 Acc@5 96.520 loss 0.929
Accuracy of the model on the 50000 test images: 82.6%
Max accuracy: 82.75%
Epoch: [190]  [   0/1251]  eta: 1:32:49  lr: 0.001340  min_lr: 0.001340  loss: 2.8677 (2.8677)  weight_decay: 0.0500 (0.0500)  time: 4.4519  data: 2.8614  max mem: 62457
Epoch: [190]  [ 200/1251]  eta: 0:14:37  lr: 0.001337  min_lr: 0.001337  loss: 3.0207 (2.9636)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3906 (1.3105)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [190]  [ 400/1251]  eta: 0:11:42  lr: 0.001333  min_lr: 0.001333  loss: 3.1197 (2.9631)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8708 (1.1509)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [190]  [ 600/1251]  eta: 0:08:55  lr: 0.001330  min_lr: 0.001330  loss: 3.0391 (2.9555)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8804 (1.0590)  time: 0.8144  data: 0.0004  max mem: 62457
Epoch: [190]  [ 800/1251]  eta: 0:06:10  lr: 0.001327  min_lr: 0.001327  loss: 3.1332 (2.9546)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1527 (1.0746)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [190]  [1000/1251]  eta: 0:03:25  lr: 0.001323  min_lr: 0.001323  loss: 2.9651 (2.9514)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9780 (1.1126)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [190]  [1200/1251]  eta: 0:00:41  lr: 0.001320  min_lr: 0.001320  loss: 3.0731 (2.9538)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9337 (1.1223)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [190]  [1250/1251]  eta: 0:00:00  lr: 0.001319  min_lr: 0.001319  loss: 2.7707 (2.9500)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9385 (1.1166)  time: 0.6927  data: 0.0005  max mem: 62457
Epoch: [190] Total time: 0:17:03 (0.8177 s / it)
Averaged stats: lr: 0.001319  min_lr: 0.001319  loss: 2.7707 (2.9499)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9385 (1.1166)
Test:  [ 0/25]  eta: 0:03:07  loss: 0.5532 (0.5532)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 7.4986  data: 7.0369  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.6991 (0.7099)  acc1: 85.2000 (85.5636)  acc5: 97.6000 (97.6000)  time: 1.0885  data: 0.6400  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8658 (0.8232)  acc1: 81.2000 (82.8571)  acc5: 96.4000 (96.2476)  time: 0.4463  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8671 (0.8306)  acc1: 81.2000 (82.5920)  acc5: 96.0000 (96.2240)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7328 s / it)
* Acc@1 82.798 Acc@5 96.516 loss 0.814
Accuracy of the model on the 50000 test images: 82.8%
Max accuracy: 82.80%
Epoch: [191]  [   0/1251]  eta: 1:33:08  lr: 0.001319  min_lr: 0.001319  loss: 2.2631 (2.2631)  weight_decay: 0.0500 (0.0500)  time: 4.4673  data: 3.6568  max mem: 62457
Epoch: [191]  [ 200/1251]  eta: 0:14:36  lr: 0.001316  min_lr: 0.001316  loss: 2.8784 (2.8866)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8494 (0.9634)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [191]  [ 400/1251]  eta: 0:11:42  lr: 0.001312  min_lr: 0.001312  loss: 3.0674 (2.9340)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0127 (1.0376)  time: 0.8235  data: 0.0004  max mem: 62457
Epoch: [191]  [ 600/1251]  eta: 0:08:55  lr: 0.001309  min_lr: 0.001309  loss: 2.9365 (2.9589)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8840 (1.0488)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [191]  [ 800/1251]  eta: 0:06:10  lr: 0.001305  min_lr: 0.001305  loss: 2.7719 (2.9555)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9737 (1.0580)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [191]  [1000/1251]  eta: 0:03:25  lr: 0.001302  min_lr: 0.001302  loss: 2.8145 (2.9606)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9435 (1.0767)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [191]  [1200/1251]  eta: 0:00:41  lr: 0.001299  min_lr: 0.001299  loss: 3.0901 (2.9553)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0113 (1.0907)  time: 0.8193  data: 0.0004  max mem: 62457
Epoch: [191]  [1250/1251]  eta: 0:00:00  lr: 0.001298  min_lr: 0.001298  loss: 3.0118 (2.9535)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2557 (1.0976)  time: 0.6921  data: 0.0005  max mem: 62457
Epoch: [191] Total time: 0:17:03 (0.8180 s / it)
Averaged stats: lr: 0.001298  min_lr: 0.001298  loss: 3.0118 (2.9396)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2557 (1.0976)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.6484 (0.6484)  acc1: 88.8000 (88.8000)  acc5: 99.2000 (99.2000)  time: 7.7064  data: 7.2260  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8112 (0.7968)  acc1: 86.0000 (85.7455)  acc5: 97.6000 (97.7818)  time: 1.1045  data: 0.6572  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9377 (0.8991)  acc1: 81.2000 (82.9143)  acc5: 96.4000 (96.5524)  time: 0.4444  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9377 (0.9107)  acc1: 81.2000 (82.5920)  acc5: 96.0000 (96.4320)  time: 0.4444  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7396 s / it)
* Acc@1 82.836 Acc@5 96.536 loss 0.900
Accuracy of the model on the 50000 test images: 82.8%
Max accuracy: 82.84%
Epoch: [192]  [   0/1251]  eta: 1:32:44  lr: 0.001298  min_lr: 0.001298  loss: 2.9616 (2.9616)  weight_decay: 0.0500 (0.0500)  time: 4.4484  data: 3.6194  max mem: 62457
Epoch: [192]  [ 200/1251]  eta: 0:14:35  lr: 0.001295  min_lr: 0.001295  loss: 2.9965 (2.9245)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2719 (1.2752)  time: 0.8152  data: 0.0004  max mem: 62457
Epoch: [192]  [ 400/1251]  eta: 0:11:42  lr: 0.001291  min_lr: 0.001291  loss: 2.8355 (2.9284)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9524 (1.1338)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [192]  [ 600/1251]  eta: 0:08:55  lr: 0.001288  min_lr: 0.001288  loss: 2.7978 (2.9099)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2658 (1.1906)  time: 0.8149  data: 0.0004  max mem: 62457
Epoch: [192]  [ 800/1251]  eta: 0:06:09  lr: 0.001284  min_lr: 0.001284  loss: 3.0921 (2.9239)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0424 (1.1761)  time: 0.8151  data: 0.0005  max mem: 62457
Epoch: [192]  [1000/1251]  eta: 0:03:25  lr: 0.001281  min_lr: 0.001281  loss: 3.2050 (2.9265)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2495 (1.1770)  time: 0.8145  data: 0.0004  max mem: 62457
Epoch: [192]  [1200/1251]  eta: 0:00:41  lr: 0.001278  min_lr: 0.001278  loss: 3.0173 (2.9386)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2959 (1.1814)  time: 0.8146  data: 0.0004  max mem: 62457
Epoch: [192]  [1250/1251]  eta: 0:00:00  lr: 0.001277  min_lr: 0.001277  loss: 2.9820 (2.9374)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1716 (1.1754)  time: 0.6920  data: 0.0006  max mem: 62457
Epoch: [192] Total time: 0:17:02 (0.8174 s / it)
Averaged stats: lr: 0.001277  min_lr: 0.001277  loss: 2.9820 (2.9440)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1716 (1.1754)
Test:  [ 0/25]  eta: 0:03:23  loss: 0.5847 (0.5847)  acc1: 88.8000 (88.8000)  acc5: 98.0000 (98.0000)  time: 8.1321  data: 7.6544  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.7496 (0.7187)  acc1: 86.4000 (85.8545)  acc5: 98.0000 (97.8546)  time: 1.1447  data: 0.6961  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.8630 (0.8425)  acc1: 81.2000 (82.6667)  acc5: 96.0000 (96.6667)  time: 0.4460  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9103 (0.8529)  acc1: 80.8000 (82.1920)  acc5: 96.0000 (96.6240)  time: 0.4459  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7582 s / it)
* Acc@1 82.932 Acc@5 96.592 loss 0.838
Accuracy of the model on the 50000 test images: 82.9%
Max accuracy: 82.93%
Epoch: [193]  [   0/1251]  eta: 1:25:10  lr: 0.001277  min_lr: 0.001277  loss: 2.7002 (2.7002)  weight_decay: 0.0500 (0.0500)  time: 4.0852  data: 3.2779  max mem: 62457
Epoch: [193]  [ 200/1251]  eta: 0:14:36  lr: 0.001274  min_lr: 0.001274  loss: 2.7323 (2.9414)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8499 (0.9926)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [193]  [ 400/1251]  eta: 0:11:41  lr: 0.001270  min_lr: 0.001270  loss: 2.9916 (2.9497)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9093 (1.0908)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [193]  [ 600/1251]  eta: 0:08:55  lr: 0.001267  min_lr: 0.001267  loss: 2.8520 (2.9615)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9243 (1.0595)  time: 0.8147  data: 0.0004  max mem: 62457
Epoch: [193]  [ 800/1251]  eta: 0:06:10  lr: 0.001264  min_lr: 0.001264  loss: 3.0146 (2.9713)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9945 (1.0584)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [193]  [1000/1251]  eta: 0:03:25  lr: 0.001260  min_lr: 0.001260  loss: 2.7661 (2.9658)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9621 (1.0820)  time: 0.8150  data: 0.0004  max mem: 62457
Epoch: [193]  [1200/1251]  eta: 0:00:41  lr: 0.001257  min_lr: 0.001257  loss: 3.0248 (2.9632)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9926 (1.0844)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [193]  [1250/1251]  eta: 0:00:00  lr: 0.001256  min_lr: 0.001256  loss: 3.0356 (2.9653)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9679 (1.0825)  time: 0.6999  data: 0.0005  max mem: 62457
Epoch: [193] Total time: 0:17:03 (0.8178 s / it)
Averaged stats: lr: 0.001256  min_lr: 0.001256  loss: 3.0356 (2.9370)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9679 (1.0825)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.6403 (0.6403)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 7.8064  data: 7.3192  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8173 (0.7883)  acc1: 85.6000 (85.6364)  acc5: 97.2000 (97.6000)  time: 1.1144  data: 0.6657  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9100 (0.9084)  acc1: 81.6000 (82.8762)  acc5: 96.8000 (96.4381)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9563 (0.9211)  acc1: 81.6000 (82.5440)  acc5: 96.0000 (96.3840)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7435 s / it)
* Acc@1 82.956 Acc@5 96.496 loss 0.912
Accuracy of the model on the 50000 test images: 83.0%
Max accuracy: 82.96%
Epoch: [194]  [   0/1251]  eta: 1:26:24  lr: 0.001256  min_lr: 0.001256  loss: 2.7578 (2.7578)  weight_decay: 0.0500 (0.0500)  time: 4.1447  data: 3.3339  max mem: 62457
Epoch: [194]  [ 200/1251]  eta: 0:14:33  lr: 0.001253  min_lr: 0.001253  loss: 2.8598 (2.9487)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1400 (1.2903)  time: 0.8148  data: 0.0004  max mem: 62457
Epoch: [194]  [ 400/1251]  eta: 0:11:40  lr: 0.001249  min_lr: 0.001249  loss: 3.1019 (2.9176)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9949 (1.1545)  time: 0.8151  data: 0.0004  max mem: 62457
Epoch: [194]  [ 600/1251]  eta: 0:08:54  lr: 0.001246  min_lr: 0.001246  loss: 3.1108 (2.9311)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2266 (1.1656)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [194]  [ 800/1251]  eta: 0:06:09  lr: 0.001243  min_lr: 0.001243  loss: 3.1168 (2.9363)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9736 (1.1850)  time: 0.8157  data: 0.0004  max mem: 62457
Epoch: [194]  [1000/1251]  eta: 0:03:25  lr: 0.001239  min_lr: 0.001239  loss: 3.1316 (2.9367)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8564 (1.1367)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [194]  [1200/1251]  eta: 0:00:41  lr: 0.001236  min_lr: 0.001236  loss: 2.9416 (2.9287)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9493 (1.1371)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [194]  [1250/1251]  eta: 0:00:00  lr: 0.001235  min_lr: 0.001235  loss: 3.0011 (2.9297)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9571 (1.1385)  time: 0.6920  data: 0.0006  max mem: 62457
Epoch: [194] Total time: 0:17:02 (0.8174 s / it)
Averaged stats: lr: 0.001235  min_lr: 0.001235  loss: 3.0011 (2.9237)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9571 (1.1385)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.6097 (0.6097)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 7.5265  data: 7.0479  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7626 (0.7491)  acc1: 85.2000 (85.5273)  acc5: 98.0000 (97.5273)  time: 1.0899  data: 0.6410  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9035 (0.8725)  acc1: 80.8000 (82.3619)  acc5: 95.6000 (96.3429)  time: 0.4460  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9282 (0.8759)  acc1: 80.8000 (82.3360)  acc5: 96.0000 (96.4000)  time: 0.4458  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7336 s / it)
* Acc@1 82.910 Acc@5 96.566 loss 0.863
Accuracy of the model on the 50000 test images: 82.9%
Max accuracy: 82.96%
Epoch: [195]  [   0/1251]  eta: 1:42:24  lr: 0.001235  min_lr: 0.001235  loss: 3.4736 (3.4736)  weight_decay: 0.0500 (0.0500)  time: 4.9115  data: 2.8434  max mem: 62457
Epoch: [195]  [ 200/1251]  eta: 0:14:38  lr: 0.001232  min_lr: 0.001232  loss: 2.9073 (2.8977)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0620 (1.3437)  time: 0.8149  data: 0.0005  max mem: 62457
Epoch: [195]  [ 400/1251]  eta: 0:11:43  lr: 0.001229  min_lr: 0.001229  loss: 2.9037 (2.9104)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7384 (1.2568)  time: 0.8234  data: 0.0004  max mem: 62457
Epoch: [195]  [ 600/1251]  eta: 0:08:55  lr: 0.001225  min_lr: 0.001225  loss: 3.1381 (2.9270)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9658 (1.1864)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [195]  [ 800/1251]  eta: 0:06:10  lr: 0.001222  min_lr: 0.001222  loss: 2.8669 (2.9179)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9646 (1.1550)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [195]  [1000/1251]  eta: 0:03:25  lr: 0.001219  min_lr: 0.001219  loss: 3.0751 (2.9235)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4822 (1.1620)  time: 0.8153  data: 0.0005  max mem: 62457
Epoch: [195]  [1200/1251]  eta: 0:00:41  lr: 0.001215  min_lr: 0.001215  loss: 2.9420 (2.9297)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1012 (1.1452)  time: 0.8191  data: 0.0005  max mem: 62457
Epoch: [195]  [1250/1251]  eta: 0:00:00  lr: 0.001215  min_lr: 0.001215  loss: 3.1433 (2.9353)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.6919  data: 0.0005  max mem: 62457
Epoch: [195] Total time: 0:17:03 (0.8181 s / it)
Averaged stats: lr: 0.001215  min_lr: 0.001215  loss: 3.1433 (2.9287)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:03:11  loss: 0.6823 (0.6823)  acc1: 88.4000 (88.4000)  acc5: 98.4000 (98.4000)  time: 7.6451  data: 7.1751  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8237 (0.8102)  acc1: 86.0000 (85.7455)  acc5: 97.6000 (97.7455)  time: 1.0988  data: 0.6525  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9638 (0.9326)  acc1: 81.6000 (82.6095)  acc5: 96.4000 (96.4762)  time: 0.4442  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9863 (0.9421)  acc1: 81.6000 (82.2880)  acc5: 96.0000 (96.3680)  time: 0.4443  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7370 s / it)
* Acc@1 83.008 Acc@5 96.494 loss 0.927
Accuracy of the model on the 50000 test images: 83.0%
Max accuracy: 83.01%
Epoch: [196]  [   0/1251]  eta: 1:39:34  lr: 0.001215  min_lr: 0.001215  loss: 2.3520 (2.3520)  weight_decay: 0.0500 (0.0500)  time: 4.7757  data: 3.9541  max mem: 62457
Epoch: [196]  [ 200/1251]  eta: 0:14:38  lr: 0.001211  min_lr: 0.001211  loss: 2.6543 (2.9163)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8228  data: 0.0004  max mem: 62457
Epoch: [196]  [ 400/1251]  eta: 0:11:43  lr: 0.001208  min_lr: 0.001208  loss: 3.0357 (2.8905)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1906 (nan)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [196]  [ 600/1251]  eta: 0:08:55  lr: 0.001205  min_lr: 0.001205  loss: 3.0890 (2.9014)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1488 (nan)  time: 0.8158  data: 0.0005  max mem: 62457
Epoch: [196]  [ 800/1251]  eta: 0:06:10  lr: 0.001201  min_lr: 0.001201  loss: 3.2180 (2.9175)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0414 (nan)  time: 0.8241  data: 0.0004  max mem: 62457
Epoch: [196]  [1000/1251]  eta: 0:03:25  lr: 0.001198  min_lr: 0.001198  loss: 3.0012 (2.9133)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2143 (nan)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [196]  [1200/1251]  eta: 0:00:41  lr: 0.001195  min_lr: 0.001195  loss: 3.1630 (2.9249)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9501 (nan)  time: 0.8156  data: 0.0004  max mem: 62457
Epoch: [196]  [1250/1251]  eta: 0:00:00  lr: 0.001194  min_lr: 0.001194  loss: 3.0941 (2.9248)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9518 (nan)  time: 0.6925  data: 0.0005  max mem: 62457
Epoch: [196] Total time: 0:17:03 (0.8183 s / it)
Averaged stats: lr: 0.001194  min_lr: 0.001194  loss: 3.0941 (2.9212)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9518 (nan)
Test:  [ 0/25]  eta: 0:03:24  loss: 0.6366 (0.6366)  acc1: 88.0000 (88.0000)  acc5: 98.8000 (98.8000)  time: 8.1676  data: 7.6959  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.7325 (0.7654)  acc1: 85.6000 (85.7455)  acc5: 98.0000 (97.9273)  time: 1.1474  data: 0.6999  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9141 (0.8754)  acc1: 82.0000 (82.8762)  acc5: 96.4000 (96.6286)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9141 (0.8859)  acc1: 82.0000 (82.3680)  acc5: 96.0000 (96.6240)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7592 s / it)
* Acc@1 82.794 Acc@5 96.620 loss 0.874
Accuracy of the model on the 50000 test images: 82.8%
Max accuracy: 83.01%
Epoch: [197]  [   0/1251]  eta: 1:39:41  lr: 0.001194  min_lr: 0.001194  loss: 3.2919 (3.2919)  weight_decay: 0.0500 (0.0500)  time: 4.7812  data: 2.8858  max mem: 62457
Epoch: [197]  [ 200/1251]  eta: 0:14:42  lr: 0.001191  min_lr: 0.001191  loss: 2.9386 (2.9615)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1437 (1.2529)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [197]  [ 400/1251]  eta: 0:11:44  lr: 0.001187  min_lr: 0.001187  loss: 2.9239 (2.9306)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8905 (1.1341)  time: 0.8155  data: 0.0004  max mem: 62457
Epoch: [197]  [ 600/1251]  eta: 0:08:56  lr: 0.001184  min_lr: 0.001184  loss: 2.7916 (2.9160)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1504 (1.1866)  time: 0.8234  data: 0.0004  max mem: 62457
Epoch: [197]  [ 800/1251]  eta: 0:06:10  lr: 0.001181  min_lr: 0.001181  loss: 2.9993 (2.9233)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0672 (1.2058)  time: 0.8158  data: 0.0004  max mem: 62457
Epoch: [197]  [1000/1251]  eta: 0:03:26  lr: 0.001178  min_lr: 0.001178  loss: 3.1226 (2.9243)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0416 (1.1921)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [197]  [1200/1251]  eta: 0:00:41  lr: 0.001174  min_lr: 0.001174  loss: 3.1483 (2.9268)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9648 (1.1847)  time: 0.8205  data: 0.0004  max mem: 62457
Epoch: [197]  [1250/1251]  eta: 0:00:00  lr: 0.001174  min_lr: 0.001174  loss: 3.1670 (2.9264)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9039 (1.1789)  time: 0.6931  data: 0.0006  max mem: 62457
Epoch: [197] Total time: 0:17:04 (0.8193 s / it)
Averaged stats: lr: 0.001174  min_lr: 0.001174  loss: 3.1670 (2.9234)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9039 (1.1789)
Test:  [ 0/25]  eta: 0:02:55  loss: 0.7011 (0.7011)  acc1: 87.2000 (87.2000)  acc5: 98.8000 (98.8000)  time: 7.0132  data: 6.5459  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8219 (0.8355)  acc1: 86.8000 (85.3818)  acc5: 97.6000 (97.7091)  time: 1.0427  data: 0.5954  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9626 (0.9601)  acc1: 81.6000 (82.6286)  acc5: 96.4000 (96.4000)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0084 (0.9665)  acc1: 81.6000 (82.2240)  acc5: 96.0000 (96.2400)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7118 s / it)
* Acc@1 82.730 Acc@5 96.452 loss 0.951
Accuracy of the model on the 50000 test images: 82.7%
Max accuracy: 83.01%
Epoch: [198]  [   0/1251]  eta: 1:37:52  lr: 0.001174  min_lr: 0.001174  loss: 2.2412 (2.2412)  weight_decay: 0.0500 (0.0500)  time: 4.6938  data: 3.8681  max mem: 62457
Epoch: [198]  [ 200/1251]  eta: 0:14:38  lr: 0.001170  min_lr: 0.001170  loss: 2.9820 (2.9117)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0361 (1.1002)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [198]  [ 400/1251]  eta: 0:11:42  lr: 0.001167  min_lr: 0.001167  loss: 2.8968 (2.9240)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1214 (1.1684)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [198]  [ 600/1251]  eta: 0:08:56  lr: 0.001164  min_lr: 0.001164  loss: 3.1085 (2.9258)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9010 (1.1401)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [198]  [ 800/1251]  eta: 0:06:10  lr: 0.001161  min_lr: 0.001161  loss: 2.9852 (2.9308)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1627 (1.1445)  time: 0.8155  data: 0.0005  max mem: 62457
Epoch: [198]  [1000/1251]  eta: 0:03:25  lr: 0.001157  min_lr: 0.001157  loss: 2.9531 (2.9246)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0469 (1.1349)  time: 0.8238  data: 0.0004  max mem: 62457
Epoch: [198]  [1200/1251]  eta: 0:00:41  lr: 0.001154  min_lr: 0.001154  loss: 2.9470 (2.9262)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1291 (1.1278)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [198]  [1250/1251]  eta: 0:00:00  lr: 0.001153  min_lr: 0.001153  loss: 3.0589 (2.9274)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1291 (1.1317)  time: 0.6928  data: 0.0007  max mem: 62457
Epoch: [198] Total time: 0:17:04 (0.8190 s / it)
Averaged stats: lr: 0.001153  min_lr: 0.001153  loss: 3.0589 (2.9122)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1291 (1.1317)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.7263 (0.7263)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.7710  data: 7.2977  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8469 (0.8522)  acc1: 86.0000 (85.7091)  acc5: 97.6000 (97.8909)  time: 1.1115  data: 0.6637  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 1.0434 (0.9750)  acc1: 80.4000 (82.6286)  acc5: 96.4000 (96.5143)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0434 (0.9829)  acc1: 81.2000 (82.5120)  acc5: 95.6000 (96.3520)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7427 s / it)
* Acc@1 82.946 Acc@5 96.420 loss 0.975
Accuracy of the model on the 50000 test images: 82.9%
Max accuracy: 83.01%
Epoch: [199]  [   0/1251]  eta: 1:37:22  lr: 0.001153  min_lr: 0.001153  loss: 3.3225 (3.3225)  weight_decay: 0.0500 (0.0500)  time: 4.6704  data: 2.1729  max mem: 62457
Epoch: [199]  [ 200/1251]  eta: 0:14:37  lr: 0.001150  min_lr: 0.001150  loss: 3.0171 (2.8880)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8550 (1.0227)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [199]  [ 400/1251]  eta: 0:11:44  lr: 0.001147  min_lr: 0.001147  loss: 2.8584 (2.9153)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0971 (1.1892)  time: 0.8239  data: 0.0004  max mem: 62457
Epoch: [199]  [ 600/1251]  eta: 0:08:56  lr: 0.001143  min_lr: 0.001143  loss: 2.8865 (2.9173)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [199]  [ 800/1251]  eta: 0:06:10  lr: 0.001140  min_lr: 0.001140  loss: 2.6845 (2.9112)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0274 (nan)  time: 0.8217  data: 0.0004  max mem: 62457
Epoch: [199]  [1000/1251]  eta: 0:03:26  lr: 0.001137  min_lr: 0.001137  loss: 2.7839 (2.9144)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1624 (nan)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [199]  [1200/1251]  eta: 0:00:41  lr: 0.001134  min_lr: 0.001134  loss: 2.9382 (2.9104)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0747 (nan)  time: 0.8168  data: 0.0005  max mem: 62457
Epoch: [199]  [1250/1251]  eta: 0:00:00  lr: 0.001133  min_lr: 0.001133  loss: 3.1047 (2.9134)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1110 (nan)  time: 0.6938  data: 0.0006  max mem: 62457
Epoch: [199] Total time: 0:17:04 (0.8190 s / it)
Averaged stats: lr: 0.001133  min_lr: 0.001133  loss: 3.1047 (2.9081)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1110 (nan)
Test:  [ 0/25]  eta: 0:02:30  loss: 0.6547 (0.6547)  acc1: 88.4000 (88.4000)  acc5: 98.4000 (98.4000)  time: 6.0283  data: 5.5283  max mem: 62457
Test:  [10/25]  eta: 0:00:14  loss: 0.7736 (0.7696)  acc1: 86.0000 (85.6000)  acc5: 98.0000 (97.7455)  time: 0.9536  data: 0.5029  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9022 (0.8785)  acc1: 80.8000 (82.8000)  acc5: 96.4000 (96.7238)  time: 0.4457  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9289 (0.8884)  acc1: 80.8000 (82.4480)  acc5: 96.0000 (96.6880)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:16 (0.6740 s / it)
* Acc@1 83.030 Acc@5 96.642 loss 0.879
Accuracy of the model on the 50000 test images: 83.0%
Max accuracy: 83.03%
Epoch: [200]  [   0/1251]  eta: 1:25:23  lr: 0.001133  min_lr: 0.001133  loss: 2.1177 (2.1177)  weight_decay: 0.0500 (0.0500)  time: 4.0956  data: 3.2605  max mem: 62457
Epoch: [200]  [ 200/1251]  eta: 0:14:36  lr: 0.001130  min_lr: 0.001130  loss: 2.7605 (2.8975)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4304 (1.3481)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [200]  [ 400/1251]  eta: 0:11:43  lr: 0.001126  min_lr: 0.001126  loss: 2.9938 (2.8889)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2020 (1.3107)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [200]  [ 600/1251]  eta: 0:08:56  lr: 0.001123  min_lr: 0.001123  loss: 2.7950 (2.8888)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9658 (1.2254)  time: 0.8163  data: 0.0005  max mem: 62457
Epoch: [200]  [ 800/1251]  eta: 0:06:10  lr: 0.001120  min_lr: 0.001120  loss: 3.0793 (2.8960)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8111 (1.1878)  time: 0.8205  data: 0.0004  max mem: 62457
Epoch: [200]  [1000/1251]  eta: 0:03:26  lr: 0.001117  min_lr: 0.001117  loss: 2.8548 (2.9031)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8357 (1.1514)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [200]  [1200/1251]  eta: 0:00:41  lr: 0.001114  min_lr: 0.001114  loss: 3.1140 (2.9035)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3318 (1.1618)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [200]  [1250/1251]  eta: 0:00:00  lr: 0.001113  min_lr: 0.001113  loss: 2.9437 (2.9034)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8551 (1.1573)  time: 0.6938  data: 0.0006  max mem: 62457
Epoch: [200] Total time: 0:17:04 (0.8190 s / it)
Averaged stats: lr: 0.001113  min_lr: 0.001113  loss: 2.9437 (2.9027)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8551 (1.1573)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.6411 (0.6411)  acc1: 88.8000 (88.8000)  acc5: 98.4000 (98.4000)  time: 7.8051  data: 7.3419  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7784 (0.7493)  acc1: 86.4000 (85.8546)  acc5: 97.6000 (97.7091)  time: 1.1158  data: 0.6677  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8851 (0.8632)  acc1: 82.0000 (83.2952)  acc5: 96.0000 (96.4191)  time: 0.4464  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9326 (0.8770)  acc1: 81.6000 (82.8160)  acc5: 96.0000 (96.3520)  time: 0.4460  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7447 s / it)
* Acc@1 83.066 Acc@5 96.542 loss 0.865
Accuracy of the model on the 50000 test images: 83.1%
Max accuracy: 83.07%
Epoch: [201]  [   0/1251]  eta: 1:33:29  lr: 0.001113  min_lr: 0.001113  loss: 3.0368 (3.0368)  weight_decay: 0.0500 (0.0500)  time: 4.4841  data: 3.6563  max mem: 62457
Epoch: [201]  [ 200/1251]  eta: 0:14:41  lr: 0.001110  min_lr: 0.001110  loss: 2.9213 (2.8562)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1854 (1.2772)  time: 0.8169  data: 0.0004  max mem: 62457
Epoch: [201]  [ 400/1251]  eta: 0:11:44  lr: 0.001106  min_lr: 0.001106  loss: 2.7323 (2.8627)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0884 (1.2681)  time: 0.8171  data: 0.0004  max mem: 62457
Epoch: [201]  [ 600/1251]  eta: 0:08:56  lr: 0.001103  min_lr: 0.001103  loss: 3.0965 (2.8741)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0133 (1.2048)  time: 0.8174  data: 0.0004  max mem: 62457
Epoch: [201]  [ 800/1251]  eta: 0:06:11  lr: 0.001100  min_lr: 0.001100  loss: 2.8566 (2.8785)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0110 (1.2252)  time: 0.8172  data: 0.0004  max mem: 62457
Epoch: [201]  [1000/1251]  eta: 0:03:26  lr: 0.001097  min_lr: 0.001097  loss: 2.9893 (2.8812)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9905 (1.2134)  time: 0.8174  data: 0.0004  max mem: 62457
Epoch: [201]  [1200/1251]  eta: 0:00:41  lr: 0.001094  min_lr: 0.001094  loss: 3.1215 (2.8821)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1616 (1.1950)  time: 0.8245  data: 0.0004  max mem: 62457
Epoch: [201]  [1250/1251]  eta: 0:00:00  lr: 0.001093  min_lr: 0.001093  loss: 3.0543 (2.8852)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9915 (1.1896)  time: 0.6937  data: 0.0005  max mem: 62457
Epoch: [201] Total time: 0:17:06 (0.8203 s / it)
Averaged stats: lr: 0.001093  min_lr: 0.001093  loss: 3.0543 (2.8989)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9915 (1.1896)
Test:  [ 0/25]  eta: 0:02:24  loss: 0.7394 (0.7394)  acc1: 89.2000 (89.2000)  acc5: 98.4000 (98.4000)  time: 5.7780  data: 5.2797  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.8607 (0.8437)  acc1: 87.6000 (86.0000)  acc5: 97.6000 (97.7091)  time: 1.0608  data: 0.5972  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9702 (0.9407)  acc1: 80.8000 (83.0286)  acc5: 96.8000 (96.7429)  time: 0.5177  data: 0.0645  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9886 (0.9504)  acc1: 80.8000 (82.6880)  acc5: 96.4000 (96.7360)  time: 0.4493  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7208 s / it)
* Acc@1 82.970 Acc@5 96.638 loss 0.939
Accuracy of the model on the 50000 test images: 83.0%
Max accuracy: 83.07%
Epoch: [202]  [   0/1251]  eta: 1:39:49  lr: 0.001093  min_lr: 0.001093  loss: 1.8653 (1.8653)  weight_decay: 0.0500 (0.0500)  time: 4.7874  data: 3.4608  max mem: 62457
Epoch: [202]  [ 200/1251]  eta: 0:14:39  lr: 0.001090  min_lr: 0.001090  loss: 2.8947 (2.8508)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4513 (1.3988)  time: 0.8169  data: 0.0004  max mem: 62457
Epoch: [202]  [ 400/1251]  eta: 0:11:43  lr: 0.001086  min_lr: 0.001086  loss: 3.0072 (2.8771)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3764 (1.3414)  time: 0.8175  data: 0.0004  max mem: 62457
Epoch: [202]  [ 600/1251]  eta: 0:08:57  lr: 0.001083  min_lr: 0.001083  loss: 3.0204 (2.8735)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0294 (1.3267)  time: 0.8172  data: 0.0004  max mem: 62457
Epoch: [202]  [ 800/1251]  eta: 0:06:11  lr: 0.001080  min_lr: 0.001080  loss: 3.0180 (2.8773)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9607 (1.2957)  time: 0.8174  data: 0.0004  max mem: 62457
Epoch: [202]  [1000/1251]  eta: 0:03:26  lr: 0.001077  min_lr: 0.001077  loss: 2.8165 (2.8697)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8854 (1.2598)  time: 0.8230  data: 0.0004  max mem: 62457
Epoch: [202]  [1200/1251]  eta: 0:00:41  lr: 0.001074  min_lr: 0.001074  loss: 2.9306 (2.8740)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3982 (1.2995)  time: 0.8176  data: 0.0004  max mem: 62457
Epoch: [202]  [1250/1251]  eta: 0:00:00  lr: 0.001073  min_lr: 0.001073  loss: 2.9601 (2.8772)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1556 (1.2899)  time: 0.6937  data: 0.0005  max mem: 62457
Epoch: [202] Total time: 0:17:06 (0.8204 s / it)
Averaged stats: lr: 0.001073  min_lr: 0.001073  loss: 2.9601 (2.8939)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1556 (1.2899)
Test:  [ 0/25]  eta: 0:03:05  loss: 0.6636 (0.6636)  acc1: 89.2000 (89.2000)  acc5: 98.4000 (98.4000)  time: 7.4223  data: 6.9227  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8061 (0.7818)  acc1: 84.4000 (85.7818)  acc5: 97.6000 (97.7091)  time: 1.0800  data: 0.6297  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9305 (0.8912)  acc1: 82.4000 (83.2571)  acc5: 96.4000 (96.5524)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9420 (0.8998)  acc1: 82.4000 (82.9600)  acc5: 96.0000 (96.5280)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7284 s / it)
* Acc@1 83.108 Acc@5 96.612 loss 0.889
Accuracy of the model on the 50000 test images: 83.1%
Max accuracy: 83.11%
Epoch: [203]  [   0/1251]  eta: 1:21:52  lr: 0.001073  min_lr: 0.001073  loss: 2.6445 (2.6445)  weight_decay: 0.0500 (0.0500)  time: 3.9265  data: 3.0952  max mem: 62457
Epoch: [203]  [ 200/1251]  eta: 0:14:35  lr: 0.001070  min_lr: 0.001070  loss: 2.6566 (2.9197)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2283 (1.2087)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [203]  [ 400/1251]  eta: 0:11:43  lr: 0.001066  min_lr: 0.001066  loss: 3.1315 (2.9161)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9720 (1.2264)  time: 0.8169  data: 0.0004  max mem: 62457
Epoch: [203]  [ 600/1251]  eta: 0:08:56  lr: 0.001063  min_lr: 0.001063  loss: 2.6596 (2.8985)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0118 (1.2082)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [203]  [ 800/1251]  eta: 0:06:10  lr: 0.001060  min_lr: 0.001060  loss: 2.7595 (2.8930)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1934 (1.2358)  time: 0.8202  data: 0.0004  max mem: 62457
Epoch: [203]  [1000/1251]  eta: 0:03:26  lr: 0.001057  min_lr: 0.001057  loss: 3.1523 (2.9048)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9657 (1.1935)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [203]  [1200/1251]  eta: 0:00:41  lr: 0.001054  min_lr: 0.001054  loss: 3.1262 (2.9081)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9722 (1.1987)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [203]  [1250/1251]  eta: 0:00:00  lr: 0.001053  min_lr: 0.001053  loss: 2.7516 (2.9047)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9414 (1.1879)  time: 0.6934  data: 0.0005  max mem: 62457
Epoch: [203] Total time: 0:17:04 (0.8190 s / it)
Averaged stats: lr: 0.001053  min_lr: 0.001053  loss: 2.7516 (2.8951)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9414 (1.1879)
Test:  [ 0/25]  eta: 0:03:04  loss: 0.6005 (0.6005)  acc1: 90.4000 (90.4000)  acc5: 98.4000 (98.4000)  time: 7.3908  data: 6.9155  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7552 (0.7482)  acc1: 86.8000 (86.0727)  acc5: 97.6000 (97.6000)  time: 1.0768  data: 0.6290  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8868 (0.8518)  acc1: 82.0000 (83.2381)  acc5: 96.4000 (96.7429)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9008 (0.8636)  acc1: 82.0000 (82.9920)  acc5: 96.0000 (96.6560)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7277 s / it)
* Acc@1 83.238 Acc@5 96.682 loss 0.854
Accuracy of the model on the 50000 test images: 83.2%
Max accuracy: 83.24%
Epoch: [204]  [   0/1251]  eta: 1:21:08  lr: 0.001053  min_lr: 0.001053  loss: 2.1935 (2.1935)  weight_decay: 0.0500 (0.0500)  time: 3.8915  data: 3.0794  max mem: 62457
Epoch: [204]  [ 200/1251]  eta: 0:14:35  lr: 0.001050  min_lr: 0.001050  loss: 2.9520 (2.8725)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1616 (1.1569)  time: 0.8244  data: 0.0004  max mem: 62457
Epoch: [204]  [ 400/1251]  eta: 0:11:42  lr: 0.001047  min_lr: 0.001047  loss: 3.0867 (2.8683)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1055 (1.2649)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [204]  [ 600/1251]  eta: 0:08:55  lr: 0.001044  min_lr: 0.001044  loss: 2.9154 (2.8810)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9755 (1.2099)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [204]  [ 800/1251]  eta: 0:06:10  lr: 0.001040  min_lr: 0.001040  loss: 2.9158 (2.8832)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2960 (1.2316)  time: 0.8262  data: 0.0004  max mem: 62457
Epoch: [204]  [1000/1251]  eta: 0:03:26  lr: 0.001037  min_lr: 0.001037  loss: 2.8947 (2.8788)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1378 (1.2001)  time: 0.8175  data: 0.0004  max mem: 62457
Epoch: [204]  [1200/1251]  eta: 0:00:41  lr: 0.001034  min_lr: 0.001034  loss: 3.0334 (2.8893)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1039 (1.2149)  time: 0.8174  data: 0.0004  max mem: 62457
Epoch: [204]  [1250/1251]  eta: 0:00:00  lr: 0.001033  min_lr: 0.001033  loss: 3.0218 (2.8907)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0382 (1.2059)  time: 0.6941  data: 0.0009  max mem: 62457
Epoch: [204] Total time: 0:17:05 (0.8194 s / it)
Averaged stats: lr: 0.001033  min_lr: 0.001033  loss: 3.0218 (2.8829)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0382 (1.2059)
Test:  [ 0/25]  eta: 0:02:57  loss: 0.6360 (0.6360)  acc1: 87.6000 (87.6000)  acc5: 99.2000 (99.2000)  time: 7.0964  data: 6.6336  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.7987 (0.7784)  acc1: 85.2000 (85.5273)  acc5: 98.0000 (97.8909)  time: 1.0575  data: 0.6107  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9289 (0.8907)  acc1: 82.0000 (83.0476)  acc5: 96.4000 (96.5905)  time: 0.4495  data: 0.0042  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9507 (0.9015)  acc1: 81.6000 (82.7360)  acc5: 96.4000 (96.5760)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7188 s / it)
* Acc@1 83.262 Acc@5 96.664 loss 0.887
Accuracy of the model on the 50000 test images: 83.3%
Max accuracy: 83.26%
Epoch: [205]  [   0/1251]  eta: 1:15:09  lr: 0.001033  min_lr: 0.001033  loss: 2.7965 (2.7965)  weight_decay: 0.0500 (0.0500)  time: 3.6047  data: 2.7870  max mem: 62457
Epoch: [205]  [ 200/1251]  eta: 0:14:36  lr: 0.001030  min_lr: 0.001030  loss: 3.0841 (2.9376)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4779 (1.2936)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [205]  [ 400/1251]  eta: 0:11:42  lr: 0.001027  min_lr: 0.001027  loss: 2.9940 (2.9146)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1839 (1.2684)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [205]  [ 600/1251]  eta: 0:08:55  lr: 0.001024  min_lr: 0.001024  loss: 3.0384 (2.8953)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0548 (1.2269)  time: 0.8169  data: 0.0004  max mem: 62457
Epoch: [205]  [ 800/1251]  eta: 0:06:10  lr: 0.001021  min_lr: 0.001021  loss: 2.9857 (2.8986)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3241 (1.2232)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [205]  [1000/1251]  eta: 0:03:26  lr: 0.001018  min_lr: 0.001018  loss: 3.1155 (2.8979)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2098 (1.2291)  time: 0.8166  data: 0.0004  max mem: 62457
Epoch: [205]  [1200/1251]  eta: 0:00:41  lr: 0.001014  min_lr: 0.001014  loss: 3.0312 (2.8912)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9564 (1.2259)  time: 0.8276  data: 0.0004  max mem: 62457
Epoch: [205]  [1250/1251]  eta: 0:00:00  lr: 0.001014  min_lr: 0.001014  loss: 3.0489 (2.8905)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9309 (1.2149)  time: 0.6925  data: 0.0005  max mem: 62457
Epoch: [205] Total time: 0:17:04 (0.8191 s / it)
Averaged stats: lr: 0.001014  min_lr: 0.001014  loss: 3.0489 (2.8750)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9309 (1.2149)
Test:  [ 0/25]  eta: 0:03:11  loss: 0.6917 (0.6917)  acc1: 87.6000 (87.6000)  acc5: 98.4000 (98.4000)  time: 7.6771  data: 7.1931  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7805 (0.7948)  acc1: 86.4000 (85.7091)  acc5: 97.6000 (97.6727)  time: 1.1028  data: 0.6542  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9214 (0.9094)  acc1: 83.2000 (83.1048)  acc5: 96.4000 (96.4762)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9521 (0.9180)  acc1: 82.4000 (82.7360)  acc5: 96.0000 (96.4000)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7389 s / it)
* Acc@1 83.208 Acc@5 96.658 loss 0.897
Accuracy of the model on the 50000 test images: 83.2%
Max accuracy: 83.26%
Epoch: [206]  [   0/1251]  eta: 1:40:38  lr: 0.001014  min_lr: 0.001014  loss: 2.8464 (2.8464)  weight_decay: 0.0500 (0.0500)  time: 4.8273  data: 3.7105  max mem: 62457
Epoch: [206]  [ 200/1251]  eta: 0:14:39  lr: 0.001011  min_lr: 0.001011  loss: 2.9732 (2.8278)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0790 (1.2573)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [206]  [ 400/1251]  eta: 0:11:43  lr: 0.001007  min_lr: 0.001007  loss: 2.8295 (2.8491)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1305 (1.2725)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [206]  [ 600/1251]  eta: 0:08:56  lr: 0.001004  min_lr: 0.001004  loss: 3.0179 (2.8446)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2237 (1.2534)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [206]  [ 800/1251]  eta: 0:06:10  lr: 0.001001  min_lr: 0.001001  loss: 3.1632 (2.8539)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1767 (1.2558)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [206]  [1000/1251]  eta: 0:03:26  lr: 0.000998  min_lr: 0.000998  loss: 2.9558 (2.8562)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1260 (1.2505)  time: 0.8195  data: 0.0004  max mem: 62457
Epoch: [206]  [1200/1251]  eta: 0:00:41  lr: 0.000995  min_lr: 0.000995  loss: 2.7192 (2.8607)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2239 (1.3058)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [206]  [1250/1251]  eta: 0:00:00  lr: 0.000994  min_lr: 0.000994  loss: 2.9556 (2.8609)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1936 (1.3047)  time: 0.6933  data: 0.0007  max mem: 62457
Epoch: [206] Total time: 0:17:04 (0.8189 s / it)
Averaged stats: lr: 0.000994  min_lr: 0.000994  loss: 2.9556 (2.8714)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1936 (1.3047)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.6273 (0.6273)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 7.7789  data: 7.2974  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7698 (0.7553)  acc1: 85.2000 (85.8182)  acc5: 98.0000 (97.8909)  time: 1.1127  data: 0.6637  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8841 (0.8802)  acc1: 82.0000 (83.0286)  acc5: 96.8000 (96.7429)  time: 0.4461  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9506 (0.8899)  acc1: 81.6000 (82.9280)  acc5: 96.4000 (96.6720)  time: 0.4460  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7439 s / it)
* Acc@1 83.356 Acc@5 96.688 loss 0.874
Accuracy of the model on the 50000 test images: 83.4%
Max accuracy: 83.36%
Epoch: [207]  [   0/1251]  eta: 1:29:36  lr: 0.000994  min_lr: 0.000994  loss: 3.0608 (3.0608)  weight_decay: 0.0500 (0.0500)  time: 4.2980  data: 3.4820  max mem: 62457
Epoch: [207]  [ 200/1251]  eta: 0:14:36  lr: 0.000991  min_lr: 0.000991  loss: 2.9630 (2.8669)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1238 (1.0632)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [207]  [ 400/1251]  eta: 0:11:43  lr: 0.000988  min_lr: 0.000988  loss: 3.0685 (2.8557)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9217 (1.0992)  time: 0.8162  data: 0.0004  max mem: 62457
Epoch: [207]  [ 600/1251]  eta: 0:08:56  lr: 0.000985  min_lr: 0.000985  loss: 3.0872 (2.8698)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0232 (1.1186)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [207]  [ 800/1251]  eta: 0:06:10  lr: 0.000982  min_lr: 0.000982  loss: 2.8925 (2.8706)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8993 (1.1182)  time: 0.8163  data: 0.0004  max mem: 62457
Epoch: [207]  [1000/1251]  eta: 0:03:26  lr: 0.000979  min_lr: 0.000979  loss: 2.9348 (2.8675)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0475 (1.1140)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [207]  [1200/1251]  eta: 0:00:41  lr: 0.000976  min_lr: 0.000976  loss: 2.8512 (2.8745)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8736 (1.2070)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [207]  [1250/1251]  eta: 0:00:00  lr: 0.000975  min_lr: 0.000975  loss: 3.0101 (2.8743)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4634 (1.2250)  time: 0.6927  data: 0.0005  max mem: 62457
Epoch: [207] Total time: 0:17:04 (0.8189 s / it)
Averaged stats: lr: 0.000975  min_lr: 0.000975  loss: 3.0101 (2.8744)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4634 (1.2250)
Test:  [ 0/25]  eta: 0:03:21  loss: 0.6695 (0.6695)  acc1: 87.2000 (87.2000)  acc5: 98.8000 (98.8000)  time: 8.0408  data: 7.5825  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8109 (0.7977)  acc1: 86.4000 (85.8545)  acc5: 97.6000 (97.6727)  time: 1.1385  data: 0.6896  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9199 (0.9012)  acc1: 82.4000 (83.1619)  acc5: 96.4000 (96.6667)  time: 0.4468  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9496 (0.9152)  acc1: 81.2000 (82.6880)  acc5: 96.4000 (96.6400)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7549 s / it)
* Acc@1 83.258 Acc@5 96.662 loss 0.898
Accuracy of the model on the 50000 test images: 83.3%
Max accuracy: 83.36%
Epoch: [208]  [   0/1251]  eta: 1:44:06  lr: 0.000975  min_lr: 0.000975  loss: 3.2471 (3.2471)  weight_decay: 0.0500 (0.0500)  time: 4.9932  data: 3.6131  max mem: 62457
Epoch: [208]  [ 200/1251]  eta: 0:14:43  lr: 0.000972  min_lr: 0.000972  loss: 3.0406 (2.8520)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9718 (1.2276)  time: 0.8308  data: 0.0004  max mem: 62457
Epoch: [208]  [ 400/1251]  eta: 0:11:45  lr: 0.000969  min_lr: 0.000969  loss: 2.8681 (2.8707)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1695 (1.2863)  time: 0.8165  data: 0.0005  max mem: 62457
Epoch: [208]  [ 600/1251]  eta: 0:08:56  lr: 0.000966  min_lr: 0.000966  loss: 3.0473 (2.8664)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1030 (1.2520)  time: 0.8167  data: 0.0005  max mem: 62457
Epoch: [208]  [ 800/1251]  eta: 0:06:11  lr: 0.000963  min_lr: 0.000963  loss: 2.9056 (2.8662)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2477 (1.2932)  time: 0.8199  data: 0.0005  max mem: 62457
Epoch: [208]  [1000/1251]  eta: 0:03:26  lr: 0.000960  min_lr: 0.000960  loss: 2.9759 (2.8721)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5742 (1.2969)  time: 0.8153  data: 0.0005  max mem: 62457
Epoch: [208]  [1200/1251]  eta: 0:00:41  lr: 0.000956  min_lr: 0.000956  loss: 2.9005 (2.8699)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9277 (1.2501)  time: 0.8159  data: 0.0005  max mem: 62457
Epoch: [208]  [1250/1251]  eta: 0:00:00  lr: 0.000956  min_lr: 0.000956  loss: 3.0667 (2.8701)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0043 (1.2459)  time: 0.6930  data: 0.0006  max mem: 62457
Epoch: [208] Total time: 0:17:05 (0.8196 s / it)
Averaged stats: lr: 0.000956  min_lr: 0.000956  loss: 3.0667 (2.8719)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0043 (1.2459)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.6584 (0.6584)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 7.5423  data: 7.0482  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.7527 (0.7727)  acc1: 86.4000 (85.9636)  acc5: 97.6000 (97.6364)  time: 1.1412  data: 0.6776  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9327 (0.8901)  acc1: 83.2000 (83.0286)  acc5: 96.4000 (96.4762)  time: 0.4738  data: 0.0203  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9702 (0.9020)  acc1: 82.4000 (82.6240)  acc5: 96.0000 (96.4160)  time: 0.4496  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7589 s / it)
* Acc@1 83.246 Acc@5 96.630 loss 0.887
Accuracy of the model on the 50000 test images: 83.2%
Max accuracy: 83.36%
Epoch: [209]  [   0/1251]  eta: 1:29:17  lr: 0.000956  min_lr: 0.000956  loss: 1.8430 (1.8430)  weight_decay: 0.0500 (0.0500)  time: 4.2822  data: 2.3890  max mem: 62457
Epoch: [209]  [ 200/1251]  eta: 0:14:38  lr: 0.000953  min_lr: 0.000953  loss: 2.9742 (2.8393)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8917 (1.1354)  time: 0.8153  data: 0.0004  max mem: 62457
Epoch: [209]  [ 400/1251]  eta: 0:11:42  lr: 0.000950  min_lr: 0.000950  loss: 2.9837 (2.8120)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0465 (1.1668)  time: 0.8154  data: 0.0004  max mem: 62457
Epoch: [209]  [ 600/1251]  eta: 0:08:55  lr: 0.000947  min_lr: 0.000947  loss: 2.8554 (2.8214)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4078 (1.2372)  time: 0.8199  data: 0.0004  max mem: 62457
Epoch: [209]  [ 800/1251]  eta: 0:06:10  lr: 0.000944  min_lr: 0.000944  loss: 3.0428 (2.8229)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9707 (1.2122)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [209]  [1000/1251]  eta: 0:03:25  lr: 0.000940  min_lr: 0.000940  loss: 3.1343 (2.8403)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4203 (1.2131)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [209]  [1200/1251]  eta: 0:00:41  lr: 0.000937  min_lr: 0.000937  loss: 2.7750 (2.8542)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2548 (nan)  time: 0.8159  data: 0.0004  max mem: 62457
Epoch: [209]  [1250/1251]  eta: 0:00:00  lr: 0.000937  min_lr: 0.000937  loss: 2.8288 (2.8562)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3159 (nan)  time: 0.6930  data: 0.0006  max mem: 62457
Epoch: [209] Total time: 0:17:04 (0.8187 s / it)
Averaged stats: lr: 0.000937  min_lr: 0.000937  loss: 2.8288 (2.8558)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3159 (nan)
Test:  [ 0/25]  eta: 0:02:30  loss: 0.6090 (0.6090)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 6.0305  data: 5.4949  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.7049 (0.7210)  acc1: 86.8000 (85.9273)  acc5: 98.0000 (97.9273)  time: 1.0216  data: 0.5682  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8666 (0.8364)  acc1: 82.0000 (83.2571)  acc5: 96.8000 (96.8191)  time: 0.4824  data: 0.0378  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8698 (0.8476)  acc1: 82.0000 (82.9440)  acc5: 96.0000 (96.6720)  time: 0.4441  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7025 s / it)
* Acc@1 83.256 Acc@5 96.702 loss 0.835
Accuracy of the model on the 50000 test images: 83.3%
Max accuracy: 83.36%
Epoch: [210]  [   0/1251]  eta: 1:35:03  lr: 0.000937  min_lr: 0.000937  loss: 3.0079 (3.0079)  weight_decay: 0.0500 (0.0500)  time: 4.5591  data: 3.2085  max mem: 62457
Epoch: [210]  [ 200/1251]  eta: 0:14:38  lr: 0.000934  min_lr: 0.000934  loss: 3.0079 (2.8355)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8532 (1.0533)  time: 0.8242  data: 0.0004  max mem: 62457
Epoch: [210]  [ 400/1251]  eta: 0:11:43  lr: 0.000931  min_lr: 0.000931  loss: 2.9614 (2.8358)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3481 (1.2723)  time: 0.8244  data: 0.0004  max mem: 62457
Epoch: [210]  [ 600/1251]  eta: 0:08:57  lr: 0.000928  min_lr: 0.000928  loss: 3.0235 (2.8539)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0845 (1.2108)  time: 0.8169  data: 0.0004  max mem: 62457
Epoch: [210]  [ 800/1251]  eta: 0:06:11  lr: 0.000925  min_lr: 0.000925  loss: 2.9287 (2.8550)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6106 (1.2796)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [210]  [1000/1251]  eta: 0:03:26  lr: 0.000922  min_lr: 0.000922  loss: 2.8326 (2.8571)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3644 (1.2992)  time: 0.8177  data: 0.0004  max mem: 62457
Epoch: [210]  [1200/1251]  eta: 0:00:41  lr: 0.000918  min_lr: 0.000918  loss: 2.7084 (2.8535)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1886 (1.2880)  time: 0.8175  data: 0.0004  max mem: 62457
Epoch: [210]  [1250/1251]  eta: 0:00:00  lr: 0.000918  min_lr: 0.000918  loss: 2.8015 (2.8524)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0927 (1.2823)  time: 0.6938  data: 0.0005  max mem: 62457
Epoch: [210] Total time: 0:17:06 (0.8203 s / it)
Averaged stats: lr: 0.000918  min_lr: 0.000918  loss: 2.8015 (2.8516)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0927 (1.2823)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.6424 (0.6424)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 7.8086  data: 7.3481  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7658 (0.7812)  acc1: 86.0000 (85.8546)  acc5: 98.0000 (97.7818)  time: 1.1167  data: 0.6683  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9135 (0.8909)  acc1: 82.8000 (83.2191)  acc5: 96.8000 (96.7429)  time: 0.4464  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9459 (0.8989)  acc1: 82.8000 (82.8000)  acc5: 96.4000 (96.6880)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7450 s / it)
* Acc@1 83.340 Acc@5 96.666 loss 0.882
Accuracy of the model on the 50000 test images: 83.3%
Max accuracy: 83.36%
Epoch: [211]  [   0/1251]  eta: 1:49:28  lr: 0.000918  min_lr: 0.000918  loss: 3.1461 (3.1461)  weight_decay: 0.0500 (0.0500)  time: 5.2503  data: 4.3981  max mem: 62457
Epoch: [211]  [ 200/1251]  eta: 0:14:41  lr: 0.000915  min_lr: 0.000915  loss: 3.0674 (2.8276)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9314 (1.2785)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [211]  [ 400/1251]  eta: 0:11:46  lr: 0.000912  min_lr: 0.000912  loss: 2.7131 (2.8228)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0337 (1.1817)  time: 0.8171  data: 0.0004  max mem: 62457
Epoch: [211]  [ 600/1251]  eta: 0:08:57  lr: 0.000909  min_lr: 0.000909  loss: 2.8647 (2.8307)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9529 (1.1452)  time: 0.8173  data: 0.0004  max mem: 62457
Epoch: [211]  [ 800/1251]  eta: 0:06:11  lr: 0.000906  min_lr: 0.000906  loss: 2.9401 (2.8287)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1480 (1.1454)  time: 0.8171  data: 0.0004  max mem: 62457
Epoch: [211]  [1000/1251]  eta: 0:03:26  lr: 0.000903  min_lr: 0.000903  loss: 3.0322 (2.8270)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1963 (1.1906)  time: 0.8171  data: 0.0004  max mem: 62457
Epoch: [211]  [1200/1251]  eta: 0:00:41  lr: 0.000900  min_lr: 0.000900  loss: 3.0273 (2.8342)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4811 (1.2149)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [211]  [1250/1251]  eta: 0:00:00  lr: 0.000899  min_lr: 0.000899  loss: 3.0931 (2.8347)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1625 (1.2169)  time: 0.6936  data: 0.0006  max mem: 62457
Epoch: [211] Total time: 0:17:06 (0.8205 s / it)
Averaged stats: lr: 0.000899  min_lr: 0.000899  loss: 3.0931 (2.8540)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1625 (1.2169)
Test:  [ 0/25]  eta: 0:03:24  loss: 0.7341 (0.7341)  acc1: 88.0000 (88.0000)  acc5: 98.4000 (98.4000)  time: 8.1810  data: 7.7053  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.8502 (0.8325)  acc1: 84.8000 (86.0727)  acc5: 98.4000 (97.8909)  time: 1.1485  data: 0.7007  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9511 (0.9477)  acc1: 82.4000 (83.2762)  acc5: 96.0000 (96.5714)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 1.0366 (0.9583)  acc1: 81.2000 (82.9440)  acc5: 96.0000 (96.4640)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7595 s / it)
* Acc@1 83.370 Acc@5 96.678 loss 0.944
Accuracy of the model on the 50000 test images: 83.4%
Max accuracy: 83.37%
Epoch: [212]  [   0/1251]  eta: 1:40:30  lr: 0.000899  min_lr: 0.000899  loss: 2.7230 (2.7230)  weight_decay: 0.0500 (0.0500)  time: 4.8205  data: 3.9864  max mem: 62457
Epoch: [212]  [ 200/1251]  eta: 0:14:43  lr: 0.000896  min_lr: 0.000896  loss: 2.8324 (2.8402)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0757 (1.2883)  time: 0.8235  data: 0.0004  max mem: 62457
Epoch: [212]  [ 400/1251]  eta: 0:11:45  lr: 0.000893  min_lr: 0.000893  loss: 2.9017 (2.8189)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2106 (1.2226)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [212]  [ 600/1251]  eta: 0:08:57  lr: 0.000890  min_lr: 0.000890  loss: 2.6436 (2.8284)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0593 (1.2613)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [212]  [ 800/1251]  eta: 0:06:11  lr: 0.000887  min_lr: 0.000887  loss: 2.8786 (2.8321)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6070 (1.2744)  time: 0.8219  data: 0.0005  max mem: 62457
Epoch: [212]  [1000/1251]  eta: 0:03:26  lr: 0.000884  min_lr: 0.000884  loss: 2.9234 (2.8450)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2744 (1.2800)  time: 0.8168  data: 0.0005  max mem: 62457
Epoch: [212]  [1200/1251]  eta: 0:00:41  lr: 0.000881  min_lr: 0.000881  loss: 2.8336 (2.8489)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3767 (1.2819)  time: 0.8175  data: 0.0004  max mem: 62457
Epoch: [212]  [1250/1251]  eta: 0:00:00  lr: 0.000880  min_lr: 0.000880  loss: 3.0042 (2.8537)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3618 (1.2848)  time: 0.6995  data: 0.0005  max mem: 62457
Epoch: [212] Total time: 0:17:06 (0.8205 s / it)
Averaged stats: lr: 0.000880  min_lr: 0.000880  loss: 3.0042 (2.8484)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3618 (1.2848)
Test:  [ 0/25]  eta: 0:02:29  loss: 0.6723 (0.6723)  acc1: 90.0000 (90.0000)  acc5: 98.4000 (98.4000)  time: 5.9669  data: 5.4631  max mem: 62457
Test:  [10/25]  eta: 0:00:14  loss: 0.7418 (0.7851)  acc1: 86.8000 (86.6182)  acc5: 98.0000 (97.9636)  time: 0.9908  data: 0.5400  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9194 (0.8987)  acc1: 81.6000 (83.1810)  acc5: 96.4000 (96.7619)  time: 0.4693  data: 0.0239  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9851 (0.9123)  acc1: 81.2000 (82.7360)  acc5: 96.0000 (96.6560)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.6964 s / it)
* Acc@1 83.444 Acc@5 96.780 loss 0.892
Accuracy of the model on the 50000 test images: 83.4%
Max accuracy: 83.44%
Epoch: [213]  [   0/1251]  eta: 1:16:05  lr: 0.000880  min_lr: 0.000880  loss: 2.7732 (2.7732)  weight_decay: 0.0500 (0.0500)  time: 3.6497  data: 2.8204  max mem: 62457
Epoch: [213]  [ 200/1251]  eta: 0:14:36  lr: 0.000877  min_lr: 0.000877  loss: 2.8056 (2.8117)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0410 (1.2842)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [213]  [ 400/1251]  eta: 0:11:42  lr: 0.000874  min_lr: 0.000874  loss: 2.6936 (2.8009)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0372 (1.1707)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [213]  [ 600/1251]  eta: 0:08:56  lr: 0.000871  min_lr: 0.000871  loss: 3.0163 (2.8277)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1750 (1.1953)  time: 0.8262  data: 0.0004  max mem: 62457
Epoch: [213]  [ 800/1251]  eta: 0:06:10  lr: 0.000868  min_lr: 0.000868  loss: 2.9448 (2.8189)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1284 (1.1927)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [213]  [1000/1251]  eta: 0:03:26  lr: 0.000865  min_lr: 0.000865  loss: 2.9562 (2.8199)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1201 (1.1990)  time: 0.8173  data: 0.0004  max mem: 62457
Epoch: [213]  [1200/1251]  eta: 0:00:41  lr: 0.000863  min_lr: 0.000863  loss: 2.8402 (2.8262)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9081 (1.2145)  time: 0.8254  data: 0.0004  max mem: 62457
Epoch: [213]  [1250/1251]  eta: 0:00:00  lr: 0.000862  min_lr: 0.000862  loss: 3.0888 (2.8295)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9037 (1.2079)  time: 0.6940  data: 0.0005  max mem: 62457
Epoch: [213] Total time: 0:17:05 (0.8197 s / it)
Averaged stats: lr: 0.000862  min_lr: 0.000862  loss: 3.0888 (2.8301)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9037 (1.2079)
Test:  [ 0/25]  eta: 0:03:00  loss: 0.6944 (0.6944)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 7.2214  data: 6.7404  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8227 (0.8140)  acc1: 86.4000 (86.3636)  acc5: 97.6000 (97.7455)  time: 1.0860  data: 0.6377  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9606 (0.9351)  acc1: 82.8000 (83.6381)  acc5: 96.4000 (96.4000)  time: 0.4589  data: 0.0138  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9606 (0.9472)  acc1: 82.4000 (83.2000)  acc5: 95.6000 (96.3360)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7331 s / it)
* Acc@1 83.500 Acc@5 96.626 loss 0.930
Accuracy of the model on the 50000 test images: 83.5%
Max accuracy: 83.50%
Epoch: [214]  [   0/1251]  eta: 1:26:27  lr: 0.000862  min_lr: 0.000862  loss: 1.9656 (1.9656)  weight_decay: 0.0500 (0.0500)  time: 4.1465  data: 3.3270  max mem: 62457
Epoch: [214]  [ 200/1251]  eta: 0:14:35  lr: 0.000859  min_lr: 0.000859  loss: 2.8157 (2.8145)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3051 (1.2317)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [214]  [ 400/1251]  eta: 0:11:42  lr: 0.000856  min_lr: 0.000856  loss: 3.0684 (2.8251)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9545 (1.1930)  time: 0.8242  data: 0.0004  max mem: 62457
Epoch: [214]  [ 600/1251]  eta: 0:08:56  lr: 0.000853  min_lr: 0.000853  loss: 2.7898 (2.8280)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9876 (1.2472)  time: 0.8169  data: 0.0005  max mem: 62457
Epoch: [214]  [ 800/1251]  eta: 0:06:10  lr: 0.000850  min_lr: 0.000850  loss: 2.9346 (2.8325)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0536 (1.2270)  time: 0.8244  data: 0.0004  max mem: 62457
Epoch: [214]  [1000/1251]  eta: 0:03:26  lr: 0.000847  min_lr: 0.000847  loss: 2.9965 (2.8338)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1932 (1.2250)  time: 0.8206  data: 0.0004  max mem: 62457
Epoch: [214]  [1200/1251]  eta: 0:00:41  lr: 0.000844  min_lr: 0.000844  loss: 2.8670 (2.8337)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1050 (1.2406)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [214]  [1250/1251]  eta: 0:00:00  lr: 0.000844  min_lr: 0.000844  loss: 2.8998 (2.8363)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2175 (1.2400)  time: 0.6939  data: 0.0004  max mem: 62457
Epoch: [214] Total time: 0:17:05 (0.8195 s / it)
Averaged stats: lr: 0.000844  min_lr: 0.000844  loss: 2.8998 (2.8351)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2175 (1.2400)
Test:  [ 0/25]  eta: 0:03:05  loss: 0.6684 (0.6684)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 7.4037  data: 6.9268  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7423 (0.7744)  acc1: 86.4000 (85.8909)  acc5: 98.4000 (97.8182)  time: 1.0781  data: 0.6300  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9172 (0.8813)  acc1: 83.2000 (83.4095)  acc5: 95.6000 (96.5524)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9180 (0.8931)  acc1: 82.8000 (83.0080)  acc5: 95.6000 (96.4640)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7279 s / it)
* Acc@1 83.616 Acc@5 96.716 loss 0.876
Accuracy of the model on the 50000 test images: 83.6%
Max accuracy: 83.62%
Epoch: [215]  [   0/1251]  eta: 1:20:33  lr: 0.000843  min_lr: 0.000843  loss: 1.8608 (1.8608)  weight_decay: 0.0500 (0.0500)  time: 3.8638  data: 3.0420  max mem: 62457
Epoch: [215]  [ 200/1251]  eta: 0:14:34  lr: 0.000841  min_lr: 0.000841  loss: 2.9365 (2.8414)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0385 (1.1271)  time: 0.8171  data: 0.0004  max mem: 62457
Epoch: [215]  [ 400/1251]  eta: 0:11:43  lr: 0.000838  min_lr: 0.000838  loss: 2.9851 (2.8272)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9909 (1.2199)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [215]  [ 600/1251]  eta: 0:08:56  lr: 0.000835  min_lr: 0.000835  loss: 2.9588 (2.8122)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1259 (1.1999)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [215]  [ 800/1251]  eta: 0:06:10  lr: 0.000832  min_lr: 0.000832  loss: 2.5909 (2.7978)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4393 (1.2652)  time: 0.8250  data: 0.0003  max mem: 62457
Epoch: [215]  [1000/1251]  eta: 0:03:26  lr: 0.000829  min_lr: 0.000829  loss: 2.8444 (2.8091)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4088 (1.2745)  time: 0.8171  data: 0.0004  max mem: 62457
Epoch: [215]  [1200/1251]  eta: 0:00:41  lr: 0.000826  min_lr: 0.000826  loss: 2.8202 (2.8060)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8175  data: 0.0004  max mem: 62457
Epoch: [215]  [1250/1251]  eta: 0:00:00  lr: 0.000825  min_lr: 0.000825  loss: 2.9562 (2.8062)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.6951  data: 0.0005  max mem: 62457
Epoch: [215] Total time: 0:17:05 (0.8197 s / it)
Averaged stats: lr: 0.000825  min_lr: 0.000825  loss: 2.9562 (2.8341)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.6356 (0.6356)  acc1: 89.6000 (89.6000)  acc5: 98.8000 (98.8000)  time: 7.8375  data: 7.3755  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7188 (0.7407)  acc1: 86.8000 (86.8000)  acc5: 98.0000 (97.9636)  time: 1.1183  data: 0.6707  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8815 (0.8580)  acc1: 82.0000 (83.4476)  acc5: 96.4000 (96.6286)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8980 (0.8691)  acc1: 82.0000 (83.1680)  acc5: 96.0000 (96.4640)  time: 0.4446  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7459 s / it)
* Acc@1 83.582 Acc@5 96.716 loss 0.854
Accuracy of the model on the 50000 test images: 83.6%
Max accuracy: 83.62%
Epoch: [216]  [   0/1251]  eta: 1:33:47  lr: 0.000825  min_lr: 0.000825  loss: 2.4432 (2.4432)  weight_decay: 0.0500 (0.0500)  time: 4.4983  data: 2.8908  max mem: 62457
Epoch: [216]  [ 200/1251]  eta: 0:14:42  lr: 0.000822  min_lr: 0.000822  loss: 3.0218 (2.8764)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1042 (1.0430)  time: 0.8248  data: 0.0003  max mem: 62457
Epoch: [216]  [ 400/1251]  eta: 0:11:46  lr: 0.000819  min_lr: 0.000819  loss: 2.8117 (2.8595)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0441 (1.0925)  time: 0.8188  data: 0.0004  max mem: 62457
Epoch: [216]  [ 600/1251]  eta: 0:08:57  lr: 0.000817  min_lr: 0.000817  loss: 3.0415 (2.8457)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3141 (1.1836)  time: 0.8185  data: 0.0004  max mem: 62457
Epoch: [216]  [ 800/1251]  eta: 0:06:12  lr: 0.000814  min_lr: 0.000814  loss: 2.8850 (2.8354)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3180 (1.1919)  time: 0.8180  data: 0.0005  max mem: 62457
Epoch: [216]  [1000/1251]  eta: 0:03:26  lr: 0.000811  min_lr: 0.000811  loss: 2.3663 (2.8215)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6662 (1.2722)  time: 0.8196  data: 0.0004  max mem: 62457
Epoch: [216]  [1200/1251]  eta: 0:00:41  lr: 0.000808  min_lr: 0.000808  loss: 2.9629 (2.8183)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2088 (1.2541)  time: 0.8185  data: 0.0004  max mem: 62457
Epoch: [216]  [1250/1251]  eta: 0:00:00  lr: 0.000807  min_lr: 0.000807  loss: 2.8043 (2.8204)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1618 (1.2520)  time: 0.6958  data: 0.0007  max mem: 62457
Epoch: [216] Total time: 0:17:08 (0.8219 s / it)
Averaged stats: lr: 0.000807  min_lr: 0.000807  loss: 2.8043 (2.8326)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1618 (1.2520)
Test:  [ 0/25]  eta: 0:03:18  loss: 0.5937 (0.5937)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 7.9492  data: 7.4796  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.6644 (0.7038)  acc1: 84.8000 (86.0727)  acc5: 98.0000 (98.0364)  time: 1.1276  data: 0.6802  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.8469 (0.8123)  acc1: 82.8000 (83.6762)  acc5: 96.8000 (96.8762)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8840 (0.8277)  acc1: 82.0000 (83.2960)  acc5: 96.0000 (96.7200)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7496 s / it)
* Acc@1 83.606 Acc@5 96.714 loss 0.814
Accuracy of the model on the 50000 test images: 83.6%
Max accuracy: 83.62%
Epoch: [217]  [   0/1251]  eta: 1:36:36  lr: 0.000807  min_lr: 0.000807  loss: 3.0311 (3.0311)  weight_decay: 0.0500 (0.0500)  time: 4.6332  data: 3.2069  max mem: 62457
Epoch: [217]  [ 200/1251]  eta: 0:14:43  lr: 0.000804  min_lr: 0.000804  loss: 2.8004 (2.8323)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1330 (1.4264)  time: 0.8186  data: 0.0004  max mem: 62457
Epoch: [217]  [ 400/1251]  eta: 0:11:45  lr: 0.000801  min_lr: 0.000801  loss: 2.8565 (2.8304)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2391 (1.3851)  time: 0.8180  data: 0.0004  max mem: 62457
Epoch: [217]  [ 600/1251]  eta: 0:08:58  lr: 0.000799  min_lr: 0.000799  loss: 2.6356 (2.8210)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0107 (1.3322)  time: 0.8228  data: 0.0004  max mem: 62457
Epoch: [217]  [ 800/1251]  eta: 0:06:11  lr: 0.000796  min_lr: 0.000796  loss: 2.7865 (2.8257)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3526 (1.3474)  time: 0.8190  data: 0.0004  max mem: 62457
Epoch: [217]  [1000/1251]  eta: 0:03:26  lr: 0.000793  min_lr: 0.000793  loss: 2.9814 (2.8232)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1778 (1.3315)  time: 0.8183  data: 0.0004  max mem: 62457
Epoch: [217]  [1200/1251]  eta: 0:00:41  lr: 0.000790  min_lr: 0.000790  loss: 2.7691 (2.8221)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8882 (1.2950)  time: 0.8267  data: 0.0004  max mem: 62457
Epoch: [217]  [1250/1251]  eta: 0:00:00  lr: 0.000789  min_lr: 0.000789  loss: 2.8905 (2.8229)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8633 (1.2835)  time: 0.6943  data: 0.0005  max mem: 62457
Epoch: [217] Total time: 0:17:07 (0.8217 s / it)
Averaged stats: lr: 0.000789  min_lr: 0.000789  loss: 2.8905 (2.8219)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8633 (1.2835)
Test:  [ 0/25]  eta: 0:03:16  loss: 0.6988 (0.6988)  acc1: 89.2000 (89.2000)  acc5: 98.4000 (98.4000)  time: 7.8738  data: 7.3919  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7710 (0.7934)  acc1: 86.4000 (86.4727)  acc5: 97.6000 (97.8545)  time: 1.1202  data: 0.6723  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9456 (0.9046)  acc1: 83.2000 (83.8095)  acc5: 96.8000 (96.6476)  time: 0.4448  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9685 (0.9187)  acc1: 82.8000 (83.2960)  acc5: 96.0000 (96.5760)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7461 s / it)
* Acc@1 83.666 Acc@5 96.716 loss 0.902
Accuracy of the model on the 50000 test images: 83.7%
Max accuracy: 83.67%
Epoch: [218]  [   0/1251]  eta: 1:21:15  lr: 0.000789  min_lr: 0.000789  loss: 3.0227 (3.0227)  weight_decay: 0.0500 (0.0500)  time: 3.8977  data: 3.0699  max mem: 62457
Epoch: [218]  [ 200/1251]  eta: 0:14:35  lr: 0.000786  min_lr: 0.000786  loss: 3.0077 (2.8065)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2075 (1.4597)  time: 0.8179  data: 0.0004  max mem: 62457
Epoch: [218]  [ 400/1251]  eta: 0:11:43  lr: 0.000784  min_lr: 0.000784  loss: 2.7125 (2.8140)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1070 (1.3951)  time: 0.8179  data: 0.0004  max mem: 62457
Epoch: [218]  [ 600/1251]  eta: 0:08:56  lr: 0.000781  min_lr: 0.000781  loss: 2.9174 (2.8082)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0985 (1.3154)  time: 0.8180  data: 0.0004  max mem: 62457
Epoch: [218]  [ 800/1251]  eta: 0:06:11  lr: 0.000778  min_lr: 0.000778  loss: 2.8978 (2.8113)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3015 (1.2899)  time: 0.8175  data: 0.0004  max mem: 62457
Epoch: [218]  [1000/1251]  eta: 0:03:26  lr: 0.000775  min_lr: 0.000775  loss: 2.6668 (2.8154)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0679 (1.2702)  time: 0.8323  data: 0.0004  max mem: 62457
Epoch: [218]  [1200/1251]  eta: 0:00:41  lr: 0.000772  min_lr: 0.000772  loss: 2.9613 (2.8069)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2183 (1.3032)  time: 0.8180  data: 0.0004  max mem: 62457
Epoch: [218]  [1250/1251]  eta: 0:00:00  lr: 0.000772  min_lr: 0.000772  loss: 2.7151 (2.8051)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0891 (1.2964)  time: 0.6945  data: 0.0004  max mem: 62457
Epoch: [218] Total time: 0:17:06 (0.8203 s / it)
Averaged stats: lr: 0.000772  min_lr: 0.000772  loss: 2.7151 (2.8122)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0891 (1.2964)
Test:  [ 0/25]  eta: 0:03:11  loss: 0.5772 (0.5772)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.6689  data: 7.1835  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.6774 (0.6986)  acc1: 85.6000 (86.2182)  acc5: 98.0000 (97.8545)  time: 1.1021  data: 0.6533  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8486 (0.8192)  acc1: 82.4000 (83.5238)  acc5: 96.0000 (96.5333)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8934 (0.8326)  acc1: 82.0000 (83.0880)  acc5: 96.0000 (96.4960)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7391 s / it)
* Acc@1 83.692 Acc@5 96.760 loss 0.817
Accuracy of the model on the 50000 test images: 83.7%
Max accuracy: 83.69%
Epoch: [219]  [   0/1251]  eta: 1:16:23  lr: 0.000771  min_lr: 0.000771  loss: 3.1416 (3.1416)  weight_decay: 0.0500 (0.0500)  time: 3.6640  data: 2.8425  max mem: 62457
Epoch: [219]  [ 200/1251]  eta: 0:14:35  lr: 0.000769  min_lr: 0.000769  loss: 2.9150 (2.8081)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1327 (1.1778)  time: 0.8186  data: 0.0004  max mem: 62457
Epoch: [219]  [ 400/1251]  eta: 0:11:44  lr: 0.000766  min_lr: 0.000766  loss: 2.9095 (2.8037)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0464 (1.3297)  time: 0.8186  data: 0.0004  max mem: 62457
Epoch: [219]  [ 600/1251]  eta: 0:08:56  lr: 0.000763  min_lr: 0.000763  loss: 2.9237 (2.7862)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4710 (1.3467)  time: 0.8178  data: 0.0004  max mem: 62457
Epoch: [219]  [ 800/1251]  eta: 0:06:11  lr: 0.000760  min_lr: 0.000760  loss: 2.9910 (2.7896)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9005 (1.3237)  time: 0.8233  data: 0.0004  max mem: 62457
Epoch: [219]  [1000/1251]  eta: 0:03:26  lr: 0.000757  min_lr: 0.000757  loss: 2.7664 (2.7843)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4336 (1.3187)  time: 0.8187  data: 0.0004  max mem: 62457
Epoch: [219]  [1200/1251]  eta: 0:00:41  lr: 0.000755  min_lr: 0.000755  loss: 2.8332 (2.7848)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8673 (1.2980)  time: 0.8186  data: 0.0004  max mem: 62457
Epoch: [219]  [1250/1251]  eta: 0:00:00  lr: 0.000754  min_lr: 0.000754  loss: 2.6346 (2.7858)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2985 (1.3086)  time: 0.6952  data: 0.0005  max mem: 62457
Epoch: [219] Total time: 0:17:06 (0.8206 s / it)
Averaged stats: lr: 0.000754  min_lr: 0.000754  loss: 2.6346 (2.8051)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2985 (1.3086)
Test:  [ 0/25]  eta: 0:03:01  loss: 0.5879 (0.5879)  acc1: 87.6000 (87.6000)  acc5: 99.2000 (99.2000)  time: 7.2496  data: 6.7679  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.7078 (0.7193)  acc1: 86.4000 (85.8909)  acc5: 98.0000 (97.8909)  time: 1.0652  data: 0.6168  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8449 (0.8331)  acc1: 82.4000 (83.4476)  acc5: 96.4000 (96.7810)  time: 0.4460  data: 0.0009  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8698 (0.8409)  acc1: 82.0000 (83.0720)  acc5: 96.4000 (96.7680)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7222 s / it)
* Acc@1 83.684 Acc@5 96.816 loss 0.824
Accuracy of the model on the 50000 test images: 83.7%
Max accuracy: 83.69%
Epoch: [220]  [   0/1251]  eta: 1:48:13  lr: 0.000754  min_lr: 0.000754  loss: 2.7216 (2.7216)  weight_decay: 0.0500 (0.0500)  time: 5.1907  data: 3.3430  max mem: 62457
Epoch: [220]  [ 200/1251]  eta: 0:14:45  lr: 0.000751  min_lr: 0.000751  loss: 2.8531 (2.7820)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2690 (1.4997)  time: 0.8183  data: 0.0004  max mem: 62457
Epoch: [220]  [ 400/1251]  eta: 0:11:47  lr: 0.000748  min_lr: 0.000748  loss: 2.8349 (2.7957)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2440 (1.3527)  time: 0.8187  data: 0.0004  max mem: 62457
Epoch: [220]  [ 600/1251]  eta: 0:08:58  lr: 0.000745  min_lr: 0.000745  loss: 2.6938 (2.7940)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4771 (1.3533)  time: 0.8182  data: 0.0005  max mem: 62457
Epoch: [220]  [ 800/1251]  eta: 0:06:12  lr: 0.000743  min_lr: 0.000743  loss: 2.9316 (2.7964)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1938 (1.3327)  time: 0.8187  data: 0.0004  max mem: 62457
Epoch: [220]  [1000/1251]  eta: 0:03:26  lr: 0.000740  min_lr: 0.000740  loss: 2.8840 (2.7987)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0165 (1.3159)  time: 0.8181  data: 0.0004  max mem: 62457
Epoch: [220]  [1200/1251]  eta: 0:00:41  lr: 0.000737  min_lr: 0.000737  loss: 2.8681 (2.7995)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9864 (1.2982)  time: 0.8187  data: 0.0004  max mem: 62457
Epoch: [220]  [1250/1251]  eta: 0:00:00  lr: 0.000736  min_lr: 0.000736  loss: 2.8716 (2.8022)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0413 (1.2939)  time: 0.6952  data: 0.0007  max mem: 62457
Epoch: [220] Total time: 0:17:07 (0.8216 s / it)
Averaged stats: lr: 0.000736  min_lr: 0.000736  loss: 2.8716 (2.8055)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0413 (1.2939)
Test:  [ 0/25]  eta: 0:03:20  loss: 0.6624 (0.6624)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 8.0062  data: 7.5482  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.7630 (0.7652)  acc1: 86.8000 (86.4364)  acc5: 97.6000 (97.8546)  time: 1.1348  data: 0.6865  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.8802 (0.8683)  acc1: 82.8000 (83.9048)  acc5: 96.8000 (96.8381)  time: 0.4466  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9334 (0.8831)  acc1: 82.8000 (83.4720)  acc5: 96.4000 (96.6880)  time: 0.4455  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7539 s / it)
* Acc@1 83.714 Acc@5 96.782 loss 0.871
Accuracy of the model on the 50000 test images: 83.7%
Max accuracy: 83.71%
Epoch: [221]  [   0/1251]  eta: 1:23:13  lr: 0.000736  min_lr: 0.000736  loss: 2.8120 (2.8120)  weight_decay: 0.0500 (0.0500)  time: 3.9917  data: 3.1660  max mem: 62457
Epoch: [221]  [ 200/1251]  eta: 0:14:40  lr: 0.000734  min_lr: 0.000734  loss: 2.9829 (2.8055)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4593 (1.3737)  time: 0.8193  data: 0.0005  max mem: 62457
Epoch: [221]  [ 400/1251]  eta: 0:11:45  lr: 0.000731  min_lr: 0.000731  loss: 2.7242 (2.7828)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9892 (1.3218)  time: 0.8182  data: 0.0004  max mem: 62457
Epoch: [221]  [ 600/1251]  eta: 0:08:57  lr: 0.000728  min_lr: 0.000728  loss: 2.9136 (2.7864)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4743 (1.3267)  time: 0.8180  data: 0.0004  max mem: 62457
Epoch: [221]  [ 800/1251]  eta: 0:06:11  lr: 0.000725  min_lr: 0.000725  loss: 2.9433 (2.7730)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7795 (1.2969)  time: 0.8179  data: 0.0004  max mem: 62457
Epoch: [221]  [1000/1251]  eta: 0:03:26  lr: 0.000722  min_lr: 0.000722  loss: 2.8136 (2.7874)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3428 (1.3168)  time: 0.8185  data: 0.0004  max mem: 62457
Epoch: [221]  [1200/1251]  eta: 0:00:41  lr: 0.000720  min_lr: 0.000720  loss: 2.9236 (2.7958)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1298 (1.3056)  time: 0.8178  data: 0.0005  max mem: 62457
Epoch: [221]  [1250/1251]  eta: 0:00:00  lr: 0.000719  min_lr: 0.000719  loss: 2.9942 (2.7974)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3075 (1.3128)  time: 0.6949  data: 0.0005  max mem: 62457
Epoch: [221] Total time: 0:17:07 (0.8215 s / it)
Averaged stats: lr: 0.000719  min_lr: 0.000719  loss: 2.9942 (2.8030)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3075 (1.3128)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.6598 (0.6598)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.7351  data: 7.2683  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.8104 (0.7811)  acc1: 86.0000 (86.2909)  acc5: 97.6000 (97.8182)  time: 1.1078  data: 0.6610  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9250 (0.8981)  acc1: 82.4000 (83.5238)  acc5: 96.4000 (96.5905)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9686 (0.9109)  acc1: 81.6000 (83.1360)  acc5: 96.0000 (96.4960)  time: 0.4447  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7407 s / it)
* Acc@1 83.540 Acc@5 96.752 loss 0.897
Accuracy of the model on the 50000 test images: 83.5%
Max accuracy: 83.71%
Epoch: [222]  [   0/1251]  eta: 1:42:01  lr: 0.000719  min_lr: 0.000719  loss: 3.2094 (3.2094)  weight_decay: 0.0500 (0.0500)  time: 4.8935  data: 2.8583  max mem: 62457
Epoch: [222]  [ 200/1251]  eta: 0:14:42  lr: 0.000716  min_lr: 0.000716  loss: 2.8200 (2.7621)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2594 (1.2905)  time: 0.8193  data: 0.0004  max mem: 62457
Epoch: [222]  [ 400/1251]  eta: 0:11:46  lr: 0.000714  min_lr: 0.000714  loss: 2.9370 (2.7851)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2380 (1.3224)  time: 0.8185  data: 0.0004  max mem: 62457
Epoch: [222]  [ 600/1251]  eta: 0:08:58  lr: 0.000711  min_lr: 0.000711  loss: 3.0283 (2.7871)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1924 (1.3167)  time: 0.8172  data: 0.0005  max mem: 62457
Epoch: [222]  [ 800/1251]  eta: 0:06:11  lr: 0.000708  min_lr: 0.000708  loss: 2.9695 (2.7847)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5706 (1.3259)  time: 0.8167  data: 0.0005  max mem: 62457
Epoch: [222]  [1000/1251]  eta: 0:03:26  lr: 0.000705  min_lr: 0.000705  loss: 3.0374 (2.7920)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1982 (1.2960)  time: 0.8309  data: 0.0005  max mem: 62457
Epoch: [222]  [1200/1251]  eta: 0:00:41  lr: 0.000703  min_lr: 0.000703  loss: 2.7726 (2.7933)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2901 (1.2806)  time: 0.8173  data: 0.0005  max mem: 62457
Epoch: [222]  [1250/1251]  eta: 0:00:00  lr: 0.000702  min_lr: 0.000702  loss: 2.8375 (2.7893)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2584 (1.2760)  time: 0.6939  data: 0.0006  max mem: 62457
Epoch: [222] Total time: 0:17:07 (0.8210 s / it)
Averaged stats: lr: 0.000702  min_lr: 0.000702  loss: 2.8375 (2.7958)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2584 (1.2760)
Test:  [ 0/25]  eta: 0:03:07  loss: 0.5871 (0.5871)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.5096  data: 7.0203  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.6732 (0.6887)  acc1: 86.4000 (87.0909)  acc5: 98.0000 (97.7818)  time: 1.0878  data: 0.6385  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8302 (0.7986)  acc1: 82.8000 (84.2095)  acc5: 96.4000 (96.7619)  time: 0.4455  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8581 (0.8134)  acc1: 82.4000 (83.7280)  acc5: 96.4000 (96.6400)  time: 0.4454  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7325 s / it)
* Acc@1 83.828 Acc@5 96.718 loss 0.804
Accuracy of the model on the 50000 test images: 83.8%
Max accuracy: 83.83%
Epoch: [223]  [   0/1251]  eta: 1:33:52  lr: 0.000702  min_lr: 0.000702  loss: 3.1561 (3.1561)  weight_decay: 0.0500 (0.0500)  time: 4.5024  data: 3.6803  max mem: 62457
Epoch: [223]  [ 200/1251]  eta: 0:14:38  lr: 0.000699  min_lr: 0.000699  loss: 2.6875 (2.7649)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5931 (1.4737)  time: 0.8160  data: 0.0004  max mem: 62457
Epoch: [223]  [ 400/1251]  eta: 0:11:44  lr: 0.000696  min_lr: 0.000696  loss: 2.7695 (2.7824)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0942 (1.3634)  time: 0.8172  data: 0.0005  max mem: 62457
Epoch: [223]  [ 600/1251]  eta: 0:08:56  lr: 0.000694  min_lr: 0.000694  loss: 2.8039 (2.7650)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0285 (1.2800)  time: 0.8172  data: 0.0004  max mem: 62457
Epoch: [223]  [ 800/1251]  eta: 0:06:11  lr: 0.000691  min_lr: 0.000691  loss: 2.8459 (2.7830)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1819 (1.2715)  time: 0.8172  data: 0.0005  max mem: 62457
Epoch: [223]  [1000/1251]  eta: 0:03:26  lr: 0.000688  min_lr: 0.000688  loss: 2.9762 (2.7752)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3587 (1.3228)  time: 0.8168  data: 0.0005  max mem: 62457
Epoch: [223]  [1200/1251]  eta: 0:00:41  lr: 0.000686  min_lr: 0.000686  loss: 2.7835 (2.7735)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2226 (1.3274)  time: 0.8170  data: 0.0005  max mem: 62457
Epoch: [223]  [1250/1251]  eta: 0:00:00  lr: 0.000685  min_lr: 0.000685  loss: 2.9828 (2.7746)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2374 (1.3247)  time: 0.6938  data: 0.0006  max mem: 62457
Epoch: [223] Total time: 0:17:05 (0.8199 s / it)
Averaged stats: lr: 0.000685  min_lr: 0.000685  loss: 2.9828 (2.7875)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2374 (1.3247)
Test:  [ 0/25]  eta: 0:03:17  loss: 0.6463 (0.6463)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 7.9035  data: 7.4121  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7581 (0.7795)  acc1: 86.8000 (86.6545)  acc5: 98.0000 (97.8909)  time: 1.1235  data: 0.6743  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9005 (0.8856)  acc1: 82.4000 (83.6571)  acc5: 96.4000 (96.6667)  time: 0.4453  data: 0.0003  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9273 (0.8984)  acc1: 82.4000 (83.2640)  acc5: 96.4000 (96.6240)  time: 0.4453  data: 0.0002  max mem: 62457
Test: Total time: 0:00:18 (0.7481 s / it)
* Acc@1 83.748 Acc@5 96.670 loss 0.880
Accuracy of the model on the 50000 test images: 83.7%
Max accuracy: 83.83%
Epoch: [224]  [   0/1251]  eta: 1:47:26  lr: 0.000685  min_lr: 0.000685  loss: 3.0808 (3.0808)  weight_decay: 0.0500 (0.0500)  time: 5.1530  data: 2.1610  max mem: 62457
Epoch: [224]  [ 200/1251]  eta: 0:14:43  lr: 0.000682  min_lr: 0.000682  loss: 3.0299 (2.7776)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1456 (1.2303)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [224]  [ 400/1251]  eta: 0:11:45  lr: 0.000680  min_lr: 0.000680  loss: 2.8072 (2.7798)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2294 (1.3026)  time: 0.8235  data: 0.0004  max mem: 62457
Epoch: [224]  [ 600/1251]  eta: 0:08:57  lr: 0.000677  min_lr: 0.000677  loss: 2.8607 (2.7803)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0812 (1.3105)  time: 0.8164  data: 0.0004  max mem: 62457
Epoch: [224]  [ 800/1251]  eta: 0:06:11  lr: 0.000674  min_lr: 0.000674  loss: 2.8840 (2.7864)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9899 (1.2702)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [224]  [1000/1251]  eta: 0:03:26  lr: 0.000671  min_lr: 0.000671  loss: 3.0033 (2.7879)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4159 (1.2879)  time: 0.8166  data: 0.0004  max mem: 62457
Epoch: [224]  [1200/1251]  eta: 0:00:41  lr: 0.000669  min_lr: 0.000669  loss: 2.8275 (2.7809)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1298 (1.2970)  time: 0.8205  data: 0.0004  max mem: 62457
Epoch: [224]  [1250/1251]  eta: 0:00:00  lr: 0.000668  min_lr: 0.000668  loss: 2.9348 (2.7781)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0337 (1.2899)  time: 0.6933  data: 0.0005  max mem: 62457
Epoch: [224] Total time: 0:17:05 (0.8199 s / it)
Averaged stats: lr: 0.000668  min_lr: 0.000668  loss: 2.9348 (2.7834)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0337 (1.2899)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.6622 (0.6622)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.5720  data: 7.0904  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7699 (0.7567)  acc1: 86.4000 (86.6182)  acc5: 98.0000 (98.0000)  time: 1.0929  data: 0.6448  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8951 (0.8667)  acc1: 82.8000 (84.0381)  acc5: 96.4000 (96.9524)  time: 0.4449  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9167 (0.8810)  acc1: 82.4000 (83.6160)  acc5: 96.4000 (96.8640)  time: 0.4448  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7351 s / it)
* Acc@1 83.822 Acc@5 96.820 loss 0.870
Accuracy of the model on the 50000 test images: 83.8%
Max accuracy: 83.83%
Epoch: [225]  [   0/1251]  eta: 1:42:35  lr: 0.000668  min_lr: 0.000668  loss: 2.7165 (2.7165)  weight_decay: 0.0500 (0.0500)  time: 4.9202  data: 2.2081  max mem: 62457
Epoch: [225]  [ 200/1251]  eta: 0:14:44  lr: 0.000665  min_lr: 0.000665  loss: 2.6137 (2.7317)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0135 (1.1929)  time: 0.8257  data: 0.0005  max mem: 62457
Epoch: [225]  [ 400/1251]  eta: 0:11:46  lr: 0.000663  min_lr: 0.000663  loss: 2.8417 (2.7399)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2764 (1.2123)  time: 0.8169  data: 0.0004  max mem: 62457
Epoch: [225]  [ 600/1251]  eta: 0:08:58  lr: 0.000660  min_lr: 0.000660  loss: 2.8143 (2.7416)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9258 (1.2126)  time: 0.8172  data: 0.0004  max mem: 62457
Epoch: [225]  [ 800/1251]  eta: 0:06:11  lr: 0.000657  min_lr: 0.000657  loss: 2.7870 (2.7517)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1589 (1.2662)  time: 0.8170  data: 0.0004  max mem: 62457
Epoch: [225]  [1000/1251]  eta: 0:03:26  lr: 0.000655  min_lr: 0.000655  loss: 2.8878 (2.7520)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0530 (1.2684)  time: 0.8169  data: 0.0004  max mem: 62457
Epoch: [225]  [1200/1251]  eta: 0:00:41  lr: 0.000652  min_lr: 0.000652  loss: 2.8510 (2.7607)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2242 (1.2870)  time: 0.8219  data: 0.0004  max mem: 62457
Epoch: [225]  [1250/1251]  eta: 0:00:00  lr: 0.000652  min_lr: 0.000652  loss: 2.9288 (2.7627)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1157 (1.2865)  time: 0.6938  data: 0.0005  max mem: 62457
Epoch: [225] Total time: 0:17:07 (0.8209 s / it)
Averaged stats: lr: 0.000652  min_lr: 0.000652  loss: 2.9288 (2.7776)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1157 (1.2865)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.6761 (0.6761)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 7.5943  data: 7.1185  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7470 (0.7650)  acc1: 86.8000 (86.4364)  acc5: 98.0000 (98.0364)  time: 1.0951  data: 0.6474  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8915 (0.8731)  acc1: 82.0000 (83.6762)  acc5: 96.0000 (96.8571)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9269 (0.8850)  acc1: 82.0000 (83.2800)  acc5: 96.0000 (96.7520)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7350 s / it)
* Acc@1 83.804 Acc@5 96.744 loss 0.877
Accuracy of the model on the 50000 test images: 83.8%
Max accuracy: 83.83%
Epoch: [226]  [   0/1251]  eta: 1:43:10  lr: 0.000651  min_lr: 0.000651  loss: 3.1345 (3.1345)  weight_decay: 0.0500 (0.0500)  time: 4.9488  data: 3.0202  max mem: 62457
Epoch: [226]  [ 200/1251]  eta: 0:14:39  lr: 0.000649  min_lr: 0.000649  loss: 2.9676 (2.7805)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4142 (1.3157)  time: 0.8166  data: 0.0004  max mem: 62457
Epoch: [226]  [ 400/1251]  eta: 0:11:43  lr: 0.000646  min_lr: 0.000646  loss: 2.7554 (2.8018)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2744 (1.3837)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [226]  [ 600/1251]  eta: 0:08:56  lr: 0.000644  min_lr: 0.000644  loss: 2.7781 (2.7965)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0255 (1.3679)  time: 0.8164  data: 0.0004  max mem: 62457
Epoch: [226]  [ 800/1251]  eta: 0:06:10  lr: 0.000641  min_lr: 0.000641  loss: 2.7011 (2.7902)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1524 (1.3470)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [226]  [1000/1251]  eta: 0:03:26  lr: 0.000638  min_lr: 0.000638  loss: 2.8538 (2.7845)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2946 (1.3277)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [226]  [1200/1251]  eta: 0:00:41  lr: 0.000636  min_lr: 0.000636  loss: 2.8839 (2.7943)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3054 (1.3324)  time: 0.8163  data: 0.0004  max mem: 62457
Epoch: [226]  [1250/1251]  eta: 0:00:00  lr: 0.000635  min_lr: 0.000635  loss: 2.8327 (2.7920)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2471 (1.3281)  time: 0.6933  data: 0.0005  max mem: 62457
Epoch: [226] Total time: 0:17:05 (0.8196 s / it)
Averaged stats: lr: 0.000635  min_lr: 0.000635  loss: 2.8327 (2.7798)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2471 (1.3281)
Test:  [ 0/25]  eta: 0:03:06  loss: 0.6448 (0.6448)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 7.4667  data: 6.9882  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7172 (0.7384)  acc1: 87.2000 (86.8727)  acc5: 98.0000 (98.0364)  time: 1.0834  data: 0.6356  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8524 (0.8577)  acc1: 82.0000 (83.7714)  acc5: 96.4000 (96.8000)  time: 0.4450  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9401 (0.8715)  acc1: 81.6000 (83.3760)  acc5: 96.4000 (96.7360)  time: 0.4449  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7300 s / it)
* Acc@1 83.834 Acc@5 96.812 loss 0.855
Accuracy of the model on the 50000 test images: 83.8%
Max accuracy: 83.83%
Epoch: [227]  [   0/1251]  eta: 1:31:38  lr: 0.000635  min_lr: 0.000635  loss: 2.4688 (2.4688)  weight_decay: 0.0500 (0.0500)  time: 4.3955  data: 3.5805  max mem: 62457
Epoch: [227]  [ 200/1251]  eta: 0:14:37  lr: 0.000632  min_lr: 0.000632  loss: 2.8325 (2.7523)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3482 (1.6067)  time: 0.8176  data: 0.0005  max mem: 62457
Epoch: [227]  [ 400/1251]  eta: 0:11:45  lr: 0.000630  min_lr: 0.000630  loss: 2.8962 (2.7622)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0994 (1.4940)  time: 0.8174  data: 0.0004  max mem: 62457
Epoch: [227]  [ 600/1251]  eta: 0:08:56  lr: 0.000627  min_lr: 0.000627  loss: 2.8316 (2.7612)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4392 (1.4142)  time: 0.8173  data: 0.0005  max mem: 62457
Epoch: [227]  [ 800/1251]  eta: 0:06:11  lr: 0.000625  min_lr: 0.000625  loss: 2.8677 (2.7618)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1793 (1.3714)  time: 0.8176  data: 0.0004  max mem: 62457
Epoch: [227]  [1000/1251]  eta: 0:03:26  lr: 0.000622  min_lr: 0.000622  loss: 2.8745 (2.7645)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3567 (1.4360)  time: 0.8175  data: 0.0004  max mem: 62457
Epoch: [227]  [1200/1251]  eta: 0:00:41  lr: 0.000619  min_lr: 0.000619  loss: 2.8101 (2.7757)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0821 (1.3986)  time: 0.8177  data: 0.0005  max mem: 62457
Epoch: [227]  [1250/1251]  eta: 0:00:00  lr: 0.000619  min_lr: 0.000619  loss: 2.8292 (2.7774)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0717 (1.3891)  time: 0.6941  data: 0.0005  max mem: 62457
Epoch: [227] Total time: 0:17:06 (0.8202 s / it)
Averaged stats: lr: 0.000619  min_lr: 0.000619  loss: 2.8292 (2.7771)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0717 (1.3891)
Test:  [ 0/25]  eta: 0:03:21  loss: 0.6895 (0.6895)  acc1: 88.8000 (88.8000)  acc5: 99.2000 (99.2000)  time: 8.0763  data: 7.5914  max mem: 62457
Test:  [10/25]  eta: 0:00:17  loss: 0.7970 (0.7797)  acc1: 86.4000 (86.3273)  acc5: 98.0000 (97.9273)  time: 1.1391  data: 0.6904  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.9241 (0.8959)  acc1: 82.8000 (83.7143)  acc5: 96.0000 (96.7810)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9668 (0.9075)  acc1: 82.8000 (83.4400)  acc5: 96.0000 (96.6880)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7544 s / it)
* Acc@1 83.788 Acc@5 96.826 loss 0.893
Accuracy of the model on the 50000 test images: 83.8%
Max accuracy: 83.83%
Epoch: [228]  [   0/1251]  eta: 1:32:13  lr: 0.000619  min_lr: 0.000619  loss: 3.1466 (3.1466)  weight_decay: 0.0500 (0.0500)  time: 4.4229  data: 3.0697  max mem: 62457
Epoch: [228]  [ 200/1251]  eta: 0:14:41  lr: 0.000616  min_lr: 0.000616  loss: 2.8828 (2.8231)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0966 (1.3093)  time: 0.8227  data: 0.0004  max mem: 62457
Epoch: [228]  [ 400/1251]  eta: 0:11:44  lr: 0.000614  min_lr: 0.000614  loss: 2.9175 (2.8002)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5890 (1.3904)  time: 0.8168  data: 0.0005  max mem: 62457
Epoch: [228]  [ 600/1251]  eta: 0:08:56  lr: 0.000611  min_lr: 0.000611  loss: 2.8275 (2.7899)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1338 (1.3836)  time: 0.8168  data: 0.0005  max mem: 62457
Epoch: [228]  [ 800/1251]  eta: 0:06:11  lr: 0.000608  min_lr: 0.000608  loss: 2.9076 (2.7873)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9157 (1.3453)  time: 0.8171  data: 0.0005  max mem: 62457
Epoch: [228]  [1000/1251]  eta: 0:03:26  lr: 0.000606  min_lr: 0.000606  loss: 2.8669 (2.7919)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4086 (1.3752)  time: 0.8162  data: 0.0005  max mem: 62457
Epoch: [228]  [1200/1251]  eta: 0:00:41  lr: 0.000603  min_lr: 0.000603  loss: 2.6660 (2.7852)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9039 (1.3482)  time: 0.8170  data: 0.0005  max mem: 62457
Epoch: [228]  [1250/1251]  eta: 0:00:00  lr: 0.000603  min_lr: 0.000603  loss: 2.7609 (2.7834)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9681 (1.3465)  time: 0.6963  data: 0.0007  max mem: 62457
Epoch: [228] Total time: 0:17:05 (0.8198 s / it)
Averaged stats: lr: 0.000603  min_lr: 0.000603  loss: 2.7609 (2.7627)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9681 (1.3465)
Test:  [ 0/25]  eta: 0:02:57  loss: 0.6170 (0.6170)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 7.1148  data: 6.6183  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.6877 (0.7036)  acc1: 86.4000 (86.4727)  acc5: 98.0000 (97.8909)  time: 1.0518  data: 0.6019  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8460 (0.8262)  acc1: 82.0000 (83.4476)  acc5: 96.8000 (96.7810)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8825 (0.8354)  acc1: 81.6000 (83.1040)  acc5: 96.8000 (96.7360)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7163 s / it)
* Acc@1 83.882 Acc@5 96.886 loss 0.824
Accuracy of the model on the 50000 test images: 83.9%
Max accuracy: 83.88%
Epoch: [229]  [   0/1251]  eta: 1:22:36  lr: 0.000603  min_lr: 0.000603  loss: 2.7341 (2.7341)  weight_decay: 0.0500 (0.0500)  time: 3.9622  data: 3.1511  max mem: 62457
Epoch: [229]  [ 200/1251]  eta: 0:14:35  lr: 0.000600  min_lr: 0.000600  loss: 2.9303 (2.7412)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2018 (nan)  time: 0.8171  data: 0.0005  max mem: 62457
Epoch: [229]  [ 400/1251]  eta: 0:11:42  lr: 0.000597  min_lr: 0.000597  loss: 2.8598 (2.7747)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1060 (nan)  time: 0.8164  data: 0.0005  max mem: 62457
Epoch: [229]  [ 600/1251]  eta: 0:08:55  lr: 0.000595  min_lr: 0.000595  loss: 2.5818 (2.7806)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2867 (nan)  time: 0.8214  data: 0.0004  max mem: 62457
Epoch: [229]  [ 800/1251]  eta: 0:06:10  lr: 0.000592  min_lr: 0.000592  loss: 2.8428 (2.7715)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0867 (nan)  time: 0.8167  data: 0.0005  max mem: 62457
Epoch: [229]  [1000/1251]  eta: 0:03:26  lr: 0.000590  min_lr: 0.000590  loss: 2.9834 (2.7649)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3535 (nan)  time: 0.8166  data: 0.0005  max mem: 62457
Epoch: [229]  [1200/1251]  eta: 0:00:41  lr: 0.000587  min_lr: 0.000587  loss: 2.5575 (2.7622)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0238 (nan)  time: 0.8166  data: 0.0005  max mem: 62457
Epoch: [229]  [1250/1251]  eta: 0:00:00  lr: 0.000587  min_lr: 0.000587  loss: 2.8350 (2.7612)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9920 (nan)  time: 0.6933  data: 0.0006  max mem: 62457
Epoch: [229] Total time: 0:17:04 (0.8189 s / it)
Averaged stats: lr: 0.000587  min_lr: 0.000587  loss: 2.8350 (2.7637)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9920 (nan)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.5842 (0.5842)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 7.7527  data: 7.2798  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7078 (0.7164)  acc1: 87.2000 (86.9455)  acc5: 98.0000 (98.1818)  time: 1.1103  data: 0.6621  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8398 (0.8260)  acc1: 83.6000 (84.2667)  acc5: 97.2000 (97.1238)  time: 0.4460  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8674 (0.8413)  acc1: 83.6000 (83.8240)  acc5: 96.4000 (96.9440)  time: 0.4459  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7427 s / it)
* Acc@1 83.940 Acc@5 96.900 loss 0.830
Accuracy of the model on the 50000 test images: 83.9%
Max accuracy: 83.94%
Epoch: [230]  [   0/1251]  eta: 1:24:47  lr: 0.000587  min_lr: 0.000587  loss: 3.1637 (3.1637)  weight_decay: 0.0500 (0.0500)  time: 4.0666  data: 3.2410  max mem: 62457
Epoch: [230]  [ 200/1251]  eta: 0:14:35  lr: 0.000584  min_lr: 0.000584  loss: 2.7647 (2.7225)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0283 (1.1515)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [230]  [ 400/1251]  eta: 0:11:42  lr: 0.000582  min_lr: 0.000582  loss: 2.9035 (2.7523)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1445 (1.3361)  time: 0.8236  data: 0.0004  max mem: 62457
Epoch: [230]  [ 600/1251]  eta: 0:08:55  lr: 0.000579  min_lr: 0.000579  loss: 2.8591 (2.7549)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2473 (1.3011)  time: 0.8166  data: 0.0004  max mem: 62457
Epoch: [230]  [ 800/1251]  eta: 0:06:10  lr: 0.000577  min_lr: 0.000577  loss: 2.9206 (2.7554)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1762 (1.3186)  time: 0.8171  data: 0.0004  max mem: 62457
Epoch: [230]  [1000/1251]  eta: 0:03:26  lr: 0.000574  min_lr: 0.000574  loss: 2.9535 (2.7481)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0281 (1.3220)  time: 0.8206  data: 0.0004  max mem: 62457
Epoch: [230]  [1200/1251]  eta: 0:00:41  lr: 0.000571  min_lr: 0.000571  loss: 2.9064 (2.7512)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3873 (1.3145)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [230]  [1250/1251]  eta: 0:00:00  lr: 0.000571  min_lr: 0.000571  loss: 2.8202 (2.7489)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3873 (1.3200)  time: 0.6936  data: 0.0004  max mem: 62457
Epoch: [230] Total time: 0:17:04 (0.8188 s / it)
Averaged stats: lr: 0.000571  min_lr: 0.000571  loss: 2.8202 (2.7541)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3873 (1.3200)
Test:  [ 0/25]  eta: 0:03:04  loss: 0.6005 (0.6005)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.3853  data: 6.9115  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7247 (0.7173)  acc1: 86.4000 (86.6545)  acc5: 97.6000 (97.9273)  time: 1.0763  data: 0.6286  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8539 (0.8272)  acc1: 82.4000 (84.0191)  acc5: 96.8000 (96.8952)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8785 (0.8412)  acc1: 82.4000 (83.7440)  acc5: 96.4000 (96.8000)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7278 s / it)
* Acc@1 83.958 Acc@5 96.820 loss 0.825
Accuracy of the model on the 50000 test images: 84.0%
Max accuracy: 83.96%
Epoch: [231]  [   0/1251]  eta: 1:25:11  lr: 0.000571  min_lr: 0.000571  loss: 2.2940 (2.2940)  weight_decay: 0.0500 (0.0500)  time: 4.0861  data: 3.2527  max mem: 62457
Epoch: [231]  [ 200/1251]  eta: 0:14:36  lr: 0.000568  min_lr: 0.000568  loss: 2.8657 (2.7646)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0771 (1.1742)  time: 0.8229  data: 0.0004  max mem: 62457
Epoch: [231]  [ 400/1251]  eta: 0:11:43  lr: 0.000566  min_lr: 0.000566  loss: 2.5584 (2.7505)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4759 (1.3427)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [231]  [ 600/1251]  eta: 0:08:56  lr: 0.000563  min_lr: 0.000563  loss: 2.8456 (2.7406)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0460 (1.2708)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [231]  [ 800/1251]  eta: 0:06:10  lr: 0.000561  min_lr: 0.000561  loss: 2.8294 (2.7405)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4505 (1.2991)  time: 0.8171  data: 0.0004  max mem: 62457
Epoch: [231]  [1000/1251]  eta: 0:03:26  lr: 0.000558  min_lr: 0.000558  loss: 2.5456 (2.7392)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4122 (1.3268)  time: 0.8166  data: 0.0004  max mem: 62457
Epoch: [231]  [1200/1251]  eta: 0:00:41  lr: 0.000556  min_lr: 0.000556  loss: 2.7756 (2.7462)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5507 (nan)  time: 0.8183  data: 0.0005  max mem: 62457
Epoch: [231]  [1250/1251]  eta: 0:00:00  lr: 0.000555  min_lr: 0.000555  loss: 2.8181 (2.7459)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2910 (nan)  time: 0.6950  data: 0.0006  max mem: 62457
Epoch: [231] Total time: 0:17:04 (0.8192 s / it)
Averaged stats: lr: 0.000555  min_lr: 0.000555  loss: 2.8181 (2.7462)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2910 (nan)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.6626 (0.6626)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 7.7476  data: 7.2796  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7430 (0.7608)  acc1: 87.2000 (86.9818)  acc5: 98.0000 (98.1455)  time: 1.1091  data: 0.6620  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8946 (0.8686)  acc1: 83.2000 (84.1333)  acc5: 96.8000 (96.9905)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9373 (0.8834)  acc1: 82.8000 (83.7440)  acc5: 96.0000 (96.7840)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7413 s / it)
* Acc@1 83.990 Acc@5 96.892 loss 0.869
Accuracy of the model on the 50000 test images: 84.0%
Max accuracy: 83.99%
Epoch: [232]  [   0/1251]  eta: 1:24:05  lr: 0.000555  min_lr: 0.000555  loss: 2.8654 (2.8654)  weight_decay: 0.0500 (0.0500)  time: 4.0329  data: 3.2122  max mem: 62457
Epoch: [232]  [ 200/1251]  eta: 0:14:39  lr: 0.000553  min_lr: 0.000553  loss: 2.7399 (2.7311)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0869 (1.2406)  time: 0.8183  data: 0.0005  max mem: 62457
Epoch: [232]  [ 400/1251]  eta: 0:11:44  lr: 0.000550  min_lr: 0.000550  loss: 2.6941 (2.7431)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2363 (1.2494)  time: 0.8176  data: 0.0004  max mem: 62457
Epoch: [232]  [ 600/1251]  eta: 0:08:56  lr: 0.000548  min_lr: 0.000548  loss: 2.5970 (2.7365)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4710 (1.2709)  time: 0.8255  data: 0.0004  max mem: 62457
Epoch: [232]  [ 800/1251]  eta: 0:06:11  lr: 0.000545  min_lr: 0.000545  loss: 2.7930 (2.7372)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1072 (1.2579)  time: 0.8181  data: 0.0004  max mem: 62457
Epoch: [232]  [1000/1251]  eta: 0:03:26  lr: 0.000543  min_lr: 0.000543  loss: 2.8141 (2.7439)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3877 (1.2988)  time: 0.8179  data: 0.0005  max mem: 62457
Epoch: [232]  [1200/1251]  eta: 0:00:41  lr: 0.000540  min_lr: 0.000540  loss: 2.5039 (2.7408)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4456 (1.3057)  time: 0.8186  data: 0.0004  max mem: 62457
Epoch: [232]  [1250/1251]  eta: 0:00:00  lr: 0.000540  min_lr: 0.000540  loss: 2.8954 (2.7404)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3727 (1.3031)  time: 0.6998  data: 0.0006  max mem: 62457
Epoch: [232] Total time: 0:17:06 (0.8209 s / it)
Averaged stats: lr: 0.000540  min_lr: 0.000540  loss: 2.8954 (2.7431)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3727 (1.3031)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.6070 (0.6070)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 7.7244  data: 7.2508  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.6990 (0.7014)  acc1: 87.2000 (86.8364)  acc5: 97.6000 (97.9636)  time: 1.1071  data: 0.6594  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8353 (0.8159)  acc1: 82.4000 (84.0952)  acc5: 97.2000 (96.9524)  time: 0.4453  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8608 (0.8307)  acc1: 82.0000 (83.6640)  acc5: 96.4000 (96.8480)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7410 s / it)
* Acc@1 84.042 Acc@5 96.878 loss 0.820
Accuracy of the model on the 50000 test images: 84.0%
Max accuracy: 84.04%
Epoch: [233]  [   0/1251]  eta: 1:28:34  lr: 0.000540  min_lr: 0.000540  loss: 2.9763 (2.9763)  weight_decay: 0.0500 (0.0500)  time: 4.2484  data: 3.4273  max mem: 62457
Epoch: [233]  [ 200/1251]  eta: 0:14:38  lr: 0.000537  min_lr: 0.000537  loss: 2.9334 (2.7228)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4750 (1.4923)  time: 0.8185  data: 0.0004  max mem: 62457
Epoch: [233]  [ 400/1251]  eta: 0:11:43  lr: 0.000535  min_lr: 0.000535  loss: 2.9828 (2.7384)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0435 (1.4289)  time: 0.8176  data: 0.0004  max mem: 62457
Epoch: [233]  [ 600/1251]  eta: 0:08:57  lr: 0.000533  min_lr: 0.000533  loss: 2.8569 (2.7416)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0695 (1.4841)  time: 0.8186  data: 0.0004  max mem: 62457
Epoch: [233]  [ 800/1251]  eta: 0:06:11  lr: 0.000530  min_lr: 0.000530  loss: 2.9871 (2.7447)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5450 (1.4777)  time: 0.8184  data: 0.0004  max mem: 62457
Epoch: [233]  [1000/1251]  eta: 0:03:26  lr: 0.000528  min_lr: 0.000528  loss: 2.8699 (2.7514)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7264 (1.4803)  time: 0.8184  data: 0.0004  max mem: 62457
Epoch: [233]  [1200/1251]  eta: 0:00:41  lr: 0.000525  min_lr: 0.000525  loss: 2.5617 (2.7520)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6119 (1.5011)  time: 0.8185  data: 0.0005  max mem: 62457
Epoch: [233]  [1250/1251]  eta: 0:00:00  lr: 0.000525  min_lr: 0.000525  loss: 2.7520 (2.7501)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3871 (1.4945)  time: 0.6953  data: 0.0004  max mem: 62457
Epoch: [233] Total time: 0:17:06 (0.8209 s / it)
Averaged stats: lr: 0.000525  min_lr: 0.000525  loss: 2.7520 (2.7442)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3871 (1.4945)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.5784 (0.5784)  acc1: 90.0000 (90.0000)  acc5: 99.6000 (99.6000)  time: 7.6917  data: 7.2282  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.6568 (0.6815)  acc1: 88.4000 (86.9455)  acc5: 97.6000 (97.9636)  time: 1.1050  data: 0.6574  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8362 (0.8010)  acc1: 82.8000 (83.8476)  acc5: 96.4000 (96.8762)  time: 0.4458  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8911 (0.8169)  acc1: 82.0000 (83.4240)  acc5: 96.0000 (96.7520)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7411 s / it)
* Acc@1 83.936 Acc@5 96.860 loss 0.804
Accuracy of the model on the 50000 test images: 83.9%
Max accuracy: 84.04%
Epoch: [234]  [   0/1251]  eta: 1:34:32  lr: 0.000525  min_lr: 0.000525  loss: 1.7734 (1.7734)  weight_decay: 0.0500 (0.0500)  time: 4.5347  data: 3.2484  max mem: 62457
Epoch: [234]  [ 200/1251]  eta: 0:14:40  lr: 0.000522  min_lr: 0.000522  loss: 2.8654 (2.7344)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4856 (1.3842)  time: 0.8196  data: 0.0004  max mem: 62457
Epoch: [234]  [ 400/1251]  eta: 0:11:46  lr: 0.000520  min_lr: 0.000520  loss: 2.7615 (2.7437)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1929 (1.3103)  time: 0.8256  data: 0.0004  max mem: 62457
Epoch: [234]  [ 600/1251]  eta: 0:08:58  lr: 0.000517  min_lr: 0.000517  loss: 2.7412 (2.7379)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5771 (1.4346)  time: 0.8190  data: 0.0004  max mem: 62457
Epoch: [234]  [ 800/1251]  eta: 0:06:11  lr: 0.000515  min_lr: 0.000515  loss: 2.7577 (2.7340)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5177 (1.4128)  time: 0.8188  data: 0.0004  max mem: 62457
Epoch: [234]  [1000/1251]  eta: 0:03:26  lr: 0.000513  min_lr: 0.000513  loss: 2.9061 (2.7428)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1044 (1.3551)  time: 0.8185  data: 0.0004  max mem: 62457
Epoch: [234]  [1200/1251]  eta: 0:00:41  lr: 0.000510  min_lr: 0.000510  loss: 2.7672 (2.7343)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1600 (1.3594)  time: 0.8229  data: 0.0004  max mem: 62457
Epoch: [234]  [1250/1251]  eta: 0:00:00  lr: 0.000510  min_lr: 0.000510  loss: 2.9988 (2.7373)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1412 (1.3561)  time: 0.6950  data: 0.0006  max mem: 62457
Epoch: [234] Total time: 0:17:07 (0.8217 s / it)
Averaged stats: lr: 0.000510  min_lr: 0.000510  loss: 2.9988 (2.7362)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1412 (1.3561)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.6458 (0.6458)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 7.5360  data: 7.0623  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7661 (0.7589)  acc1: 85.6000 (87.0909)  acc5: 97.6000 (97.9273)  time: 1.0899  data: 0.6423  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.9018 (0.8758)  acc1: 82.4000 (83.9238)  acc5: 96.8000 (96.8952)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9278 (0.8870)  acc1: 81.2000 (83.4560)  acc5: 96.0000 (96.8000)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7329 s / it)
* Acc@1 83.912 Acc@5 96.848 loss 0.875
Accuracy of the model on the 50000 test images: 83.9%
Max accuracy: 84.04%
Epoch: [235]  [   0/1251]  eta: 1:28:02  lr: 0.000510  min_lr: 0.000510  loss: 1.9774 (1.9774)  weight_decay: 0.0500 (0.0500)  time: 4.2226  data: 2.2420  max mem: 62457
Epoch: [235]  [ 200/1251]  eta: 0:14:38  lr: 0.000507  min_lr: 0.000507  loss: 2.7699 (2.6870)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4031 (1.4387)  time: 0.8190  data: 0.0004  max mem: 62457
Epoch: [235]  [ 400/1251]  eta: 0:11:44  lr: 0.000505  min_lr: 0.000505  loss: 3.0111 (2.7192)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3648 (1.5097)  time: 0.8184  data: 0.0004  max mem: 62457
Epoch: [235]  [ 600/1251]  eta: 0:08:57  lr: 0.000502  min_lr: 0.000502  loss: 2.8357 (2.7204)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0819 (1.4263)  time: 0.8187  data: 0.0004  max mem: 62457
Epoch: [235]  [ 800/1251]  eta: 0:06:11  lr: 0.000500  min_lr: 0.000500  loss: 2.7445 (2.7316)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0017 (1.4194)  time: 0.8234  data: 0.0004  max mem: 62457
Epoch: [235]  [1000/1251]  eta: 0:03:26  lr: 0.000498  min_lr: 0.000498  loss: 2.6152 (2.7280)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1019 (1.4160)  time: 0.8175  data: 0.0004  max mem: 62457
Epoch: [235]  [1200/1251]  eta: 0:00:41  lr: 0.000495  min_lr: 0.000495  loss: 2.8287 (2.7273)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4459 (1.4016)  time: 0.8184  data: 0.0004  max mem: 62457
Epoch: [235]  [1250/1251]  eta: 0:00:00  lr: 0.000495  min_lr: 0.000495  loss: 2.9067 (2.7276)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3509 (1.3998)  time: 0.6949  data: 0.0006  max mem: 62457
Epoch: [235] Total time: 0:17:06 (0.8207 s / it)
Averaged stats: lr: 0.000495  min_lr: 0.000495  loss: 2.9067 (2.7333)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3509 (1.3998)
Test:  [ 0/25]  eta: 0:03:20  loss: 0.6276 (0.6276)  acc1: 91.2000 (91.2000)  acc5: 98.8000 (98.8000)  time: 8.0120  data: 7.5303  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7322 (0.7343)  acc1: 87.2000 (86.8364)  acc5: 97.6000 (97.8909)  time: 1.1331  data: 0.6848  max mem: 62457
Test:  [20/25]  eta: 0:00:04  loss: 0.8282 (0.8560)  acc1: 82.4000 (83.8476)  acc5: 96.8000 (96.7619)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9157 (0.8685)  acc1: 82.0000 (83.5040)  acc5: 96.4000 (96.6880)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7525 s / it)
* Acc@1 83.870 Acc@5 96.834 loss 0.856
Accuracy of the model on the 50000 test images: 83.9%
Max accuracy: 84.04%
Epoch: [236]  [   0/1251]  eta: 1:30:09  lr: 0.000495  min_lr: 0.000495  loss: 1.9427 (1.9427)  weight_decay: 0.0500 (0.0500)  time: 4.3242  data: 2.9323  max mem: 62457
Epoch: [236]  [ 200/1251]  eta: 0:14:42  lr: 0.000492  min_lr: 0.000492  loss: 2.7650 (2.7240)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5872 (1.5646)  time: 0.8242  data: 0.0004  max mem: 62457
Epoch: [236]  [ 400/1251]  eta: 0:11:45  lr: 0.000490  min_lr: 0.000490  loss: 2.8752 (2.7429)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3573 (1.4822)  time: 0.8176  data: 0.0004  max mem: 62457
Epoch: [236]  [ 600/1251]  eta: 0:08:56  lr: 0.000488  min_lr: 0.000488  loss: 2.8814 (2.7301)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3823 (1.4851)  time: 0.8179  data: 0.0004  max mem: 62457
Epoch: [236]  [ 800/1251]  eta: 0:06:11  lr: 0.000485  min_lr: 0.000485  loss: 2.7163 (2.7206)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9851 (1.4440)  time: 0.8186  data: 0.0004  max mem: 62457
Epoch: [236]  [1000/1251]  eta: 0:03:26  lr: 0.000483  min_lr: 0.000483  loss: 2.7764 (2.7121)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3247 (1.4144)  time: 0.8181  data: 0.0004  max mem: 62457
Epoch: [236]  [1200/1251]  eta: 0:00:41  lr: 0.000481  min_lr: 0.000481  loss: 2.7267 (2.7134)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1547 (1.3948)  time: 0.8183  data: 0.0004  max mem: 62457
Epoch: [236]  [1250/1251]  eta: 0:00:00  lr: 0.000480  min_lr: 0.000480  loss: 2.4644 (2.7089)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3144 (1.3978)  time: 0.6949  data: 0.0006  max mem: 62457
Epoch: [236] Total time: 0:17:06 (0.8205 s / it)
Averaged stats: lr: 0.000480  min_lr: 0.000480  loss: 2.4644 (2.7218)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3144 (1.3978)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.5879 (0.5879)  acc1: 89.2000 (89.2000)  acc5: 98.4000 (98.4000)  time: 7.7055  data: 7.2342  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.6780 (0.6779)  acc1: 88.0000 (86.9455)  acc5: 98.0000 (98.0727)  time: 1.1055  data: 0.6579  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8000 (0.7899)  acc1: 82.8000 (84.0762)  acc5: 97.2000 (97.0476)  time: 0.4454  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8572 (0.8031)  acc1: 82.8000 (83.6800)  acc5: 96.4000 (96.8320)  time: 0.4453  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7400 s / it)
* Acc@1 84.028 Acc@5 96.922 loss 0.787
Accuracy of the model on the 50000 test images: 84.0%
Max accuracy: 84.04%
Epoch: [237]  [   0/1251]  eta: 1:45:24  lr: 0.000480  min_lr: 0.000480  loss: 2.8287 (2.8287)  weight_decay: 0.0500 (0.0500)  time: 5.0553  data: 3.1126  max mem: 62457
Epoch: [237]  [ 200/1251]  eta: 0:14:42  lr: 0.000478  min_lr: 0.000478  loss: 2.9513 (2.7063)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1997 (1.2540)  time: 0.8179  data: 0.0004  max mem: 62457
Epoch: [237]  [ 400/1251]  eta: 0:11:45  lr: 0.000475  min_lr: 0.000475  loss: 2.5019 (2.7192)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3084 (1.4297)  time: 0.8186  data: 0.0005  max mem: 62457
Epoch: [237]  [ 600/1251]  eta: 0:08:58  lr: 0.000473  min_lr: 0.000473  loss: 2.8213 (2.7086)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2369 (1.4058)  time: 0.8190  data: 0.0005  max mem: 62457
Epoch: [237]  [ 800/1251]  eta: 0:06:12  lr: 0.000471  min_lr: 0.000471  loss: 2.7158 (2.7165)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7306 (1.4287)  time: 0.8194  data: 0.0005  max mem: 62457
Epoch: [237]  [1000/1251]  eta: 0:03:26  lr: 0.000468  min_lr: 0.000468  loss: 2.8317 (2.7244)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1955 (1.4126)  time: 0.8192  data: 0.0005  max mem: 62457
Epoch: [237]  [1200/1251]  eta: 0:00:41  lr: 0.000466  min_lr: 0.000466  loss: 2.6820 (2.7293)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2588 (1.4414)  time: 0.8193  data: 0.0005  max mem: 62457
Epoch: [237]  [1250/1251]  eta: 0:00:00  lr: 0.000466  min_lr: 0.000466  loss: 2.8389 (2.7307)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2406 (1.4357)  time: 0.6952  data: 0.0007  max mem: 62457
Epoch: [237] Total time: 0:17:08 (0.8221 s / it)
Averaged stats: lr: 0.000466  min_lr: 0.000466  loss: 2.8389 (2.7226)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2406 (1.4357)
Test:  [ 0/25]  eta: 0:02:24  loss: 0.6500 (0.6500)  acc1: 90.4000 (90.4000)  acc5: 98.8000 (98.8000)  time: 5.7961  data: 5.2711  max mem: 62457
Test:  [10/25]  eta: 0:00:14  loss: 0.7412 (0.7390)  acc1: 87.6000 (86.8727)  acc5: 97.6000 (98.0364)  time: 0.9598  data: 0.5051  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8763 (0.8488)  acc1: 82.8000 (83.9619)  acc5: 97.2000 (97.0476)  time: 0.4606  data: 0.0143  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8989 (0.8639)  acc1: 82.4000 (83.5360)  acc5: 96.4000 (96.8640)  time: 0.4452  data: 0.0001  max mem: 62457
Test: Total time: 0:00:16 (0.6788 s / it)
* Acc@1 84.084 Acc@5 96.870 loss 0.850
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.08%
Epoch: [238]  [   0/1251]  eta: 1:29:31  lr: 0.000466  min_lr: 0.000466  loss: 2.9120 (2.9120)  weight_decay: 0.0500 (0.0500)  time: 4.2936  data: 3.4692  max mem: 62457
Epoch: [238]  [ 200/1251]  eta: 0:14:37  lr: 0.000463  min_lr: 0.000463  loss: 2.9096 (2.7494)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0320 (1.4043)  time: 0.8181  data: 0.0004  max mem: 62457
Epoch: [238]  [ 400/1251]  eta: 0:11:44  lr: 0.000461  min_lr: 0.000461  loss: 2.3753 (2.7250)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4833 (1.4655)  time: 0.8174  data: 0.0004  max mem: 62457
Epoch: [238]  [ 600/1251]  eta: 0:08:56  lr: 0.000459  min_lr: 0.000459  loss: 2.8982 (2.7192)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3987 (1.4428)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [238]  [ 800/1251]  eta: 0:06:10  lr: 0.000456  min_lr: 0.000456  loss: 2.9095 (2.7156)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2893 (1.3947)  time: 0.8169  data: 0.0004  max mem: 62457
Epoch: [238]  [1000/1251]  eta: 0:03:26  lr: 0.000454  min_lr: 0.000454  loss: 2.3658 (2.7159)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6378 (1.4255)  time: 0.8172  data: 0.0004  max mem: 62457
Epoch: [238]  [1200/1251]  eta: 0:00:41  lr: 0.000452  min_lr: 0.000452  loss: 2.3468 (2.7187)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4275 (1.4432)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [238]  [1250/1251]  eta: 0:00:00  lr: 0.000451  min_lr: 0.000451  loss: 2.7628 (2.7165)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4271 (1.4378)  time: 0.6931  data: 0.0004  max mem: 62457
Epoch: [238] Total time: 0:17:05 (0.8197 s / it)
Averaged stats: lr: 0.000451  min_lr: 0.000451  loss: 2.7628 (2.7199)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4271 (1.4378)
Test:  [ 0/25]  eta: 0:02:20  loss: 0.5808 (0.5808)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 5.6287  data: 5.1399  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.6958 (0.6952)  acc1: 87.2000 (86.7273)  acc5: 97.6000 (97.8909)  time: 1.0445  data: 0.5964  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8247 (0.8086)  acc1: 83.2000 (84.0952)  acc5: 96.4000 (96.8191)  time: 0.5151  data: 0.0710  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8934 (0.8262)  acc1: 82.4000 (83.5040)  acc5: 96.0000 (96.6880)  time: 0.4442  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7131 s / it)
* Acc@1 84.090 Acc@5 96.886 loss 0.814
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.09%
Epoch: [239]  [   0/1251]  eta: 1:17:53  lr: 0.000451  min_lr: 0.000451  loss: 2.2986 (2.2986)  weight_decay: 0.0500 (0.0500)  time: 3.7354  data: 2.9123  max mem: 62457
Epoch: [239]  [ 200/1251]  eta: 0:14:34  lr: 0.000449  min_lr: 0.000449  loss: 2.7733 (2.6548)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2278 (1.4244)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [239]  [ 400/1251]  eta: 0:11:42  lr: 0.000447  min_lr: 0.000447  loss: 2.8399 (2.6897)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5672 (1.4491)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [239]  [ 600/1251]  eta: 0:08:55  lr: 0.000445  min_lr: 0.000445  loss: 2.8740 (2.6970)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2764 (1.4091)  time: 0.8233  data: 0.0004  max mem: 62457
Epoch: [239]  [ 800/1251]  eta: 0:06:10  lr: 0.000442  min_lr: 0.000442  loss: 2.7136 (2.6886)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2559 (1.4332)  time: 0.8212  data: 0.0004  max mem: 62457
Epoch: [239]  [1000/1251]  eta: 0:03:26  lr: 0.000440  min_lr: 0.000440  loss: 2.9075 (2.6863)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2273 (1.3802)  time: 0.8166  data: 0.0004  max mem: 62457
Epoch: [239]  [1200/1251]  eta: 0:00:41  lr: 0.000438  min_lr: 0.000438  loss: 2.9296 (2.6937)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5085 (1.4082)  time: 0.8175  data: 0.0004  max mem: 62457
Epoch: [239]  [1250/1251]  eta: 0:00:00  lr: 0.000437  min_lr: 0.000437  loss: 2.8919 (2.6971)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6651 (1.4148)  time: 0.6939  data: 0.0005  max mem: 62457
Epoch: [239] Total time: 0:17:04 (0.8189 s / it)
Averaged stats: lr: 0.000437  min_lr: 0.000437  loss: 2.8919 (2.7106)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6651 (1.4148)
Test:  [ 0/25]  eta: 0:03:04  loss: 0.6449 (0.6449)  acc1: 90.4000 (90.4000)  acc5: 99.2000 (99.2000)  time: 7.3956  data: 6.9121  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7301 (0.7477)  acc1: 87.6000 (87.4909)  acc5: 98.0000 (97.9636)  time: 1.0771  data: 0.6287  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8732 (0.8521)  acc1: 84.4000 (84.6286)  acc5: 96.4000 (96.9333)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9082 (0.8667)  acc1: 83.2000 (84.0000)  acc5: 96.4000 (96.7840)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7271 s / it)
* Acc@1 84.242 Acc@5 96.884 loss 0.855
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.24%
Epoch: [240]  [   0/1251]  eta: 1:19:43  lr: 0.000437  min_lr: 0.000437  loss: 2.5271 (2.5271)  weight_decay: 0.0500 (0.0500)  time: 3.8236  data: 2.9933  max mem: 62457
Epoch: [240]  [ 200/1251]  eta: 0:14:37  lr: 0.000435  min_lr: 0.000435  loss: 2.7156 (2.7270)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9778 (1.2987)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [240]  [ 400/1251]  eta: 0:11:43  lr: 0.000433  min_lr: 0.000433  loss: 2.8606 (2.6948)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4030 (1.3400)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [240]  [ 600/1251]  eta: 0:08:56  lr: 0.000431  min_lr: 0.000431  loss: 2.7985 (2.6945)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9917 (1.3648)  time: 0.8230  data: 0.0004  max mem: 62457
Epoch: [240]  [ 800/1251]  eta: 0:06:10  lr: 0.000428  min_lr: 0.000428  loss: 2.8765 (2.7008)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2971 (1.3826)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [240]  [1000/1251]  eta: 0:03:26  lr: 0.000426  min_lr: 0.000426  loss: 2.7855 (2.6991)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1508 (1.3985)  time: 0.8172  data: 0.0004  max mem: 62457
Epoch: [240]  [1200/1251]  eta: 0:00:41  lr: 0.000424  min_lr: 0.000424  loss: 2.4812 (2.7103)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2665 (1.3708)  time: 0.8262  data: 0.0004  max mem: 62457
Epoch: [240]  [1250/1251]  eta: 0:00:00  lr: 0.000423  min_lr: 0.000423  loss: 2.7456 (2.7074)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1405 (1.3639)  time: 0.6936  data: 0.0005  max mem: 62457
Epoch: [240] Total time: 0:17:05 (0.8195 s / it)
Averaged stats: lr: 0.000423  min_lr: 0.000423  loss: 2.7456 (2.7036)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1405 (1.3639)
Test:  [ 0/25]  eta: 0:02:33  loss: 0.5866 (0.5866)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 6.1339  data: 5.6571  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.6711 (0.6768)  acc1: 88.0000 (87.6000)  acc5: 97.6000 (98.0727)  time: 1.0502  data: 0.6023  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8129 (0.7877)  acc1: 82.8000 (84.5143)  acc5: 97.2000 (97.0095)  time: 0.4935  data: 0.0484  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8516 (0.8014)  acc1: 82.0000 (84.0160)  acc5: 96.8000 (96.9280)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7157 s / it)
* Acc@1 84.214 Acc@5 96.994 loss 0.791
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.24%
Epoch: [241]  [   0/1251]  eta: 1:41:58  lr: 0.000423  min_lr: 0.000423  loss: 3.1839 (3.1839)  weight_decay: 0.0500 (0.0500)  time: 4.8912  data: 2.8779  max mem: 62457
Epoch: [241]  [ 200/1251]  eta: 0:14:40  lr: 0.000421  min_lr: 0.000421  loss: 2.8129 (2.7408)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5167 (1.3288)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [241]  [ 400/1251]  eta: 0:11:43  lr: 0.000419  min_lr: 0.000419  loss: 2.8870 (2.7260)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2545 (1.3436)  time: 0.8166  data: 0.0004  max mem: 62457
Epoch: [241]  [ 600/1251]  eta: 0:08:56  lr: 0.000417  min_lr: 0.000417  loss: 2.8088 (2.7224)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3278 (1.3360)  time: 0.8159  data: 0.0005  max mem: 62457
Epoch: [241]  [ 800/1251]  eta: 0:06:11  lr: 0.000415  min_lr: 0.000415  loss: 2.7049 (2.7219)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0917 (1.3677)  time: 0.8161  data: 0.0004  max mem: 62457
Epoch: [241]  [1000/1251]  eta: 0:03:26  lr: 0.000412  min_lr: 0.000412  loss: 2.9284 (2.7181)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1315 (1.3451)  time: 0.8166  data: 0.0004  max mem: 62457
Epoch: [241]  [1200/1251]  eta: 0:00:41  lr: 0.000410  min_lr: 0.000410  loss: 2.8372 (2.7220)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8629 (1.3872)  time: 0.8213  data: 0.0004  max mem: 62457
Epoch: [241]  [1250/1251]  eta: 0:00:00  lr: 0.000410  min_lr: 0.000410  loss: 2.6380 (2.7191)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0113 (1.4057)  time: 0.6929  data: 0.0007  max mem: 62457
Epoch: [241] Total time: 0:17:05 (0.8195 s / it)
Averaged stats: lr: 0.000410  min_lr: 0.000410  loss: 2.6380 (2.7001)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0113 (1.4057)
Test:  [ 0/25]  eta: 0:02:57  loss: 0.5474 (0.5474)  acc1: 90.0000 (90.0000)  acc5: 99.6000 (99.6000)  time: 7.1179  data: 6.6230  max mem: 62457
Test:  [10/25]  eta: 0:00:15  loss: 0.6595 (0.6524)  acc1: 88.4000 (87.2364)  acc5: 98.4000 (98.1091)  time: 1.0518  data: 0.6024  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.7661 (0.7704)  acc1: 83.2000 (84.5905)  acc5: 96.8000 (96.9714)  time: 0.4451  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8452 (0.7886)  acc1: 82.8000 (83.9040)  acc5: 96.4000 (96.8480)  time: 0.4450  data: 0.0001  max mem: 62457
Test: Total time: 0:00:17 (0.7163 s / it)
* Acc@1 84.256 Acc@5 96.902 loss 0.781
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.26%
Epoch: [242]  [   0/1251]  eta: 1:27:16  lr: 0.000410  min_lr: 0.000410  loss: 2.3969 (2.3969)  weight_decay: 0.0500 (0.0500)  time: 4.1858  data: 3.3705  max mem: 62457
Epoch: [242]  [ 200/1251]  eta: 0:14:35  lr: 0.000407  min_lr: 0.000407  loss: 2.5922 (2.6497)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1763 (1.6247)  time: 0.8168  data: 0.0004  max mem: 62457
Epoch: [242]  [ 400/1251]  eta: 0:11:43  lr: 0.000405  min_lr: 0.000405  loss: 2.8242 (2.6722)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0992 (1.3900)  time: 0.8165  data: 0.0005  max mem: 62457
Epoch: [242]  [ 600/1251]  eta: 0:08:56  lr: 0.000403  min_lr: 0.000403  loss: 2.7063 (2.6875)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6595 (1.3849)  time: 0.8170  data: 0.0005  max mem: 62457
Epoch: [242]  [ 800/1251]  eta: 0:06:10  lr: 0.000401  min_lr: 0.000401  loss: 2.5591 (2.6796)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0008 (1.4092)  time: 0.8166  data: 0.0005  max mem: 62457
Epoch: [242]  [1000/1251]  eta: 0:03:26  lr: 0.000399  min_lr: 0.000399  loss: 2.5588 (2.6808)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1272 (1.3940)  time: 0.8169  data: 0.0005  max mem: 62457
Epoch: [242]  [1200/1251]  eta: 0:00:41  lr: 0.000397  min_lr: 0.000397  loss: 2.7644 (2.6895)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1672 (1.3800)  time: 0.8168  data: 0.0005  max mem: 62457
Epoch: [242]  [1250/1251]  eta: 0:00:00  lr: 0.000396  min_lr: 0.000396  loss: 2.8581 (2.6931)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0272 (1.3727)  time: 0.6938  data: 0.0006  max mem: 62457
Epoch: [242] Total time: 0:17:04 (0.8192 s / it)
Averaged stats: lr: 0.000396  min_lr: 0.000396  loss: 2.8581 (2.6946)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0272 (1.3727)
Test:  [ 0/25]  eta: 0:03:06  loss: 0.6512 (0.6512)  acc1: 90.4000 (90.4000)  acc5: 99.6000 (99.6000)  time: 7.4691  data: 6.9952  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7651 (0.7709)  acc1: 87.6000 (87.3818)  acc5: 97.6000 (98.0000)  time: 1.0838  data: 0.6362  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8932 (0.8878)  acc1: 84.0000 (84.3429)  acc5: 96.4000 (96.8381)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.9495 (0.9017)  acc1: 82.4000 (83.9200)  acc5: 96.0000 (96.7200)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7304 s / it)
* Acc@1 84.096 Acc@5 96.834 loss 0.888
Accuracy of the model on the 50000 test images: 84.1%
Max accuracy: 84.26%
Epoch: [243]  [   0/1251]  eta: 1:41:16  lr: 0.000396  min_lr: 0.000396  loss: 1.9360 (1.9360)  weight_decay: 0.0500 (0.0500)  time: 4.8574  data: 1.9714  max mem: 62457
Epoch: [243]  [ 200/1251]  eta: 0:14:42  lr: 0.000394  min_lr: 0.000394  loss: 2.7508 (2.6607)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0427 (1.2893)  time: 0.8312  data: 0.0004  max mem: 62457
Epoch: [243]  [ 400/1251]  eta: 0:11:45  lr: 0.000392  min_lr: 0.000392  loss: 2.7416 (2.6726)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0204 (1.2912)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [243]  [ 600/1251]  eta: 0:08:57  lr: 0.000390  min_lr: 0.000390  loss: 2.8102 (2.6732)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4793 (1.3400)  time: 0.8166  data: 0.0004  max mem: 62457
Epoch: [243]  [ 800/1251]  eta: 0:06:11  lr: 0.000388  min_lr: 0.000388  loss: 2.7655 (2.6792)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3879 (1.3840)  time: 0.8210  data: 0.0004  max mem: 62457
Epoch: [243]  [1000/1251]  eta: 0:03:26  lr: 0.000385  min_lr: 0.000385  loss: 2.6053 (2.6808)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5464 (1.3901)  time: 0.8162  data: 0.0004  max mem: 62457
Epoch: [243]  [1200/1251]  eta: 0:00:41  lr: 0.000383  min_lr: 0.000383  loss: 2.7248 (2.6840)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3831 (1.3891)  time: 0.8167  data: 0.0004  max mem: 62457
Epoch: [243]  [1250/1251]  eta: 0:00:00  lr: 0.000383  min_lr: 0.000383  loss: 2.9413 (2.6828)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2013 (1.3798)  time: 0.6937  data: 0.0005  max mem: 62457
Epoch: [243] Total time: 0:17:05 (0.8198 s / it)
Averaged stats: lr: 0.000383  min_lr: 0.000383  loss: 2.9413 (2.6984)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2013 (1.3798)
Test:  [ 0/25]  eta: 0:03:05  loss: 0.6046 (0.6046)  acc1: 89.2000 (89.2000)  acc5: 99.6000 (99.6000)  time: 7.4099  data: 6.9421  max mem: 62457
Test:  [10/25]  eta: 0:00:16  loss: 0.7184 (0.7195)  acc1: 88.4000 (87.0909)  acc5: 98.0000 (98.1091)  time: 1.0786  data: 0.6314  max mem: 62457
Test:  [20/25]  eta: 0:00:03  loss: 0.8537 (0.8235)  acc1: 83.6000 (84.3619)  acc5: 96.8000 (96.9333)  time: 0.4452  data: 0.0002  max mem: 62457
Test:  [24/25]  eta: 0:00:00  loss: 0.8597 (0.8390)  acc1: 83.2000 (83.8880)  acc5: 96.4000 (96.8320)  time: 0.4451  data: 0.0001  max mem: 62457
Test: Total time: 0:00:18 (0.7278 s / it)
* Acc@1 84.226 Acc@5 96.856 loss 0.827
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.26%
Epoch: [244]  [   0/1251]  eta: 1:44:08  lr: 0.000383  min_lr: 0.000383  loss: 2.9842 (2.9842)  weight_decay: 0.0500 (0.0500)  time: 4.9947  data: 4.1653  max mem: 62457
Epoch: [244]  [ 200/1251]  eta: 0:14:43  lr: 0.000381  min_lr: 0.000381  loss: 2.6983 (2.6778)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1621 (1.3307)  time: 0.8164  data: 0.0004  max mem: 62457
Epoch: [244]  [ 400/1251]  eta: 0:11:44  lr: 0.000379  min_lr: 0.000379  loss: 2.6639 (2.6731)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5787 (1.4383)  time: 0.8165  data: 0.0004  max mem: 62457
Epoch: [244]  [ 600/1251]  eta: 0:08:56  lr: 0.000377  min_lr: 0.000377  loss: 2.8953 (2.6997)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2539 (1.4320)  time: 0.8164  data: 0.0004  max mem: 62457
Epoch: [244]  [ 800/1251]  eta: 0:07:07  lr: 0.000374  min_lr: 0.000374  loss: 2.8195 (2.6882)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0572 (1.3814)  time: 1.8626  data: 0.0004  max mem: 62457
Epoch: [244]  [1000/1251]  eta: 0:04:43  lr: 0.000372  min_lr: 0.000372  loss: 2.7080 (2.6874)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4273 (1.4118)  time: 1.8611  data: 0.0005  max mem: 62457
Epoch: [244]  [1200/1251]  eta: 0:01:03  lr: 0.000370  min_lr: 0.000370  loss: 2.7922 (2.6946)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2523 (1.4161)  time: 1.8598  data: 0.0004  max mem: 62457
Epoch: [244]  [1250/1251]  eta: 0:00:01  lr: 0.000370  min_lr: 0.000370  loss: 2.8050 (2.6960)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2871 (1.4149)  time: 1.5777  data: 0.0007  max mem: 62457
Epoch: [244] Total time: 0:26:21 (1.2641 s / it)
Averaged stats: lr: 0.000370  min_lr: 0.000370  loss: 2.8050 (2.6858)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2871 (1.4149)
Test:  [ 0/25]  eta: 0:05:27  loss: 0.6797 (0.6797)  acc1: 89.2000 (89.2000)  acc5: 99.6000 (99.6000)  time: 13.1012  data: 12.0678  max mem: 62457
Test:  [10/25]  eta: 0:00:31  loss: 0.7647 (0.7799)  acc1: 88.0000 (87.3455)  acc5: 97.6000 (98.0000)  time: 2.0780  data: 1.0974  max mem: 62457
Test:  [20/25]  eta: 0:00:07  loss: 0.9303 (0.8908)  acc1: 82.4000 (84.4571)  acc5: 96.8000 (96.9333)  time: 0.9925  data: 0.0003  max mem: 62457
Test:  [24/25]  eta: 0:00:01  loss: 0.9541 (0.9019)  acc1: 82.4000 (84.0160)  acc5: 96.4000 (96.8480)  time: 0.9966  data: 0.0002  max mem: 62457
Test: Total time: 0:00:37 (1.4885 s / it)
* Acc@1 84.200 Acc@5 96.902 loss 0.893
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.26%
Epoch: [245]  [   0/1251]  eta: 3:03:12  lr: 0.000370  min_lr: 0.000370  loss: 2.9699 (2.9699)  weight_decay: 0.0500 (0.0500)  time: 8.7871  data: 4.7474  max mem: 62457
Epoch: [245]  [ 200/1251]  eta: 0:32:34  lr: 0.000368  min_lr: 0.000368  loss: 2.7676 (2.6759)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2031 (1.2667)  time: 1.8631  data: 0.0005  max mem: 62457
Epoch: [245]  [ 400/1251]  eta: 0:26:22  lr: 0.000366  min_lr: 0.000366  loss: 2.6212 (2.6818)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5809 (1.3686)  time: 1.8600  data: 0.0004  max mem: 62457
Epoch: [245]  [ 600/1251]  eta: 0:20:03  lr: 0.000364  min_lr: 0.000364  loss: 2.7624 (2.6732)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5016 (1.4001)  time: 1.8644  data: 0.0004  max mem: 62457
| distributed init (rank 0): env://, gpu 0
| distributed init (rank 7): env://, gpu 7
| distributed init (rank 6): env://, gpu 6
| distributed init (rank 1): env://, gpu 1
| distributed init (rank 2): env://, gpu 2
| distributed init (rank 3): env://, gpu 3
| distributed init (rank 4): env://, gpu 4
| distributed init (rank 5): env://, gpu 5
Namespace(batch_size=128, epochs=300, update_freq=4, model='base', drop_path=0, input_size=288, layer_scale_init_value=1e-06, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, model_ema_eval=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=5.0, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=0.004, layer_decay=1.0, min_lr=1e-06, warmup_epochs=20, warmup_steps=-1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', crop_pct=None, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='', head_init_scale=1.0, model_key='model|module', model_prefix='', data_path='/dev/shm/imagenet', eval_data_path=None, nb_classes=1000, imagenet_default_mean_and_std=True, data_set='IMNET', output_dir='./checkpoint_base_288_14.1G', log_dir=None, device='cuda', seed=0, resume='', auto_resume=True, save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, start_epoch=0, eval=False, dist_eval=True, disable_eval=False, num_workers=10, pin_mem=True, world_size=8, local_rank=-1, dist_on_itp=False, dist_url='env://', use_amp=True, enable_wandb=False, project='convnext', wandb_ckpt=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
Transform = 
RandomResizedCropAndInterpolation(size=(288, 288), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic)
RandomHorizontalFlip(p=0.5)
RandAugment(n=2, ops=
	AugmentOp(name=AutoContrast, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Equalize, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Invert, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Rotate, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=PosterizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeAdd, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ColorIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ContrastIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=BrightnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SharpnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearX, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearY, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateXRel, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateYRel, p=0.5, m=9, mstd=0.5))
ToTensor()
Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))
RandomErasing(p=0.25, mode=pixel, count=(1, 1))
---------------------------
reading from datapath /dev/shm/imagenet
Number of the class = 1000
Transform = 
Resize(size=329, interpolation=bicubic, max_size=None, antialias=True)
CenterCrop(size=(288, 288))
ToTensor()
Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
---------------------------
reading from datapath /dev/shm/imagenet
Number of the class = 1000
Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7feaba8cbe10>
Mixup is activated!
Model = SPCNN(
  (first_conv): ConvX(
    (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
  )
  (layer1): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): Identity()
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.010)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.020)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.030)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.040)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer2): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.050)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.060)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.070)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.080)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.090)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (5): BottleNeck(
      (drop_path): DropPath(drop_prob=0.100)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (6): BottleNeck(
      (drop_path): DropPath(drop_prob=0.110)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (7): BottleNeck(
      (drop_path): DropPath(drop_prob=0.120)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (8): BottleNeck(
      (drop_path): DropPath(drop_prob=0.130)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer3): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=768, bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.140)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.150)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.160)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.170)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.180)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (5): BottleNeck(
      (drop_path): DropPath(drop_prob=0.190)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (6): BottleNeck(
      (drop_path): DropPath(drop_prob=0.200)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (7): BottleNeck(
      (drop_path): DropPath(drop_prob=0.210)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (8): BottleNeck(
      (drop_path): DropPath(drop_prob=0.220)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (9): BottleNeck(
      (drop_path): DropPath(drop_prob=0.230)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (10): BottleNeck(
      (drop_path): DropPath(drop_prob=0.240)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (11): BottleNeck(
      (drop_path): DropPath(drop_prob=0.250)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (12): BottleNeck(
      (drop_path): DropPath(drop_prob=0.260)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (13): BottleNeck(
      (drop_path): DropPath(drop_prob=0.270)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (14): BottleNeck(
      (drop_path): DropPath(drop_prob=0.280)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (15): BottleNeck(
      (drop_path): DropPath(drop_prob=0.290)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (16): BottleNeck(
      (drop_path): DropPath(drop_prob=0.300)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (layer4): Sequential(
    (0): DownBlock(
      (mlp): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): ConvX(
          (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1536, bias=False)
          (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (skip): Sequential(
        (0): ConvX(
          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
          (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
        (1): ConvX(
          (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
      (drop_path): DropPath(drop_prob=0.310)
    )
    (1): BottleNeck(
      (drop_path): DropPath(drop_prob=0.320)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (2): BottleNeck(
      (drop_path): DropPath(drop_prob=0.330)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (3): BottleNeck(
      (drop_path): DropPath(drop_prob=0.340)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
    (4): BottleNeck(
      (drop_path): DropPath(drop_prob=0.350)
      (ln): LayerNorm()
      (sblock_in): ConvX(
        (conv): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act(
          (act): GELU(approximate='none')
        )
      )
      (sblock_dw): ConvX(
        (conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
        (norm): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (sblock_proj): ConvX(
        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): Act()
      )
      (mblock): Sequential(
        (0): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (1): PyramidConvX(
          (branch_1): Sequential(
            (0): AvgPool2d(kernel_size=3, stride=1, padding=1)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_2): Sequential(
            (0): AvgPool2d(kernel_size=5, stride=2, padding=2)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (branch_3): Sequential(
            (0): AvgPool2d(kernel_size=7, stride=3, padding=3)
            (1): ConvX(
              (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
              (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Act()
            )
          )
          (act): Act(
            (act): GELU(approximate='none')
          )
        )
        (2): ConvX(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Act()
        )
      )
    )
  )
  (head): ConvX(
    (conv): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (classifier): MlpHead(
    (fc1): Linear(in_features=1024, out_features=2048, bias=False)
    (norm): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act): Act(
      (act): GELU(approximate='none')
    )
    (drop): Dropout(p=0.2, inplace=False)
    (fc2): Linear(in_features=2048, out_features=1000, bias=False)
  )
)
number of params: 48903328
LR = 0.00400000
Batch size = 4096
Update frequent = 4
Number of training examples = 1281167
Number of training training per epoch = 312
Param groups = {
  "decay": {
    "weight_decay": 0.05,
    "params": [
      "first_conv.conv.weight",
      "layer1.0.mlp.0.conv.weight",
      "layer1.0.mlp.1.conv.weight",
      "layer1.0.mlp.2.conv.weight",
      "layer1.0.skip.0.conv.weight",
      "layer1.0.skip.1.conv.weight",
      "layer1.1.sblock_in.conv.weight",
      "layer1.1.sblock_dw.conv.weight",
      "layer1.1.sblock_proj.conv.weight",
      "layer1.1.mblock.0.conv.weight",
      "layer1.1.mblock.1.branch_1.1.conv.weight",
      "layer1.1.mblock.1.branch_2.1.conv.weight",
      "layer1.1.mblock.1.branch_3.1.conv.weight",
      "layer1.1.mblock.2.conv.weight",
      "layer1.2.sblock_in.conv.weight",
      "layer1.2.sblock_dw.conv.weight",
      "layer1.2.sblock_proj.conv.weight",
      "layer1.2.mblock.0.conv.weight",
      "layer1.2.mblock.1.branch_1.1.conv.weight",
      "layer1.2.mblock.1.branch_2.1.conv.weight",
      "layer1.2.mblock.1.branch_3.1.conv.weight",
      "layer1.2.mblock.2.conv.weight",
      "layer1.3.sblock_in.conv.weight",
      "layer1.3.sblock_dw.conv.weight",
      "layer1.3.sblock_proj.conv.weight",
      "layer1.3.mblock.0.conv.weight",
      "layer1.3.mblock.1.branch_1.1.conv.weight",
      "layer1.3.mblock.1.branch_2.1.conv.weight",
      "layer1.3.mblock.1.branch_3.1.conv.weight",
      "layer1.3.mblock.2.conv.weight",
      "layer1.4.sblock_in.conv.weight",
      "layer1.4.sblock_dw.conv.weight",
      "layer1.4.sblock_proj.conv.weight",
      "layer1.4.mblock.0.conv.weight",
      "layer1.4.mblock.1.branch_1.1.conv.weight",
      "layer1.4.mblock.1.branch_2.1.conv.weight",
      "layer1.4.mblock.1.branch_3.1.conv.weight",
      "layer1.4.mblock.2.conv.weight",
      "layer2.0.mlp.0.conv.weight",
      "layer2.0.mlp.1.conv.weight",
      "layer2.0.mlp.2.conv.weight",
      "layer2.0.skip.0.conv.weight",
      "layer2.0.skip.1.conv.weight",
      "layer2.1.sblock_in.conv.weight",
      "layer2.1.sblock_dw.conv.weight",
      "layer2.1.sblock_proj.conv.weight",
      "layer2.1.mblock.0.conv.weight",
      "layer2.1.mblock.1.branch_1.1.conv.weight",
      "layer2.1.mblock.1.branch_2.1.conv.weight",
      "layer2.1.mblock.1.branch_3.1.conv.weight",
      "layer2.1.mblock.2.conv.weight",
      "layer2.2.sblock_in.conv.weight",
      "layer2.2.sblock_dw.conv.weight",
      "layer2.2.sblock_proj.conv.weight",
      "layer2.2.mblock.0.conv.weight",
      "layer2.2.mblock.1.branch_1.1.conv.weight",
      "layer2.2.mblock.1.branch_2.1.conv.weight",
      "layer2.2.mblock.1.branch_3.1.conv.weight",
      "layer2.2.mblock.2.conv.weight",
      "layer2.3.sblock_in.conv.weight",
      "layer2.3.sblock_dw.conv.weight",
      "layer2.3.sblock_proj.conv.weight",
      "layer2.3.mblock.0.conv.weight",
      "layer2.3.mblock.1.branch_1.1.conv.weight",
      "layer2.3.mblock.1.branch_2.1.conv.weight",
      "layer2.3.mblock.1.branch_3.1.conv.weight",
      "layer2.3.mblock.2.conv.weight",
      "layer2.4.sblock_in.conv.weight",
      "layer2.4.sblock_dw.conv.weight",
      "layer2.4.sblock_proj.conv.weight",
      "layer2.4.mblock.0.conv.weight",
      "layer2.4.mblock.1.branch_1.1.conv.weight",
      "layer2.4.mblock.1.branch_2.1.conv.weight",
      "layer2.4.mblock.1.branch_3.1.conv.weight",
      "layer2.4.mblock.2.conv.weight",
      "layer2.5.sblock_in.conv.weight",
      "layer2.5.sblock_dw.conv.weight",
      "layer2.5.sblock_proj.conv.weight",
      "layer2.5.mblock.0.conv.weight",
      "layer2.5.mblock.1.branch_1.1.conv.weight",
      "layer2.5.mblock.1.branch_2.1.conv.weight",
      "layer2.5.mblock.1.branch_3.1.conv.weight",
      "layer2.5.mblock.2.conv.weight",
      "layer2.6.sblock_in.conv.weight",
      "layer2.6.sblock_dw.conv.weight",
      "layer2.6.sblock_proj.conv.weight",
      "layer2.6.mblock.0.conv.weight",
      "layer2.6.mblock.1.branch_1.1.conv.weight",
      "layer2.6.mblock.1.branch_2.1.conv.weight",
      "layer2.6.mblock.1.branch_3.1.conv.weight",
      "layer2.6.mblock.2.conv.weight",
      "layer2.7.sblock_in.conv.weight",
      "layer2.7.sblock_dw.conv.weight",
      "layer2.7.sblock_proj.conv.weight",
      "layer2.7.mblock.0.conv.weight",
      "layer2.7.mblock.1.branch_1.1.conv.weight",
      "layer2.7.mblock.1.branch_2.1.conv.weight",
      "layer2.7.mblock.1.branch_3.1.conv.weight",
      "layer2.7.mblock.2.conv.weight",
      "layer2.8.sblock_in.conv.weight",
      "layer2.8.sblock_dw.conv.weight",
      "layer2.8.sblock_proj.conv.weight",
      "layer2.8.mblock.0.conv.weight",
      "layer2.8.mblock.1.branch_1.1.conv.weight",
      "layer2.8.mblock.1.branch_2.1.conv.weight",
      "layer2.8.mblock.1.branch_3.1.conv.weight",
      "layer2.8.mblock.2.conv.weight",
      "layer3.0.mlp.0.conv.weight",
      "layer3.0.mlp.1.conv.weight",
      "layer3.0.mlp.2.conv.weight",
      "layer3.0.skip.0.conv.weight",
      "layer3.0.skip.1.conv.weight",
      "layer3.1.sblock_in.conv.weight",
      "layer3.1.sblock_dw.conv.weight",
      "layer3.1.sblock_proj.conv.weight",
      "layer3.1.mblock.0.conv.weight",
      "layer3.1.mblock.1.branch_1.1.conv.weight",
      "layer3.1.mblock.1.branch_2.1.conv.weight",
      "layer3.1.mblock.1.branch_3.1.conv.weight",
      "layer3.1.mblock.2.conv.weight",
      "layer3.2.sblock_in.conv.weight",
      "layer3.2.sblock_dw.conv.weight",
      "layer3.2.sblock_proj.conv.weight",
      "layer3.2.mblock.0.conv.weight",
      "layer3.2.mblock.1.branch_1.1.conv.weight",
      "layer3.2.mblock.1.branch_2.1.conv.weight",
      "layer3.2.mblock.1.branch_3.1.conv.weight",
      "layer3.2.mblock.2.conv.weight",
      "layer3.3.sblock_in.conv.weight",
      "layer3.3.sblock_dw.conv.weight",
      "layer3.3.sblock_proj.conv.weight",
      "layer3.3.mblock.0.conv.weight",
      "layer3.3.mblock.1.branch_1.1.conv.weight",
      "layer3.3.mblock.1.branch_2.1.conv.weight",
      "layer3.3.mblock.1.branch_3.1.conv.weight",
      "layer3.3.mblock.2.conv.weight",
      "layer3.4.sblock_in.conv.weight",
      "layer3.4.sblock_dw.conv.weight",
      "layer3.4.sblock_proj.conv.weight",
      "layer3.4.mblock.0.conv.weight",
      "layer3.4.mblock.1.branch_1.1.conv.weight",
      "layer3.4.mblock.1.branch_2.1.conv.weight",
      "layer3.4.mblock.1.branch_3.1.conv.weight",
      "layer3.4.mblock.2.conv.weight",
      "layer3.5.sblock_in.conv.weight",
      "layer3.5.sblock_dw.conv.weight",
      "layer3.5.sblock_proj.conv.weight",
      "layer3.5.mblock.0.conv.weight",
      "layer3.5.mblock.1.branch_1.1.conv.weight",
      "layer3.5.mblock.1.branch_2.1.conv.weight",
      "layer3.5.mblock.1.branch_3.1.conv.weight",
      "layer3.5.mblock.2.conv.weight",
      "layer3.6.sblock_in.conv.weight",
      "layer3.6.sblock_dw.conv.weight",
      "layer3.6.sblock_proj.conv.weight",
      "layer3.6.mblock.0.conv.weight",
      "layer3.6.mblock.1.branch_1.1.conv.weight",
      "layer3.6.mblock.1.branch_2.1.conv.weight",
      "layer3.6.mblock.1.branch_3.1.conv.weight",
      "layer3.6.mblock.2.conv.weight",
      "layer3.7.sblock_in.conv.weight",
      "layer3.7.sblock_dw.conv.weight",
      "layer3.7.sblock_proj.conv.weight",
      "layer3.7.mblock.0.conv.weight",
      "layer3.7.mblock.1.branch_1.1.conv.weight",
      "layer3.7.mblock.1.branch_2.1.conv.weight",
      "layer3.7.mblock.1.branch_3.1.conv.weight",
      "layer3.7.mblock.2.conv.weight",
      "layer3.8.sblock_in.conv.weight",
      "layer3.8.sblock_dw.conv.weight",
      "layer3.8.sblock_proj.conv.weight",
      "layer3.8.mblock.0.conv.weight",
      "layer3.8.mblock.1.branch_1.1.conv.weight",
      "layer3.8.mblock.1.branch_2.1.conv.weight",
      "layer3.8.mblock.1.branch_3.1.conv.weight",
      "layer3.8.mblock.2.conv.weight",
      "layer3.9.sblock_in.conv.weight",
      "layer3.9.sblock_dw.conv.weight",
      "layer3.9.sblock_proj.conv.weight",
      "layer3.9.mblock.0.conv.weight",
      "layer3.9.mblock.1.branch_1.1.conv.weight",
      "layer3.9.mblock.1.branch_2.1.conv.weight",
      "layer3.9.mblock.1.branch_3.1.conv.weight",
      "layer3.9.mblock.2.conv.weight",
      "layer3.10.sblock_in.conv.weight",
      "layer3.10.sblock_dw.conv.weight",
      "layer3.10.sblock_proj.conv.weight",
      "layer3.10.mblock.0.conv.weight",
      "layer3.10.mblock.1.branch_1.1.conv.weight",
      "layer3.10.mblock.1.branch_2.1.conv.weight",
      "layer3.10.mblock.1.branch_3.1.conv.weight",
      "layer3.10.mblock.2.conv.weight",
      "layer3.11.sblock_in.conv.weight",
      "layer3.11.sblock_dw.conv.weight",
      "layer3.11.sblock_proj.conv.weight",
      "layer3.11.mblock.0.conv.weight",
      "layer3.11.mblock.1.branch_1.1.conv.weight",
      "layer3.11.mblock.1.branch_2.1.conv.weight",
      "layer3.11.mblock.1.branch_3.1.conv.weight",
      "layer3.11.mblock.2.conv.weight",
      "layer3.12.sblock_in.conv.weight",
      "layer3.12.sblock_dw.conv.weight",
      "layer3.12.sblock_proj.conv.weight",
      "layer3.12.mblock.0.conv.weight",
      "layer3.12.mblock.1.branch_1.1.conv.weight",
      "layer3.12.mblock.1.branch_2.1.conv.weight",
      "layer3.12.mblock.1.branch_3.1.conv.weight",
      "layer3.12.mblock.2.conv.weight",
      "layer3.13.sblock_in.conv.weight",
      "layer3.13.sblock_dw.conv.weight",
      "layer3.13.sblock_proj.conv.weight",
      "layer3.13.mblock.0.conv.weight",
      "layer3.13.mblock.1.branch_1.1.conv.weight",
      "layer3.13.mblock.1.branch_2.1.conv.weight",
      "layer3.13.mblock.1.branch_3.1.conv.weight",
      "layer3.13.mblock.2.conv.weight",
      "layer3.14.sblock_in.conv.weight",
      "layer3.14.sblock_dw.conv.weight",
      "layer3.14.sblock_proj.conv.weight",
      "layer3.14.mblock.0.conv.weight",
      "layer3.14.mblock.1.branch_1.1.conv.weight",
      "layer3.14.mblock.1.branch_2.1.conv.weight",
      "layer3.14.mblock.1.branch_3.1.conv.weight",
      "layer3.14.mblock.2.conv.weight",
      "layer3.15.sblock_in.conv.weight",
      "layer3.15.sblock_dw.conv.weight",
      "layer3.15.sblock_proj.conv.weight",
      "layer3.15.mblock.0.conv.weight",
      "layer3.15.mblock.1.branch_1.1.conv.weight",
      "layer3.15.mblock.1.branch_2.1.conv.weight",
      "layer3.15.mblock.1.branch_3.1.conv.weight",
      "layer3.15.mblock.2.conv.weight",
      "layer3.16.sblock_in.conv.weight",
      "layer3.16.sblock_dw.conv.weight",
      "layer3.16.sblock_proj.conv.weight",
      "layer3.16.mblock.0.conv.weight",
      "layer3.16.mblock.1.branch_1.1.conv.weight",
      "layer3.16.mblock.1.branch_2.1.conv.weight",
      "layer3.16.mblock.1.branch_3.1.conv.weight",
      "layer3.16.mblock.2.conv.weight",
      "layer4.0.mlp.0.conv.weight",
      "layer4.0.mlp.1.conv.weight",
      "layer4.0.mlp.2.conv.weight",
      "layer4.0.skip.0.conv.weight",
      "layer4.0.skip.1.conv.weight",
      "layer4.1.sblock_in.conv.weight",
      "layer4.1.sblock_dw.conv.weight",
      "layer4.1.sblock_proj.conv.weight",
      "layer4.1.mblock.0.conv.weight",
      "layer4.1.mblock.1.branch_1.1.conv.weight",
      "layer4.1.mblock.1.branch_2.1.conv.weight",
      "layer4.1.mblock.1.branch_3.1.conv.weight",
      "layer4.1.mblock.2.conv.weight",
      "layer4.2.sblock_in.conv.weight",
      "layer4.2.sblock_dw.conv.weight",
      "layer4.2.sblock_proj.conv.weight",
      "layer4.2.mblock.0.conv.weight",
      "layer4.2.mblock.1.branch_1.1.conv.weight",
      "layer4.2.mblock.1.branch_2.1.conv.weight",
      "layer4.2.mblock.1.branch_3.1.conv.weight",
      "layer4.2.mblock.2.conv.weight",
      "layer4.3.sblock_in.conv.weight",
      "layer4.3.sblock_dw.conv.weight",
      "layer4.3.sblock_proj.conv.weight",
      "layer4.3.mblock.0.conv.weight",
      "layer4.3.mblock.1.branch_1.1.conv.weight",
      "layer4.3.mblock.1.branch_2.1.conv.weight",
      "layer4.3.mblock.1.branch_3.1.conv.weight",
      "layer4.3.mblock.2.conv.weight",
      "layer4.4.sblock_in.conv.weight",
      "layer4.4.sblock_dw.conv.weight",
      "layer4.4.sblock_proj.conv.weight",
      "layer4.4.mblock.0.conv.weight",
      "layer4.4.mblock.1.branch_1.1.conv.weight",
      "layer4.4.mblock.1.branch_2.1.conv.weight",
      "layer4.4.mblock.1.branch_3.1.conv.weight",
      "layer4.4.mblock.2.conv.weight",
      "head.conv.weight",
      "classifier.fc1.weight",
      "classifier.fc2.weight"
    ],
    "lr_scale": 1.0
  },
  "no_decay": {
    "weight_decay": 0.0,
    "params": [
      "first_conv.norm.weight",
      "first_conv.norm.bias",
      "layer1.0.mlp.0.norm.weight",
      "layer1.0.mlp.0.norm.bias",
      "layer1.0.mlp.1.norm.weight",
      "layer1.0.mlp.1.norm.bias",
      "layer1.0.mlp.2.norm.weight",
      "layer1.0.mlp.2.norm.bias",
      "layer1.0.skip.0.norm.weight",
      "layer1.0.skip.0.norm.bias",
      "layer1.0.skip.1.norm.weight",
      "layer1.0.skip.1.norm.bias",
      "layer1.1.sblock_in.norm.weight",
      "layer1.1.sblock_in.norm.bias",
      "layer1.1.sblock_dw.norm.weight",
      "layer1.1.sblock_dw.norm.bias",
      "layer1.1.sblock_proj.norm.weight",
      "layer1.1.sblock_proj.norm.bias",
      "layer1.1.mblock.0.norm.weight",
      "layer1.1.mblock.0.norm.bias",
      "layer1.1.mblock.1.branch_1.1.norm.weight",
      "layer1.1.mblock.1.branch_1.1.norm.bias",
      "layer1.1.mblock.1.branch_2.1.norm.weight",
      "layer1.1.mblock.1.branch_2.1.norm.bias",
      "layer1.1.mblock.1.branch_3.1.norm.weight",
      "layer1.1.mblock.1.branch_3.1.norm.bias",
      "layer1.1.mblock.2.norm.weight",
      "layer1.1.mblock.2.norm.bias",
      "layer1.2.sblock_in.norm.weight",
      "layer1.2.sblock_in.norm.bias",
      "layer1.2.sblock_dw.norm.weight",
      "layer1.2.sblock_dw.norm.bias",
      "layer1.2.sblock_proj.norm.weight",
      "layer1.2.sblock_proj.norm.bias",
      "layer1.2.mblock.0.norm.weight",
      "layer1.2.mblock.0.norm.bias",
      "layer1.2.mblock.1.branch_1.1.norm.weight",
      "layer1.2.mblock.1.branch_1.1.norm.bias",
      "layer1.2.mblock.1.branch_2.1.norm.weight",
      "layer1.2.mblock.1.branch_2.1.norm.bias",
      "layer1.2.mblock.1.branch_3.1.norm.weight",
      "layer1.2.mblock.1.branch_3.1.norm.bias",
      "layer1.2.mblock.2.norm.weight",
      "layer1.2.mblock.2.norm.bias",
      "layer1.3.sblock_in.norm.weight",
      "layer1.3.sblock_in.norm.bias",
      "layer1.3.sblock_dw.norm.weight",
      "layer1.3.sblock_dw.norm.bias",
      "layer1.3.sblock_proj.norm.weight",
      "layer1.3.sblock_proj.norm.bias",
      "layer1.3.mblock.0.norm.weight",
      "layer1.3.mblock.0.norm.bias",
      "layer1.3.mblock.1.branch_1.1.norm.weight",
      "layer1.3.mblock.1.branch_1.1.norm.bias",
      "layer1.3.mblock.1.branch_2.1.norm.weight",
      "layer1.3.mblock.1.branch_2.1.norm.bias",
      "layer1.3.mblock.1.branch_3.1.norm.weight",
      "layer1.3.mblock.1.branch_3.1.norm.bias",
      "layer1.3.mblock.2.norm.weight",
      "layer1.3.mblock.2.norm.bias",
      "layer1.4.sblock_in.norm.weight",
      "layer1.4.sblock_in.norm.bias",
      "layer1.4.sblock_dw.norm.weight",
      "layer1.4.sblock_dw.norm.bias",
      "layer1.4.sblock_proj.norm.weight",
      "layer1.4.sblock_proj.norm.bias",
      "layer1.4.mblock.0.norm.weight",
      "layer1.4.mblock.0.norm.bias",
      "layer1.4.mblock.1.branch_1.1.norm.weight",
      "layer1.4.mblock.1.branch_1.1.norm.bias",
      "layer1.4.mblock.1.branch_2.1.norm.weight",
      "layer1.4.mblock.1.branch_2.1.norm.bias",
      "layer1.4.mblock.1.branch_3.1.norm.weight",
      "layer1.4.mblock.1.branch_3.1.norm.bias",
      "layer1.4.mblock.2.norm.weight",
      "layer1.4.mblock.2.norm.bias",
      "layer2.0.mlp.0.norm.weight",
      "layer2.0.mlp.0.norm.bias",
      "layer2.0.mlp.1.norm.weight",
      "layer2.0.mlp.1.norm.bias",
      "layer2.0.mlp.2.norm.weight",
      "layer2.0.mlp.2.norm.bias",
      "layer2.0.skip.0.norm.weight",
      "layer2.0.skip.0.norm.bias",
      "layer2.0.skip.1.norm.weight",
      "layer2.0.skip.1.norm.bias",
      "layer2.1.sblock_in.norm.weight",
      "layer2.1.sblock_in.norm.bias",
      "layer2.1.sblock_dw.norm.weight",
      "layer2.1.sblock_dw.norm.bias",
      "layer2.1.sblock_proj.norm.weight",
      "layer2.1.sblock_proj.norm.bias",
      "layer2.1.mblock.0.norm.weight",
      "layer2.1.mblock.0.norm.bias",
      "layer2.1.mblock.1.branch_1.1.norm.weight",
      "layer2.1.mblock.1.branch_1.1.norm.bias",
      "layer2.1.mblock.1.branch_2.1.norm.weight",
      "layer2.1.mblock.1.branch_2.1.norm.bias",
      "layer2.1.mblock.1.branch_3.1.norm.weight",
      "layer2.1.mblock.1.branch_3.1.norm.bias",
      "layer2.1.mblock.2.norm.weight",
      "layer2.1.mblock.2.norm.bias",
      "layer2.2.sblock_in.norm.weight",
      "layer2.2.sblock_in.norm.bias",
      "layer2.2.sblock_dw.norm.weight",
      "layer2.2.sblock_dw.norm.bias",
      "layer2.2.sblock_proj.norm.weight",
      "layer2.2.sblock_proj.norm.bias",
      "layer2.2.mblock.0.norm.weight",
      "layer2.2.mblock.0.norm.bias",
      "layer2.2.mblock.1.branch_1.1.norm.weight",
      "layer2.2.mblock.1.branch_1.1.norm.bias",
      "layer2.2.mblock.1.branch_2.1.norm.weight",
      "layer2.2.mblock.1.branch_2.1.norm.bias",
      "layer2.2.mblock.1.branch_3.1.norm.weight",
      "layer2.2.mblock.1.branch_3.1.norm.bias",
      "layer2.2.mblock.2.norm.weight",
      "layer2.2.mblock.2.norm.bias",
      "layer2.3.sblock_in.norm.weight",
      "layer2.3.sblock_in.norm.bias",
      "layer2.3.sblock_dw.norm.weight",
      "layer2.3.sblock_dw.norm.bias",
      "layer2.3.sblock_proj.norm.weight",
      "layer2.3.sblock_proj.norm.bias",
      "layer2.3.mblock.0.norm.weight",
      "layer2.3.mblock.0.norm.bias",
      "layer2.3.mblock.1.branch_1.1.norm.weight",
      "layer2.3.mblock.1.branch_1.1.norm.bias",
      "layer2.3.mblock.1.branch_2.1.norm.weight",
      "layer2.3.mblock.1.branch_2.1.norm.bias",
      "layer2.3.mblock.1.branch_3.1.norm.weight",
      "layer2.3.mblock.1.branch_3.1.norm.bias",
      "layer2.3.mblock.2.norm.weight",
      "layer2.3.mblock.2.norm.bias",
      "layer2.4.sblock_in.norm.weight",
      "layer2.4.sblock_in.norm.bias",
      "layer2.4.sblock_dw.norm.weight",
      "layer2.4.sblock_dw.norm.bias",
      "layer2.4.sblock_proj.norm.weight",
      "layer2.4.sblock_proj.norm.bias",
      "layer2.4.mblock.0.norm.weight",
      "layer2.4.mblock.0.norm.bias",
      "layer2.4.mblock.1.branch_1.1.norm.weight",
      "layer2.4.mblock.1.branch_1.1.norm.bias",
      "layer2.4.mblock.1.branch_2.1.norm.weight",
      "layer2.4.mblock.1.branch_2.1.norm.bias",
      "layer2.4.mblock.1.branch_3.1.norm.weight",
      "layer2.4.mblock.1.branch_3.1.norm.bias",
      "layer2.4.mblock.2.norm.weight",
      "layer2.4.mblock.2.norm.bias",
      "layer2.5.sblock_in.norm.weight",
      "layer2.5.sblock_in.norm.bias",
      "layer2.5.sblock_dw.norm.weight",
      "layer2.5.sblock_dw.norm.bias",
      "layer2.5.sblock_proj.norm.weight",
      "layer2.5.sblock_proj.norm.bias",
      "layer2.5.mblock.0.norm.weight",
      "layer2.5.mblock.0.norm.bias",
      "layer2.5.mblock.1.branch_1.1.norm.weight",
      "layer2.5.mblock.1.branch_1.1.norm.bias",
      "layer2.5.mblock.1.branch_2.1.norm.weight",
      "layer2.5.mblock.1.branch_2.1.norm.bias",
      "layer2.5.mblock.1.branch_3.1.norm.weight",
      "layer2.5.mblock.1.branch_3.1.norm.bias",
      "layer2.5.mblock.2.norm.weight",
      "layer2.5.mblock.2.norm.bias",
      "layer2.6.sblock_in.norm.weight",
      "layer2.6.sblock_in.norm.bias",
      "layer2.6.sblock_dw.norm.weight",
      "layer2.6.sblock_dw.norm.bias",
      "layer2.6.sblock_proj.norm.weight",
      "layer2.6.sblock_proj.norm.bias",
      "layer2.6.mblock.0.norm.weight",
      "layer2.6.mblock.0.norm.bias",
      "layer2.6.mblock.1.branch_1.1.norm.weight",
      "layer2.6.mblock.1.branch_1.1.norm.bias",
      "layer2.6.mblock.1.branch_2.1.norm.weight",
      "layer2.6.mblock.1.branch_2.1.norm.bias",
      "layer2.6.mblock.1.branch_3.1.norm.weight",
      "layer2.6.mblock.1.branch_3.1.norm.bias",
      "layer2.6.mblock.2.norm.weight",
      "layer2.6.mblock.2.norm.bias",
      "layer2.7.sblock_in.norm.weight",
      "layer2.7.sblock_in.norm.bias",
      "layer2.7.sblock_dw.norm.weight",
      "layer2.7.sblock_dw.norm.bias",
      "layer2.7.sblock_proj.norm.weight",
      "layer2.7.sblock_proj.norm.bias",
      "layer2.7.mblock.0.norm.weight",
      "layer2.7.mblock.0.norm.bias",
      "layer2.7.mblock.1.branch_1.1.norm.weight",
      "layer2.7.mblock.1.branch_1.1.norm.bias",
      "layer2.7.mblock.1.branch_2.1.norm.weight",
      "layer2.7.mblock.1.branch_2.1.norm.bias",
      "layer2.7.mblock.1.branch_3.1.norm.weight",
      "layer2.7.mblock.1.branch_3.1.norm.bias",
      "layer2.7.mblock.2.norm.weight",
      "layer2.7.mblock.2.norm.bias",
      "layer2.8.sblock_in.norm.weight",
      "layer2.8.sblock_in.norm.bias",
      "layer2.8.sblock_dw.norm.weight",
      "layer2.8.sblock_dw.norm.bias",
      "layer2.8.sblock_proj.norm.weight",
      "layer2.8.sblock_proj.norm.bias",
      "layer2.8.mblock.0.norm.weight",
      "layer2.8.mblock.0.norm.bias",
      "layer2.8.mblock.1.branch_1.1.norm.weight",
      "layer2.8.mblock.1.branch_1.1.norm.bias",
      "layer2.8.mblock.1.branch_2.1.norm.weight",
      "layer2.8.mblock.1.branch_2.1.norm.bias",
      "layer2.8.mblock.1.branch_3.1.norm.weight",
      "layer2.8.mblock.1.branch_3.1.norm.bias",
      "layer2.8.mblock.2.norm.weight",
      "layer2.8.mblock.2.norm.bias",
      "layer3.0.mlp.0.norm.weight",
      "layer3.0.mlp.0.norm.bias",
      "layer3.0.mlp.1.norm.weight",
      "layer3.0.mlp.1.norm.bias",
      "layer3.0.mlp.2.norm.weight",
      "layer3.0.mlp.2.norm.bias",
      "layer3.0.skip.0.norm.weight",
      "layer3.0.skip.0.norm.bias",
      "layer3.0.skip.1.norm.weight",
      "layer3.0.skip.1.norm.bias",
      "layer3.1.sblock_in.norm.weight",
      "layer3.1.sblock_in.norm.bias",
      "layer3.1.sblock_dw.norm.weight",
      "layer3.1.sblock_dw.norm.bias",
      "layer3.1.sblock_proj.norm.weight",
      "layer3.1.sblock_proj.norm.bias",
      "layer3.1.mblock.0.norm.weight",
      "layer3.1.mblock.0.norm.bias",
      "layer3.1.mblock.1.branch_1.1.norm.weight",
      "layer3.1.mblock.1.branch_1.1.norm.bias",
      "layer3.1.mblock.1.branch_2.1.norm.weight",
      "layer3.1.mblock.1.branch_2.1.norm.bias",
      "layer3.1.mblock.1.branch_3.1.norm.weight",
      "layer3.1.mblock.1.branch_3.1.norm.bias",
      "layer3.1.mblock.2.norm.weight",
      "layer3.1.mblock.2.norm.bias",
      "layer3.2.sblock_in.norm.weight",
      "layer3.2.sblock_in.norm.bias",
      "layer3.2.sblock_dw.norm.weight",
      "layer3.2.sblock_dw.norm.bias",
      "layer3.2.sblock_proj.norm.weight",
      "layer3.2.sblock_proj.norm.bias",
      "layer3.2.mblock.0.norm.weight",
      "layer3.2.mblock.0.norm.bias",
      "layer3.2.mblock.1.branch_1.1.norm.weight",
      "layer3.2.mblock.1.branch_1.1.norm.bias",
      "layer3.2.mblock.1.branch_2.1.norm.weight",
      "layer3.2.mblock.1.branch_2.1.norm.bias",
      "layer3.2.mblock.1.branch_3.1.norm.weight",
      "layer3.2.mblock.1.branch_3.1.norm.bias",
      "layer3.2.mblock.2.norm.weight",
      "layer3.2.mblock.2.norm.bias",
      "layer3.3.sblock_in.norm.weight",
      "layer3.3.sblock_in.norm.bias",
      "layer3.3.sblock_dw.norm.weight",
      "layer3.3.sblock_dw.norm.bias",
      "layer3.3.sblock_proj.norm.weight",
      "layer3.3.sblock_proj.norm.bias",
      "layer3.3.mblock.0.norm.weight",
      "layer3.3.mblock.0.norm.bias",
      "layer3.3.mblock.1.branch_1.1.norm.weight",
      "layer3.3.mblock.1.branch_1.1.norm.bias",
      "layer3.3.mblock.1.branch_2.1.norm.weight",
      "layer3.3.mblock.1.branch_2.1.norm.bias",
      "layer3.3.mblock.1.branch_3.1.norm.weight",
      "layer3.3.mblock.1.branch_3.1.norm.bias",
      "layer3.3.mblock.2.norm.weight",
      "layer3.3.mblock.2.norm.bias",
      "layer3.4.sblock_in.norm.weight",
      "layer3.4.sblock_in.norm.bias",
      "layer3.4.sblock_dw.norm.weight",
      "layer3.4.sblock_dw.norm.bias",
      "layer3.4.sblock_proj.norm.weight",
      "layer3.4.sblock_proj.norm.bias",
      "layer3.4.mblock.0.norm.weight",
      "layer3.4.mblock.0.norm.bias",
      "layer3.4.mblock.1.branch_1.1.norm.weight",
      "layer3.4.mblock.1.branch_1.1.norm.bias",
      "layer3.4.mblock.1.branch_2.1.norm.weight",
      "layer3.4.mblock.1.branch_2.1.norm.bias",
      "layer3.4.mblock.1.branch_3.1.norm.weight",
      "layer3.4.mblock.1.branch_3.1.norm.bias",
      "layer3.4.mblock.2.norm.weight",
      "layer3.4.mblock.2.norm.bias",
      "layer3.5.sblock_in.norm.weight",
      "layer3.5.sblock_in.norm.bias",
      "layer3.5.sblock_dw.norm.weight",
      "layer3.5.sblock_dw.norm.bias",
      "layer3.5.sblock_proj.norm.weight",
      "layer3.5.sblock_proj.norm.bias",
      "layer3.5.mblock.0.norm.weight",
      "layer3.5.mblock.0.norm.bias",
      "layer3.5.mblock.1.branch_1.1.norm.weight",
      "layer3.5.mblock.1.branch_1.1.norm.bias",
      "layer3.5.mblock.1.branch_2.1.norm.weight",
      "layer3.5.mblock.1.branch_2.1.norm.bias",
      "layer3.5.mblock.1.branch_3.1.norm.weight",
      "layer3.5.mblock.1.branch_3.1.norm.bias",
      "layer3.5.mblock.2.norm.weight",
      "layer3.5.mblock.2.norm.bias",
      "layer3.6.sblock_in.norm.weight",
      "layer3.6.sblock_in.norm.bias",
      "layer3.6.sblock_dw.norm.weight",
      "layer3.6.sblock_dw.norm.bias",
      "layer3.6.sblock_proj.norm.weight",
      "layer3.6.sblock_proj.norm.bias",
      "layer3.6.mblock.0.norm.weight",
      "layer3.6.mblock.0.norm.bias",
      "layer3.6.mblock.1.branch_1.1.norm.weight",
      "layer3.6.mblock.1.branch_1.1.norm.bias",
      "layer3.6.mblock.1.branch_2.1.norm.weight",
      "layer3.6.mblock.1.branch_2.1.norm.bias",
      "layer3.6.mblock.1.branch_3.1.norm.weight",
      "layer3.6.mblock.1.branch_3.1.norm.bias",
      "layer3.6.mblock.2.norm.weight",
      "layer3.6.mblock.2.norm.bias",
      "layer3.7.sblock_in.norm.weight",
      "layer3.7.sblock_in.norm.bias",
      "layer3.7.sblock_dw.norm.weight",
      "layer3.7.sblock_dw.norm.bias",
      "layer3.7.sblock_proj.norm.weight",
      "layer3.7.sblock_proj.norm.bias",
      "layer3.7.mblock.0.norm.weight",
      "layer3.7.mblock.0.norm.bias",
      "layer3.7.mblock.1.branch_1.1.norm.weight",
      "layer3.7.mblock.1.branch_1.1.norm.bias",
      "layer3.7.mblock.1.branch_2.1.norm.weight",
      "layer3.7.mblock.1.branch_2.1.norm.bias",
      "layer3.7.mblock.1.branch_3.1.norm.weight",
      "layer3.7.mblock.1.branch_3.1.norm.bias",
      "layer3.7.mblock.2.norm.weight",
      "layer3.7.mblock.2.norm.bias",
      "layer3.8.sblock_in.norm.weight",
      "layer3.8.sblock_in.norm.bias",
      "layer3.8.sblock_dw.norm.weight",
      "layer3.8.sblock_dw.norm.bias",
      "layer3.8.sblock_proj.norm.weight",
      "layer3.8.sblock_proj.norm.bias",
      "layer3.8.mblock.0.norm.weight",
      "layer3.8.mblock.0.norm.bias",
      "layer3.8.mblock.1.branch_1.1.norm.weight",
      "layer3.8.mblock.1.branch_1.1.norm.bias",
      "layer3.8.mblock.1.branch_2.1.norm.weight",
      "layer3.8.mblock.1.branch_2.1.norm.bias",
      "layer3.8.mblock.1.branch_3.1.norm.weight",
      "layer3.8.mblock.1.branch_3.1.norm.bias",
      "layer3.8.mblock.2.norm.weight",
      "layer3.8.mblock.2.norm.bias",
      "layer3.9.sblock_in.norm.weight",
      "layer3.9.sblock_in.norm.bias",
      "layer3.9.sblock_dw.norm.weight",
      "layer3.9.sblock_dw.norm.bias",
      "layer3.9.sblock_proj.norm.weight",
      "layer3.9.sblock_proj.norm.bias",
      "layer3.9.mblock.0.norm.weight",
      "layer3.9.mblock.0.norm.bias",
      "layer3.9.mblock.1.branch_1.1.norm.weight",
      "layer3.9.mblock.1.branch_1.1.norm.bias",
      "layer3.9.mblock.1.branch_2.1.norm.weight",
      "layer3.9.mblock.1.branch_2.1.norm.bias",
      "layer3.9.mblock.1.branch_3.1.norm.weight",
      "layer3.9.mblock.1.branch_3.1.norm.bias",
      "layer3.9.mblock.2.norm.weight",
      "layer3.9.mblock.2.norm.bias",
      "layer3.10.sblock_in.norm.weight",
      "layer3.10.sblock_in.norm.bias",
      "layer3.10.sblock_dw.norm.weight",
      "layer3.10.sblock_dw.norm.bias",
      "layer3.10.sblock_proj.norm.weight",
      "layer3.10.sblock_proj.norm.bias",
      "layer3.10.mblock.0.norm.weight",
      "layer3.10.mblock.0.norm.bias",
      "layer3.10.mblock.1.branch_1.1.norm.weight",
      "layer3.10.mblock.1.branch_1.1.norm.bias",
      "layer3.10.mblock.1.branch_2.1.norm.weight",
      "layer3.10.mblock.1.branch_2.1.norm.bias",
      "layer3.10.mblock.1.branch_3.1.norm.weight",
      "layer3.10.mblock.1.branch_3.1.norm.bias",
      "layer3.10.mblock.2.norm.weight",
      "layer3.10.mblock.2.norm.bias",
      "layer3.11.sblock_in.norm.weight",
      "layer3.11.sblock_in.norm.bias",
      "layer3.11.sblock_dw.norm.weight",
      "layer3.11.sblock_dw.norm.bias",
      "layer3.11.sblock_proj.norm.weight",
      "layer3.11.sblock_proj.norm.bias",
      "layer3.11.mblock.0.norm.weight",
      "layer3.11.mblock.0.norm.bias",
      "layer3.11.mblock.1.branch_1.1.norm.weight",
      "layer3.11.mblock.1.branch_1.1.norm.bias",
      "layer3.11.mblock.1.branch_2.1.norm.weight",
      "layer3.11.mblock.1.branch_2.1.norm.bias",
      "layer3.11.mblock.1.branch_3.1.norm.weight",
      "layer3.11.mblock.1.branch_3.1.norm.bias",
      "layer3.11.mblock.2.norm.weight",
      "layer3.11.mblock.2.norm.bias",
      "layer3.12.sblock_in.norm.weight",
      "layer3.12.sblock_in.norm.bias",
      "layer3.12.sblock_dw.norm.weight",
      "layer3.12.sblock_dw.norm.bias",
      "layer3.12.sblock_proj.norm.weight",
      "layer3.12.sblock_proj.norm.bias",
      "layer3.12.mblock.0.norm.weight",
      "layer3.12.mblock.0.norm.bias",
      "layer3.12.mblock.1.branch_1.1.norm.weight",
      "layer3.12.mblock.1.branch_1.1.norm.bias",
      "layer3.12.mblock.1.branch_2.1.norm.weight",
      "layer3.12.mblock.1.branch_2.1.norm.bias",
      "layer3.12.mblock.1.branch_3.1.norm.weight",
      "layer3.12.mblock.1.branch_3.1.norm.bias",
      "layer3.12.mblock.2.norm.weight",
      "layer3.12.mblock.2.norm.bias",
      "layer3.13.sblock_in.norm.weight",
      "layer3.13.sblock_in.norm.bias",
      "layer3.13.sblock_dw.norm.weight",
      "layer3.13.sblock_dw.norm.bias",
      "layer3.13.sblock_proj.norm.weight",
      "layer3.13.sblock_proj.norm.bias",
      "layer3.13.mblock.0.norm.weight",
      "layer3.13.mblock.0.norm.bias",
      "layer3.13.mblock.1.branch_1.1.norm.weight",
      "layer3.13.mblock.1.branch_1.1.norm.bias",
      "layer3.13.mblock.1.branch_2.1.norm.weight",
      "layer3.13.mblock.1.branch_2.1.norm.bias",
      "layer3.13.mblock.1.branch_3.1.norm.weight",
      "layer3.13.mblock.1.branch_3.1.norm.bias",
      "layer3.13.mblock.2.norm.weight",
      "layer3.13.mblock.2.norm.bias",
      "layer3.14.sblock_in.norm.weight",
      "layer3.14.sblock_in.norm.bias",
      "layer3.14.sblock_dw.norm.weight",
      "layer3.14.sblock_dw.norm.bias",
      "layer3.14.sblock_proj.norm.weight",
      "layer3.14.sblock_proj.norm.bias",
      "layer3.14.mblock.0.norm.weight",
      "layer3.14.mblock.0.norm.bias",
      "layer3.14.mblock.1.branch_1.1.norm.weight",
      "layer3.14.mblock.1.branch_1.1.norm.bias",
      "layer3.14.mblock.1.branch_2.1.norm.weight",
      "layer3.14.mblock.1.branch_2.1.norm.bias",
      "layer3.14.mblock.1.branch_3.1.norm.weight",
      "layer3.14.mblock.1.branch_3.1.norm.bias",
      "layer3.14.mblock.2.norm.weight",
      "layer3.14.mblock.2.norm.bias",
      "layer3.15.sblock_in.norm.weight",
      "layer3.15.sblock_in.norm.bias",
      "layer3.15.sblock_dw.norm.weight",
      "layer3.15.sblock_dw.norm.bias",
      "layer3.15.sblock_proj.norm.weight",
      "layer3.15.sblock_proj.norm.bias",
      "layer3.15.mblock.0.norm.weight",
      "layer3.15.mblock.0.norm.bias",
      "layer3.15.mblock.1.branch_1.1.norm.weight",
      "layer3.15.mblock.1.branch_1.1.norm.bias",
      "layer3.15.mblock.1.branch_2.1.norm.weight",
      "layer3.15.mblock.1.branch_2.1.norm.bias",
      "layer3.15.mblock.1.branch_3.1.norm.weight",
      "layer3.15.mblock.1.branch_3.1.norm.bias",
      "layer3.15.mblock.2.norm.weight",
      "layer3.15.mblock.2.norm.bias",
      "layer3.16.sblock_in.norm.weight",
      "layer3.16.sblock_in.norm.bias",
      "layer3.16.sblock_dw.norm.weight",
      "layer3.16.sblock_dw.norm.bias",
      "layer3.16.sblock_proj.norm.weight",
      "layer3.16.sblock_proj.norm.bias",
      "layer3.16.mblock.0.norm.weight",
      "layer3.16.mblock.0.norm.bias",
      "layer3.16.mblock.1.branch_1.1.norm.weight",
      "layer3.16.mblock.1.branch_1.1.norm.bias",
      "layer3.16.mblock.1.branch_2.1.norm.weight",
      "layer3.16.mblock.1.branch_2.1.norm.bias",
      "layer3.16.mblock.1.branch_3.1.norm.weight",
      "layer3.16.mblock.1.branch_3.1.norm.bias",
      "layer3.16.mblock.2.norm.weight",
      "layer3.16.mblock.2.norm.bias",
      "layer4.0.mlp.0.norm.weight",
      "layer4.0.mlp.0.norm.bias",
      "layer4.0.mlp.1.norm.weight",
      "layer4.0.mlp.1.norm.bias",
      "layer4.0.mlp.2.norm.weight",
      "layer4.0.mlp.2.norm.bias",
      "layer4.0.skip.0.norm.weight",
      "layer4.0.skip.0.norm.bias",
      "layer4.0.skip.1.norm.weight",
      "layer4.0.skip.1.norm.bias",
      "layer4.1.sblock_in.norm.weight",
      "layer4.1.sblock_in.norm.bias",
      "layer4.1.sblock_dw.norm.weight",
      "layer4.1.sblock_dw.norm.bias",
      "layer4.1.sblock_proj.norm.weight",
      "layer4.1.sblock_proj.norm.bias",
      "layer4.1.mblock.0.norm.weight",
      "layer4.1.mblock.0.norm.bias",
      "layer4.1.mblock.1.branch_1.1.norm.weight",
      "layer4.1.mblock.1.branch_1.1.norm.bias",
      "layer4.1.mblock.1.branch_2.1.norm.weight",
      "layer4.1.mblock.1.branch_2.1.norm.bias",
      "layer4.1.mblock.1.branch_3.1.norm.weight",
      "layer4.1.mblock.1.branch_3.1.norm.bias",
      "layer4.1.mblock.2.norm.weight",
      "layer4.1.mblock.2.norm.bias",
      "layer4.2.sblock_in.norm.weight",
      "layer4.2.sblock_in.norm.bias",
      "layer4.2.sblock_dw.norm.weight",
      "layer4.2.sblock_dw.norm.bias",
      "layer4.2.sblock_proj.norm.weight",
      "layer4.2.sblock_proj.norm.bias",
      "layer4.2.mblock.0.norm.weight",
      "layer4.2.mblock.0.norm.bias",
      "layer4.2.mblock.1.branch_1.1.norm.weight",
      "layer4.2.mblock.1.branch_1.1.norm.bias",
      "layer4.2.mblock.1.branch_2.1.norm.weight",
      "layer4.2.mblock.1.branch_2.1.norm.bias",
      "layer4.2.mblock.1.branch_3.1.norm.weight",
      "layer4.2.mblock.1.branch_3.1.norm.bias",
      "layer4.2.mblock.2.norm.weight",
      "layer4.2.mblock.2.norm.bias",
      "layer4.3.sblock_in.norm.weight",
      "layer4.3.sblock_in.norm.bias",
      "layer4.3.sblock_dw.norm.weight",
      "layer4.3.sblock_dw.norm.bias",
      "layer4.3.sblock_proj.norm.weight",
      "layer4.3.sblock_proj.norm.bias",
      "layer4.3.mblock.0.norm.weight",
      "layer4.3.mblock.0.norm.bias",
      "layer4.3.mblock.1.branch_1.1.norm.weight",
      "layer4.3.mblock.1.branch_1.1.norm.bias",
      "layer4.3.mblock.1.branch_2.1.norm.weight",
      "layer4.3.mblock.1.branch_2.1.norm.bias",
      "layer4.3.mblock.1.branch_3.1.norm.weight",
      "layer4.3.mblock.1.branch_3.1.norm.bias",
      "layer4.3.mblock.2.norm.weight",
      "layer4.3.mblock.2.norm.bias",
      "layer4.4.sblock_in.norm.weight",
      "layer4.4.sblock_in.norm.bias",
      "layer4.4.sblock_dw.norm.weight",
      "layer4.4.sblock_dw.norm.bias",
      "layer4.4.sblock_proj.norm.weight",
      "layer4.4.sblock_proj.norm.bias",
      "layer4.4.mblock.0.norm.weight",
      "layer4.4.mblock.0.norm.bias",
      "layer4.4.mblock.1.branch_1.1.norm.weight",
      "layer4.4.mblock.1.branch_1.1.norm.bias",
      "layer4.4.mblock.1.branch_2.1.norm.weight",
      "layer4.4.mblock.1.branch_2.1.norm.bias",
      "layer4.4.mblock.1.branch_3.1.norm.weight",
      "layer4.4.mblock.1.branch_3.1.norm.bias",
      "layer4.4.mblock.2.norm.weight",
      "layer4.4.mblock.2.norm.bias",
      "head.norm.weight",
      "head.norm.bias",
      "classifier.norm.weight",
      "classifier.norm.bias"
    ],
    "lr_scale": 1.0
  }
}
Use Cosine LR scheduler
Set warmup steps = 6240
Set warmup steps = 0
Max WD = 0.0500000, Min WD = 0.0500000
criterion = SoftTargetCrossEntropy()
Auto resume checkpoint: checkpoint_base_288_14.1G/checkpoint-244.pth
Resume checkpoint checkpoint_base_288_14.1G/checkpoint-244.pth
With optim & sched!
Start training for 300 epochs
Epoch: [245]  [   0/1251]  eta: 6:29:21  lr: 0.000370  min_lr: 0.000370  loss: 3.2087 (3.2087)  weight_decay: 0.0500 (0.0500)  time: 18.6744  data: 4.7311  max mem: 62835
Epoch: [245]  [ 200/1251]  eta: 0:16:01  lr: 0.000368  min_lr: 0.000368  loss: 2.6838 (2.6716)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1103 (1.2048)  time: 0.8237  data: 0.0006  max mem: 62835
Epoch: [245]  [ 400/1251]  eta: 0:12:20  lr: 0.000366  min_lr: 0.000366  loss: 2.8619 (2.6628)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6201 (1.4653)  time: 0.8238  data: 0.0007  max mem: 62835
Epoch: [245]  [ 600/1251]  eta: 0:09:16  lr: 0.000364  min_lr: 0.000364  loss: 2.8545 (2.6742)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9442 (1.4435)  time: 0.8237  data: 0.0006  max mem: 62835
Epoch: [245]  [ 800/1251]  eta: 0:06:21  lr: 0.000362  min_lr: 0.000362  loss: 2.7722 (2.6824)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3379 (1.4798)  time: 0.8294  data: 0.0006  max mem: 62835
Epoch: [245]  [1000/1251]  eta: 0:03:31  lr: 0.000359  min_lr: 0.000359  loss: 2.8632 (2.6816)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2487 (1.4550)  time: 0.8236  data: 0.0006  max mem: 62835
Epoch: [245]  [1200/1251]  eta: 0:00:42  lr: 0.000357  min_lr: 0.000357  loss: 2.7709 (2.6772)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5216 (1.4381)  time: 0.8234  data: 0.0006  max mem: 62835
Epoch: [245]  [1250/1251]  eta: 0:00:00  lr: 0.000357  min_lr: 0.000357  loss: 2.5872 (2.6788)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4945 (1.4424)  time: 0.7001  data: 0.0006  max mem: 62835
Epoch: [245] Total time: 0:17:27 (0.8373 s / it)
Averaged stats: lr: 0.000357  min_lr: 0.000357  loss: 2.5872 (2.6785)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4945 (1.4424)
Test:  [ 0/25]  eta: 0:05:42  loss: 0.5603 (0.5603)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 13.7185  data: 8.1564  max mem: 62835
Test:  [10/25]  eta: 0:00:24  loss: 0.6392 (0.6582)  acc1: 88.0000 (87.4909)  acc5: 98.4000 (97.9273)  time: 1.6514  data: 0.7417  max mem: 62835
Test:  [20/25]  eta: 0:00:05  loss: 0.8010 (0.7730)  acc1: 82.8000 (84.4762)  acc5: 96.8000 (96.8000)  time: 0.4447  data: 0.0001  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8482 (0.7885)  acc1: 82.8000 (84.0000)  acc5: 96.8000 (96.7840)  time: 0.4447  data: 0.0001  max mem: 62835
Test: Total time: 0:00:24 (0.9799 s / it)
* Acc@1 84.224 Acc@5 96.938 loss 0.776
Accuracy of the model on the 50000 test images: 84.2%
Max accuracy: 84.22%
Epoch: [246]  [   0/1251]  eta: 1:26:44  lr: 0.000357  min_lr: 0.000357  loss: 2.9756 (2.9756)  weight_decay: 0.0500 (0.0500)  time: 4.1601  data: 3.2183  max mem: 62835
Epoch: [246]  [ 200/1251]  eta: 0:14:35  lr: 0.000355  min_lr: 0.000355  loss: 2.7626 (2.7091)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6326 (1.4007)  time: 0.8154  data: 0.0004  max mem: 62835
Epoch: [246]  [ 400/1251]  eta: 0:11:41  lr: 0.000353  min_lr: 0.000353  loss: 2.7815 (2.6917)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5917 (1.3965)  time: 0.8153  data: 0.0004  max mem: 62835
Epoch: [246]  [ 600/1251]  eta: 0:08:54  lr: 0.000351  min_lr: 0.000351  loss: 2.8464 (2.7056)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1656 (1.4322)  time: 0.8153  data: 0.0004  max mem: 62835
Epoch: [246]  [ 800/1251]  eta: 0:06:09  lr: 0.000349  min_lr: 0.000349  loss: 2.7945 (2.6917)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4187 (1.5443)  time: 0.8156  data: 0.0004  max mem: 62835
Epoch: [246]  [1000/1251]  eta: 0:03:25  lr: 0.000347  min_lr: 0.000347  loss: 2.5076 (2.6820)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0079 (1.4869)  time: 0.8138  data: 0.0004  max mem: 62835
Epoch: [246]  [1200/1251]  eta: 0:00:41  lr: 0.000345  min_lr: 0.000345  loss: 2.5187 (2.6879)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1482 (1.4733)  time: 0.8149  data: 0.0004  max mem: 62835
Epoch: [246]  [1250/1251]  eta: 0:00:00  lr: 0.000344  min_lr: 0.000344  loss: 2.6313 (2.6832)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2429 (1.4653)  time: 0.6921  data: 0.0005  max mem: 62835
Epoch: [246] Total time: 0:17:02 (0.8172 s / it)
Averaged stats: lr: 0.000344  min_lr: 0.000344  loss: 2.6313 (2.6756)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2429 (1.4653)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.6358 (0.6358)  acc1: 88.8000 (88.8000)  acc5: 99.6000 (99.6000)  time: 7.5538  data: 7.0697  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6937 (0.7107)  acc1: 87.6000 (87.1636)  acc5: 98.0000 (97.9636)  time: 1.0910  data: 0.6430  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8402 (0.8244)  acc1: 83.6000 (84.4571)  acc5: 96.8000 (96.8762)  time: 0.4447  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9068 (0.8401)  acc1: 82.8000 (83.9680)  acc5: 96.0000 (96.8000)  time: 0.4446  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7340 s / it)
* Acc@1 84.288 Acc@5 96.910 loss 0.831
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.29%
Epoch: [247]  [   0/1251]  eta: 1:24:28  lr: 0.000344  min_lr: 0.000344  loss: 3.4087 (3.4087)  weight_decay: 0.0500 (0.0500)  time: 4.0517  data: 3.2234  max mem: 62835
Epoch: [247]  [ 200/1251]  eta: 0:14:34  lr: 0.000342  min_lr: 0.000342  loss: 2.4897 (2.7106)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3432 (1.5305)  time: 0.8234  data: 0.0004  max mem: 62835
Epoch: [247]  [ 400/1251]  eta: 0:11:41  lr: 0.000340  min_lr: 0.000340  loss: 2.5749 (2.6843)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0976 (1.4687)  time: 0.8159  data: 0.0004  max mem: 62835
Epoch: [247]  [ 600/1251]  eta: 0:08:55  lr: 0.000338  min_lr: 0.000338  loss: 2.7100 (2.6597)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1369 (1.4596)  time: 0.8158  data: 0.0004  max mem: 62835
Epoch: [247]  [ 800/1251]  eta: 0:06:10  lr: 0.000336  min_lr: 0.000336  loss: 2.7458 (2.6634)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2821 (1.4194)  time: 0.8162  data: 0.0005  max mem: 62835
Epoch: [247]  [1000/1251]  eta: 0:03:25  lr: 0.000334  min_lr: 0.000334  loss: 2.8363 (2.6694)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0624 (1.4061)  time: 0.8158  data: 0.0004  max mem: 62835
Epoch: [247]  [1200/1251]  eta: 0:00:41  lr: 0.000332  min_lr: 0.000332  loss: 2.9193 (2.6751)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7672 (1.4275)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [247]  [1250/1251]  eta: 0:00:00  lr: 0.000332  min_lr: 0.000332  loss: 2.5547 (2.6715)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3727 (1.4278)  time: 0.6930  data: 0.0006  max mem: 62835
Epoch: [247] Total time: 0:17:03 (0.8178 s / it)
Averaged stats: lr: 0.000332  min_lr: 0.000332  loss: 2.5547 (2.6719)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3727 (1.4278)
Test:  [ 0/25]  eta: 0:03:20  loss: 0.6168 (0.6168)  acc1: 90.0000 (90.0000)  acc5: 98.4000 (98.4000)  time: 8.0163  data: 7.5402  max mem: 62835
Test:  [10/25]  eta: 0:00:17  loss: 0.6779 (0.6894)  acc1: 88.4000 (87.6364)  acc5: 98.0000 (98.0000)  time: 1.1339  data: 0.6857  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8251 (0.7975)  acc1: 84.4000 (84.6476)  acc5: 96.8000 (96.9143)  time: 0.4456  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8576 (0.8102)  acc1: 84.0000 (84.0480)  acc5: 96.4000 (96.8800)  time: 0.4455  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7550 s / it)
* Acc@1 84.250 Acc@5 96.916 loss 0.800
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.29%
Epoch: [248]  [   0/1251]  eta: 1:43:38  lr: 0.000332  min_lr: 0.000332  loss: 3.1921 (3.1921)  weight_decay: 0.0500 (0.0500)  time: 4.9712  data: 3.7444  max mem: 62835
Epoch: [248]  [ 200/1251]  eta: 0:14:38  lr: 0.000330  min_lr: 0.000330  loss: 2.8067 (2.7179)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9011 (1.5303)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [248]  [ 400/1251]  eta: 0:11:43  lr: 0.000328  min_lr: 0.000328  loss: 2.6329 (2.6523)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3845 (1.5586)  time: 0.8229  data: 0.0004  max mem: 62835
Epoch: [248]  [ 600/1251]  eta: 0:08:56  lr: 0.000326  min_lr: 0.000326  loss: 2.6569 (2.6623)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2826 (1.5163)  time: 0.8158  data: 0.0004  max mem: 62835
Epoch: [248]  [ 800/1251]  eta: 0:06:10  lr: 0.000324  min_lr: 0.000324  loss: 2.6688 (2.6705)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2107 (1.5107)  time: 0.8159  data: 0.0004  max mem: 62835
Epoch: [248]  [1000/1251]  eta: 0:03:25  lr: 0.000322  min_lr: 0.000322  loss: 2.7441 (2.6640)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1111 (1.4617)  time: 0.8162  data: 0.0004  max mem: 62835
Epoch: [248]  [1200/1251]  eta: 0:00:41  lr: 0.000320  min_lr: 0.000320  loss: 2.5161 (2.6539)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5005 (1.4507)  time: 0.8158  data: 0.0004  max mem: 62835
Epoch: [248]  [1250/1251]  eta: 0:00:00  lr: 0.000320  min_lr: 0.000320  loss: 2.9094 (2.6568)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4152 (1.4520)  time: 0.6929  data: 0.0005  max mem: 62835
Epoch: [248] Total time: 0:17:03 (0.8185 s / it)
Averaged stats: lr: 0.000320  min_lr: 0.000320  loss: 2.9094 (2.6678)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4152 (1.4520)
Test:  [ 0/25]  eta: 0:03:28  loss: 0.6487 (0.6487)  acc1: 88.4000 (88.4000)  acc5: 98.8000 (98.8000)  time: 8.3502  data: 7.8539  max mem: 62835
Test:  [10/25]  eta: 0:00:17  loss: 0.7196 (0.7290)  acc1: 87.2000 (87.4546)  acc5: 97.6000 (98.0000)  time: 1.1645  data: 0.7143  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8684 (0.8447)  acc1: 84.0000 (84.6857)  acc5: 96.8000 (96.9714)  time: 0.4458  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9054 (0.8571)  acc1: 83.2000 (84.3360)  acc5: 96.4000 (96.9120)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:19 (0.7702 s / it)
* Acc@1 84.302 Acc@5 97.012 loss 0.848
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.30%
Epoch: [249]  [   0/1251]  eta: 1:23:10  lr: 0.000320  min_lr: 0.000320  loss: 3.3247 (3.3247)  weight_decay: 0.0500 (0.0500)  time: 3.9894  data: 3.1745  max mem: 62835
Epoch: [249]  [ 200/1251]  eta: 0:14:34  lr: 0.000318  min_lr: 0.000318  loss: 2.4789 (2.6433)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2725 (1.5896)  time: 0.8169  data: 0.0004  max mem: 62835
Epoch: [249]  [ 400/1251]  eta: 0:11:42  lr: 0.000316  min_lr: 0.000316  loss: 2.5660 (2.6494)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4153 (1.4562)  time: 0.8163  data: 0.0004  max mem: 62835
Epoch: [249]  [ 600/1251]  eta: 0:08:55  lr: 0.000314  min_lr: 0.000314  loss: 2.5893 (2.6577)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2382 (1.4460)  time: 0.8161  data: 0.0005  max mem: 62835
Epoch: [249]  [ 800/1251]  eta: 0:06:10  lr: 0.000312  min_lr: 0.000312  loss: 2.7223 (2.6447)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3847 (1.4342)  time: 0.8246  data: 0.0004  max mem: 62835
Epoch: [249]  [1000/1251]  eta: 0:03:25  lr: 0.000310  min_lr: 0.000310  loss: 2.6301 (2.6501)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7162 (1.4530)  time: 0.8163  data: 0.0005  max mem: 62835
Epoch: [249]  [1200/1251]  eta: 0:00:41  lr: 0.000308  min_lr: 0.000308  loss: 2.7122 (2.6561)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3362 (1.4371)  time: 0.8159  data: 0.0005  max mem: 62835
Epoch: [249]  [1250/1251]  eta: 0:00:00  lr: 0.000308  min_lr: 0.000308  loss: 2.7904 (2.6587)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3009 (1.4398)  time: 0.6931  data: 0.0005  max mem: 62835
Epoch: [249] Total time: 0:17:03 (0.8179 s / it)
Averaged stats: lr: 0.000308  min_lr: 0.000308  loss: 2.7904 (2.6695)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3009 (1.4398)
Test:  [ 0/25]  eta: 0:03:17  loss: 0.6913 (0.6913)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.8917  data: 7.4115  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7684 (0.7727)  acc1: 86.8000 (86.9818)  acc5: 98.0000 (98.0000)  time: 1.1230  data: 0.6740  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8907 (0.8776)  acc1: 84.0000 (84.6095)  acc5: 96.8000 (96.9714)  time: 0.4460  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9593 (0.8932)  acc1: 83.6000 (84.1280)  acc5: 96.4000 (96.8160)  time: 0.4459  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7512 s / it)
* Acc@1 84.312 Acc@5 96.912 loss 0.885
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.31%
Epoch: [250]  [   0/1251]  eta: 1:11:20  lr: 0.000307  min_lr: 0.000307  loss: 2.7843 (2.7843)  weight_decay: 0.0500 (0.0500)  time: 3.4215  data: 2.5964  max mem: 62835
Epoch: [250]  [ 200/1251]  eta: 0:14:34  lr: 0.000306  min_lr: 0.000306  loss: 2.3812 (2.6259)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2498 (1.3828)  time: 0.8174  data: 0.0004  max mem: 62835
Epoch: [250]  [ 400/1251]  eta: 0:11:41  lr: 0.000304  min_lr: 0.000304  loss: 2.7444 (2.6490)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1852 (1.4141)  time: 0.8163  data: 0.0004  max mem: 62835
Epoch: [250]  [ 600/1251]  eta: 0:08:54  lr: 0.000302  min_lr: 0.000302  loss: 2.9018 (2.6403)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5826 (1.3869)  time: 0.8159  data: 0.0005  max mem: 62835
Epoch: [250]  [ 800/1251]  eta: 0:06:10  lr: 0.000300  min_lr: 0.000300  loss: 2.8165 (2.6456)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9607 (1.3495)  time: 0.8154  data: 0.0005  max mem: 62835
Epoch: [250]  [1000/1251]  eta: 0:03:25  lr: 0.000298  min_lr: 0.000298  loss: 2.8693 (2.6496)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9616 (1.3188)  time: 0.8149  data: 0.0004  max mem: 62835
Epoch: [250]  [1200/1251]  eta: 0:00:41  lr: 0.000296  min_lr: 0.000296  loss: 2.8315 (2.6499)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1771 (1.3525)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [250]  [1250/1251]  eta: 0:00:00  lr: 0.000296  min_lr: 0.000296  loss: 2.9083 (2.6507)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1614 (1.3555)  time: 0.6959  data: 0.0006  max mem: 62835
Epoch: [250] Total time: 0:17:02 (0.8176 s / it)
Averaged stats: lr: 0.000296  min_lr: 0.000296  loss: 2.9083 (2.6683)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1614 (1.3555)
Test:  [ 0/25]  eta: 0:03:17  loss: 0.6526 (0.6526)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 7.8866  data: 7.4170  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7349 (0.7419)  acc1: 87.2000 (87.6000)  acc5: 97.6000 (97.9636)  time: 1.1226  data: 0.6745  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8456 (0.8468)  acc1: 84.8000 (84.8571)  acc5: 97.2000 (96.9333)  time: 0.4460  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9222 (0.8602)  acc1: 84.4000 (84.4480)  acc5: 96.4000 (96.8480)  time: 0.4458  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7513 s / it)
* Acc@1 84.386 Acc@5 96.948 loss 0.851
Accuracy of the model on the 50000 test images: 84.4%
Max accuracy: 84.39%
Epoch: [251]  [   0/1251]  eta: 1:30:38  lr: 0.000296  min_lr: 0.000296  loss: 2.9085 (2.9085)  weight_decay: 0.0500 (0.0500)  time: 4.3473  data: 3.5274  max mem: 62835
Epoch: [251]  [ 200/1251]  eta: 0:14:36  lr: 0.000294  min_lr: 0.000294  loss: 2.7145 (2.6233)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2180 (1.3142)  time: 0.8152  data: 0.0004  max mem: 62835
Epoch: [251]  [ 400/1251]  eta: 0:11:41  lr: 0.000292  min_lr: 0.000292  loss: 2.6106 (2.6236)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2362 (1.3897)  time: 0.8138  data: 0.0004  max mem: 62835
Epoch: [251]  [ 600/1251]  eta: 0:08:55  lr: 0.000290  min_lr: 0.000290  loss: 2.5316 (2.6249)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1386 (nan)  time: 0.8151  data: 0.0004  max mem: 62835
Epoch: [251]  [ 800/1251]  eta: 0:06:09  lr: 0.000288  min_lr: 0.000288  loss: 2.5635 (2.6473)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3906 (nan)  time: 0.8184  data: 0.0004  max mem: 62835
Epoch: [251]  [1000/1251]  eta: 0:03:25  lr: 0.000286  min_lr: 0.000286  loss: 2.7270 (2.6463)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4206 (nan)  time: 0.8155  data: 0.0004  max mem: 62835
Epoch: [251]  [1200/1251]  eta: 0:00:41  lr: 0.000284  min_lr: 0.000284  loss: 2.7069 (2.6511)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2498 (nan)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [251]  [1250/1251]  eta: 0:00:00  lr: 0.000284  min_lr: 0.000284  loss: 2.8038 (2.6519)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3065 (nan)  time: 0.6927  data: 0.0004  max mem: 62835
Epoch: [251] Total time: 0:17:02 (0.8172 s / it)
Averaged stats: lr: 0.000284  min_lr: 0.000284  loss: 2.8038 (2.6516)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3065 (nan)
Test:  [ 0/25]  eta: 0:03:23  loss: 0.6876 (0.6876)  acc1: 88.4000 (88.4000)  acc5: 99.2000 (99.2000)  time: 8.1307  data: 7.6609  max mem: 62835
Test:  [10/25]  eta: 0:00:17  loss: 0.7754 (0.7722)  acc1: 88.0000 (87.3818)  acc5: 98.0000 (98.1091)  time: 1.1446  data: 0.6967  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.9078 (0.8821)  acc1: 84.0000 (84.7429)  acc5: 96.8000 (96.9714)  time: 0.4459  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9635 (0.8954)  acc1: 83.6000 (84.4000)  acc5: 96.4000 (96.8640)  time: 0.4459  data: 0.0001  max mem: 62835
Test: Total time: 0:00:19 (0.7635 s / it)
* Acc@1 84.396 Acc@5 96.942 loss 0.883
Accuracy of the model on the 50000 test images: 84.4%
Max accuracy: 84.40%
Epoch: [252]  [   0/1251]  eta: 1:23:03  lr: 0.000284  min_lr: 0.000284  loss: 2.9676 (2.9676)  weight_decay: 0.0500 (0.0500)  time: 3.9835  data: 3.1564  max mem: 62835
Epoch: [252]  [ 200/1251]  eta: 0:14:33  lr: 0.000282  min_lr: 0.000282  loss: 2.4135 (2.6049)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3292 (1.3860)  time: 0.8163  data: 0.0004  max mem: 62835
Epoch: [252]  [ 400/1251]  eta: 0:11:41  lr: 0.000280  min_lr: 0.000280  loss: 2.8450 (2.6469)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2463 (1.4768)  time: 0.8161  data: 0.0004  max mem: 62835
Epoch: [252]  [ 600/1251]  eta: 0:08:55  lr: 0.000279  min_lr: 0.000279  loss: 2.8449 (2.6413)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1107 (1.4392)  time: 0.8158  data: 0.0004  max mem: 62835
Epoch: [252]  [ 800/1251]  eta: 0:06:10  lr: 0.000277  min_lr: 0.000277  loss: 2.7556 (2.6453)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1769 (1.4007)  time: 0.8158  data: 0.0003  max mem: 62835
Epoch: [252]  [1000/1251]  eta: 0:03:25  lr: 0.000275  min_lr: 0.000275  loss: 2.7155 (2.6537)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3053 (1.4023)  time: 0.8159  data: 0.0004  max mem: 62835
Epoch: [252]  [1200/1251]  eta: 0:00:41  lr: 0.000273  min_lr: 0.000273  loss: 2.6285 (2.6519)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1775 (1.4008)  time: 0.8162  data: 0.0004  max mem: 62835
Epoch: [252]  [1250/1251]  eta: 0:00:00  lr: 0.000273  min_lr: 0.000273  loss: 2.5020 (2.6479)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2116 (1.3926)  time: 0.6929  data: 0.0005  max mem: 62835
Epoch: [252] Total time: 0:17:03 (0.8180 s / it)
Averaged stats: lr: 0.000273  min_lr: 0.000273  loss: 2.5020 (2.6547)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2116 (1.3926)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.5786 (0.5786)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.7901  data: 7.3215  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6715 (0.6798)  acc1: 88.0000 (87.7091)  acc5: 98.0000 (98.1455)  time: 1.1136  data: 0.6658  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8074 (0.8003)  acc1: 84.0000 (84.9714)  acc5: 96.8000 (96.9714)  time: 0.4459  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8725 (0.8147)  acc1: 83.6000 (84.5440)  acc5: 96.4000 (96.8320)  time: 0.4458  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7471 s / it)
* Acc@1 84.438 Acc@5 96.908 loss 0.808
Accuracy of the model on the 50000 test images: 84.4%
Max accuracy: 84.44%
Epoch: [253]  [   0/1251]  eta: 1:26:49  lr: 0.000273  min_lr: 0.000273  loss: 2.9102 (2.9102)  weight_decay: 0.0500 (0.0500)  time: 4.1639  data: 3.3444  max mem: 62835
Epoch: [253]  [ 200/1251]  eta: 0:14:35  lr: 0.000271  min_lr: 0.000271  loss: 2.6728 (2.6820)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2472 (1.3004)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [253]  [ 400/1251]  eta: 0:11:42  lr: 0.000269  min_lr: 0.000269  loss: 2.8714 (2.6650)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1974 (1.5368)  time: 0.8162  data: 0.0004  max mem: 62835
Epoch: [253]  [ 600/1251]  eta: 0:08:55  lr: 0.000267  min_lr: 0.000267  loss: 2.5745 (2.6478)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5972 (nan)  time: 0.8173  data: 0.0004  max mem: 62835
Epoch: [253]  [ 800/1251]  eta: 0:06:10  lr: 0.000265  min_lr: 0.000265  loss: 2.6449 (2.6440)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2352 (nan)  time: 0.8218  data: 0.0004  max mem: 62835
Epoch: [253]  [1000/1251]  eta: 0:03:26  lr: 0.000264  min_lr: 0.000264  loss: 2.7955 (2.6486)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1655 (nan)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [253]  [1200/1251]  eta: 0:00:41  lr: 0.000262  min_lr: 0.000262  loss: 2.6371 (2.6495)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4770 (nan)  time: 0.8172  data: 0.0005  max mem: 62835
Epoch: [253]  [1250/1251]  eta: 0:00:00  lr: 0.000261  min_lr: 0.000261  loss: 2.7615 (2.6496)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2645 (nan)  time: 0.6936  data: 0.0006  max mem: 62835
Epoch: [253] Total time: 0:17:04 (0.8187 s / it)
Averaged stats: lr: 0.000261  min_lr: 0.000261  loss: 2.7615 (2.6538)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2645 (nan)
Test:  [ 0/25]  eta: 0:03:11  loss: 0.6655 (0.6655)  acc1: 88.8000 (88.8000)  acc5: 99.2000 (99.2000)  time: 7.6699  data: 7.1990  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7420 (0.7490)  acc1: 86.8000 (87.4909)  acc5: 98.0000 (98.0364)  time: 1.1018  data: 0.6547  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8766 (0.8666)  acc1: 84.4000 (84.7810)  acc5: 96.8000 (96.9333)  time: 0.4449  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9449 (0.8829)  acc1: 83.2000 (84.2720)  acc5: 96.4000 (96.8320)  time: 0.4448  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7409 s / it)
* Acc@1 84.376 Acc@5 96.902 loss 0.873
Accuracy of the model on the 50000 test images: 84.4%
Max accuracy: 84.44%
Epoch: [254]  [   0/1251]  eta: 1:51:13  lr: 0.000261  min_lr: 0.000261  loss: 2.3697 (2.3697)  weight_decay: 0.0500 (0.0500)  time: 5.3343  data: 3.5380  max mem: 62835
Epoch: [254]  [ 200/1251]  eta: 0:14:44  lr: 0.000260  min_lr: 0.000260  loss: 2.4076 (2.6256)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1785 (1.3025)  time: 0.8171  data: 0.0004  max mem: 62835
Epoch: [254]  [ 400/1251]  eta: 0:11:45  lr: 0.000258  min_lr: 0.000258  loss: 2.7320 (2.6341)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3989 (1.5571)  time: 0.8167  data: 0.0005  max mem: 62835
Epoch: [254]  [ 600/1251]  eta: 0:08:57  lr: 0.000256  min_lr: 0.000256  loss: 2.8867 (2.6438)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2025 (1.5413)  time: 0.8157  data: 0.0005  max mem: 62835
Epoch: [254]  [ 800/1251]  eta: 0:06:11  lr: 0.000254  min_lr: 0.000254  loss: 2.5476 (2.6451)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1930 (1.5267)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [254]  [1000/1251]  eta: 0:03:26  lr: 0.000253  min_lr: 0.000253  loss: 2.5959 (2.6475)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2686 (1.4584)  time: 0.8155  data: 0.0004  max mem: 62835
Epoch: [254]  [1200/1251]  eta: 0:00:41  lr: 0.000251  min_lr: 0.000251  loss: 2.6422 (2.6420)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2935 (1.4487)  time: 0.8166  data: 0.0005  max mem: 62835
Epoch: [254]  [1250/1251]  eta: 0:00:00  lr: 0.000251  min_lr: 0.000251  loss: 2.7373 (2.6436)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1744 (1.4415)  time: 0.6959  data: 0.0007  max mem: 62835
Epoch: [254] Total time: 0:17:05 (0.8195 s / it)
Averaged stats: lr: 0.000251  min_lr: 0.000251  loss: 2.7373 (2.6439)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1744 (1.4415)
Test:  [ 0/25]  eta: 0:03:30  loss: 0.6107 (0.6107)  acc1: 88.8000 (88.8000)  acc5: 98.8000 (98.8000)  time: 8.4316  data: 7.9486  max mem: 62835
Test:  [10/25]  eta: 0:00:17  loss: 0.6962 (0.7002)  acc1: 88.0000 (87.5636)  acc5: 98.0000 (98.0364)  time: 1.1710  data: 0.7229  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8239 (0.8063)  acc1: 84.4000 (84.7619)  acc5: 97.2000 (97.0857)  time: 0.4448  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8768 (0.8194)  acc1: 83.6000 (84.4480)  acc5: 96.4000 (96.9120)  time: 0.4448  data: 0.0001  max mem: 62835
Test: Total time: 0:00:19 (0.7703 s / it)
* Acc@1 84.434 Acc@5 96.954 loss 0.814
Accuracy of the model on the 50000 test images: 84.4%
Max accuracy: 84.44%
Epoch: [255]  [   0/1251]  eta: 1:35:26  lr: 0.000250  min_lr: 0.000250  loss: 2.8459 (2.8459)  weight_decay: 0.0500 (0.0500)  time: 4.5774  data: 3.2809  max mem: 62835
Epoch: [255]  [ 200/1251]  eta: 0:14:38  lr: 0.000249  min_lr: 0.000249  loss: 2.7460 (2.6577)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3420 (1.4201)  time: 0.8177  data: 0.0004  max mem: 62835
Epoch: [255]  [ 400/1251]  eta: 0:11:43  lr: 0.000247  min_lr: 0.000247  loss: 2.7444 (2.6480)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2541 (1.4419)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [255]  [ 600/1251]  eta: 0:08:56  lr: 0.000245  min_lr: 0.000245  loss: 2.8022 (2.6549)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4937 (1.4994)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [255]  [ 800/1251]  eta: 0:06:10  lr: 0.000244  min_lr: 0.000244  loss: 2.4065 (2.6387)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6079 (1.4722)  time: 0.8172  data: 0.0004  max mem: 62835
Epoch: [255]  [1000/1251]  eta: 0:03:26  lr: 0.000242  min_lr: 0.000242  loss: 2.5289 (2.6368)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3355 (1.4848)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [255]  [1200/1251]  eta: 0:00:41  lr: 0.000240  min_lr: 0.000240  loss: 2.2501 (2.6311)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3207 (1.5212)  time: 0.8173  data: 0.0004  max mem: 62835
Epoch: [255]  [1250/1251]  eta: 0:00:00  lr: 0.000240  min_lr: 0.000240  loss: 2.6624 (2.6308)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2753 (1.5137)  time: 0.6941  data: 0.0007  max mem: 62835
Epoch: [255] Total time: 0:17:04 (0.8189 s / it)
Averaged stats: lr: 0.000240  min_lr: 0.000240  loss: 2.6624 (2.6470)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2753 (1.5137)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.5818 (0.5818)  acc1: 90.0000 (90.0000)  acc5: 98.8000 (98.8000)  time: 7.7182  data: 7.2444  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6725 (0.6816)  acc1: 87.2000 (87.7455)  acc5: 97.6000 (97.8909)  time: 1.1074  data: 0.6589  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8169 (0.7977)  acc1: 83.2000 (84.8381)  acc5: 96.8000 (96.9905)  time: 0.4461  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8805 (0.8127)  acc1: 82.4000 (84.3680)  acc5: 96.4000 (96.9120)  time: 0.4460  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7453 s / it)
* Acc@1 84.338 Acc@5 96.946 loss 0.804
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.44%
Epoch: [256]  [   0/1251]  eta: 1:51:15  lr: 0.000240  min_lr: 0.000240  loss: 3.2030 (3.2030)  weight_decay: 0.0500 (0.0500)  time: 5.3361  data: 3.1870  max mem: 62835
Epoch: [256]  [ 200/1251]  eta: 0:14:42  lr: 0.000238  min_lr: 0.000238  loss: 2.8410 (2.6337)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3649 (1.4300)  time: 0.8163  data: 0.0004  max mem: 62835
Epoch: [256]  [ 400/1251]  eta: 0:11:44  lr: 0.000236  min_lr: 0.000236  loss: 2.7136 (2.6423)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3556 (1.4880)  time: 0.8231  data: 0.0004  max mem: 62835
Epoch: [256]  [ 600/1251]  eta: 0:08:56  lr: 0.000235  min_lr: 0.000235  loss: 2.6606 (2.6312)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6804 (1.5534)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [256]  [ 800/1251]  eta: 0:06:11  lr: 0.000233  min_lr: 0.000233  loss: 2.8248 (2.6342)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3392 (1.4966)  time: 0.8170  data: 0.0004  max mem: 62835
Epoch: [256]  [1000/1251]  eta: 0:03:26  lr: 0.000231  min_lr: 0.000231  loss: 2.6931 (2.6402)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2176 (1.4631)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [256]  [1200/1251]  eta: 0:00:41  lr: 0.000230  min_lr: 0.000230  loss: 2.8384 (2.6405)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4048 (1.4513)  time: 0.8169  data: 0.0004  max mem: 62835
Epoch: [256]  [1250/1251]  eta: 0:00:00  lr: 0.000229  min_lr: 0.000229  loss: 2.6518 (2.6411)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5182 (1.4508)  time: 0.6967  data: 0.0005  max mem: 62835
Epoch: [256] Total time: 0:17:05 (0.8195 s / it)
Averaged stats: lr: 0.000229  min_lr: 0.000229  loss: 2.6518 (2.6315)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5182 (1.4508)
Test:  [ 0/25]  eta: 0:03:15  loss: 0.6190 (0.6190)  acc1: 90.0000 (90.0000)  acc5: 99.2000 (99.2000)  time: 7.8086  data: 7.3309  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7140 (0.7171)  acc1: 86.8000 (87.0909)  acc5: 98.0000 (98.1091)  time: 1.1153  data: 0.6667  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8516 (0.8238)  acc1: 83.2000 (84.4571)  acc5: 96.8000 (96.9714)  time: 0.4458  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8963 (0.8380)  acc1: 83.2000 (84.0320)  acc5: 96.4000 (96.8640)  time: 0.4458  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7485 s / it)
* Acc@1 84.424 Acc@5 96.936 loss 0.830
Accuracy of the model on the 50000 test images: 84.4%
Max accuracy: 84.44%
Epoch: [257]  [   0/1251]  eta: 1:40:44  lr: 0.000229  min_lr: 0.000229  loss: 2.1163 (2.1163)  weight_decay: 0.0500 (0.0500)  time: 4.8317  data: 3.2626  max mem: 62835
Epoch: [257]  [ 200/1251]  eta: 0:14:39  lr: 0.000228  min_lr: 0.000228  loss: 2.5397 (2.6478)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1603 (1.3657)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [257]  [ 400/1251]  eta: 0:11:44  lr: 0.000226  min_lr: 0.000226  loss: 2.4266 (2.6202)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5893 (1.5908)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [257]  [ 600/1251]  eta: 0:08:56  lr: 0.000224  min_lr: 0.000224  loss: 2.6686 (2.6264)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4760 (1.5544)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [257]  [ 800/1251]  eta: 0:06:10  lr: 0.000223  min_lr: 0.000223  loss: 2.8005 (2.6357)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1617 (1.5036)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [257]  [1000/1251]  eta: 0:03:26  lr: 0.000221  min_lr: 0.000221  loss: 2.5927 (2.6345)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2765 (1.4716)  time: 0.8164  data: 0.0004  max mem: 62835
Epoch: [257]  [1200/1251]  eta: 0:00:41  lr: 0.000219  min_lr: 0.000219  loss: 2.9629 (2.6321)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2947 (1.4656)  time: 0.8164  data: 0.0004  max mem: 62835
Epoch: [257]  [1250/1251]  eta: 0:00:00  lr: 0.000219  min_lr: 0.000219  loss: 2.7601 (2.6346)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2092 (1.4599)  time: 0.6934  data: 0.0005  max mem: 62835
Epoch: [257] Total time: 0:17:04 (0.8189 s / it)
Averaged stats: lr: 0.000219  min_lr: 0.000219  loss: 2.7601 (2.6319)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2092 (1.4599)
Test:  [ 0/25]  eta: 0:03:05  loss: 0.6658 (0.6658)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.4318  data: 6.9677  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7568 (0.7640)  acc1: 87.2000 (87.4546)  acc5: 98.0000 (98.0364)  time: 1.0823  data: 0.6337  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8886 (0.8771)  acc1: 83.6000 (84.7048)  acc5: 96.8000 (97.1238)  time: 0.4461  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9548 (0.8924)  acc1: 83.2000 (84.1760)  acc5: 96.4000 (97.0080)  time: 0.4452  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7342 s / it)
* Acc@1 84.378 Acc@5 96.924 loss 0.884
Accuracy of the model on the 50000 test images: 84.4%
Max accuracy: 84.44%
Epoch: [258]  [   0/1251]  eta: 1:41:58  lr: 0.000219  min_lr: 0.000219  loss: 2.8635 (2.8635)  weight_decay: 0.0500 (0.0500)  time: 4.8908  data: 3.4648  max mem: 62835
Epoch: [258]  [ 200/1251]  eta: 0:14:41  lr: 0.000217  min_lr: 0.000217  loss: 2.7577 (2.6449)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5064 (1.4886)  time: 0.8176  data: 0.0004  max mem: 62835
Epoch: [258]  [ 400/1251]  eta: 0:11:44  lr: 0.000216  min_lr: 0.000216  loss: 2.7599 (2.6296)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3567 (1.4832)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [258]  [ 600/1251]  eta: 0:08:56  lr: 0.000214  min_lr: 0.000214  loss: 2.8879 (2.6207)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0266 (1.5375)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [258]  [ 800/1251]  eta: 0:06:11  lr: 0.000212  min_lr: 0.000212  loss: 2.7708 (2.6153)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2624 (1.4892)  time: 0.8204  data: 0.0004  max mem: 62835
Epoch: [258]  [1000/1251]  eta: 0:03:26  lr: 0.000211  min_lr: 0.000211  loss: 2.7210 (2.6165)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4448 (1.4728)  time: 0.8169  data: 0.0008  max mem: 62835
Epoch: [258]  [1200/1251]  eta: 0:00:41  lr: 0.000209  min_lr: 0.000209  loss: 2.4657 (2.6128)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4846 (1.5056)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [258]  [1250/1251]  eta: 0:00:00  lr: 0.000209  min_lr: 0.000209  loss: 2.7998 (2.6170)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7218 (1.5179)  time: 0.6968  data: 0.0006  max mem: 62835
Epoch: [258] Total time: 0:17:04 (0.8193 s / it)
Averaged stats: lr: 0.000209  min_lr: 0.000209  loss: 2.7998 (2.6224)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7218 (1.5179)
Test:  [ 0/25]  eta: 0:03:07  loss: 0.6737 (0.6737)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.4991  data: 7.0312  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7441 (0.7523)  acc1: 88.4000 (87.4546)  acc5: 97.6000 (98.0000)  time: 1.0863  data: 0.6395  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8703 (0.8668)  acc1: 83.2000 (84.4952)  acc5: 96.8000 (96.9714)  time: 0.4449  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9501 (0.8829)  acc1: 83.2000 (84.0160)  acc5: 96.0000 (96.8960)  time: 0.4447  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7313 s / it)
* Acc@1 84.318 Acc@5 96.930 loss 0.871
Accuracy of the model on the 50000 test images: 84.3%
Max accuracy: 84.44%
Epoch: [259]  [   0/1251]  eta: 1:34:43  lr: 0.000209  min_lr: 0.000209  loss: 2.9720 (2.9720)  weight_decay: 0.0500 (0.0500)  time: 4.5432  data: 3.5844  max mem: 62835
Epoch: [259]  [ 200/1251]  eta: 0:14:37  lr: 0.000207  min_lr: 0.000207  loss: 2.8024 (2.6245)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3079 (1.3245)  time: 0.8158  data: 0.0004  max mem: 62835
Epoch: [259]  [ 400/1251]  eta: 0:11:42  lr: 0.000206  min_lr: 0.000206  loss: 2.5650 (2.6078)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5674 (1.4010)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [259]  [ 600/1251]  eta: 0:08:56  lr: 0.000204  min_lr: 0.000204  loss: 2.8099 (2.5940)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1460 (1.3624)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [259]  [ 800/1251]  eta: 0:06:10  lr: 0.000203  min_lr: 0.000203  loss: 2.6993 (2.5913)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3066 (1.4395)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [259]  [1000/1251]  eta: 0:03:26  lr: 0.000201  min_lr: 0.000201  loss: 2.7764 (2.6066)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5469 (1.4310)  time: 0.8162  data: 0.0004  max mem: 62835
Epoch: [259]  [1200/1251]  eta: 0:00:41  lr: 0.000199  min_lr: 0.000199  loss: 2.7996 (2.6060)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2496 (1.4268)  time: 0.8154  data: 0.0004  max mem: 62835
Epoch: [259]  [1250/1251]  eta: 0:00:00  lr: 0.000199  min_lr: 0.000199  loss: 2.6330 (2.6047)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2496 (1.4244)  time: 0.6925  data: 0.0006  max mem: 62835
Epoch: [259] Total time: 0:17:04 (0.8188 s / it)
Averaged stats: lr: 0.000199  min_lr: 0.000199  loss: 2.6330 (2.6282)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2496 (1.4244)
Test:  [ 0/25]  eta: 0:03:25  loss: 0.6137 (0.6137)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 8.2051  data: 7.7369  max mem: 62835
Test:  [10/25]  eta: 0:00:17  loss: 0.6898 (0.6981)  acc1: 87.6000 (87.5636)  acc5: 97.6000 (97.8182)  time: 1.1494  data: 0.7036  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8331 (0.8048)  acc1: 84.8000 (84.8952)  acc5: 96.8000 (96.8762)  time: 0.4437  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8602 (0.8231)  acc1: 84.4000 (84.3360)  acc5: 96.4000 (96.7840)  time: 0.4436  data: 0.0001  max mem: 62835
Test: Total time: 0:00:19 (0.7612 s / it)
* Acc@1 84.436 Acc@5 96.914 loss 0.812
Accuracy of the model on the 50000 test images: 84.4%
Max accuracy: 84.44%
Epoch: [260]  [   0/1251]  eta: 1:42:06  lr: 0.000199  min_lr: 0.000199  loss: 2.6949 (2.6949)  weight_decay: 0.0500 (0.0500)  time: 4.8971  data: 2.9749  max mem: 62835
Epoch: [260]  [ 200/1251]  eta: 0:14:37  lr: 0.000197  min_lr: 0.000197  loss: 2.8353 (2.6402)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2627 (1.4503)  time: 0.8151  data: 0.0004  max mem: 62835
Epoch: [260]  [ 400/1251]  eta: 0:11:43  lr: 0.000196  min_lr: 0.000196  loss: 2.5918 (2.6113)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0723 (1.3671)  time: 0.8221  data: 0.0004  max mem: 62835
Epoch: [260]  [ 600/1251]  eta: 0:08:55  lr: 0.000194  min_lr: 0.000194  loss: 2.5272 (2.6159)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6327 (1.4348)  time: 0.8154  data: 0.0004  max mem: 62835
Epoch: [260]  [ 800/1251]  eta: 0:06:10  lr: 0.000193  min_lr: 0.000193  loss: 2.7619 (2.6227)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2875 (1.4527)  time: 0.8147  data: 0.0004  max mem: 62835
Epoch: [260]  [1000/1251]  eta: 0:03:25  lr: 0.000191  min_lr: 0.000191  loss: 2.7514 (2.6252)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4512 (1.4852)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [260]  [1200/1251]  eta: 0:00:41  lr: 0.000190  min_lr: 0.000190  loss: 2.6072 (2.6242)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0839 (1.4787)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [260]  [1250/1251]  eta: 0:00:00  lr: 0.000189  min_lr: 0.000189  loss: 2.7517 (2.6215)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3053 (1.4772)  time: 0.6927  data: 0.0005  max mem: 62835
Epoch: [260] Total time: 0:17:03 (0.8182 s / it)
Averaged stats: lr: 0.000189  min_lr: 0.000189  loss: 2.7517 (2.6232)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3053 (1.4772)
Test:  [ 0/25]  eta: 0:03:24  loss: 0.5931 (0.5931)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 8.1674  data: 7.7020  max mem: 62835
Test:  [10/25]  eta: 0:00:17  loss: 0.6802 (0.6768)  acc1: 87.2000 (87.9273)  acc5: 98.0000 (98.0000)  time: 1.1483  data: 0.7005  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8075 (0.7870)  acc1: 84.4000 (84.8571)  acc5: 96.8000 (97.0286)  time: 0.4461  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8302 (0.8034)  acc1: 84.0000 (84.4160)  acc5: 96.8000 (96.9760)  time: 0.4458  data: 0.0001  max mem: 62835
Test: Total time: 0:00:19 (0.7639 s / it)
* Acc@1 84.532 Acc@5 97.008 loss 0.792
Accuracy of the model on the 50000 test images: 84.5%
Max accuracy: 84.53%
Epoch: [261]  [   0/1251]  eta: 1:31:14  lr: 0.000189  min_lr: 0.000189  loss: 3.0023 (3.0023)  weight_decay: 0.0500 (0.0500)  time: 4.3760  data: 3.5543  max mem: 62835
Epoch: [261]  [ 200/1251]  eta: 0:14:37  lr: 0.000188  min_lr: 0.000188  loss: 2.5713 (2.6169)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5574 (1.5260)  time: 0.8162  data: 0.0004  max mem: 62835
Epoch: [261]  [ 400/1251]  eta: 0:11:43  lr: 0.000186  min_lr: 0.000186  loss: 2.6418 (2.6204)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1905 (1.4953)  time: 0.8159  data: 0.0004  max mem: 62835
Epoch: [261]  [ 600/1251]  eta: 0:08:55  lr: 0.000185  min_lr: 0.000185  loss: 2.7506 (2.6363)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8158  data: 0.0004  max mem: 62835
Epoch: [261]  [ 800/1251]  eta: 0:06:10  lr: 0.000183  min_lr: 0.000183  loss: 2.5657 (2.6270)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4200 (nan)  time: 0.8164  data: 0.0004  max mem: 62835
Epoch: [261]  [1000/1251]  eta: 0:03:26  lr: 0.000182  min_lr: 0.000182  loss: 2.7990 (2.6268)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1068 (nan)  time: 0.8173  data: 0.0004  max mem: 62835
Epoch: [261]  [1200/1251]  eta: 0:00:41  lr: 0.000180  min_lr: 0.000180  loss: 2.6917 (2.6203)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1362 (nan)  time: 0.8212  data: 0.0004  max mem: 62835
Epoch: [261]  [1250/1251]  eta: 0:00:00  lr: 0.000180  min_lr: 0.000180  loss: 2.7027 (2.6209)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2491 (nan)  time: 0.6939  data: 0.0005  max mem: 62835
Epoch: [261] Total time: 0:17:04 (0.8190 s / it)
Averaged stats: lr: 0.000180  min_lr: 0.000180  loss: 2.7027 (2.6248)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2491 (nan)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.6530 (0.6530)  acc1: 89.2000 (89.2000)  acc5: 98.8000 (98.8000)  time: 7.5329  data: 7.0546  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7401 (0.7351)  acc1: 87.2000 (87.4182)  acc5: 98.0000 (98.1091)  time: 1.0902  data: 0.6416  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8688 (0.8495)  acc1: 83.2000 (84.5143)  acc5: 97.2000 (96.9714)  time: 0.4459  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9277 (0.8649)  acc1: 83.2000 (84.1920)  acc5: 96.0000 (96.8800)  time: 0.4458  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7383 s / it)
* Acc@1 84.410 Acc@5 96.930 loss 0.852
Accuracy of the model on the 50000 test images: 84.4%
Max accuracy: 84.53%
Epoch: [262]  [   0/1251]  eta: 1:47:27  lr: 0.000180  min_lr: 0.000180  loss: 2.8306 (2.8306)  weight_decay: 0.0500 (0.0500)  time: 5.1537  data: 3.1878  max mem: 62835
Epoch: [262]  [ 200/1251]  eta: 0:14:43  lr: 0.000179  min_lr: 0.000179  loss: 2.7202 (2.6083)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2993 (1.4096)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [262]  [ 400/1251]  eta: 0:11:45  lr: 0.000177  min_lr: 0.000177  loss: 2.8170 (2.6146)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6070 (1.6002)  time: 0.8242  data: 0.0004  max mem: 62835
Epoch: [262]  [ 600/1251]  eta: 0:08:57  lr: 0.000176  min_lr: 0.000176  loss: 2.6380 (2.5970)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0597 (1.5767)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [262]  [ 800/1251]  eta: 0:06:11  lr: 0.000174  min_lr: 0.000174  loss: 2.3194 (2.5935)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4039 (1.5236)  time: 0.8172  data: 0.0004  max mem: 62835
Epoch: [262]  [1000/1251]  eta: 0:03:26  lr: 0.000173  min_lr: 0.000173  loss: 2.6617 (2.5835)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5877 (1.5142)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [262]  [1200/1251]  eta: 0:00:41  lr: 0.000171  min_lr: 0.000171  loss: 2.7345 (2.5909)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0745 (1.4749)  time: 0.8162  data: 0.0004  max mem: 62835
Epoch: [262]  [1250/1251]  eta: 0:00:00  lr: 0.000171  min_lr: 0.000171  loss: 2.5709 (2.5880)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0745 (1.4820)  time: 0.6979  data: 0.0005  max mem: 62835
Epoch: [262] Total time: 0:17:05 (0.8198 s / it)
Averaged stats: lr: 0.000171  min_lr: 0.000171  loss: 2.5709 (2.6141)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0745 (1.4820)
Test:  [ 0/25]  eta: 0:03:14  loss: 0.5983 (0.5983)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.7758  data: 7.2976  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6910 (0.6939)  acc1: 87.2000 (87.7091)  acc5: 97.6000 (98.0000)  time: 1.1104  data: 0.6637  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8182 (0.8073)  acc1: 84.4000 (84.9143)  acc5: 96.8000 (96.9714)  time: 0.4437  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8750 (0.8240)  acc1: 84.4000 (84.4480)  acc5: 96.8000 (96.9120)  time: 0.4436  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7426 s / it)
* Acc@1 84.484 Acc@5 96.974 loss 0.815
Accuracy of the model on the 50000 test images: 84.5%
Max accuracy: 84.53%
Epoch: [263]  [   0/1251]  eta: 1:38:27  lr: 0.000171  min_lr: 0.000171  loss: 2.7448 (2.7448)  weight_decay: 0.0500 (0.0500)  time: 4.7219  data: 3.2715  max mem: 62835
Epoch: [263]  [ 200/1251]  eta: 0:14:40  lr: 0.000169  min_lr: 0.000169  loss: 2.7851 (2.6096)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2101 (1.5276)  time: 0.8164  data: 0.0004  max mem: 62835
Epoch: [263]  [ 400/1251]  eta: 0:11:43  lr: 0.000168  min_lr: 0.000168  loss: 2.7963 (2.5957)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3671 (1.4223)  time: 0.8172  data: 0.0004  max mem: 62835
Epoch: [263]  [ 600/1251]  eta: 0:08:56  lr: 0.000167  min_lr: 0.000167  loss: 2.6082 (2.5969)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3609 (1.4175)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [263]  [ 800/1251]  eta: 0:06:11  lr: 0.000165  min_lr: 0.000165  loss: 2.7116 (2.6156)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2991 (1.4074)  time: 0.8170  data: 0.0004  max mem: 62835
Epoch: [263]  [1000/1251]  eta: 0:03:26  lr: 0.000164  min_lr: 0.000164  loss: 2.8612 (2.6168)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2823 (1.4015)  time: 0.8171  data: 0.0005  max mem: 62835
Epoch: [263]  [1200/1251]  eta: 0:00:41  lr: 0.000162  min_lr: 0.000162  loss: 2.6942 (2.6304)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2975 (1.4003)  time: 0.8170  data: 0.0004  max mem: 62835
Epoch: [263]  [1250/1251]  eta: 0:00:00  lr: 0.000162  min_lr: 0.000162  loss: 2.6294 (2.6280)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2794 (1.3943)  time: 0.6937  data: 0.0007  max mem: 62835
Epoch: [263] Total time: 0:17:05 (0.8197 s / it)
Averaged stats: lr: 0.000162  min_lr: 0.000162  loss: 2.6294 (2.6186)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2794 (1.3943)
Test:  [ 0/25]  eta: 0:03:02  loss: 0.6071 (0.6071)  acc1: 88.0000 (88.0000)  acc5: 99.2000 (99.2000)  time: 7.3192  data: 6.8195  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7149 (0.7174)  acc1: 87.6000 (87.4909)  acc5: 97.6000 (97.8545)  time: 1.0707  data: 0.6202  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8392 (0.8272)  acc1: 84.0000 (84.7048)  acc5: 96.8000 (96.8571)  time: 0.4457  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8763 (0.8430)  acc1: 83.6000 (84.3360)  acc5: 96.4000 (96.7200)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7274 s / it)
* Acc@1 84.508 Acc@5 96.948 loss 0.832
Accuracy of the model on the 50000 test images: 84.5%
Max accuracy: 84.53%
Epoch: [264]  [   0/1251]  eta: 1:39:03  lr: 0.000162  min_lr: 0.000162  loss: 1.9357 (1.9357)  weight_decay: 0.0500 (0.0500)  time: 4.7508  data: 2.9978  max mem: 62835
Epoch: [264]  [ 200/1251]  eta: 0:14:38  lr: 0.000160  min_lr: 0.000160  loss: 2.8258 (2.5961)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2257 (1.3179)  time: 0.8163  data: 0.0004  max mem: 62835
Epoch: [264]  [ 400/1251]  eta: 0:11:43  lr: 0.000159  min_lr: 0.000159  loss: 2.6989 (2.6061)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6549 (1.3559)  time: 0.8250  data: 0.0004  max mem: 62835
Epoch: [264]  [ 600/1251]  eta: 0:08:56  lr: 0.000158  min_lr: 0.000158  loss: 2.8685 (2.6171)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1931 (1.3611)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [264]  [ 800/1251]  eta: 0:06:10  lr: 0.000156  min_lr: 0.000156  loss: 2.7115 (2.6115)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6382 (1.4277)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [264]  [1000/1251]  eta: 0:03:26  lr: 0.000155  min_lr: 0.000155  loss: 2.6228 (2.6076)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2332 (1.4526)  time: 0.8250  data: 0.0004  max mem: 62835
Epoch: [264]  [1200/1251]  eta: 0:00:41  lr: 0.000154  min_lr: 0.000154  loss: 2.6620 (2.6106)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3911 (1.4776)  time: 0.8171  data: 0.0004  max mem: 62835
Epoch: [264]  [1250/1251]  eta: 0:00:00  lr: 0.000153  min_lr: 0.000153  loss: 2.6016 (2.6095)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3911 (1.4812)  time: 0.6939  data: 0.0007  max mem: 62835
Epoch: [264] Total time: 0:17:05 (0.8195 s / it)
Averaged stats: lr: 0.000153  min_lr: 0.000153  loss: 2.6016 (2.6012)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3911 (1.4812)
Test:  [ 0/25]  eta: 0:03:27  loss: 0.5743 (0.5743)  acc1: 88.8000 (88.8000)  acc5: 99.2000 (99.2000)  time: 8.2971  data: 7.8255  max mem: 62835
Test:  [10/25]  eta: 0:00:17  loss: 0.6770 (0.6844)  acc1: 87.6000 (87.7091)  acc5: 97.6000 (98.0000)  time: 1.1596  data: 0.7117  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.7874 (0.7927)  acc1: 84.8000 (84.8381)  acc5: 97.2000 (96.9714)  time: 0.4457  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8657 (0.8095)  acc1: 84.0000 (84.3840)  acc5: 96.4000 (96.8640)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:19 (0.7696 s / it)
* Acc@1 84.572 Acc@5 96.986 loss 0.800
Accuracy of the model on the 50000 test images: 84.6%
Max accuracy: 84.57%
Epoch: [265]  [   0/1251]  eta: 1:34:59  lr: 0.000153  min_lr: 0.000153  loss: 2.1398 (2.1398)  weight_decay: 0.0500 (0.0500)  time: 4.5556  data: 3.7185  max mem: 62835
Epoch: [265]  [ 200/1251]  eta: 0:14:38  lr: 0.000152  min_lr: 0.000152  loss: 2.7378 (2.6387)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7149 (1.5653)  time: 0.8174  data: 0.0004  max mem: 62835
Epoch: [265]  [ 400/1251]  eta: 0:11:44  lr: 0.000150  min_lr: 0.000150  loss: 2.6022 (2.6084)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3576 (1.5543)  time: 0.8175  data: 0.0004  max mem: 62835
Epoch: [265]  [ 600/1251]  eta: 0:08:56  lr: 0.000149  min_lr: 0.000149  loss: 2.8838 (2.6215)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3918 (1.4695)  time: 0.8173  data: 0.0004  max mem: 62835
Epoch: [265]  [ 800/1251]  eta: 0:06:10  lr: 0.000148  min_lr: 0.000148  loss: 2.6072 (2.6272)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2649 (1.4820)  time: 0.8216  data: 0.0004  max mem: 62835
Epoch: [265]  [1000/1251]  eta: 0:03:26  lr: 0.000146  min_lr: 0.000146  loss: 2.7085 (2.6165)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0255 (1.5268)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [265]  [1200/1251]  eta: 0:00:41  lr: 0.000145  min_lr: 0.000145  loss: 2.5918 (2.6175)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3369 (1.5369)  time: 0.8169  data: 0.0004  max mem: 62835
Epoch: [265]  [1250/1251]  eta: 0:00:00  lr: 0.000145  min_lr: 0.000145  loss: 2.3792 (2.6115)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4122 (1.5310)  time: 0.6942  data: 0.0006  max mem: 62835
Epoch: [265] Total time: 0:17:05 (0.8195 s / it)
Averaged stats: lr: 0.000145  min_lr: 0.000145  loss: 2.3792 (2.6055)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4122 (1.5310)
Test:  [ 0/25]  eta: 0:03:17  loss: 0.5311 (0.5311)  acc1: 89.2000 (89.2000)  acc5: 100.0000 (100.0000)  time: 7.9069  data: 7.4395  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6417 (0.6426)  acc1: 86.8000 (87.6364)  acc5: 98.0000 (98.0000)  time: 1.1242  data: 0.6766  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.7669 (0.7559)  acc1: 83.2000 (84.7619)  acc5: 96.8000 (97.1048)  time: 0.4457  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8229 (0.7725)  acc1: 83.2000 (84.3040)  acc5: 96.4000 (96.9760)  time: 0.4456  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7523 s / it)
* Acc@1 84.522 Acc@5 97.002 loss 0.765
Accuracy of the model on the 50000 test images: 84.5%
Max accuracy: 84.57%
Epoch: [266]  [   0/1251]  eta: 1:41:23  lr: 0.000145  min_lr: 0.000145  loss: 2.6026 (2.6026)  weight_decay: 0.0500 (0.0500)  time: 4.8633  data: 3.6259  max mem: 62835
Epoch: [266]  [ 200/1251]  eta: 0:14:41  lr: 0.000143  min_lr: 0.000143  loss: 2.6309 (2.6048)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4396 (1.4041)  time: 0.8172  data: 0.0005  max mem: 62835
Epoch: [266]  [ 400/1251]  eta: 0:11:44  lr: 0.000142  min_lr: 0.000142  loss: 2.3490 (2.6145)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2362 (1.4177)  time: 0.8177  data: 0.0005  max mem: 62835
Epoch: [266]  [ 600/1251]  eta: 0:08:57  lr: 0.000141  min_lr: 0.000141  loss: 2.8156 (2.6136)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1914 (1.3694)  time: 0.8261  data: 0.0004  max mem: 62835
Epoch: [266]  [ 800/1251]  eta: 0:06:11  lr: 0.000139  min_lr: 0.000139  loss: 2.7157 (2.6147)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3497 (1.4090)  time: 0.8174  data: 0.0004  max mem: 62835
Epoch: [266]  [1000/1251]  eta: 0:03:26  lr: 0.000138  min_lr: 0.000138  loss: 2.3485 (2.6066)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1614 (1.3882)  time: 0.8173  data: 0.0004  max mem: 62835
Epoch: [266]  [1200/1251]  eta: 0:00:41  lr: 0.000137  min_lr: 0.000137  loss: 2.6736 (2.6101)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3115 (1.3675)  time: 0.8173  data: 0.0004  max mem: 62835
Epoch: [266]  [1250/1251]  eta: 0:00:00  lr: 0.000137  min_lr: 0.000137  loss: 2.6127 (2.6100)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5628 (1.3764)  time: 0.6997  data: 0.0007  max mem: 62835
Epoch: [266] Total time: 0:17:06 (0.8203 s / it)
Averaged stats: lr: 0.000137  min_lr: 0.000137  loss: 2.6127 (2.6091)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5628 (1.3764)
Test:  [ 0/25]  eta: 0:03:27  loss: 0.5977 (0.5977)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 8.2817  data: 7.7955  max mem: 62835
Test:  [10/25]  eta: 0:00:17  loss: 0.7155 (0.7156)  acc1: 86.8000 (87.6000)  acc5: 97.6000 (98.0000)  time: 1.1584  data: 0.7090  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8437 (0.8284)  acc1: 83.6000 (84.6857)  acc5: 96.8000 (97.0476)  time: 0.4459  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8891 (0.8446)  acc1: 83.2000 (84.2720)  acc5: 96.4000 (96.9440)  time: 0.4459  data: 0.0001  max mem: 62835
Test: Total time: 0:00:19 (0.7662 s / it)
* Acc@1 84.506 Acc@5 97.020 loss 0.834
Accuracy of the model on the 50000 test images: 84.5%
Max accuracy: 84.57%
Epoch: [267]  [   0/1251]  eta: 1:44:23  lr: 0.000136  min_lr: 0.000136  loss: 2.8953 (2.8953)  weight_decay: 0.0500 (0.0500)  time: 5.0064  data: 2.1888  max mem: 62835
Epoch: [267]  [ 200/1251]  eta: 0:14:40  lr: 0.000135  min_lr: 0.000135  loss: 2.6921 (2.6214)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1158 (1.3057)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [267]  [ 400/1251]  eta: 0:11:44  lr: 0.000134  min_lr: 0.000134  loss: 2.6885 (2.5893)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3154 (1.3288)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [267]  [ 600/1251]  eta: 0:08:56  lr: 0.000133  min_lr: 0.000133  loss: 2.8603 (2.5911)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2927 (1.3473)  time: 0.8216  data: 0.0004  max mem: 62835
Epoch: [267]  [ 800/1251]  eta: 0:06:11  lr: 0.000131  min_lr: 0.000131  loss: 2.7094 (2.5883)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4799 (1.3694)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [267]  [1000/1251]  eta: 0:03:26  lr: 0.000130  min_lr: 0.000130  loss: 2.6552 (2.5877)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5386 (1.3940)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [267]  [1200/1251]  eta: 0:00:41  lr: 0.000129  min_lr: 0.000129  loss: 2.6225 (2.5901)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4270 (1.4120)  time: 0.8153  data: 0.0004  max mem: 62835
Epoch: [267]  [1250/1251]  eta: 0:00:00  lr: 0.000129  min_lr: 0.000129  loss: 2.6470 (2.5883)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2161 (1.4070)  time: 0.6931  data: 0.0007  max mem: 62835
Epoch: [267] Total time: 0:17:04 (0.8193 s / it)
Averaged stats: lr: 0.000129  min_lr: 0.000129  loss: 2.6470 (2.5981)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2161 (1.4070)
Test:  [ 0/25]  eta: 0:03:22  loss: 0.5655 (0.5655)  acc1: 89.2000 (89.2000)  acc5: 100.0000 (100.0000)  time: 8.1008  data: 7.6418  max mem: 62835
Test:  [10/25]  eta: 0:00:17  loss: 0.6703 (0.6771)  acc1: 86.8000 (87.4909)  acc5: 98.0000 (98.0000)  time: 1.1453  data: 0.6950  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8001 (0.7934)  acc1: 83.6000 (84.4571)  acc5: 96.8000 (97.0095)  time: 0.4480  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8768 (0.8080)  acc1: 82.8000 (84.1120)  acc5: 96.4000 (96.8800)  time: 0.4464  data: 0.0001  max mem: 62835
Test: Total time: 0:00:19 (0.7619 s / it)
* Acc@1 84.590 Acc@5 97.014 loss 0.797
Accuracy of the model on the 50000 test images: 84.6%
Max accuracy: 84.59%
Epoch: [268]  [   0/1251]  eta: 1:36:42  lr: 0.000128  min_lr: 0.000128  loss: 2.8057 (2.8057)  weight_decay: 0.0500 (0.0500)  time: 4.6384  data: 3.8154  max mem: 62835
Epoch: [268]  [ 200/1251]  eta: 0:14:38  lr: 0.000127  min_lr: 0.000127  loss: 2.5417 (2.5903)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9735 (1.1806)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [268]  [ 400/1251]  eta: 0:11:42  lr: 0.000126  min_lr: 0.000126  loss: 2.7639 (2.6059)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4571 (1.3768)  time: 0.8149  data: 0.0004  max mem: 62835
Epoch: [268]  [ 600/1251]  eta: 0:08:55  lr: 0.000125  min_lr: 0.000125  loss: 2.8749 (2.6197)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5648 (1.4248)  time: 0.8146  data: 0.0004  max mem: 62835
Epoch: [268]  [ 800/1251]  eta: 0:06:10  lr: 0.000123  min_lr: 0.000123  loss: 2.7818 (2.6176)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5881 (1.4832)  time: 0.8155  data: 0.0004  max mem: 62835
Epoch: [268]  [1000/1251]  eta: 0:03:25  lr: 0.000122  min_lr: 0.000122  loss: 2.7320 (2.6158)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4397 (1.5187)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [268]  [1200/1251]  eta: 0:00:41  lr: 0.000121  min_lr: 0.000121  loss: 2.4467 (2.6144)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2591 (1.4917)  time: 0.8202  data: 0.0004  max mem: 62835
Epoch: [268]  [1250/1251]  eta: 0:00:00  lr: 0.000121  min_lr: 0.000121  loss: 2.5691 (2.6135)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2451 (1.4859)  time: 0.6930  data: 0.0005  max mem: 62835
Epoch: [268] Total time: 0:17:03 (0.8180 s / it)
Averaged stats: lr: 0.000121  min_lr: 0.000121  loss: 2.5691 (2.5929)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2451 (1.4859)
Test:  [ 0/25]  eta: 0:03:19  loss: 0.5977 (0.5977)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.9788  data: 7.4973  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7039 (0.6971)  acc1: 86.8000 (87.7091)  acc5: 98.0000 (98.0000)  time: 1.1306  data: 0.6819  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8250 (0.8134)  acc1: 84.0000 (84.6857)  acc5: 96.8000 (97.0095)  time: 0.4457  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8718 (0.8286)  acc1: 83.2000 (84.3200)  acc5: 96.4000 (96.8640)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7522 s / it)
* Acc@1 84.564 Acc@5 96.986 loss 0.815
Accuracy of the model on the 50000 test images: 84.6%
Max accuracy: 84.59%
Epoch: [269]  [   0/1251]  eta: 1:42:56  lr: 0.000121  min_lr: 0.000121  loss: 2.8784 (2.8784)  weight_decay: 0.0500 (0.0500)  time: 4.9375  data: 3.9587  max mem: 62835
Epoch: [269]  [ 200/1251]  eta: 0:14:39  lr: 0.000120  min_lr: 0.000120  loss: 2.5992 (2.5838)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3483 (1.2918)  time: 0.8163  data: 0.0004  max mem: 62835
Epoch: [269]  [ 400/1251]  eta: 0:11:44  lr: 0.000118  min_lr: 0.000118  loss: 2.7995 (2.5980)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4062 (1.4708)  time: 0.8164  data: 0.0004  max mem: 62835
Epoch: [269]  [ 600/1251]  eta: 0:08:56  lr: 0.000117  min_lr: 0.000117  loss: 2.6282 (2.5972)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2529 (1.4561)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [269]  [ 800/1251]  eta: 0:06:10  lr: 0.000116  min_lr: 0.000116  loss: 2.5832 (2.5959)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2405 (1.4242)  time: 0.8159  data: 0.0004  max mem: 62835
Epoch: [269]  [1000/1251]  eta: 0:03:26  lr: 0.000115  min_lr: 0.000115  loss: 2.8055 (2.5835)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1791 (1.4075)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [269]  [1200/1251]  eta: 0:00:41  lr: 0.000113  min_lr: 0.000113  loss: 2.7140 (2.5859)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3710 (1.4294)  time: 0.8159  data: 0.0004  max mem: 62835
Epoch: [269]  [1250/1251]  eta: 0:00:00  lr: 0.000113  min_lr: 0.000113  loss: 2.7814 (2.5860)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3519 (1.4370)  time: 0.6932  data: 0.0005  max mem: 62835
Epoch: [269] Total time: 0:17:04 (0.8186 s / it)
Averaged stats: lr: 0.000113  min_lr: 0.000113  loss: 2.7814 (2.5897)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3519 (1.4370)
Test:  [ 0/25]  eta: 0:02:17  loss: 0.6079 (0.6079)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 5.5099  data: 5.0097  max mem: 62835
Test:  [10/25]  eta: 0:00:15  loss: 0.7228 (0.7188)  acc1: 87.2000 (87.5636)  acc5: 97.6000 (98.0364)  time: 1.0296  data: 0.5797  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8526 (0.8391)  acc1: 84.0000 (84.6476)  acc5: 96.8000 (96.8952)  time: 0.5133  data: 0.0684  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9120 (0.8550)  acc1: 83.6000 (84.2080)  acc5: 96.0000 (96.7680)  time: 0.4450  data: 0.0001  max mem: 62835
Test: Total time: 0:00:17 (0.7072 s / it)
* Acc@1 84.476 Acc@5 96.930 loss 0.842
Accuracy of the model on the 50000 test images: 84.5%
Max accuracy: 84.59%
Epoch: [270]  [   0/1251]  eta: 1:41:37  lr: 0.000113  min_lr: 0.000113  loss: 2.6385 (2.6385)  weight_decay: 0.0500 (0.0500)  time: 4.8743  data: 2.7290  max mem: 62835
Epoch: [270]  [ 200/1251]  eta: 0:14:41  lr: 0.000112  min_lr: 0.000112  loss: 2.5514 (2.6215)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1035 (1.4098)  time: 0.8227  data: 0.0005  max mem: 62835
Epoch: [270]  [ 400/1251]  eta: 0:11:43  lr: 0.000111  min_lr: 0.000111  loss: 2.7535 (2.6261)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2451 (1.3757)  time: 0.8158  data: 0.0005  max mem: 62835
Epoch: [270]  [ 600/1251]  eta: 0:08:55  lr: 0.000110  min_lr: 0.000110  loss: 2.5027 (2.6036)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2819 (1.3657)  time: 0.8161  data: 0.0005  max mem: 62835
Epoch: [270]  [ 800/1251]  eta: 0:06:10  lr: 0.000109  min_lr: 0.000109  loss: 2.5836 (2.6038)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2026 (1.3906)  time: 0.8152  data: 0.0005  max mem: 62835
Epoch: [270]  [1000/1251]  eta: 0:03:25  lr: 0.000107  min_lr: 0.000107  loss: 2.6192 (2.5998)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6416 (1.4257)  time: 0.8159  data: 0.0005  max mem: 62835
Epoch: [270]  [1200/1251]  eta: 0:00:41  lr: 0.000106  min_lr: 0.000106  loss: 2.6282 (2.5951)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3304 (1.4180)  time: 0.8162  data: 0.0004  max mem: 62835
Epoch: [270]  [1250/1251]  eta: 0:00:00  lr: 0.000106  min_lr: 0.000106  loss: 2.6373 (2.5945)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1469 (1.4134)  time: 0.6931  data: 0.0007  max mem: 62835
Epoch: [270] Total time: 0:17:03 (0.8183 s / it)
Averaged stats: lr: 0.000106  min_lr: 0.000106  loss: 2.6373 (2.5872)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1469 (1.4134)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.5996 (0.5996)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.6814  data: 7.1941  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6907 (0.6998)  acc1: 86.8000 (87.4909)  acc5: 97.6000 (97.9636)  time: 1.1037  data: 0.6543  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8409 (0.8158)  acc1: 84.0000 (84.7619)  acc5: 96.8000 (97.0095)  time: 0.4458  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8951 (0.8300)  acc1: 83.6000 (84.3200)  acc5: 96.4000 (96.9120)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7428 s / it)
* Acc@1 84.574 Acc@5 96.970 loss 0.818
Accuracy of the model on the 50000 test images: 84.6%
Max accuracy: 84.59%
Epoch: [271]  [   0/1251]  eta: 1:45:01  lr: 0.000106  min_lr: 0.000106  loss: 2.1542 (2.1542)  weight_decay: 0.0500 (0.0500)  time: 5.0374  data: 3.0439  max mem: 62835
Epoch: [271]  [ 200/1251]  eta: 0:14:40  lr: 0.000105  min_lr: 0.000105  loss: 2.6663 (2.5828)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2836 (1.2930)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [271]  [ 400/1251]  eta: 0:11:43  lr: 0.000104  min_lr: 0.000104  loss: 2.5088 (2.5579)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4255 (1.4212)  time: 0.8162  data: 0.0003  max mem: 62835
Epoch: [271]  [ 600/1251]  eta: 0:08:56  lr: 0.000102  min_lr: 0.000102  loss: 2.6559 (2.5730)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1205 (1.4105)  time: 0.8216  data: 0.0003  max mem: 62835
Epoch: [271]  [ 800/1251]  eta: 0:06:10  lr: 0.000101  min_lr: 0.000101  loss: 2.5498 (2.5777)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0071 (1.3636)  time: 0.8159  data: 0.0004  max mem: 62835
Epoch: [271]  [1000/1251]  eta: 0:03:26  lr: 0.000100  min_lr: 0.000100  loss: 2.6141 (2.5879)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4762 (1.3748)  time: 0.8152  data: 0.0004  max mem: 62835
Epoch: [271]  [1200/1251]  eta: 0:00:41  lr: 0.000099  min_lr: 0.000099  loss: 2.5727 (2.5915)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2263 (1.3654)  time: 0.8163  data: 0.0003  max mem: 62835
Epoch: [271]  [1250/1251]  eta: 0:00:00  lr: 0.000099  min_lr: 0.000099  loss: 2.6093 (2.5925)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1574 (1.3535)  time: 0.6932  data: 0.0006  max mem: 62835
Epoch: [271] Total time: 0:17:04 (0.8188 s / it)
Averaged stats: lr: 0.000099  min_lr: 0.000099  loss: 2.6093 (2.5871)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1574 (1.3535)
Test:  [ 0/25]  eta: 0:02:27  loss: 0.6187 (0.6187)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 5.8817  data: 5.4015  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7332 (0.7256)  acc1: 87.2000 (87.6000)  acc5: 97.6000 (98.0000)  time: 1.1313  data: 0.6807  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8584 (0.8385)  acc1: 84.4000 (84.7810)  acc5: 97.2000 (97.0667)  time: 0.5510  data: 0.1043  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9071 (0.8527)  acc1: 83.2000 (84.3200)  acc5: 96.4000 (96.9440)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7519 s / it)
* Acc@1 84.648 Acc@5 96.972 loss 0.842
Accuracy of the model on the 50000 test images: 84.6%
Max accuracy: 84.65%
Epoch: [272]  [   0/1251]  eta: 1:43:36  lr: 0.000099  min_lr: 0.000099  loss: 1.8256 (1.8256)  weight_decay: 0.0500 (0.0500)  time: 4.9689  data: 4.1556  max mem: 62835
Epoch: [272]  [ 200/1251]  eta: 0:14:39  lr: 0.000098  min_lr: 0.000098  loss: 2.5168 (2.5903)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3508 (1.5473)  time: 0.8161  data: 0.0004  max mem: 62835
Epoch: [272]  [ 400/1251]  eta: 0:11:43  lr: 0.000097  min_lr: 0.000097  loss: 2.7066 (2.5654)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1277 (1.4681)  time: 0.8162  data: 0.0004  max mem: 62835
Epoch: [272]  [ 600/1251]  eta: 0:08:56  lr: 0.000096  min_lr: 0.000096  loss: 2.8219 (2.5861)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2925 (1.4951)  time: 0.8148  data: 0.0004  max mem: 62835
Epoch: [272]  [ 800/1251]  eta: 0:06:10  lr: 0.000094  min_lr: 0.000094  loss: 2.7152 (2.5936)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5116 (1.4974)  time: 0.8148  data: 0.0004  max mem: 62835
Epoch: [272]  [1000/1251]  eta: 0:03:25  lr: 0.000093  min_lr: 0.000093  loss: 2.5858 (2.5900)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0443 (1.4514)  time: 0.8206  data: 0.0004  max mem: 62835
Epoch: [272]  [1200/1251]  eta: 0:00:41  lr: 0.000092  min_lr: 0.000092  loss: 2.7608 (2.5893)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2251 (1.4593)  time: 0.8156  data: 0.0004  max mem: 62835
Epoch: [272]  [1250/1251]  eta: 0:00:00  lr: 0.000092  min_lr: 0.000092  loss: 2.6650 (2.5900)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.6935  data: 0.0005  max mem: 62835
Epoch: [272] Total time: 0:17:03 (0.8183 s / it)
Averaged stats: lr: 0.000092  min_lr: 0.000092  loss: 2.6650 (2.5874)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:03:18  loss: 0.6138 (0.6138)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 7.9481  data: 7.4772  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7292 (0.7235)  acc1: 87.6000 (87.7818)  acc5: 98.0000 (98.0364)  time: 1.1279  data: 0.6800  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8540 (0.8425)  acc1: 84.4000 (84.8952)  acc5: 96.8000 (97.0476)  time: 0.4457  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9201 (0.8582)  acc1: 84.0000 (84.3200)  acc5: 96.0000 (96.9120)  time: 0.4456  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7567 s / it)
* Acc@1 84.640 Acc@5 96.974 loss 0.847
Accuracy of the model on the 50000 test images: 84.6%
Max accuracy: 84.65%
Epoch: [273]  [   0/1251]  eta: 1:38:42  lr: 0.000092  min_lr: 0.000092  loss: 2.4461 (2.4461)  weight_decay: 0.0500 (0.0500)  time: 4.7344  data: 3.8934  max mem: 62835
Epoch: [273]  [ 200/1251]  eta: 0:14:39  lr: 0.000091  min_lr: 0.000091  loss: 2.2606 (2.6208)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2077 (1.4253)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [273]  [ 400/1251]  eta: 0:11:44  lr: 0.000090  min_lr: 0.000090  loss: 2.4838 (2.6016)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2797 (1.4829)  time: 0.8172  data: 0.0004  max mem: 62835
Epoch: [273]  [ 600/1251]  eta: 0:08:56  lr: 0.000089  min_lr: 0.000089  loss: 2.6306 (2.5867)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0957 (1.4150)  time: 0.8170  data: 0.0004  max mem: 62835
Epoch: [273]  [ 800/1251]  eta: 0:06:10  lr: 0.000088  min_lr: 0.000088  loss: 2.6602 (2.5853)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2290 (1.3526)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [273]  [1000/1251]  eta: 0:03:26  lr: 0.000087  min_lr: 0.000087  loss: 2.6127 (2.5887)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1576 (1.3623)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [273]  [1200/1251]  eta: 0:00:41  lr: 0.000086  min_lr: 0.000086  loss: 2.5492 (2.5891)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4056 (1.3646)  time: 0.8159  data: 0.0005  max mem: 62835
Epoch: [273]  [1250/1251]  eta: 0:00:00  lr: 0.000085  min_lr: 0.000085  loss: 2.5147 (2.5882)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0366 (1.3618)  time: 0.6929  data: 0.0005  max mem: 62835
Epoch: [273] Total time: 0:17:04 (0.8193 s / it)
Averaged stats: lr: 0.000085  min_lr: 0.000085  loss: 2.5147 (2.5820)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0366 (1.3618)
Test:  [ 0/25]  eta: 0:03:26  loss: 0.5540 (0.5540)  acc1: 89.6000 (89.6000)  acc5: 100.0000 (100.0000)  time: 8.2708  data: 7.8153  max mem: 62835
Test:  [10/25]  eta: 0:00:17  loss: 0.6785 (0.6731)  acc1: 87.2000 (87.8182)  acc5: 98.0000 (98.0727)  time: 1.1667  data: 0.7107  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8065 (0.7874)  acc1: 84.4000 (84.9333)  acc5: 96.8000 (97.1619)  time: 0.4558  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8717 (0.8035)  acc1: 84.0000 (84.4480)  acc5: 96.4000 (97.0240)  time: 0.4554  data: 0.0001  max mem: 62835
Test: Total time: 0:00:19 (0.7874 s / it)
* Acc@1 84.732 Acc@5 97.028 loss 0.795
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.73%
Epoch: [274]  [   0/1251]  eta: 1:34:50  lr: 0.000085  min_lr: 0.000085  loss: 2.9269 (2.9269)  weight_decay: 0.0500 (0.0500)  time: 4.5486  data: 3.7403  max mem: 62835
Epoch: [274]  [ 200/1251]  eta: 0:14:39  lr: 0.000084  min_lr: 0.000084  loss: 2.7031 (2.5973)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3358 (1.3432)  time: 0.8262  data: 0.0004  max mem: 62835
Epoch: [274]  [ 400/1251]  eta: 0:11:44  lr: 0.000083  min_lr: 0.000083  loss: 2.7651 (2.6018)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2136 (1.3657)  time: 0.8175  data: 0.0004  max mem: 62835
Epoch: [274]  [ 600/1251]  eta: 0:08:56  lr: 0.000082  min_lr: 0.000082  loss: 2.6773 (2.6106)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3470 (1.3599)  time: 0.8171  data: 0.0004  max mem: 62835
Epoch: [274]  [ 800/1251]  eta: 0:06:11  lr: 0.000081  min_lr: 0.000081  loss: 2.7157 (2.6008)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1948 (1.3403)  time: 0.8171  data: 0.0004  max mem: 62835
Epoch: [274]  [1000/1251]  eta: 0:03:26  lr: 0.000080  min_lr: 0.000080  loss: 2.7090 (2.5967)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5385 (1.3851)  time: 0.8174  data: 0.0004  max mem: 62835
Epoch: [274]  [1200/1251]  eta: 0:00:41  lr: 0.000079  min_lr: 0.000079  loss: 2.6469 (2.5935)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5318 (1.3821)  time: 0.8176  data: 0.0004  max mem: 62835
Epoch: [274]  [1250/1251]  eta: 0:00:00  lr: 0.000079  min_lr: 0.000079  loss: 2.5160 (2.5877)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4294 (1.3901)  time: 0.6939  data: 0.0004  max mem: 62835
Epoch: [274] Total time: 0:17:05 (0.8195 s / it)
Averaged stats: lr: 0.000079  min_lr: 0.000079  loss: 2.5160 (2.5838)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4294 (1.3901)
Test:  [ 0/25]  eta: 0:02:15  loss: 0.5530 (0.5530)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 5.4057  data: 4.8977  max mem: 62835
Test:  [10/25]  eta: 0:00:15  loss: 0.6723 (0.6637)  acc1: 87.2000 (87.8182)  acc5: 97.6000 (97.9273)  time: 1.0205  data: 0.5698  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.7911 (0.7810)  acc1: 84.0000 (84.9905)  acc5: 96.8000 (97.0476)  time: 0.5134  data: 0.0686  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8592 (0.7959)  acc1: 83.6000 (84.5120)  acc5: 96.0000 (96.9440)  time: 0.4450  data: 0.0001  max mem: 62835
Test: Total time: 0:00:17 (0.7031 s / it)
* Acc@1 84.696 Acc@5 96.976 loss 0.786
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.73%
Epoch: [275]  [   0/1251]  eta: 1:45:41  lr: 0.000079  min_lr: 0.000079  loss: 1.5288 (1.5288)  weight_decay: 0.0500 (0.0500)  time: 5.0690  data: 3.4022  max mem: 62835
Epoch: [275]  [ 200/1251]  eta: 0:14:42  lr: 0.000078  min_lr: 0.000078  loss: 2.7738 (2.6016)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6873 (1.5493)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [275]  [ 400/1251]  eta: 0:11:45  lr: 0.000077  min_lr: 0.000077  loss: 2.8527 (2.6182)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0849 (1.4099)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [275]  [ 600/1251]  eta: 0:08:56  lr: 0.000076  min_lr: 0.000076  loss: 2.6570 (2.5966)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0418 (1.3767)  time: 0.8221  data: 0.0004  max mem: 62835
Epoch: [275]  [ 800/1251]  eta: 0:06:11  lr: 0.000075  min_lr: 0.000075  loss: 2.6934 (2.5825)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3302 (1.4354)  time: 0.8156  data: 0.0004  max mem: 62835
Epoch: [275]  [1000/1251]  eta: 0:03:26  lr: 0.000074  min_lr: 0.000074  loss: 2.3736 (2.5820)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3870 (1.4406)  time: 0.8181  data: 0.0004  max mem: 62835
Epoch: [275]  [1200/1251]  eta: 0:00:41  lr: 0.000073  min_lr: 0.000073  loss: 2.6064 (2.5763)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4326 (1.4495)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [275]  [1250/1251]  eta: 0:00:00  lr: 0.000073  min_lr: 0.000073  loss: 2.6380 (2.5757)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5069 (1.4448)  time: 0.6939  data: 0.0007  max mem: 62835
Epoch: [275] Total time: 0:17:05 (0.8196 s / it)
Averaged stats: lr: 0.000073  min_lr: 0.000073  loss: 2.6380 (2.5763)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5069 (1.4448)
Test:  [ 0/25]  eta: 0:03:16  loss: 0.5860 (0.5860)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.8790  data: 7.3935  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6902 (0.6908)  acc1: 87.2000 (87.6727)  acc5: 97.6000 (98.0000)  time: 1.1199  data: 0.6724  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8180 (0.8053)  acc1: 84.4000 (84.8191)  acc5: 96.8000 (97.0476)  time: 0.4439  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8847 (0.8207)  acc1: 83.6000 (84.3680)  acc5: 96.4000 (96.9280)  time: 0.4439  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7460 s / it)
* Acc@1 84.670 Acc@5 97.008 loss 0.813
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.73%
Epoch: [276]  [   0/1251]  eta: 1:28:37  lr: 0.000073  min_lr: 0.000073  loss: 2.6999 (2.6999)  weight_decay: 0.0500 (0.0500)  time: 4.2508  data: 3.0074  max mem: 62835
Epoch: [276]  [ 200/1251]  eta: 0:14:35  lr: 0.000072  min_lr: 0.000072  loss: 2.7597 (2.5382)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2223 (1.5230)  time: 0.8158  data: 0.0004  max mem: 62835
Epoch: [276]  [ 400/1251]  eta: 0:11:41  lr: 0.000071  min_lr: 0.000071  loss: 2.5083 (2.5521)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0645 (1.4193)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [276]  [ 600/1251]  eta: 0:08:55  lr: 0.000070  min_lr: 0.000070  loss: 2.7546 (2.5664)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1767 (1.3738)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [276]  [ 800/1251]  eta: 0:06:10  lr: 0.000069  min_lr: 0.000069  loss: 2.6670 (2.5747)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2683 (1.3706)  time: 0.8170  data: 0.0004  max mem: 62835
Epoch: [276]  [1000/1251]  eta: 0:03:25  lr: 0.000068  min_lr: 0.000068  loss: 2.6193 (2.5774)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2974 (1.3490)  time: 0.8166  data: 0.0003  max mem: 62835
Epoch: [276]  [1200/1251]  eta: 0:00:41  lr: 0.000067  min_lr: 0.000067  loss: 2.7659 (2.5809)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3012 (1.3551)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [276]  [1250/1251]  eta: 0:00:00  lr: 0.000067  min_lr: 0.000067  loss: 2.5347 (2.5792)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3271 (1.3591)  time: 0.6934  data: 0.0006  max mem: 62835
Epoch: [276] Total time: 0:17:04 (0.8186 s / it)
Averaged stats: lr: 0.000067  min_lr: 0.000067  loss: 2.5347 (2.5729)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3271 (1.3591)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.6063 (0.6063)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.5942  data: 7.1039  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7143 (0.7101)  acc1: 87.2000 (87.6727)  acc5: 98.0000 (97.9273)  time: 1.0957  data: 0.6461  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8282 (0.8242)  acc1: 84.0000 (84.8000)  acc5: 96.8000 (97.0286)  time: 0.4458  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8984 (0.8397)  acc1: 82.8000 (84.3680)  acc5: 96.4000 (96.9440)  time: 0.4458  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7389 s / it)
* Acc@1 84.712 Acc@5 96.940 loss 0.831
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.73%
Epoch: [277]  [   0/1251]  eta: 1:48:28  lr: 0.000067  min_lr: 0.000067  loss: 2.3991 (2.3991)  weight_decay: 0.0500 (0.0500)  time: 5.2028  data: 4.2394  max mem: 62835
Epoch: [277]  [ 200/1251]  eta: 0:14:41  lr: 0.000066  min_lr: 0.000066  loss: 2.5914 (2.5373)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2582 (1.2842)  time: 0.8169  data: 0.0004  max mem: 62835
Epoch: [277]  [ 400/1251]  eta: 0:11:45  lr: 0.000065  min_lr: 0.000065  loss: 2.6351 (2.5444)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1688 (1.2965)  time: 0.8171  data: 0.0004  max mem: 62835
Epoch: [277]  [ 600/1251]  eta: 0:08:57  lr: 0.000064  min_lr: 0.000064  loss: 2.7416 (2.5450)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1346 (1.3346)  time: 0.8172  data: 0.0004  max mem: 62835
Epoch: [277]  [ 800/1251]  eta: 0:06:11  lr: 0.000064  min_lr: 0.000064  loss: 2.4951 (2.5428)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1149 (1.3492)  time: 0.8220  data: 0.0004  max mem: 62835
Epoch: [277]  [1000/1251]  eta: 0:03:26  lr: 0.000063  min_lr: 0.000063  loss: 2.6595 (2.5563)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2972 (1.3360)  time: 0.8172  data: 0.0004  max mem: 62835
Epoch: [277]  [1200/1251]  eta: 0:00:41  lr: 0.000062  min_lr: 0.000062  loss: 2.7094 (2.5635)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1961 (1.3581)  time: 0.8170  data: 0.0003  max mem: 62835
Epoch: [277]  [1250/1251]  eta: 0:00:00  lr: 0.000062  min_lr: 0.000062  loss: 2.7821 (2.5666)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1488 (1.3570)  time: 0.6941  data: 0.0005  max mem: 62835
Epoch: [277] Total time: 0:17:05 (0.8198 s / it)
Averaged stats: lr: 0.000062  min_lr: 0.000062  loss: 2.7821 (2.5670)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1488 (1.3570)
Test:  [ 0/25]  eta: 0:03:06  loss: 0.6462 (0.6462)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.4620  data: 6.9928  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7539 (0.7574)  acc1: 88.4000 (87.7455)  acc5: 98.0000 (98.0364)  time: 1.0838  data: 0.6360  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8910 (0.8731)  acc1: 83.2000 (84.7429)  acc5: 96.8000 (97.0095)  time: 0.4458  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9560 (0.8879)  acc1: 83.2000 (84.2560)  acc5: 96.0000 (96.9120)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7337 s / it)
* Acc@1 84.680 Acc@5 96.954 loss 0.878
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.73%
Epoch: [278]  [   0/1251]  eta: 1:35:16  lr: 0.000062  min_lr: 0.000062  loss: 2.1297 (2.1297)  weight_decay: 0.0500 (0.0500)  time: 4.5699  data: 3.3882  max mem: 62835
Epoch: [278]  [ 200/1251]  eta: 0:14:39  lr: 0.000061  min_lr: 0.000061  loss: 2.6972 (2.5549)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2345 (1.4177)  time: 0.8170  data: 0.0004  max mem: 62835
Epoch: [278]  [ 400/1251]  eta: 0:11:44  lr: 0.000060  min_lr: 0.000060  loss: 2.6832 (2.5605)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1542 (1.4069)  time: 0.8172  data: 0.0003  max mem: 62835
Epoch: [278]  [ 600/1251]  eta: 0:08:56  lr: 0.000059  min_lr: 0.000059  loss: 2.6804 (2.5664)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3690 (1.3902)  time: 0.8237  data: 0.0004  max mem: 62835
Epoch: [278]  [ 800/1251]  eta: 0:06:10  lr: 0.000058  min_lr: 0.000058  loss: 2.7104 (2.5697)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1691 (1.3480)  time: 0.8154  data: 0.0004  max mem: 62835
Epoch: [278]  [1000/1251]  eta: 0:03:26  lr: 0.000057  min_lr: 0.000057  loss: 2.5250 (2.5773)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2857 (1.3965)  time: 0.8168  data: 0.0003  max mem: 62835
Epoch: [278]  [1200/1251]  eta: 0:00:41  lr: 0.000056  min_lr: 0.000056  loss: 2.7002 (2.5793)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0947 (1.3747)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [278]  [1250/1251]  eta: 0:00:00  lr: 0.000056  min_lr: 0.000056  loss: 2.4708 (2.5773)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1174 (1.3697)  time: 0.6935  data: 0.0005  max mem: 62835
Epoch: [278] Total time: 0:17:04 (0.8191 s / it)
Averaged stats: lr: 0.000056  min_lr: 0.000056  loss: 2.4708 (2.5671)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1174 (1.3697)
Test:  [ 0/25]  eta: 0:03:18  loss: 0.6030 (0.6030)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.9504  data: 7.4626  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7148 (0.7098)  acc1: 87.2000 (87.6364)  acc5: 98.0000 (98.1091)  time: 1.1282  data: 0.6787  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8354 (0.8248)  acc1: 84.0000 (84.6476)  acc5: 97.2000 (97.0286)  time: 0.4459  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9004 (0.8399)  acc1: 83.6000 (84.2560)  acc5: 96.4000 (96.9280)  time: 0.4459  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7562 s / it)
* Acc@1 84.650 Acc@5 96.970 loss 0.831
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.73%
Epoch: [279]  [   0/1251]  eta: 1:52:36  lr: 0.000056  min_lr: 0.000056  loss: 3.1837 (3.1837)  weight_decay: 0.0500 (0.0500)  time: 5.4010  data: 2.2864  max mem: 62835
Epoch: [279]  [ 200/1251]  eta: 0:14:43  lr: 0.000055  min_lr: 0.000055  loss: 2.6877 (2.5825)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3087 (1.3473)  time: 0.8158  data: 0.0004  max mem: 62835
Epoch: [279]  [ 400/1251]  eta: 0:11:45  lr: 0.000055  min_lr: 0.000055  loss: 2.5514 (2.5758)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2582 (1.3680)  time: 0.8158  data: 0.0003  max mem: 62835
Epoch: [279]  [ 600/1251]  eta: 0:08:56  lr: 0.000054  min_lr: 0.000054  loss: 2.6174 (2.5735)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4575 (1.3895)  time: 0.8226  data: 0.0004  max mem: 62835
Epoch: [279]  [ 800/1251]  eta: 0:06:10  lr: 0.000053  min_lr: 0.000053  loss: 2.3943 (2.5613)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2770 (1.3956)  time: 0.8161  data: 0.0004  max mem: 62835
Epoch: [279]  [1000/1251]  eta: 0:03:26  lr: 0.000052  min_lr: 0.000052  loss: 2.7679 (2.5623)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1671 (1.3769)  time: 0.8144  data: 0.0003  max mem: 62835
Epoch: [279]  [1200/1251]  eta: 0:00:41  lr: 0.000051  min_lr: 0.000051  loss: 2.5159 (2.5583)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1489 (1.3643)  time: 0.8204  data: 0.0003  max mem: 62835
Epoch: [279]  [1250/1251]  eta: 0:00:00  lr: 0.000051  min_lr: 0.000051  loss: 2.4535 (2.5546)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3220 (1.3745)  time: 0.6926  data: 0.0005  max mem: 62835
Epoch: [279] Total time: 0:17:04 (0.8187 s / it)
Averaged stats: lr: 0.000051  min_lr: 0.000051  loss: 2.4535 (2.5706)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3220 (1.3745)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.5795 (0.5795)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.7410  data: 7.2795  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6971 (0.6891)  acc1: 87.2000 (87.8545)  acc5: 98.0000 (97.9273)  time: 1.1107  data: 0.6621  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8122 (0.8023)  acc1: 84.0000 (84.8762)  acc5: 96.8000 (97.0286)  time: 0.4467  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8813 (0.8175)  acc1: 83.6000 (84.4800)  acc5: 96.0000 (96.9120)  time: 0.4459  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7469 s / it)
* Acc@1 84.658 Acc@5 96.966 loss 0.811
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.73%
Epoch: [280]  [   0/1251]  eta: 1:35:25  lr: 0.000051  min_lr: 0.000051  loss: 2.7149 (2.7149)  weight_decay: 0.0500 (0.0500)  time: 4.5767  data: 3.2882  max mem: 62835
Epoch: [280]  [ 200/1251]  eta: 0:14:38  lr: 0.000050  min_lr: 0.000050  loss: 2.7959 (2.5930)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3669 (1.3563)  time: 0.8161  data: 0.0004  max mem: 62835
Epoch: [280]  [ 400/1251]  eta: 0:11:42  lr: 0.000050  min_lr: 0.000050  loss: 2.4461 (2.5676)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0286 (1.3041)  time: 0.8149  data: 0.0004  max mem: 62835
Epoch: [280]  [ 600/1251]  eta: 0:08:55  lr: 0.000049  min_lr: 0.000049  loss: 2.4718 (2.5514)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3007 (1.3364)  time: 0.8156  data: 0.0004  max mem: 62835
Epoch: [280]  [ 800/1251]  eta: 0:06:10  lr: 0.000048  min_lr: 0.000048  loss: 2.4790 (2.5503)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2113 (1.3354)  time: 0.8161  data: 0.0005  max mem: 62835
Epoch: [280]  [1000/1251]  eta: 0:03:25  lr: 0.000047  min_lr: 0.000047  loss: 2.7692 (2.5541)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3985 (1.3438)  time: 0.8158  data: 0.0005  max mem: 62835
Epoch: [280]  [1200/1251]  eta: 0:00:41  lr: 0.000046  min_lr: 0.000046  loss: 2.5922 (2.5579)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3205 (1.3338)  time: 0.8160  data: 0.0005  max mem: 62835
Epoch: [280]  [1250/1251]  eta: 0:00:00  lr: 0.000046  min_lr: 0.000046  loss: 2.2434 (2.5566)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.6936  data: 0.0007  max mem: 62835
Epoch: [280] Total time: 0:17:03 (0.8182 s / it)
Averaged stats: lr: 0.000046  min_lr: 0.000046  loss: 2.2434 (2.5691)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)
Test:  [ 0/25]  eta: 0:03:06  loss: 0.5589 (0.5589)  acc1: 89.2000 (89.2000)  acc5: 99.2000 (99.2000)  time: 7.4778  data: 7.0023  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6732 (0.6712)  acc1: 87.2000 (88.1091)  acc5: 98.0000 (98.0000)  time: 1.0846  data: 0.6369  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.7940 (0.7855)  acc1: 84.4000 (84.9524)  acc5: 96.8000 (97.0095)  time: 0.4451  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8701 (0.8011)  acc1: 83.2000 (84.4960)  acc5: 96.0000 (96.8800)  time: 0.4450  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7327 s / it)
* Acc@1 84.728 Acc@5 96.982 loss 0.793
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.73%
Epoch: [281]  [   0/1251]  eta: 1:41:37  lr: 0.000046  min_lr: 0.000046  loss: 3.0583 (3.0583)  weight_decay: 0.0500 (0.0500)  time: 4.8744  data: 3.6559  max mem: 62835
Epoch: [281]  [ 200/1251]  eta: 0:14:39  lr: 0.000046  min_lr: 0.000046  loss: 2.5126 (2.5844)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5269 (1.3628)  time: 0.8152  data: 0.0004  max mem: 62835
Epoch: [281]  [ 400/1251]  eta: 0:11:43  lr: 0.000045  min_lr: 0.000045  loss: 2.6814 (2.5915)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3565 (1.3770)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [281]  [ 600/1251]  eta: 0:08:56  lr: 0.000044  min_lr: 0.000044  loss: 2.6658 (2.5891)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1596 (1.3350)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [281]  [ 800/1251]  eta: 0:06:10  lr: 0.000043  min_lr: 0.000043  loss: 2.7614 (2.5883)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3898 (1.3083)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [281]  [1000/1251]  eta: 0:03:26  lr: 0.000043  min_lr: 0.000043  loss: 2.6036 (2.5829)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4174 (1.3404)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [281]  [1200/1251]  eta: 0:00:41  lr: 0.000042  min_lr: 0.000042  loss: 2.7068 (2.5781)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2798 (1.3262)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [281]  [1250/1251]  eta: 0:00:00  lr: 0.000042  min_lr: 0.000042  loss: 2.6357 (2.5759)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1811 (1.3244)  time: 0.6929  data: 0.0005  max mem: 62835
Epoch: [281] Total time: 0:17:04 (0.8188 s / it)
Averaged stats: lr: 0.000042  min_lr: 0.000042  loss: 2.6357 (2.5613)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1811 (1.3244)
Test:  [ 0/25]  eta: 0:03:21  loss: 0.5865 (0.5865)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 8.0501  data: 7.5816  max mem: 62835
Test:  [10/25]  eta: 0:00:17  loss: 0.6946 (0.6974)  acc1: 88.0000 (88.0000)  acc5: 98.0000 (97.9636)  time: 1.1356  data: 0.6895  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8239 (0.8118)  acc1: 84.0000 (85.0667)  acc5: 96.4000 (96.8762)  time: 0.4442  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8887 (0.8274)  acc1: 84.0000 (84.5600)  acc5: 96.4000 (96.8000)  time: 0.4442  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7537 s / it)
* Acc@1 84.676 Acc@5 96.988 loss 0.819
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.73%
Epoch: [282]  [   0/1251]  eta: 1:42:39  lr: 0.000042  min_lr: 0.000042  loss: 2.7007 (2.7007)  weight_decay: 0.0500 (0.0500)  time: 4.9234  data: 3.5954  max mem: 62835
Epoch: [282]  [ 200/1251]  eta: 0:14:40  lr: 0.000041  min_lr: 0.000041  loss: 2.6550 (2.5678)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3687 (1.4928)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [282]  [ 400/1251]  eta: 0:11:44  lr: 0.000040  min_lr: 0.000040  loss: 2.6790 (2.5941)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2898 (1.4026)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [282]  [ 600/1251]  eta: 0:08:56  lr: 0.000040  min_lr: 0.000040  loss: 2.5631 (2.5802)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2104 (1.3605)  time: 0.8172  data: 0.0004  max mem: 62835
Epoch: [282]  [ 800/1251]  eta: 0:06:10  lr: 0.000039  min_lr: 0.000039  loss: 2.8023 (2.5788)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1791 (1.3581)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [282]  [1000/1251]  eta: 0:03:26  lr: 0.000038  min_lr: 0.000038  loss: 2.5448 (2.5765)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3277 (1.3732)  time: 0.8170  data: 0.0004  max mem: 62835
Epoch: [282]  [1200/1251]  eta: 0:00:41  lr: 0.000037  min_lr: 0.000037  loss: 2.6797 (2.5688)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2353 (1.3618)  time: 0.8173  data: 0.0004  max mem: 62835
Epoch: [282]  [1250/1251]  eta: 0:00:00  lr: 0.000037  min_lr: 0.000037  loss: 2.4891 (2.5703)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3186 (1.3592)  time: 0.6941  data: 0.0006  max mem: 62835
Epoch: [282] Total time: 0:17:05 (0.8194 s / it)
Averaged stats: lr: 0.000037  min_lr: 0.000037  loss: 2.4891 (2.5666)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3186 (1.3592)
Test:  [ 0/25]  eta: 0:02:43  loss: 0.5598 (0.5598)  acc1: 90.0000 (90.0000)  acc5: 99.6000 (99.6000)  time: 6.5484  data: 6.0799  max mem: 62835
Test:  [10/25]  eta: 0:00:15  loss: 0.6722 (0.6685)  acc1: 87.6000 (87.9636)  acc5: 98.0000 (98.0364)  time: 1.0008  data: 0.5531  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.7981 (0.7857)  acc1: 83.6000 (84.8191)  acc5: 96.8000 (97.0476)  time: 0.4459  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8585 (0.8007)  acc1: 82.8000 (84.4800)  acc5: 96.4000 (96.9280)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:17 (0.6982 s / it)
* Acc@1 84.762 Acc@5 97.026 loss 0.792
Accuracy of the model on the 50000 test images: 84.8%
Max accuracy: 84.76%
Epoch: [283]  [   0/1251]  eta: 1:30:47  lr: 0.000037  min_lr: 0.000037  loss: 2.2571 (2.2571)  weight_decay: 0.0500 (0.0500)  time: 4.3543  data: 3.5210  max mem: 62835
Epoch: [283]  [ 200/1251]  eta: 0:14:38  lr: 0.000037  min_lr: 0.000037  loss: 2.6784 (2.5794)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1682 (1.1969)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [283]  [ 400/1251]  eta: 0:11:42  lr: 0.000036  min_lr: 0.000036  loss: 2.5590 (2.5787)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0581 (1.2187)  time: 0.8156  data: 0.0004  max mem: 62835
Epoch: [283]  [ 600/1251]  eta: 0:08:55  lr: 0.000035  min_lr: 0.000035  loss: 2.7345 (2.5980)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2679 (1.2733)  time: 0.8153  data: 0.0004  max mem: 62835
Epoch: [283]  [ 800/1251]  eta: 0:06:10  lr: 0.000035  min_lr: 0.000035  loss: 2.4863 (2.5903)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0992 (1.2935)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [283]  [1000/1251]  eta: 0:03:25  lr: 0.000034  min_lr: 0.000034  loss: 2.6218 (2.5838)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2576 (1.3153)  time: 0.8161  data: 0.0005  max mem: 62835
Epoch: [283]  [1200/1251]  eta: 0:00:41  lr: 0.000033  min_lr: 0.000033  loss: 2.5406 (2.5753)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3034 (1.3293)  time: 0.8216  data: 0.0004  max mem: 62835
Epoch: [283]  [1250/1251]  eta: 0:00:00  lr: 0.000033  min_lr: 0.000033  loss: 2.7625 (2.5728)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1471 (1.3275)  time: 0.6935  data: 0.0005  max mem: 62835
Epoch: [283] Total time: 0:17:03 (0.8185 s / it)
Averaged stats: lr: 0.000033  min_lr: 0.000033  loss: 2.7625 (2.5636)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1471 (1.3275)
Test:  [ 0/25]  eta: 0:02:13  loss: 0.6281 (0.6281)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 5.3531  data: 4.8182  max mem: 62835
Test:  [10/25]  eta: 0:00:15  loss: 0.7376 (0.7355)  acc1: 87.6000 (87.6727)  acc5: 98.0000 (98.1818)  time: 1.0154  data: 0.5623  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8676 (0.8507)  acc1: 84.4000 (84.9714)  acc5: 97.2000 (96.9714)  time: 0.5133  data: 0.0684  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9225 (0.8662)  acc1: 83.6000 (84.5600)  acc5: 96.4000 (96.8800)  time: 0.4450  data: 0.0002  max mem: 62835
Test: Total time: 0:00:17 (0.7005 s / it)
* Acc@1 84.722 Acc@5 96.978 loss 0.857
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Epoch: [284]  [   0/1251]  eta: 1:37:57  lr: 0.000033  min_lr: 0.000033  loss: 2.8019 (2.8019)  weight_decay: 0.0500 (0.0500)  time: 4.6986  data: 3.5382  max mem: 62835
Epoch: [284]  [ 200/1251]  eta: 0:14:39  lr: 0.000032  min_lr: 0.000032  loss: 2.6055 (2.5689)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2876 (1.3166)  time: 0.8177  data: 0.0004  max mem: 62835
Epoch: [284]  [ 400/1251]  eta: 0:11:44  lr: 0.000032  min_lr: 0.000032  loss: 2.7011 (2.5770)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1355 (1.3221)  time: 0.8173  data: 0.0004  max mem: 62835
Epoch: [284]  [ 600/1251]  eta: 0:08:56  lr: 0.000031  min_lr: 0.000031  loss: 2.5275 (2.5843)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1479 (1.3744)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [284]  [ 800/1251]  eta: 0:06:10  lr: 0.000031  min_lr: 0.000031  loss: 2.5142 (2.5715)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2598 (1.3634)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [284]  [1000/1251]  eta: 0:03:26  lr: 0.000030  min_lr: 0.000030  loss: 2.5725 (2.5733)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1851 (1.3855)  time: 0.8158  data: 0.0004  max mem: 62835
Epoch: [284]  [1200/1251]  eta: 0:00:41  lr: 0.000029  min_lr: 0.000029  loss: 2.6847 (2.5720)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3155 (1.3815)  time: 0.8170  data: 0.0004  max mem: 62835
Epoch: [284]  [1250/1251]  eta: 0:00:00  lr: 0.000029  min_lr: 0.000029  loss: 2.4890 (2.5724)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2116 (1.3735)  time: 0.6942  data: 0.0005  max mem: 62835
Epoch: [284] Total time: 0:17:05 (0.8194 s / it)
Averaged stats: lr: 0.000029  min_lr: 0.000029  loss: 2.4890 (2.5670)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2116 (1.3735)
Test:  [ 0/25]  eta: 0:03:16  loss: 0.5468 (0.5468)  acc1: 90.0000 (90.0000)  acc5: 99.6000 (99.6000)  time: 7.8616  data: 7.3803  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6687 (0.6609)  acc1: 88.0000 (88.0000)  acc5: 98.0000 (98.0364)  time: 1.1200  data: 0.6712  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.7894 (0.7778)  acc1: 84.4000 (84.9905)  acc5: 96.8000 (97.0286)  time: 0.4459  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8465 (0.7927)  acc1: 83.6000 (84.5760)  acc5: 96.4000 (96.9600)  time: 0.4459  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7498 s / it)
* Acc@1 84.710 Acc@5 97.036 loss 0.785
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Epoch: [285]  [   0/1251]  eta: 1:50:48  lr: 0.000029  min_lr: 0.000029  loss: 2.0697 (2.0697)  weight_decay: 0.0500 (0.0500)  time: 5.3143  data: 3.8774  max mem: 62835
Epoch: [285]  [ 200/1251]  eta: 0:14:42  lr: 0.000029  min_lr: 0.000029  loss: 2.6684 (2.5597)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2711 (1.3606)  time: 0.8171  data: 0.0004  max mem: 62835
Epoch: [285]  [ 400/1251]  eta: 0:11:45  lr: 0.000028  min_lr: 0.000028  loss: 2.6633 (2.5720)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1521 (1.3628)  time: 0.8172  data: 0.0004  max mem: 62835
Epoch: [285]  [ 600/1251]  eta: 0:08:57  lr: 0.000027  min_lr: 0.000027  loss: 2.6718 (2.5627)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1762 (1.3739)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [285]  [ 800/1251]  eta: 0:06:11  lr: 0.000027  min_lr: 0.000027  loss: 2.7015 (2.5731)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1587 (1.3750)  time: 0.8169  data: 0.0004  max mem: 62835
Epoch: [285]  [1000/1251]  eta: 0:03:26  lr: 0.000026  min_lr: 0.000026  loss: 2.7636 (2.5733)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1950 (1.3748)  time: 0.8169  data: 0.0004  max mem: 62835
Epoch: [285]  [1200/1251]  eta: 0:00:41  lr: 0.000026  min_lr: 0.000026  loss: 2.6939 (2.5782)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1607 (1.3647)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [285]  [1250/1251]  eta: 0:00:00  lr: 0.000026  min_lr: 0.000026  loss: 2.5532 (2.5757)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1300 (1.3559)  time: 0.6937  data: 0.0007  max mem: 62835
Epoch: [285] Total time: 0:17:05 (0.8197 s / it)
Averaged stats: lr: 0.000026  min_lr: 0.000026  loss: 2.5532 (2.5670)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1300 (1.3559)
Test:  [ 0/25]  eta: 0:03:09  loss: 0.6047 (0.6047)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 7.5753  data: 7.0919  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7074 (0.7096)  acc1: 88.0000 (87.9273)  acc5: 98.0000 (98.1091)  time: 1.0940  data: 0.6450  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8440 (0.8238)  acc1: 84.0000 (85.0095)  acc5: 97.2000 (97.1048)  time: 0.4458  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8876 (0.8389)  acc1: 84.0000 (84.6560)  acc5: 96.4000 (97.0080)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7414 s / it)
* Acc@1 84.732 Acc@5 97.006 loss 0.831
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Epoch: [286]  [   0/1251]  eta: 1:42:42  lr: 0.000026  min_lr: 0.000026  loss: 3.0087 (3.0087)  weight_decay: 0.0500 (0.0500)  time: 4.9258  data: 2.1008  max mem: 62835
Epoch: [286]  [ 200/1251]  eta: 0:14:40  lr: 0.000025  min_lr: 0.000025  loss: 2.4951 (2.5149)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3934 (1.3456)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [286]  [ 400/1251]  eta: 0:11:43  lr: 0.000025  min_lr: 0.000025  loss: 2.7425 (2.5502)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2729 (1.4248)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [286]  [ 600/1251]  eta: 0:08:56  lr: 0.000024  min_lr: 0.000024  loss: 2.5984 (2.5432)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2008 (1.3753)  time: 0.8155  data: 0.0004  max mem: 62835
Epoch: [286]  [ 800/1251]  eta: 0:06:10  lr: 0.000023  min_lr: 0.000023  loss: 2.5597 (2.5458)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1620 (1.3434)  time: 0.8217  data: 0.0004  max mem: 62835
Epoch: [286]  [1000/1251]  eta: 0:03:26  lr: 0.000023  min_lr: 0.000023  loss: 2.5509 (2.5408)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2054 (1.3293)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [286]  [1200/1251]  eta: 0:00:41  lr: 0.000022  min_lr: 0.000022  loss: 2.6311 (2.5435)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3185 (1.3234)  time: 0.8159  data: 0.0004  max mem: 62835
Epoch: [286]  [1250/1251]  eta: 0:00:00  lr: 0.000022  min_lr: 0.000022  loss: 2.6571 (2.5450)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1609 (1.3270)  time: 0.6927  data: 0.0007  max mem: 62835
Epoch: [286] Total time: 0:17:04 (0.8187 s / it)
Averaged stats: lr: 0.000022  min_lr: 0.000022  loss: 2.6571 (2.5545)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1609 (1.3270)
Test:  [ 0/25]  eta: 0:03:03  loss: 0.6341 (0.6341)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 7.3522  data: 6.8777  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7394 (0.7392)  acc1: 88.0000 (87.7455)  acc5: 98.0000 (98.0364)  time: 1.0716  data: 0.6255  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8706 (0.8572)  acc1: 84.0000 (84.8762)  acc5: 96.8000 (97.0095)  time: 0.4435  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9356 (0.8729)  acc1: 83.6000 (84.4480)  acc5: 96.4000 (96.9120)  time: 0.4437  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7255 s / it)
* Acc@1 84.622 Acc@5 96.982 loss 0.864
Accuracy of the model on the 50000 test images: 84.6%
Max accuracy: 84.76%
Epoch: [287]  [   0/1251]  eta: 1:40:22  lr: 0.000022  min_lr: 0.000022  loss: 2.6037 (2.6037)  weight_decay: 0.0500 (0.0500)  time: 4.8145  data: 3.1475  max mem: 62835
Epoch: [287]  [ 200/1251]  eta: 0:14:40  lr: 0.000022  min_lr: 0.000022  loss: 2.5993 (2.5792)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0021 (1.2922)  time: 0.8169  data: 0.0004  max mem: 62835
Epoch: [287]  [ 400/1251]  eta: 0:11:44  lr: 0.000021  min_lr: 0.000021  loss: 2.6384 (2.5723)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1648 (1.3256)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [287]  [ 600/1251]  eta: 0:08:56  lr: 0.000021  min_lr: 0.000021  loss: 2.4620 (2.5688)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0493 (1.3304)  time: 0.8214  data: 0.0004  max mem: 62835
Epoch: [287]  [ 800/1251]  eta: 0:06:10  lr: 0.000020  min_lr: 0.000020  loss: 2.5339 (2.5716)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2281 (1.3384)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [287]  [1000/1251]  eta: 0:03:26  lr: 0.000020  min_lr: 0.000020  loss: 2.6439 (2.5698)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1854 (1.3357)  time: 0.8160  data: 0.0004  max mem: 62835
Epoch: [287]  [1200/1251]  eta: 0:00:41  lr: 0.000019  min_lr: 0.000019  loss: 2.6000 (2.5692)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2478 (1.3281)  time: 0.8174  data: 0.0005  max mem: 62835
Epoch: [287]  [1250/1251]  eta: 0:00:00  lr: 0.000019  min_lr: 0.000019  loss: 2.8747 (2.5724)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2200 (1.3316)  time: 0.6942  data: 0.0007  max mem: 62835
Epoch: [287] Total time: 0:17:04 (0.8191 s / it)
Averaged stats: lr: 0.000019  min_lr: 0.000019  loss: 2.8747 (2.5629)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2200 (1.3316)
Test:  [ 0/25]  eta: 0:03:10  loss: 0.6425 (0.6425)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.6371  data: 7.1411  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7447 (0.7442)  acc1: 87.6000 (87.6364)  acc5: 97.6000 (97.9636)  time: 1.1001  data: 0.6496  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8787 (0.8592)  acc1: 84.0000 (84.7810)  acc5: 96.8000 (96.9524)  time: 0.4462  data: 0.0003  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9294 (0.8755)  acc1: 83.6000 (84.4000)  acc5: 96.0000 (96.8160)  time: 0.4460  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7409 s / it)
* Acc@1 84.584 Acc@5 96.902 loss 0.865
Accuracy of the model on the 50000 test images: 84.6%
Max accuracy: 84.76%
Epoch: [288]  [   0/1251]  eta: 1:38:32  lr: 0.000019  min_lr: 0.000019  loss: 2.8445 (2.8445)  weight_decay: 0.0500 (0.0500)  time: 4.7264  data: 3.8204  max mem: 62835
Epoch: [288]  [ 200/1251]  eta: 0:14:39  lr: 0.000019  min_lr: 0.000019  loss: 2.5507 (2.5403)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0586 (1.1774)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [288]  [ 400/1251]  eta: 0:11:43  lr: 0.000018  min_lr: 0.000018  loss: 2.6084 (2.5570)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1568 (1.2224)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [288]  [ 600/1251]  eta: 0:08:56  lr: 0.000018  min_lr: 0.000018  loss: 2.6507 (2.5552)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3546 (1.2626)  time: 0.8166  data: 0.0004  max mem: 62835
Epoch: [288]  [ 800/1251]  eta: 0:06:10  lr: 0.000017  min_lr: 0.000017  loss: 2.6688 (2.5485)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1434 (1.2816)  time: 0.8159  data: 0.0005  max mem: 62835
Epoch: [288]  [1000/1251]  eta: 0:03:26  lr: 0.000017  min_lr: 0.000017  loss: 2.6539 (2.5433)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0457 (1.2827)  time: 0.8161  data: 0.0004  max mem: 62835
Epoch: [288]  [1200/1251]  eta: 0:00:41  lr: 0.000016  min_lr: 0.000016  loss: 2.7686 (2.5486)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1358 (1.2891)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [288]  [1250/1251]  eta: 0:00:00  lr: 0.000016  min_lr: 0.000016  loss: 2.5503 (2.5479)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2459 (1.2908)  time: 0.6961  data: 0.0006  max mem: 62835
Epoch: [288] Total time: 0:17:04 (0.8188 s / it)
Averaged stats: lr: 0.000016  min_lr: 0.000016  loss: 2.5503 (2.5574)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2459 (1.2908)
Test:  [ 0/25]  eta: 0:03:20  loss: 0.5780 (0.5780)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 8.0062  data: 7.5224  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6833 (0.6797)  acc1: 88.0000 (87.9273)  acc5: 98.0000 (98.1091)  time: 1.1332  data: 0.6841  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8052 (0.7945)  acc1: 84.0000 (84.8952)  acc5: 96.8000 (97.0667)  time: 0.4457  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8673 (0.8100)  acc1: 83.6000 (84.4640)  acc5: 96.8000 (96.9760)  time: 0.4456  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7577 s / it)
* Acc@1 84.678 Acc@5 97.004 loss 0.802
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Epoch: [289]  [   0/1251]  eta: 1:34:09  lr: 0.000016  min_lr: 0.000016  loss: 2.5550 (2.5550)  weight_decay: 0.0500 (0.0500)  time: 4.5161  data: 2.1452  max mem: 62835
Epoch: [289]  [ 200/1251]  eta: 0:14:36  lr: 0.000016  min_lr: 0.000016  loss: 2.7817 (2.5613)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2399 (1.2199)  time: 0.8155  data: 0.0004  max mem: 62835
Epoch: [289]  [ 400/1251]  eta: 0:11:42  lr: 0.000015  min_lr: 0.000015  loss: 2.6937 (2.5783)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0828 (1.2383)  time: 0.8155  data: 0.0004  max mem: 62835
Epoch: [289]  [ 600/1251]  eta: 0:08:55  lr: 0.000015  min_lr: 0.000015  loss: 2.6787 (2.5805)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0465 (1.2146)  time: 0.8157  data: 0.0004  max mem: 62835
Epoch: [289]  [ 800/1251]  eta: 0:06:10  lr: 0.000014  min_lr: 0.000014  loss: 2.6843 (2.5765)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2153 (1.2479)  time: 0.8156  data: 0.0004  max mem: 62835
Epoch: [289]  [1000/1251]  eta: 0:03:25  lr: 0.000014  min_lr: 0.000014  loss: 2.7562 (2.5744)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1988 (1.2521)  time: 0.8152  data: 0.0004  max mem: 62835
Epoch: [289]  [1200/1251]  eta: 0:00:41  lr: 0.000014  min_lr: 0.000014  loss: 2.5127 (2.5681)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0538 (1.2674)  time: 0.8156  data: 0.0004  max mem: 62835
Epoch: [289]  [1250/1251]  eta: 0:00:00  lr: 0.000014  min_lr: 0.000014  loss: 2.5635 (2.5689)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2916 (1.2714)  time: 0.6928  data: 0.0007  max mem: 62835
Epoch: [289] Total time: 0:17:03 (0.8178 s / it)
Averaged stats: lr: 0.000014  min_lr: 0.000014  loss: 2.5635 (2.5623)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2916 (1.2714)
Test:  [ 0/25]  eta: 0:03:11  loss: 0.5929 (0.5929)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 7.6572  data: 7.1676  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7002 (0.6982)  acc1: 88.0000 (87.8182)  acc5: 97.6000 (98.0727)  time: 1.1015  data: 0.6519  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8318 (0.8150)  acc1: 84.0000 (84.9905)  acc5: 97.2000 (97.0286)  time: 0.4457  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8913 (0.8307)  acc1: 83.6000 (84.5760)  acc5: 96.4000 (96.9440)  time: 0.4456  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7442 s / it)
* Acc@1 84.702 Acc@5 97.000 loss 0.822
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Epoch: [290]  [   0/1251]  eta: 1:43:44  lr: 0.000014  min_lr: 0.000014  loss: 3.0697 (3.0697)  weight_decay: 0.0500 (0.0500)  time: 4.9757  data: 3.5565  max mem: 62835
Epoch: [290]  [ 200/1251]  eta: 0:14:40  lr: 0.000013  min_lr: 0.000013  loss: 2.6846 (2.5445)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1590 (1.2174)  time: 0.8243  data: 0.0004  max mem: 62835
Epoch: [290]  [ 400/1251]  eta: 0:11:44  lr: 0.000013  min_lr: 0.000013  loss: 2.6055 (2.5516)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9830 (1.1691)  time: 0.8165  data: 0.0004  max mem: 62835
Epoch: [290]  [ 600/1251]  eta: 0:08:56  lr: 0.000012  min_lr: 0.000012  loss: 2.6732 (2.5517)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3955 (nan)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [290]  [ 800/1251]  eta: 0:06:10  lr: 0.000012  min_lr: 0.000012  loss: 2.6894 (2.5616)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2009 (nan)  time: 0.8221  data: 0.0004  max mem: 62835
Epoch: [290]  [1000/1251]  eta: 0:03:26  lr: 0.000012  min_lr: 0.000012  loss: 2.4785 (2.5684)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2871 (nan)  time: 0.8173  data: 0.0004  max mem: 62835
Epoch: [290]  [1200/1251]  eta: 0:00:41  lr: 0.000011  min_lr: 0.000011  loss: 2.6864 (2.5666)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1475 (nan)  time: 0.8169  data: 0.0004  max mem: 62835
Epoch: [290]  [1250/1251]  eta: 0:00:00  lr: 0.000011  min_lr: 0.000011  loss: 2.5039 (2.5628)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9996 (nan)  time: 0.6939  data: 0.0007  max mem: 62835
Epoch: [290] Total time: 0:17:04 (0.8193 s / it)
Averaged stats: lr: 0.000011  min_lr: 0.000011  loss: 2.5039 (2.5619)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9996 (nan)
Test:  [ 0/25]  eta: 0:03:18  loss: 0.5482 (0.5482)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 7.9257  data: 7.4460  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6672 (0.6588)  acc1: 88.0000 (87.8909)  acc5: 97.6000 (98.1091)  time: 1.1257  data: 0.6771  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.7773 (0.7745)  acc1: 83.6000 (84.8952)  acc5: 97.2000 (97.0286)  time: 0.4457  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8478 (0.7895)  acc1: 83.2000 (84.5280)  acc5: 96.0000 (96.8800)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7512 s / it)
* Acc@1 84.728 Acc@5 97.008 loss 0.782
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Epoch: [291]  [   0/1251]  eta: 1:48:08  lr: 0.000011  min_lr: 0.000011  loss: 2.9567 (2.9567)  weight_decay: 0.0500 (0.0500)  time: 5.1870  data: 2.9461  max mem: 62835
Epoch: [291]  [ 200/1251]  eta: 0:14:42  lr: 0.000011  min_lr: 0.000011  loss: 2.5001 (2.5824)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1034 (1.2545)  time: 0.8170  data: 0.0004  max mem: 62835
Epoch: [291]  [ 400/1251]  eta: 0:11:44  lr: 0.000010  min_lr: 0.000010  loss: 2.5469 (2.5755)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1797 (1.2665)  time: 0.8159  data: 0.0004  max mem: 62835
Epoch: [291]  [ 600/1251]  eta: 0:08:56  lr: 0.000010  min_lr: 0.000010  loss: 2.6488 (2.5732)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0729 (1.2486)  time: 0.8221  data: 0.0004  max mem: 62835
Epoch: [291]  [ 800/1251]  eta: 0:06:11  lr: 0.000010  min_lr: 0.000010  loss: 2.6894 (2.5770)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2269 (1.2548)  time: 0.8171  data: 0.0004  max mem: 62835
Epoch: [291]  [1000/1251]  eta: 0:03:26  lr: 0.000009  min_lr: 0.000009  loss: 2.7597 (2.5773)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2712 (1.2493)  time: 0.8169  data: 0.0004  max mem: 62835
Epoch: [291]  [1200/1251]  eta: 0:00:41  lr: 0.000009  min_lr: 0.000009  loss: 2.3883 (2.5787)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1569 (1.2542)  time: 0.8182  data: 0.0004  max mem: 62835
Epoch: [291]  [1250/1251]  eta: 0:00:00  lr: 0.000009  min_lr: 0.000009  loss: 2.7098 (2.5816)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0393 (1.2539)  time: 0.6948  data: 0.0007  max mem: 62835
Epoch: [291] Total time: 0:17:05 (0.8198 s / it)
Averaged stats: lr: 0.000009  min_lr: 0.000009  loss: 2.7098 (2.5664)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0393 (1.2539)
Test:  [ 0/25]  eta: 0:03:05  loss: 0.6582 (0.6582)  acc1: 89.6000 (89.6000)  acc5: 99.2000 (99.2000)  time: 7.4344  data: 6.9399  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7592 (0.7615)  acc1: 88.0000 (87.6727)  acc5: 98.0000 (98.0364)  time: 1.0807  data: 0.6312  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8981 (0.8796)  acc1: 83.6000 (84.8191)  acc5: 96.8000 (96.9333)  time: 0.4451  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9592 (0.8957)  acc1: 83.6000 (84.4160)  acc5: 96.4000 (96.8160)  time: 0.4450  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7320 s / it)
* Acc@1 84.648 Acc@5 96.916 loss 0.886
Accuracy of the model on the 50000 test images: 84.6%
Max accuracy: 84.76%
Epoch: [292]  [   0/1251]  eta: 1:40:11  lr: 0.000009  min_lr: 0.000009  loss: 3.0865 (3.0865)  weight_decay: 0.0500 (0.0500)  time: 4.8051  data: 2.7546  max mem: 62835
Epoch: [292]  [ 200/1251]  eta: 0:14:37  lr: 0.000009  min_lr: 0.000009  loss: 2.6654 (2.5820)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1446 (1.2968)  time: 0.8154  data: 0.0004  max mem: 62835
Epoch: [292]  [ 400/1251]  eta: 0:11:43  lr: 0.000008  min_lr: 0.000008  loss: 2.5807 (2.5677)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1801 (1.2854)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [292]  [ 600/1251]  eta: 0:08:56  lr: 0.000008  min_lr: 0.000008  loss: 2.7063 (2.5494)  weight_decay: 0.0500 (0.0500)  grad_norm: nan (nan)  time: 0.8179  data: 0.0004  max mem: 62835
Epoch: [292]  [ 800/1251]  eta: 0:06:10  lr: 0.000008  min_lr: 0.000008  loss: 2.4726 (2.5466)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2262 (nan)  time: 0.8183  data: 0.0004  max mem: 62835
Epoch: [292]  [1000/1251]  eta: 0:03:26  lr: 0.000008  min_lr: 0.000008  loss: 2.6530 (2.5512)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1015 (nan)  time: 0.8180  data: 0.0004  max mem: 62835
Epoch: [292]  [1200/1251]  eta: 0:00:41  lr: 0.000007  min_lr: 0.000007  loss: 2.7174 (2.5546)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2859 (nan)  time: 0.8178  data: 0.0004  max mem: 62835
Epoch: [292]  [1250/1251]  eta: 0:00:00  lr: 0.000007  min_lr: 0.000007  loss: 2.5283 (2.5533)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1016 (nan)  time: 0.6945  data: 0.0006  max mem: 62835
Epoch: [292] Total time: 0:17:05 (0.8195 s / it)
Averaged stats: lr: 0.000007  min_lr: 0.000007  loss: 2.5283 (2.5539)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1016 (nan)
Test:  [ 0/25]  eta: 0:03:19  loss: 0.6023 (0.6023)  acc1: 90.0000 (90.0000)  acc5: 99.6000 (99.6000)  time: 8.0000  data: 7.5196  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7092 (0.7107)  acc1: 87.6000 (87.8182)  acc5: 98.0000 (98.1091)  time: 1.1326  data: 0.6839  max mem: 62835
Test:  [20/25]  eta: 0:00:04  loss: 0.8409 (0.8255)  acc1: 84.0000 (84.8762)  acc5: 97.2000 (97.0095)  time: 0.4458  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8989 (0.8407)  acc1: 83.6000 (84.4960)  acc5: 96.4000 (96.9120)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7562 s / it)
* Acc@1 84.714 Acc@5 97.000 loss 0.833
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Epoch: [293]  [   0/1251]  eta: 1:50:49  lr: 0.000007  min_lr: 0.000007  loss: 2.1581 (2.1581)  weight_decay: 0.0500 (0.0500)  time: 5.3153  data: 3.8030  max mem: 62835
Epoch: [293]  [ 200/1251]  eta: 0:14:43  lr: 0.000007  min_lr: 0.000007  loss: 2.6553 (2.5403)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1056 (1.2086)  time: 0.8176  data: 0.0003  max mem: 62835
Epoch: [293]  [ 400/1251]  eta: 0:11:46  lr: 0.000007  min_lr: 0.000007  loss: 2.7270 (2.5341)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1525 (1.2101)  time: 0.8242  data: 0.0005  max mem: 62835
Epoch: [293]  [ 600/1251]  eta: 0:08:57  lr: 0.000006  min_lr: 0.000006  loss: 2.8344 (2.5632)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1106 (1.2335)  time: 0.8180  data: 0.0005  max mem: 62835
Epoch: [293]  [ 800/1251]  eta: 0:06:11  lr: 0.000006  min_lr: 0.000006  loss: 2.6688 (2.5561)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1819 (1.2400)  time: 0.8184  data: 0.0005  max mem: 62835
Epoch: [293]  [1000/1251]  eta: 0:03:26  lr: 0.000006  min_lr: 0.000006  loss: 2.5544 (2.5546)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3015 (1.2470)  time: 0.8192  data: 0.0005  max mem: 62835
Epoch: [293]  [1200/1251]  eta: 0:00:41  lr: 0.000006  min_lr: 0.000006  loss: 2.6388 (2.5529)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2648 (1.2529)  time: 0.8192  data: 0.0004  max mem: 62835
Epoch: [293]  [1250/1251]  eta: 0:00:00  lr: 0.000006  min_lr: 0.000006  loss: 2.4897 (2.5519)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4565 (1.2583)  time: 0.6956  data: 0.0006  max mem: 62835
Epoch: [293] Total time: 0:17:07 (0.8214 s / it)
Averaged stats: lr: 0.000006  min_lr: 0.000006  loss: 2.4897 (2.5577)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4565 (1.2583)
Test:  [ 0/25]  eta: 0:03:10  loss: 0.5511 (0.5511)  acc1: 90.0000 (90.0000)  acc5: 99.6000 (99.6000)  time: 7.6327  data: 7.1601  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6617 (0.6606)  acc1: 88.0000 (88.0000)  acc5: 98.0000 (98.0727)  time: 1.0992  data: 0.6512  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.7816 (0.7746)  acc1: 84.0000 (84.9714)  acc5: 97.2000 (97.0286)  time: 0.4457  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8491 (0.7900)  acc1: 84.0000 (84.5280)  acc5: 96.4000 (96.8960)  time: 0.4456  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7415 s / it)
* Acc@1 84.742 Acc@5 97.006 loss 0.782
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Epoch: [294]  [   0/1251]  eta: 1:40:57  lr: 0.000006  min_lr: 0.000006  loss: 2.3047 (2.3047)  weight_decay: 0.0500 (0.0500)  time: 4.8418  data: 3.8501  max mem: 62835
Epoch: [294]  [ 200/1251]  eta: 0:14:40  lr: 0.000005  min_lr: 0.000005  loss: 2.6551 (2.6054)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0988 (1.2657)  time: 0.8180  data: 0.0003  max mem: 62835
Epoch: [294]  [ 400/1251]  eta: 0:11:45  lr: 0.000005  min_lr: 0.000005  loss: 2.7460 (2.5804)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1565 (1.2661)  time: 0.8184  data: 0.0004  max mem: 62835
Epoch: [294]  [ 600/1251]  eta: 0:08:57  lr: 0.000005  min_lr: 0.000005  loss: 2.5325 (2.5842)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1184 (1.2780)  time: 0.8179  data: 0.0004  max mem: 62835
Epoch: [294]  [ 800/1251]  eta: 0:06:11  lr: 0.000005  min_lr: 0.000005  loss: 2.4625 (2.5766)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2192 (1.2580)  time: 0.8171  data: 0.0004  max mem: 62835
Epoch: [294]  [1000/1251]  eta: 0:03:26  lr: 0.000004  min_lr: 0.000004  loss: 2.7744 (2.5839)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2447 (1.2639)  time: 0.8176  data: 0.0003  max mem: 62835
Epoch: [294]  [1200/1251]  eta: 0:00:41  lr: 0.000004  min_lr: 0.000004  loss: 2.6253 (2.5785)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2822 (1.2685)  time: 0.8180  data: 0.0003  max mem: 62835
Epoch: [294]  [1250/1251]  eta: 0:00:00  lr: 0.000004  min_lr: 0.000004  loss: 2.6657 (2.5767)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1971 (1.2700)  time: 0.6952  data: 0.0007  max mem: 62835
Epoch: [294] Total time: 0:17:06 (0.8206 s / it)
Averaged stats: lr: 0.000004  min_lr: 0.000004  loss: 2.6657 (2.5604)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1971 (1.2700)
Test:  [ 0/25]  eta: 0:03:13  loss: 0.6210 (0.6210)  acc1: 90.0000 (90.0000)  acc5: 99.6000 (99.6000)  time: 7.7304  data: 7.2238  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.7319 (0.7279)  acc1: 88.0000 (88.0364)  acc5: 98.0000 (98.0727)  time: 1.1082  data: 0.6571  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8620 (0.8431)  acc1: 83.6000 (84.9905)  acc5: 96.8000 (97.0095)  time: 0.4458  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9231 (0.8576)  acc1: 83.2000 (84.6080)  acc5: 96.4000 (96.9120)  time: 0.4458  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7460 s / it)
* Acc@1 84.754 Acc@5 97.008 loss 0.849
Accuracy of the model on the 50000 test images: 84.8%
Max accuracy: 84.76%
Epoch: [295]  [   0/1251]  eta: 1:36:24  lr: 0.000004  min_lr: 0.000004  loss: 2.6908 (2.6908)  weight_decay: 0.0500 (0.0500)  time: 4.6239  data: 2.3926  max mem: 62835
Epoch: [295]  [ 200/1251]  eta: 0:14:41  lr: 0.000004  min_lr: 0.000004  loss: 2.5728 (2.5228)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1433 (1.2588)  time: 0.8186  data: 0.0006  max mem: 62835
Epoch: [295]  [ 400/1251]  eta: 0:11:45  lr: 0.000004  min_lr: 0.000004  loss: 2.5615 (2.5339)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1445 (1.2127)  time: 0.8183  data: 0.0005  max mem: 62835
Epoch: [295]  [ 600/1251]  eta: 0:08:57  lr: 0.000004  min_lr: 0.000004  loss: 2.6729 (2.5391)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1596 (1.2324)  time: 0.8180  data: 0.0004  max mem: 62835
Epoch: [295]  [ 800/1251]  eta: 0:06:11  lr: 0.000003  min_lr: 0.000003  loss: 2.5576 (2.5455)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2418 (1.2335)  time: 0.8189  data: 0.0004  max mem: 62835
Epoch: [295]  [1000/1251]  eta: 0:03:26  lr: 0.000003  min_lr: 0.000003  loss: 2.6873 (2.5461)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3360 (1.2473)  time: 0.8189  data: 0.0004  max mem: 62835
Epoch: [295]  [1200/1251]  eta: 0:00:41  lr: 0.000003  min_lr: 0.000003  loss: 2.5839 (2.5461)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3596 (1.2523)  time: 0.8244  data: 0.0005  max mem: 62835
Epoch: [295]  [1250/1251]  eta: 0:00:00  lr: 0.000003  min_lr: 0.000003  loss: 2.6654 (2.5477)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1487 (1.2558)  time: 0.6990  data: 0.0007  max mem: 62835
Epoch: [295] Total time: 0:17:07 (0.8210 s / it)
Averaged stats: lr: 0.000003  min_lr: 0.000003  loss: 2.6654 (2.5565)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1487 (1.2558)
Test:  [ 0/25]  eta: 0:03:00  loss: 0.6163 (0.6163)  acc1: 90.0000 (90.0000)  acc5: 99.6000 (99.6000)  time: 7.2202  data: 6.7354  max mem: 62835
Test:  [10/25]  eta: 0:00:15  loss: 0.7229 (0.7248)  acc1: 88.4000 (87.8909)  acc5: 98.0000 (98.0727)  time: 1.0627  data: 0.6127  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8538 (0.8407)  acc1: 84.4000 (85.0095)  acc5: 96.8000 (96.9905)  time: 0.4463  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9238 (0.8559)  acc1: 83.6000 (84.5920)  acc5: 96.4000 (96.9120)  time: 0.4457  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7259 s / it)
* Acc@1 84.742 Acc@5 97.018 loss 0.848
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Epoch: [296]  [   0/1251]  eta: 1:42:55  lr: 0.000003  min_lr: 0.000003  loss: 2.7384 (2.7384)  weight_decay: 0.0500 (0.0500)  time: 4.9367  data: 4.1084  max mem: 62835
Epoch: [296]  [ 200/1251]  eta: 0:14:42  lr: 0.000003  min_lr: 0.000003  loss: 2.7158 (2.5378)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2105 (1.2660)  time: 0.8179  data: 0.0004  max mem: 62835
Epoch: [296]  [ 400/1251]  eta: 0:11:45  lr: 0.000003  min_lr: 0.000003  loss: 2.7460 (2.5635)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1155 (1.2804)  time: 0.8180  data: 0.0004  max mem: 62835
Epoch: [296]  [ 600/1251]  eta: 0:08:57  lr: 0.000003  min_lr: 0.000003  loss: 2.7005 (2.5495)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3142 (1.2852)  time: 0.8180  data: 0.0004  max mem: 62835
Epoch: [296]  [ 800/1251]  eta: 0:06:11  lr: 0.000002  min_lr: 0.000002  loss: 2.7073 (2.5519)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0629 (1.2728)  time: 0.8187  data: 0.0004  max mem: 62835
Epoch: [296]  [1000/1251]  eta: 0:03:26  lr: 0.000002  min_lr: 0.000002  loss: 2.6366 (2.5556)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2116 (1.2762)  time: 0.8186  data: 0.0004  max mem: 62835
Epoch: [296]  [1200/1251]  eta: 0:00:41  lr: 0.000002  min_lr: 0.000002  loss: 2.8396 (2.5580)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0386 (1.2681)  time: 0.8192  data: 0.0004  max mem: 62835
Epoch: [296]  [1250/1251]  eta: 0:00:00  lr: 0.000002  min_lr: 0.000002  loss: 2.6530 (2.5573)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0480 (1.2619)  time: 0.6984  data: 0.0006  max mem: 62835
Epoch: [296] Total time: 0:17:07 (0.8213 s / it)
Averaged stats: lr: 0.000002  min_lr: 0.000002  loss: 2.6530 (2.5568)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0480 (1.2619)
Test:  [ 0/25]  eta: 0:03:08  loss: 0.5882 (0.5882)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 7.5496  data: 7.0823  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6935 (0.6966)  acc1: 88.0000 (87.8182)  acc5: 98.0000 (98.0364)  time: 1.0918  data: 0.6441  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8303 (0.8136)  acc1: 84.0000 (84.9143)  acc5: 96.8000 (96.9905)  time: 0.4459  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8990 (0.8296)  acc1: 83.6000 (84.5600)  acc5: 96.4000 (96.8640)  time: 0.4458  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7383 s / it)
* Acc@1 84.742 Acc@5 96.964 loss 0.821
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Epoch: [297]  [   0/1251]  eta: 1:43:07  lr: 0.000002  min_lr: 0.000002  loss: 2.5340 (2.5340)  weight_decay: 0.0500 (0.0500)  time: 4.9458  data: 2.0650  max mem: 62835
Epoch: [297]  [ 200/1251]  eta: 0:14:41  lr: 0.000002  min_lr: 0.000002  loss: 2.7530 (2.5474)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1263 (1.2772)  time: 0.8186  data: 0.0004  max mem: 62835
Epoch: [297]  [ 400/1251]  eta: 0:11:45  lr: 0.000002  min_lr: 0.000002  loss: 2.5612 (2.5649)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1520 (1.2959)  time: 0.8188  data: 0.0004  max mem: 62835
Epoch: [297]  [ 600/1251]  eta: 0:08:57  lr: 0.000002  min_lr: 0.000002  loss: 2.5879 (2.5669)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1535 (1.2705)  time: 0.8186  data: 0.0004  max mem: 62835
Epoch: [297]  [ 800/1251]  eta: 0:06:11  lr: 0.000002  min_lr: 0.000002  loss: 2.6243 (2.5641)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0153 (1.2268)  time: 0.8187  data: 0.0005  max mem: 62835
Epoch: [297]  [1000/1251]  eta: 0:03:26  lr: 0.000002  min_lr: 0.000002  loss: 2.7004 (2.5523)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2063 (1.2386)  time: 0.8184  data: 0.0005  max mem: 62835
Epoch: [297]  [1200/1251]  eta: 0:00:41  lr: 0.000002  min_lr: 0.000002  loss: 2.4642 (2.5488)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1444 (1.2381)  time: 0.8172  data: 0.0004  max mem: 62835
Epoch: [297]  [1250/1251]  eta: 0:00:00  lr: 0.000002  min_lr: 0.000002  loss: 2.4613 (2.5465)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1733 (1.2373)  time: 0.6943  data: 0.0007  max mem: 62835
Epoch: [297] Total time: 0:17:06 (0.8207 s / it)
Averaged stats: lr: 0.000002  min_lr: 0.000002  loss: 2.4613 (2.5478)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1733 (1.2373)
Test:  [ 0/25]  eta: 0:03:12  loss: 0.5843 (0.5843)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 7.7165  data: 7.2296  max mem: 62835
Test:  [10/25]  eta: 0:00:16  loss: 0.6920 (0.6888)  acc1: 88.0000 (87.9636)  acc5: 97.6000 (98.0364)  time: 1.1046  data: 0.6575  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8158 (0.8024)  acc1: 83.6000 (84.9905)  acc5: 96.8000 (97.0286)  time: 0.4433  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.8766 (0.8173)  acc1: 83.6000 (84.5920)  acc5: 96.4000 (96.9280)  time: 0.4432  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7404 s / it)
* Acc@1 84.730 Acc@5 97.008 loss 0.809
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Epoch: [298]  [   0/1251]  eta: 1:41:02  lr: 0.000002  min_lr: 0.000002  loss: 2.0947 (2.0947)  weight_decay: 0.0500 (0.0500)  time: 4.8461  data: 2.6054  max mem: 62835
Epoch: [298]  [ 200/1251]  eta: 0:14:40  lr: 0.000001  min_lr: 0.000001  loss: 2.6833 (2.5557)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2087 (1.2181)  time: 0.8182  data: 0.0004  max mem: 62835
Epoch: [298]  [ 400/1251]  eta: 0:11:45  lr: 0.000001  min_lr: 0.000001  loss: 2.6956 (2.5643)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1893 (1.2311)  time: 0.8181  data: 0.0004  max mem: 62835
Epoch: [298]  [ 600/1251]  eta: 0:08:57  lr: 0.000001  min_lr: 0.000001  loss: 2.4626 (2.5606)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2801 (1.2325)  time: 0.8184  data: 0.0004  max mem: 62835
Epoch: [298]  [ 800/1251]  eta: 0:06:11  lr: 0.000001  min_lr: 0.000001  loss: 2.5427 (2.5545)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1005 (1.2316)  time: 0.8256  data: 0.0004  max mem: 62835
Epoch: [298]  [1000/1251]  eta: 0:03:26  lr: 0.000001  min_lr: 0.000001  loss: 2.7747 (2.5586)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4455 (1.2631)  time: 0.8178  data: 0.0004  max mem: 62835
Epoch: [298]  [1200/1251]  eta: 0:00:41  lr: 0.000001  min_lr: 0.000001  loss: 2.7761 (2.5579)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2111 (1.2694)  time: 0.8168  data: 0.0004  max mem: 62835
Epoch: [298]  [1250/1251]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 2.8584 (2.5604)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0638 (1.2639)  time: 0.6933  data: 0.0006  max mem: 62835
Epoch: [298] Total time: 0:17:05 (0.8201 s / it)
Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 2.8584 (2.5566)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0638 (1.2639)
Test:  [ 0/25]  eta: 0:02:01  loss: 0.6671 (0.6671)  acc1: 89.6000 (89.6000)  acc5: 99.6000 (99.6000)  time: 4.8509  data: 4.3532  max mem: 62835
Test:  [10/25]  eta: 0:00:15  loss: 0.7749 (0.7747)  acc1: 88.0000 (87.6727)  acc5: 98.0000 (98.0727)  time: 1.0403  data: 0.5871  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.9111 (0.8909)  acc1: 84.4000 (84.9524)  acc5: 96.8000 (96.9333)  time: 0.5524  data: 0.1053  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9684 (0.9067)  acc1: 84.0000 (84.4960)  acc5: 96.0000 (96.7840)  time: 0.4457  data: 0.0002  max mem: 62835
Test: Total time: 0:00:17 (0.7118 s / it)
* Acc@1 84.626 Acc@5 96.916 loss 0.897
Accuracy of the model on the 50000 test images: 84.6%
Max accuracy: 84.76%
Epoch: [299]  [   0/1251]  eta: 1:48:06  lr: 0.000001  min_lr: 0.000001  loss: 2.6818 (2.6818)  weight_decay: 0.0500 (0.0500)  time: 5.1852  data: 3.8866  max mem: 62835
Epoch: [299]  [ 200/1251]  eta: 0:14:43  lr: 0.000001  min_lr: 0.000001  loss: 2.7195 (2.5427)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0970 (1.1617)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [299]  [ 400/1251]  eta: 0:11:45  lr: 0.000001  min_lr: 0.000001  loss: 2.7412 (2.5572)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1971 (1.2118)  time: 0.8167  data: 0.0004  max mem: 62835
Epoch: [299]  [ 600/1251]  eta: 0:08:56  lr: 0.000001  min_lr: 0.000001  loss: 2.6872 (2.5568)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0386 (1.2247)  time: 0.8169  data: 0.0004  max mem: 62835
Epoch: [299]  [ 800/1251]  eta: 0:06:11  lr: 0.000001  min_lr: 0.000001  loss: 2.6848 (2.5702)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0930 (1.2311)  time: 0.8170  data: 0.0003  max mem: 62835
Epoch: [299]  [1000/1251]  eta: 0:03:26  lr: 0.000001  min_lr: 0.000001  loss: 2.5665 (2.5708)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2151 (1.2301)  time: 0.8153  data: 0.0004  max mem: 62835
Epoch: [299]  [1200/1251]  eta: 0:00:41  lr: 0.000001  min_lr: 0.000001  loss: 2.6243 (2.5637)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1715 (1.2208)  time: 0.8159  data: 0.0004  max mem: 62835
Epoch: [299]  [1250/1251]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 2.6955 (2.5624)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1752 (1.2170)  time: 0.6932  data: 0.0006  max mem: 62835
Epoch: [299] Total time: 0:17:05 (0.8194 s / it)
Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 2.6955 (2.5506)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1752 (1.2170)
Test:  [ 0/25]  eta: 0:03:01  loss: 0.6305 (0.6305)  acc1: 90.0000 (90.0000)  acc5: 99.6000 (99.6000)  time: 7.2451  data: 6.7444  max mem: 62835
Test:  [10/25]  eta: 0:00:15  loss: 0.7380 (0.7391)  acc1: 88.4000 (88.1091)  acc5: 98.0000 (98.0364)  time: 1.0630  data: 0.6134  max mem: 62835
Test:  [20/25]  eta: 0:00:03  loss: 0.8775 (0.8561)  acc1: 83.6000 (85.0286)  acc5: 96.8000 (97.0286)  time: 0.4448  data: 0.0002  max mem: 62835
Test:  [24/25]  eta: 0:00:00  loss: 0.9372 (0.8718)  acc1: 83.2000 (84.5920)  acc5: 96.4000 (96.9280)  time: 0.4447  data: 0.0001  max mem: 62835
Test: Total time: 0:00:18 (0.7262 s / it)
* Acc@1 84.686 Acc@5 96.974 loss 0.864
Accuracy of the model on the 50000 test images: 84.7%
Max accuracy: 84.76%
Training time 15:59:07
